{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecfc21d8-e7b1-481c-a605-001c66d32c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.fixes import loguniform    \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ce956b-f00d-40e6-a8d9-d21f4325d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503dcdf1-d4dd-40f0-bf20-f9beda083b5e",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e74fa63-8bfb-4509-831b-2ea1ac7ffffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chen_data = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_data.csv\"), index_col=0)\n",
    "tap_data = pd.read_csv(path.join(DATA_DIR, \"tap/TAP_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e90515b-49e9-490d-a82c-94f19c815091",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = pd.read_csv(path.join(DATA_DIR, \"chen/clustering.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b2fe2f7-5b67-454f-9149-e633fb8fd8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_assignment = {}\n",
    "for i, cl in enumerate(clusters[\"0\"]):\n",
    "    cluster_assignment[cl] = cluster_assignment.get(cl, []) + [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ed880eb-1976-41f9-9b4a-1fea4fe1a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [2, 13, 19, 27, 38, 42, 56, 63, 6, 78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a23bafa3-eed4-45db-888b-8f7231808200",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    train_indices, test_indices = train_test_split(range(int(clusters.max())), test_size=0.2, random_state=seed)\n",
    "    train_set = []\n",
    "    for idx in train_indices:\n",
    "        train_set += cluster_assignment[idx + 1]\n",
    "    chen_train = chen_data.iloc[train_set]\n",
    "    chen_train.to_csv(path.join(DATA_DIR, f\"chen/deduplicated/crossval/chen_train_{seed}.csv\"))\n",
    "    \n",
    "    test_set = []\n",
    "    for idx in test_indices:\n",
    "        test_set += cluster_assignment[idx + 1]\n",
    "    chen_test = chen_data.iloc[test_set]\n",
    "    chen_test.to_csv(path.join(DATA_DIR, f\"chen/deduplicated/crossval/chen_test_{seed}.csv\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c3a2f-e451-4323-b7c6-67e607553d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cd0b795-5533-4113-a6da-49c3fbd83ea2",
   "metadata": {},
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35897a38-59f7-4b17-8f17-d459aa2e4035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_clusters(train_df, cluster_df):\n",
    "    df = train_df.merge(cluster_df, left_index=True, right_index=True).rename({\"0\": \"cluster\"}, axis=1)\n",
    "    df[\"cluster_merged\"] = df[\"cluster\"]\n",
    "    df[\"cluster_merged\"][df[\"cluster\"] < 300] = df[\"cluster\"][df[\"cluster\"] < 300] // 30\n",
    "    df[\"cluster_merged\"][df[\"cluster\"] >= 300] = df[\"cluster\"][df[\"cluster\"] >= 300] // 100\n",
    "    print(f'Unique clusters after merge: {df[\"cluster_merged\"].nunique()}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c495e032-8e73-4a72-934c-1af401442ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(n):\n",
    "    model = KNeighborsClassifier()  # default metric is Euclidean\n",
    "    parameters = {'n_neighbors': [1,3,5]}\n",
    "    return model, parameters, \"kNN\"\n",
    "\n",
    "def logistic_regression(n):\n",
    "    lr = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "    parameters = {'C':loguniform(0.001, 1000), 'penalty': [\"l2\"], \"solver\": [\"lbfgs\", \"sag\"]}\n",
    "    return lr, parameters, \"logistic_regression\"\n",
    "\n",
    "def random_forest(n):\n",
    "    rf = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "    parameters = {'n_estimators': np.arange(1, 200, 10), 'max_depth': np.arange(1, min(50,n), 2), \n",
    "                  'max_features': np.arange(0.1, 0.75, 0.05)}\n",
    "    return rf, parameters, \"random_forest\"\n",
    "\n",
    "def multilayer_perceptron(n):\n",
    "    mlp = MLPClassifier(random_state=42, max_iter=int(1000))\n",
    "    parameters = {'hidden_layer_sizes': [(100,), (50,), (50, 50), (100, 100)], \"activation\": [\"relu\", \"logistic\"]}\n",
    "    return mlp, parameters, \"multilayer_perceptron\"\n",
    "\n",
    "def svm(n):\n",
    "    svc = SVC(max_iter=8000, probability=True, class_weight='balanced')\n",
    "    parameters = {'C': loguniform(0.001, 100), 'kernel':[\"linear\", \"rbf\"], 'gamma': loguniform(1e-3, 1e0)}\n",
    "    return svc, parameters, \"SVM\"\n",
    "\n",
    "def gradient_boosting(n):\n",
    "    gb = GradientBoostingClassifier(random_state=42, n_iter_no_change=70)\n",
    "    parameters = {'learning_rate': loguniform(0.01, 0.5), \n",
    "                  'n_estimators': np.arange(1, 200, 10), \n",
    "                  'max_depth': np.arange(1, min(20,n), 2), \n",
    "                  'max_features': np.arange(0.1, 0.6, 0.1)}\n",
    "    return gb, parameters, \"gradient_boosting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fe8f1aa-8566-4422-9c0b-5524e2bc51d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_evaluation(model_type, params, best_params, metrics, data, outpath, preprocessing):\n",
    "    prepro = \"_\"+preprocessing if preprocessing is not None else \"\"\n",
    "    filename = os.path.join(DATA_DIR, \"evaluations\", outpath, f\"{model_type}_{data}{prepro}.json\")\n",
    "    out_dict = {\n",
    "        \"model_type\": model_type,\n",
    "        \"data\": data\n",
    "    }\n",
    "    out_dict[\"params\"] = {}\n",
    "    out_dict[\"best_params\"] = {}\n",
    "    for key, value in params.items():\n",
    "        out_dict[\"params\"][key] = str(value)\n",
    "    for key, value in best_params.items():\n",
    "        out_dict[\"best_params\"][key] = str(value)\n",
    "    out_dict[\"metrics\"] = metrics\n",
    "    out_dict[\"preprocessing\"] = \"none\" if preprocessing is None else preprocessing\n",
    "    \n",
    "    json.dump(out_dict, open(filename, \"w\"))\n",
    "    \n",
    "    filename_sum = os.path.join(DATA_DIR, f\"evaluations/{outpath}/all.csv\")\n",
    "    line = [model_type, data, out_dict[\"preprocessing\"], metrics[\"f1\"], metrics[\"mcc\"], metrics[\"acc\"],metrics[\"precision\"],metrics[\"recall\"],metrics[\"auc\"], filename]\n",
    "    with open(filename_sum, 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter='\\t')\n",
    "        csvwriter.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30261672-998d-49ee-ae5e-00533fd5176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(model_name, classifier, parameters, X_train, y_train, X_valid, y_valid, groups,\n",
    "                   data_name, outpath, preprocessing):\n",
    "    splitter = LeaveOneGroupOut()\n",
    "    split = splitter.split(X_train, y_train, groups=groups)\n",
    "    grid = RandomizedSearchCV(classifier, parameters, verbose=0, scoring=\"f1\", cv=split)\n",
    "    grid.fit(X_train, y_train)\n",
    "    estimator = grid.best_estimator_\n",
    "    best_params = grid.best_params_\n",
    "    y_pred = estimator.predict(X_valid)\n",
    "    filename = path.join(DATA_DIR, \"evaluations\", outpath, \"models\", f\"{model_name}_{data_name}_{preprocessing}.pkl\")\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(estimator, f)\n",
    "    metric_dict = {\n",
    "        \"f1\": float(metrics.f1_score(y_valid, y_pred)),\n",
    "        \"acc\": float(metrics.accuracy_score(y_valid, y_pred)),\n",
    "        \"mcc\": float(metrics.matthews_corrcoef(y_valid, y_pred)),\n",
    "        \"auc\": float(metrics.roc_auc_score(y_valid, y_pred)),\n",
    "        \"precision\": float(metrics.precision_score(y_valid, y_pred)),\n",
    "        \"recall\": float(metrics.recall_score(y_valid, y_pred))\n",
    "    }\n",
    "    \n",
    "    print(f\"{model_name}, {data_name}, {preprocessing}\")\n",
    "    print(f\"F1: {metric_dict['f1']}\")\n",
    "    print(f\"MCC: {metric_dict['mcc']}\")\n",
    "    print(f\"Accuracy: {metric_dict['acc']}\")\n",
    "    print(f\"Precision: {metric_dict['precision']}\")\n",
    "    print(f\"Recall: {metric_dict['recall']}\")\n",
    "    print(f\"AUC: {metric_dict['auc']}\")\n",
    "    print(f\"-----\")\n",
    "    \n",
    "    output_evaluation(model_name, parameters, best_params, metric_dict, data_name, outpath, preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "903eadf8-6779-4214-a7f9-c879f52f2b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all(X_train, y_train, X_valid, y_valid, groups, data_name, outpath, preprocessing, models):\n",
    "    n = len(y_train)\n",
    "    for model_creator in models:\n",
    "    #for model_creator in [logistic_regression, random_forest]:\n",
    "\n",
    "        classifier, params, model_label = model_creator(n)\n",
    "        print(\"\\n\")\n",
    "        print(f'Training model {model_label} on data {data_name} with preprocessing {preprocessing} \\n')\n",
    "        train_and_eval(model_label, classifier, params, X_train, y_train, X_valid, y_valid, groups,\n",
    "                   data_name, outpath, preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59232f39-b5be-4c8c-9cb2-d68d029abc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_tap(model_name, x_test, y_test,\n",
    "                   data_name, outpath, preprocessing=None):\n",
    "    prepro = \"_\"+preprocessing if preprocessing is not None else \"\"\n",
    "    filename = path.join(DATA_DIR, \"evaluations\", outpath, \"models\", f\"{model_name}_{data_name}{prepro}.pkl\")\n",
    "    with open(filename, 'rb') as f:\n",
    "        estimator = pickle.load(f)\n",
    "    y_pred = estimator.predict(x_test)\n",
    "    metric_dict = {\n",
    "        \"f1\": float(metrics.f1_score(y_test, y_pred)),\n",
    "        \"acc\": float(metrics.accuracy_score(y_test, y_pred)),\n",
    "        \"mcc\": float(metrics.matthews_corrcoef(y_test, y_pred)),\n",
    "        \"auc\": float(metrics.roc_auc_score(y_test, y_pred)),\n",
    "        \"precision\": float(metrics.precision_score(y_test, y_pred)),\n",
    "        \"recall\": float(metrics.recall_score(y_test, y_pred))\n",
    "    }\n",
    "    filename_sum = os.path.join(DATA_DIR, f\"evaluations/{outpath}/tap.csv\")\n",
    "    line = [model_name, data_name, prepro, metric_dict[\"f1\"], metric_dict[\"mcc\"], metric_dict[\"acc\"],metric_dict[\"precision\"],metric_dict[\"recall\"],metric_dict[\"auc\"], filename]\n",
    "    with open(filename_sum, 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter='\\t')\n",
    "        csvwriter.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "433dcbda-4b86-4de8-99a9-11d90e80bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all(x_test, y_test, data_name, outpath, preprocessing):\n",
    "    for model in [\"logistic_regression\", \"random_forest\", \"gradient_boosting\", \"SVM\", \"multilayer_perceptron\"]:\n",
    "        print(f\"Testing model {model} on {data_name} with preprocessing {preprocessing}...\")\n",
    "        test_on_tap(model, x_test, y_test, data_name, outpath, preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdfcbd3-c40d-444c-a476-cb1b49a1c804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdacb7e5-1db6-45aa-b34a-e7044ae14912",
   "metadata": {},
   "source": [
    "## Loading data representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cb8ef4b-6e41-4141-a109-14fbb29080ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_encoded(train_df, test_df):\n",
    "    x_chen = pd.read_csv(path.join(DATA_DIR, \"chen/integer_encoding/chen_integer_encoded.csv\"), index_col=0)\n",
    "    x_chen_train = x_chen.merge(train_df[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "    x_chen_test = x_chen.merge(test_df[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "    x_tap = pd.read_csv(path.join(DATA_DIR, \"tap/integer_encoding/tap_integer_encoded.csv\"))\n",
    "    x_tap.drop(\"Ab_ID\", axis=1, inplace=True)\n",
    "    return x_chen_train, x_chen_test, x_tap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57663b4a-e419-4dc9-8086-6d11adb2435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pybiomed(train_df, test_df):\n",
    "    x_chen = pd.read_feather(path.join(DATA_DIR, \"chen/pybiomed/X_data.ftr\"))\n",
    "    x_chen_train = x_chen.merge(train_df[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "    x_chen_test = x_chen.merge(test_df[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "    x_tap = pd.read_feather(path.join(DATA_DIR, \"tap/pybiomed/X_TAP_data.ftr\"))\n",
    "    return x_chen_train, x_chen_test, x_tap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8aa389f-2b92-454a-a990-4b19db579fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def protparam(train_df, test_df):\n",
    "    x_chen = pd.read_csv(path.join(DATA_DIR, \"chen/protparam/protparam_features.csv\"))\n",
    "    x_chen.rename({\"Unnamed: 0\": \"Ab_ID\"}, axis=1, inplace=True)\n",
    "    x_chen = x_chen.drop(\"name\", axis=1)\n",
    "    x_chen_train = x_chen.merge(train_df[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "    x_chen_test = x_chen.merge(test_df[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "    \n",
    "    x_tap = pd.read_csv(path.join(DATA_DIR, \"tap/protparam/protparam_features_tap.csv\"))\n",
    "    x_tap = x_tap.drop(\"Unnamed: 0\", axis=1)\n",
    "    return x_chen_train, x_chen_test, x_tap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65e7bc96-a11f-407c-aae9-5ba92e0ef1ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bert(train_df, test_df):\n",
    "    x_chen = pd.read_feather(path.join(DATA_DIR, \"chen/embeddings/bert/bert_chen_embeddings.ftr\"))\n",
    "    x_chen_train = x_chen.merge(train_df[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "    x_chen_test = x_chen.merge(test_df[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "    x_tap = pd.read_feather(path.join(DATA_DIR, \"tap/embeddings/bert/bert_tap_embeddings.ftr\"))\n",
    "    x_tap = x_tap.drop(\"Ab_ID\", axis=1)\n",
    "    return x_chen_train, x_chen_test, x_tap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdb5a65b-0a25-4c71-950a-699e8b5efc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqvec(train_df, test_df):\n",
    "    x_chen = pd.read_feather(path.join(DATA_DIR, \"chen/embeddings/seqvec/seqvec_chen_embeddings.ftr\"))\n",
    "    x_chen_train = x_chen.merge(train_df[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "    x_chen_test = x_chen.merge(test_df[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "    x_tap = pd.read_feather(path.join(DATA_DIR, \"tap/embeddings/seqvec/seqvec_tap_embeddings.ftr\"))\n",
    "    x_tap = x_tap.drop(\"Ab_ID\", axis=1)\n",
    "    return x_chen_train, x_chen_test, x_tap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8662c081-c5ec-4d5e-ad1f-af8c46ae8553",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sapiens(train_df, test_df):\n",
    "    x_chen = pd.read_csv(path.join(DATA_DIR, \"chen/embeddings/sapiens/sapiens_chen_embeddings.csv\"), index_col=0).drop(\"Y\", axis=1)\n",
    "    x_chen_train = x_chen.merge(train_df[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "    x_chen_test = x_chen.merge(test_df[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "    x_tap = pd.read_csv(path.join(DATA_DIR, \"tap/embeddings/sapiens/sapiens_tap_embeddings.csv\"), index_col=0)\n",
    "    x_tap = x_tap.drop([\"Ab_ID\", \"Y\"], axis=1)\n",
    "    return x_chen_train, x_chen_test, x_tap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f0afe3-89c2-45aa-9c8e-708eed78309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(train_df, test_df):\n",
    "    x_chen = pd.read_feather(path.join(DATA_DIR, \"chen/onehot/chen_onehot.ftr\"))\n",
    "    x_chen_train = x_chen.merge(train_df[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "    x_chen_test = x_chen.merge(test_df[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "    x_tap = pd.read_feather(path.join(DATA_DIR, \"tap/onehot/tap_onehot.ftr\"))\n",
    "    x_tap = x_tap.drop([\"Ab_ID\"], axis=1)\n",
    "    return x_chen_train, x_chen_test, x_tap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b469bb-d838-47b8-b2d7-9e06c418c95a",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7032b3e6-7339-443a-906e-33eaee092af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_prepro(train_df, test_df, tap_df):\n",
    "    return train_df.drop(\"Y\", axis=1), train_df[\"Y\"], test_df, tap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6fcb18b-1da9-448c-8540-0f463f81b2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(train_df, test_df, tap_df):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_df.drop([\"Ab_ID\", \"Y\", \"cluster_merged\"], axis=1))\n",
    "    x_train_tr = scaler.transform(train_df.drop([\"Ab_ID\", \"Y\", \"cluster_merged\"], axis=1))\n",
    "    x_train_df = pd.DataFrame(data=train_df,  index=train_df.index, columns=train_df.drop([\"Ab_ID\", \"Y\", \"cluster_merged\"], axis=1).columns)\n",
    "    x_train_df[\"cluster_merged\"] = train_df[\"cluster_merged\"]\n",
    "    x_train_df[\"Ab_ID\"] = train_df[\"Ab_ID\"]\n",
    "    \n",
    "    x_test_tr = scaler.transform(test_df.drop([\"Ab_ID\", \"Y\"], axis=1))\n",
    "    x_test_df = pd.DataFrame(data=test_df,  index=test_df.index, columns=test_df.drop([\"Ab_ID\", \"Y\"], axis=1).columns)\n",
    "    x_test_df[\"Y\"] = test_df[\"Y\"]\n",
    "    x_test_df[\"Ab_ID\"] = test_df[\"Ab_ID\"]\n",
    "    \n",
    "    x_tap_tr = scaler.transform(tap_df)\n",
    "    x_tap_df = pd.DataFrame(data=tap_df,  index=tap_df.index, columns=tap_df.columns)\n",
    "\n",
    "    return x_train_df, train_df[\"Y\"], x_test_df, x_tap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf7564a5-b547-480f-af76-4d70df0f809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(train_df, test_df, tap_df):\n",
    "    sampler = RandomOverSampler(random_state=42)\n",
    "    x_train, y_train = sampler.fit_resample(train_df.drop(\"Y\", axis=1), train_df[\"Y\"])\n",
    "    return x_train, y_train, test_df, tap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5b727e8-a5a6-4e63-9101-0e197a00af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_os(train_df, test_df, tap_df):\n",
    "    sampler = SMOTE(random_state=42)\n",
    "    x_train_tr, y_train = sampler.fit_resample(train_df.drop([\"Ab_ID\", \"Y\"], axis=1), train_df[\"Y\"])\n",
    "    x_train_tr[\"Ab_ID\"] = \"\"\n",
    "    return x_train_tr, y_train, test_df, tap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b6761da-3143-4367-a1af-29a106737595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersampling(train_df, test_df, tap_df):\n",
    "    sampler = RandomUnderSampler(random_state=42)\n",
    "    x_train, y_train = sampler.fit_resample(train_df.drop(\"Y\", axis=1), train_df[\"Y\"]) \n",
    "    return x_train, y_train, test_df, tap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fb87fa-62cf-4e60-bd04-f4d455b01b60",
   "metadata": {},
   "source": [
    "## All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d5d4230-73b8-4137-bd2c-c9f6c4f4d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaders = [integer_encoded, pybiomed, protparam, bert, seqvec, sapiens, onehot]\n",
    "model_creators = [knn, logistic_regression, random_forest, multilayer_perceptron, svm, gradient_boosting]\n",
    "preprocessing = [no_prepro, scaling, oversampling, smote_os, undersampling]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f6addff-9402-4caf-b839-ff6f0b806217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval_round(train_df, test_df, eval_dir):\n",
    "    for prepro in preprocessing:\n",
    "        prepro_name = prepro.__name__\n",
    "        for data_rep in data_loaders:\n",
    "            data_name = data_rep.__name__\n",
    "            x_train, x_test, x_tap = data_rep(train_df, test_df)\n",
    "            x_train_tr, y_train_tr, x_test_tr, tap_tr = prepro(x_train, x_test, x_tap)\n",
    "            \n",
    "            try_all(x_train_tr.drop([\"Ab_ID\", \"cluster_merged\"], axis=1), y_train_tr, \n",
    "                x_test_tr.drop([\"Ab_ID\", \"Y\"], axis=1), x_test_tr[\"Y\"], \n",
    "                x_train_tr[\"cluster_merged\"], data_name, eval_dir, prepro_name, model_creators)\n",
    "            \n",
    "            test_all(tap_tr, tap_data[\"Y\"], data_name, eval_dir, prepro_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0842c3-2e61-41a7-8043-8cc816c5c9f2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique clusters after merge: 10\n",
      "\n",
      "\n",
      "Training model kNN on data integer_encoded with preprocessing no_prepro \n",
      "\n",
      "kNN, integer_encoded, no_prepro\n",
      "F1: 0.22222222222222224\n",
      "MCC: -0.007061249691130693\n",
      "Accuracy: 0.6455696202531646\n",
      "Precision: 0.21621621621621623\n",
      "Recall: 0.22857142857142856\n",
      "AUC: 0.4963995354239257\n",
      "-----\n",
      "\n",
      "\n",
      "Training model logistic_regression on data integer_encoded with preprocessing no_prepro \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression, integer_encoded, no_prepro\n",
      "F1: 0.391304347826087\n",
      "MCC: 0.17053871945589077\n",
      "Accuracy: 0.6455696202531646\n",
      "Precision: 0.3157894736842105\n",
      "Recall: 0.5142857142857142\n",
      "AUC: 0.5986062717770034\n",
      "-----\n",
      "\n",
      "\n",
      "Training model random_forest on data integer_encoded with preprocessing no_prepro \n",
      "\n",
      "random_forest, integer_encoded, no_prepro\n",
      "F1: 0.24203821656050956\n",
      "MCC: -0.0046430622913821665\n",
      "Accuracy: 0.6234177215189873\n",
      "Precision: 0.21839080459770116\n",
      "Recall: 0.2714285714285714\n",
      "AUC: 0.49750290360046456\n",
      "-----\n",
      "\n",
      "\n",
      "Training model multilayer_perceptron on data integer_encoded with preprocessing no_prepro \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron, integer_encoded, no_prepro\n",
      "F1: 0.2923076923076923\n",
      "MCC: 0.11092370107563784\n",
      "Accuracy: 0.7088607594936709\n",
      "Precision: 0.31666666666666665\n",
      "Recall: 0.2714285714285714\n",
      "AUC: 0.5523809523809524\n",
      "-----\n",
      "\n",
      "\n",
      "Training model SVM on data integer_encoded with preprocessing no_prepro \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, integer_encoded, no_prepro\n",
      "F1: 0.41530054644808745\n",
      "MCC: 0.20619025693587661\n",
      "Accuracy: 0.6613924050632911\n",
      "Precision: 0.336283185840708\n",
      "Recall: 0.5428571428571428\n",
      "AUC: 0.6189895470383273\n",
      "-----\n",
      "\n",
      "\n",
      "Training model gradient_boosting on data integer_encoded with preprocessing no_prepro \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_boosting, integer_encoded, no_prepro\n",
      "F1: 0.12500000000000003\n",
      "MCC: 0.006669777491504802\n",
      "Accuracy: 0.7341772151898734\n",
      "Precision: 0.23076923076923078\n",
      "Recall: 0.08571428571428572\n",
      "AUC: 0.5022067363530778\n",
      "-----\n",
      "Testing model logistic_regression on integer_encoded with preprocessing no_prepro...\n",
      "Testing model random_forest on integer_encoded with preprocessing no_prepro...\n",
      "Testing model gradient_boosting on integer_encoded with preprocessing no_prepro...\n",
      "Testing model SVM on integer_encoded with preprocessing no_prepro...\n",
      "Testing model multilayer_perceptron on integer_encoded with preprocessing no_prepro...\n",
      "\n",
      "\n",
      "Training model kNN on data pybiomed with preprocessing no_prepro \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN, pybiomed, no_prepro\n",
      "F1: 0.3165467625899281\n",
      "MCC: 0.12386704697272526\n",
      "Accuracy: 0.6993670886075949\n",
      "Precision: 0.3188405797101449\n",
      "Recall: 0.3142857142857143\n",
      "AUC: 0.5616144018583044\n",
      "-----\n",
      "\n",
      "\n",
      "Training model logistic_regression on data pybiomed with preprocessing no_prepro \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/tf-gpu/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "chen_filtered = pd.read_csv(path.join(DATA_DIR, f\"chen/deduplicated/filtered_chen_data.csv\"), index_col=0)\n",
    "for seed in seeds:\n",
    "    chen_train = pd.read_csv(path.join(DATA_DIR, f\"chen/deduplicated/crossval/chen_train_{seed}.csv\"), index_col=0)\n",
    "    chen_train = merge_clusters(chen_train, clusters)\n",
    "    chen_train = chen_train.merge(chen_filtered[[\"Antibody_ID\"]], on=\"Antibody_ID\")\n",
    "    \n",
    "    chen_test = pd.read_csv(path.join(DATA_DIR, f\"chen/deduplicated/crossval/chen_test_{seed}.csv\"), index_col=0)\n",
    "    eval_dir = f\"10-fold-cross-val/training_split_{seed}\"\n",
    "    try:\n",
    "        os.mkdir(os.path.join(DATA_DIR, f\"evaluations/{eval_dir}\"))\n",
    "        os.mkdir(os.path.join(DATA_DIR, f\"evaluations/{eval_dir}/models\"))\n",
    "    except:\n",
    "        pass\n",
    "    crossval_round(chen_train, chen_test, eval_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c963d937-e0f2-4b63-a9bd-241b689b23a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique clusters after merge: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "chen_train = pd.read_csv(path.join(DATA_DIR, f\"chen/deduplicated/crossval/chen_train_2.csv\"), index_col=0)\n",
    "chen_train = merge_clusters(chen_train, clusters)\n",
    "#chen_train = chen_train.merge(chen_filtered[[\"Antibody_ID\"]], on=\"Antibody_ID\")\n",
    "chen_test = pd.read_csv(path.join(DATA_DIR, f\"chen/deduplicated/crossval/chen_test_2.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b35adf3-4067-4a48-bd82-e4c4f43791aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
