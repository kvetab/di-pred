{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe7d231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CDR_Length', 'PSH', 'PPC', 'PNC', 'SFvCSP']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tdc.utils import retrieve_label_name_list\n",
    "label_list = retrieve_label_name_list('TAP')\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32382ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from tdc.single_pred import Develop\n",
    "data_tap = Develop(name = 'TAP', label_name = label_list[0])\n",
    "data_chen = Develop(name = 'SAbDab_Chen')\n",
    "#split = data.get_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d55b51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = data_chen.get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78fbcd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>Antibody</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12e8</td>\n",
       "      <td>['EVQLQQSGAEVVRSGASVKLSCTASGFNIKDYYIHWVKQRPEKG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15c8</td>\n",
       "      <td>['EVQLQQSGAELVKPGASVKLSCTASGFNIKDTYMHWVKQKPEQG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a0q</td>\n",
       "      <td>['EVQLQESDAELVKPGASVKISCKASGYTFTDHVIHWVKQKPEQG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a14</td>\n",
       "      <td>['QVQLQQSGAELVKPGASVRMSCKASGYTFTNYNMYWVKQSPGQG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a2y</td>\n",
       "      <td>['QVQLQESGPGLVAPSQSLSITCTVSGFSLTGYGVNWVRQPPGKG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>6rcs</td>\n",
       "      <td>['QVQLVQSGAEVKKPGASVRVSCKASGYTFTSYGISWVRQAPGQG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>6s5a</td>\n",
       "      <td>['EVKLLESGGGLVQPGGSLKLSCAASGFDFSRYWMNWVRQAPGKG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>6u1t</td>\n",
       "      <td>['EVQLVESGGGLVKPGGSLKLSCAASGFTFSSYDMSWVRQTPEKR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>7fab</td>\n",
       "      <td>['AVQLEQSGPGLVRPSQTLSLTCTVSGTSFDDYYWTWVRQPPGRG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>8fab</td>\n",
       "      <td>['AVKLVQAGGGVVQPGRSLRLSCIASGFTFSNYGMHWVRQAPGKG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Antibody_ID                                           Antibody  Y\n",
       "0           12e8  ['EVQLQQSGAEVVRSGASVKLSCTASGFNIKDYYIHWVKQRPEKG...  0\n",
       "1           15c8  ['EVQLQQSGAELVKPGASVKLSCTASGFNIKDTYMHWVKQKPEQG...  0\n",
       "2           1a0q  ['EVQLQESDAELVKPGASVKISCKASGYTFTDHVIHWVKQKPEQG...  1\n",
       "3           1a14  ['QVQLQQSGAELVKPGASVRMSCKASGYTFTNYNMYWVKQSPGQG...  0\n",
       "4           1a2y  ['QVQLQESGPGLVAPSQSLSITCTVSGFSLTGYGVNWVRQPPGKG...  0\n",
       "...          ...                                                ... ..\n",
       "1681        6rcs  ['QVQLVQSGAEVKKPGASVRVSCKASGYTFTSYGISWVRQAPGQG...  0\n",
       "1682        6s5a  ['EVKLLESGGGLVQPGGSLKLSCAASGFDFSRYWMNWVRQAPGKG...  0\n",
       "1683        6u1t  ['EVQLVESGGGLVKPGGSLKLSCAASGFTFSSYDMSWVRQTPEKR...  0\n",
       "1684        7fab  ['AVQLEQSGPGLVRPSQTLSLTCTVSGTSFDDYYWTWVRQPPGRG...  0\n",
       "1685        8fab  ['AVKLVQAGGGVVQPGRSLRLSCIASGFTFSNYGMHWVRQAPGKG...  0\n",
       "\n",
       "[1686 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49bc06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "split['train'].to_csv(\"chen_train_data.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75176643",
   "metadata": {},
   "outputs": [],
   "source": [
    "split['test'].to_csv(\"chen_test_data.csv\", index=False, sep=\";\")\n",
    "split['valid'].to_csv(\"chen_valid_data.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4f5cb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test successfully!\n"
     ]
    }
   ],
   "source": [
    "from pydpi import test\n",
    "test.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e20cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydpi.pypro import AAComposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce874168",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = AAComposition.CalculateAAComposition(\"PSSGHVCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aed2f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0.0,\n",
       " 'R': 0.0,\n",
       " 'N': 0.0,\n",
       " 'D': 0.0,\n",
       " 'C': 12.5,\n",
       " 'E': 12.5,\n",
       " 'Q': 0.0,\n",
       " 'G': 12.5,\n",
       " 'H': 12.5,\n",
       " 'I': 0.0,\n",
       " 'L': 0.0,\n",
       " 'K': 0.0,\n",
       " 'M': 0.0,\n",
       " 'F': 0.0,\n",
       " 'P': 12.5,\n",
       " 'S': 25.0,\n",
       " 'T': 0.0,\n",
       " 'W': 0.0,\n",
       " 'Y': 0.0,\n",
       " 'V': 12.5}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc60729",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-706bbac0aea0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprotein\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPyPro\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprotein\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReadProteinSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"PSSGHVCE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdesc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprotein\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetALL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramFiles\\Anaconda3\\envs\\data_science\\lib\\site-packages\\pydpi\\pypro.py\u001b[0m in \u001b[0;36mGetALL\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    400\u001b[0m                 \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetGearyAuto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                 \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetCTD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                 \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetPAAC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m                 \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetAPAAC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetSOCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramFiles\\Anaconda3\\envs\\data_science\\lib\\site-packages\\pydpi\\pypro.py\u001b[0m in \u001b[0;36mGetPAAC\u001b[1;34m(self, lamda, weight)\u001b[0m\n\u001b[0;32m    200\u001b[0m                 \u001b[0mregion\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;36m0.05\u001b[0m \u001b[0mto\u001b[0m \u001b[1;36m0.7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mweight\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \t\t\"\"\"\n\u001b[1;32m--> 202\u001b[1;33m                 \u001b[0mres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_GetPseudoAAC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProteinSequence\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlamda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlamda\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramFiles\\Anaconda3\\envs\\data_science\\lib\\site-packages\\pydpi\\protein\\PseudoAAC.py\u001b[0m in \u001b[0;36m_GetPseudoAAC\u001b[1;34m(ProteinSequence, lamda, weight)\u001b[0m\n\u001b[0;32m    294\u001b[0m \t\"\"\"\n\u001b[0;32m    295\u001b[0m         \u001b[0mres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_GetPseudoAAC1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mProteinSequence\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlamda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlamda\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m         \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_GetPseudoAAC2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mProteinSequence\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlamda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlamda\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramFiles\\Anaconda3\\envs\\data_science\\lib\\site-packages\\pydpi\\protein\\PseudoAAC.py\u001b[0m in \u001b[0;36m_GetPseudoAAC1\u001b[1;34m(ProteinSequence, lamda, weight)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0mrightpart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlamda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                 \u001b[0mrightpart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrightpart\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0m_GetSequenceOrderCorrelationFactor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mProteinSequence\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m         \u001b[0mAAC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGetAAComposition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mProteinSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramFiles\\Anaconda3\\envs\\data_science\\lib\\site-packages\\pydpi\\protein\\PseudoAAC.py\u001b[0m in \u001b[0;36m_GetSequenceOrderCorrelationFactor\u001b[1;34m(ProteinSequence, k)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[0mAA2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mProteinSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_GetCorrelationFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAA1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAA2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLengthSequence\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;31m#############################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "from pydpi.pypro import PyPro\n",
    "protein = PyPro()\n",
    "protein.ReadProteinSequence(\"PSSGHVCE\")\n",
    "desc = protein.GetALL()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32043053",
   "metadata": {},
   "source": [
    "# PyBioMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ab9c070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "from PyBioMed import Pyprotein\n",
    "protein=\"ADGCGVGEGTGQGPMCNCMCMKWVYADEDAADLESDSFADEDASLESDSFPWSNQRVFCSFADEDAS\"\n",
    "protein_class = Pyprotein.PyProtein(protein)\n",
    "print(len(protein_class.GetDPComp()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a85b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = protein_class.GetALL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ff17db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9880"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ad677f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 11.94,\n",
       " 'R': 1.493,\n",
       " 'N': 2.985,\n",
       " 'D': 14.925,\n",
       " 'C': 7.463,\n",
       " 'E': 8.955,\n",
       " 'Q': 2.985,\n",
       " 'G': 8.955,\n",
       " 'H': 0.0,\n",
       " 'I': 0.0,\n",
       " 'L': 2.985,\n",
       " 'K': 1.493,\n",
       " 'M': 4.478,\n",
       " 'F': 5.97,\n",
       " 'P': 2.985,\n",
       " 'S': 11.94,\n",
       " 'T': 1.493,\n",
       " 'W': 2.985,\n",
       " 'Y': 1.493,\n",
       " 'V': 4.478,\n",
       " 'AA': 1.52,\n",
       " 'AR': 0.0,\n",
       " 'AN': 0.0,\n",
       " 'AD': 7.58,\n",
       " 'AC': 0.0,\n",
       " 'AE': 0.0,\n",
       " 'AQ': 0.0,\n",
       " 'AG': 0.0,\n",
       " 'AH': 0.0,\n",
       " 'AI': 0.0,\n",
       " 'AL': 0.0,\n",
       " 'AK': 0.0,\n",
       " 'AM': 0.0,\n",
       " 'AF': 0.0,\n",
       " 'AP': 0.0,\n",
       " 'AS': 3.03,\n",
       " 'AT': 0.0,\n",
       " 'AW': 0.0,\n",
       " 'AY': 0.0,\n",
       " 'AV': 0.0,\n",
       " 'RA': 0.0,\n",
       " 'RR': 0.0,\n",
       " 'RN': 0.0,\n",
       " 'RD': 0.0,\n",
       " 'RC': 0.0,\n",
       " 'RE': 0.0,\n",
       " 'RQ': 0.0,\n",
       " 'RG': 0.0,\n",
       " 'RH': 0.0,\n",
       " 'RI': 0.0,\n",
       " 'RL': 0.0,\n",
       " 'RK': 0.0,\n",
       " 'RM': 0.0,\n",
       " 'RF': 0.0,\n",
       " 'RP': 0.0,\n",
       " 'RS': 0.0,\n",
       " 'RT': 0.0,\n",
       " 'RW': 0.0,\n",
       " 'RY': 0.0,\n",
       " 'RV': 1.52,\n",
       " 'NA': 0.0,\n",
       " 'NR': 0.0,\n",
       " 'NN': 0.0,\n",
       " 'ND': 0.0,\n",
       " 'NC': 1.52,\n",
       " 'NE': 0.0,\n",
       " 'NQ': 1.52,\n",
       " 'NG': 0.0,\n",
       " 'NH': 0.0,\n",
       " 'NI': 0.0,\n",
       " 'NL': 0.0,\n",
       " 'NK': 0.0,\n",
       " 'NM': 0.0,\n",
       " 'NF': 0.0,\n",
       " 'NP': 0.0,\n",
       " 'NS': 0.0,\n",
       " 'NT': 0.0,\n",
       " 'NW': 0.0,\n",
       " 'NY': 0.0,\n",
       " 'NV': 0.0,\n",
       " 'DA': 4.55,\n",
       " 'DR': 0.0,\n",
       " 'DN': 0.0,\n",
       " 'DD': 0.0,\n",
       " 'DC': 0.0,\n",
       " 'DE': 4.55,\n",
       " 'DQ': 0.0,\n",
       " 'DG': 1.52,\n",
       " 'DH': 0.0,\n",
       " 'DI': 0.0,\n",
       " 'DL': 1.52,\n",
       " 'DK': 0.0,\n",
       " 'DM': 0.0,\n",
       " 'DF': 0.0,\n",
       " 'DP': 0.0,\n",
       " 'DS': 3.03,\n",
       " 'DT': 0.0,\n",
       " 'DW': 0.0,\n",
       " 'DY': 0.0,\n",
       " 'DV': 0.0,\n",
       " 'CA': 0.0,\n",
       " 'CR': 0.0,\n",
       " 'CN': 1.52,\n",
       " 'CD': 0.0,\n",
       " 'CC': 0.0,\n",
       " 'CE': 0.0,\n",
       " 'CQ': 0.0,\n",
       " 'CG': 1.52,\n",
       " 'CH': 0.0,\n",
       " 'CI': 0.0,\n",
       " 'CL': 0.0,\n",
       " 'CK': 0.0,\n",
       " 'CM': 3.03,\n",
       " 'CF': 0.0,\n",
       " 'CP': 0.0,\n",
       " 'CS': 1.52,\n",
       " 'CT': 0.0,\n",
       " 'CW': 0.0,\n",
       " 'CY': 0.0,\n",
       " 'CV': 0.0,\n",
       " 'EA': 0.0,\n",
       " 'ER': 0.0,\n",
       " 'EN': 0.0,\n",
       " 'ED': 4.55,\n",
       " 'EC': 0.0,\n",
       " 'EE': 0.0,\n",
       " 'EQ': 0.0,\n",
       " 'EG': 1.52,\n",
       " 'EH': 0.0,\n",
       " 'EI': 0.0,\n",
       " 'EL': 0.0,\n",
       " 'EK': 0.0,\n",
       " 'EM': 0.0,\n",
       " 'EF': 0.0,\n",
       " 'EP': 0.0,\n",
       " 'ES': 3.03,\n",
       " 'ET': 0.0,\n",
       " 'EW': 0.0,\n",
       " 'EY': 0.0,\n",
       " 'EV': 0.0,\n",
       " 'QA': 0.0,\n",
       " 'QR': 1.52,\n",
       " 'QN': 0.0,\n",
       " 'QD': 0.0,\n",
       " 'QC': 0.0,\n",
       " 'QE': 0.0,\n",
       " 'QQ': 0.0,\n",
       " 'QG': 1.52,\n",
       " 'QH': 0.0,\n",
       " 'QI': 0.0,\n",
       " 'QL': 0.0,\n",
       " 'QK': 0.0,\n",
       " 'QM': 0.0,\n",
       " 'QF': 0.0,\n",
       " 'QP': 0.0,\n",
       " 'QS': 0.0,\n",
       " 'QT': 0.0,\n",
       " 'QW': 0.0,\n",
       " 'QY': 0.0,\n",
       " 'QV': 0.0,\n",
       " 'GA': 0.0,\n",
       " 'GR': 0.0,\n",
       " 'GN': 0.0,\n",
       " 'GD': 0.0,\n",
       " 'GC': 1.52,\n",
       " 'GE': 1.52,\n",
       " 'GQ': 1.52,\n",
       " 'GG': 0.0,\n",
       " 'GH': 0.0,\n",
       " 'GI': 0.0,\n",
       " 'GL': 0.0,\n",
       " 'GK': 0.0,\n",
       " 'GM': 0.0,\n",
       " 'GF': 0.0,\n",
       " 'GP': 1.52,\n",
       " 'GS': 0.0,\n",
       " 'GT': 1.52,\n",
       " 'GW': 0.0,\n",
       " 'GY': 0.0,\n",
       " 'GV': 1.52,\n",
       " 'HA': 0.0,\n",
       " 'HR': 0.0,\n",
       " 'HN': 0.0,\n",
       " 'HD': 0.0,\n",
       " 'HC': 0.0,\n",
       " 'HE': 0.0,\n",
       " 'HQ': 0.0,\n",
       " 'HG': 0.0,\n",
       " 'HH': 0.0,\n",
       " 'HI': 0.0,\n",
       " 'HL': 0.0,\n",
       " 'HK': 0.0,\n",
       " 'HM': 0.0,\n",
       " 'HF': 0.0,\n",
       " 'HP': 0.0,\n",
       " 'HS': 0.0,\n",
       " 'HT': 0.0,\n",
       " 'HW': 0.0,\n",
       " 'HY': 0.0,\n",
       " 'HV': 0.0,\n",
       " 'IA': 0.0,\n",
       " 'IR': 0.0,\n",
       " 'IN': 0.0,\n",
       " 'ID': 0.0,\n",
       " 'IC': 0.0,\n",
       " 'IE': 0.0,\n",
       " 'IQ': 0.0,\n",
       " 'IG': 0.0,\n",
       " 'IH': 0.0,\n",
       " 'II': 0.0,\n",
       " 'IL': 0.0,\n",
       " 'IK': 0.0,\n",
       " 'IM': 0.0,\n",
       " 'IF': 0.0,\n",
       " 'IP': 0.0,\n",
       " 'IS': 0.0,\n",
       " 'IT': 0.0,\n",
       " 'IW': 0.0,\n",
       " 'IY': 0.0,\n",
       " 'IV': 0.0,\n",
       " 'LA': 0.0,\n",
       " 'LR': 0.0,\n",
       " 'LN': 0.0,\n",
       " 'LD': 0.0,\n",
       " 'LC': 0.0,\n",
       " 'LE': 3.03,\n",
       " 'LQ': 0.0,\n",
       " 'LG': 0.0,\n",
       " 'LH': 0.0,\n",
       " 'LI': 0.0,\n",
       " 'LL': 0.0,\n",
       " 'LK': 0.0,\n",
       " 'LM': 0.0,\n",
       " 'LF': 0.0,\n",
       " 'LP': 0.0,\n",
       " 'LS': 0.0,\n",
       " 'LT': 0.0,\n",
       " 'LW': 0.0,\n",
       " 'LY': 0.0,\n",
       " 'LV': 0.0,\n",
       " 'KA': 0.0,\n",
       " 'KR': 0.0,\n",
       " 'KN': 0.0,\n",
       " 'KD': 0.0,\n",
       " 'KC': 0.0,\n",
       " 'KE': 0.0,\n",
       " 'KQ': 0.0,\n",
       " 'KG': 0.0,\n",
       " 'KH': 0.0,\n",
       " 'KI': 0.0,\n",
       " 'KL': 0.0,\n",
       " 'KK': 0.0,\n",
       " 'KM': 0.0,\n",
       " 'KF': 0.0,\n",
       " 'KP': 0.0,\n",
       " 'KS': 0.0,\n",
       " 'KT': 0.0,\n",
       " 'KW': 1.52,\n",
       " 'KY': 0.0,\n",
       " 'KV': 0.0,\n",
       " 'MA': 0.0,\n",
       " 'MR': 0.0,\n",
       " 'MN': 0.0,\n",
       " 'MD': 0.0,\n",
       " 'MC': 3.03,\n",
       " 'ME': 0.0,\n",
       " 'MQ': 0.0,\n",
       " 'MG': 0.0,\n",
       " 'MH': 0.0,\n",
       " 'MI': 0.0,\n",
       " 'ML': 0.0,\n",
       " 'MK': 1.52,\n",
       " 'MM': 0.0,\n",
       " 'MF': 0.0,\n",
       " 'MP': 0.0,\n",
       " 'MS': 0.0,\n",
       " 'MT': 0.0,\n",
       " 'MW': 0.0,\n",
       " 'MY': 0.0,\n",
       " 'MV': 0.0,\n",
       " 'FA': 3.03,\n",
       " 'FR': 0.0,\n",
       " 'FN': 0.0,\n",
       " 'FD': 0.0,\n",
       " 'FC': 1.52,\n",
       " 'FE': 0.0,\n",
       " 'FQ': 0.0,\n",
       " 'FG': 0.0,\n",
       " 'FH': 0.0,\n",
       " 'FI': 0.0,\n",
       " 'FL': 0.0,\n",
       " 'FK': 0.0,\n",
       " 'FM': 0.0,\n",
       " 'FF': 0.0,\n",
       " 'FP': 1.52,\n",
       " 'FS': 0.0,\n",
       " 'FT': 0.0,\n",
       " 'FW': 0.0,\n",
       " 'FY': 0.0,\n",
       " 'FV': 0.0,\n",
       " 'PA': 0.0,\n",
       " 'PR': 0.0,\n",
       " 'PN': 0.0,\n",
       " 'PD': 0.0,\n",
       " 'PC': 0.0,\n",
       " 'PE': 0.0,\n",
       " 'PQ': 0.0,\n",
       " 'PG': 0.0,\n",
       " 'PH': 0.0,\n",
       " 'PI': 0.0,\n",
       " 'PL': 0.0,\n",
       " 'PK': 0.0,\n",
       " 'PM': 1.52,\n",
       " 'PF': 0.0,\n",
       " 'PP': 0.0,\n",
       " 'PS': 0.0,\n",
       " 'PT': 0.0,\n",
       " 'PW': 1.52,\n",
       " 'PY': 0.0,\n",
       " 'PV': 0.0,\n",
       " 'SA': 0.0,\n",
       " 'SR': 0.0,\n",
       " 'SN': 1.52,\n",
       " 'SD': 3.03,\n",
       " 'SC': 0.0,\n",
       " 'SE': 0.0,\n",
       " 'SQ': 0.0,\n",
       " 'SG': 0.0,\n",
       " 'SH': 0.0,\n",
       " 'SI': 0.0,\n",
       " 'SL': 1.52,\n",
       " 'SK': 0.0,\n",
       " 'SM': 0.0,\n",
       " 'SF': 4.55,\n",
       " 'SP': 0.0,\n",
       " 'SS': 0.0,\n",
       " 'ST': 0.0,\n",
       " 'SW': 0.0,\n",
       " 'SY': 0.0,\n",
       " 'SV': 0.0,\n",
       " 'TA': 0.0,\n",
       " 'TR': 0.0,\n",
       " 'TN': 0.0,\n",
       " 'TD': 0.0,\n",
       " 'TC': 0.0,\n",
       " 'TE': 0.0,\n",
       " 'TQ': 0.0,\n",
       " 'TG': 1.52,\n",
       " 'TH': 0.0,\n",
       " 'TI': 0.0,\n",
       " 'TL': 0.0,\n",
       " 'TK': 0.0,\n",
       " 'TM': 0.0,\n",
       " 'TF': 0.0,\n",
       " 'TP': 0.0,\n",
       " 'TS': 0.0,\n",
       " 'TT': 0.0,\n",
       " 'TW': 0.0,\n",
       " 'TY': 0.0,\n",
       " 'TV': 0.0,\n",
       " 'WA': 0.0,\n",
       " 'WR': 0.0,\n",
       " 'WN': 0.0,\n",
       " 'WD': 0.0,\n",
       " 'WC': 0.0,\n",
       " 'WE': 0.0,\n",
       " 'WQ': 0.0,\n",
       " 'WG': 0.0,\n",
       " 'WH': 0.0,\n",
       " 'WI': 0.0,\n",
       " 'WL': 0.0,\n",
       " 'WK': 0.0,\n",
       " 'WM': 0.0,\n",
       " 'WF': 0.0,\n",
       " 'WP': 0.0,\n",
       " 'WS': 1.52,\n",
       " 'WT': 0.0,\n",
       " 'WW': 0.0,\n",
       " 'WY': 0.0,\n",
       " 'WV': 1.52,\n",
       " 'YA': 1.52,\n",
       " 'YR': 0.0,\n",
       " 'YN': 0.0,\n",
       " 'YD': 0.0,\n",
       " 'YC': 0.0,\n",
       " 'YE': 0.0,\n",
       " 'YQ': 0.0,\n",
       " 'YG': 0.0,\n",
       " 'YH': 0.0,\n",
       " 'YI': 0.0,\n",
       " 'YL': 0.0,\n",
       " 'YK': 0.0,\n",
       " 'YM': 0.0,\n",
       " 'YF': 0.0,\n",
       " 'YP': 0.0,\n",
       " 'YS': 0.0,\n",
       " 'YT': 0.0,\n",
       " 'YW': 0.0,\n",
       " 'YY': 0.0,\n",
       " 'YV': 0.0,\n",
       " 'VA': 0.0,\n",
       " 'VR': 0.0,\n",
       " 'VN': 0.0,\n",
       " 'VD': 0.0,\n",
       " 'VC': 0.0,\n",
       " 'VE': 0.0,\n",
       " 'VQ': 0.0,\n",
       " 'VG': 1.52,\n",
       " 'VH': 0.0,\n",
       " 'VI': 0.0,\n",
       " 'VL': 0.0,\n",
       " 'VK': 0.0,\n",
       " 'VM': 0.0,\n",
       " 'VF': 1.52,\n",
       " 'VP': 0.0,\n",
       " 'VS': 0.0,\n",
       " 'VT': 0.0,\n",
       " 'VW': 0.0,\n",
       " 'VY': 1.52,\n",
       " 'VV': 0.0,\n",
       " 'AAA': 0,\n",
       " 'AAR': 0,\n",
       " 'AAN': 0,\n",
       " 'AAD': 1,\n",
       " 'AAC': 0,\n",
       " 'AAE': 0,\n",
       " 'AAQ': 0,\n",
       " 'AAG': 0,\n",
       " 'AAH': 0,\n",
       " 'AAI': 0,\n",
       " 'AAL': 0,\n",
       " 'AAK': 0,\n",
       " 'AAM': 0,\n",
       " 'AAF': 0,\n",
       " 'AAP': 0,\n",
       " 'AAS': 0,\n",
       " 'AAT': 0,\n",
       " 'AAW': 0,\n",
       " 'AAY': 0,\n",
       " 'AAV': 0,\n",
       " 'ARA': 0,\n",
       " 'ARR': 0,\n",
       " 'ARN': 0,\n",
       " 'ARD': 0,\n",
       " 'ARC': 0,\n",
       " 'ARE': 0,\n",
       " 'ARQ': 0,\n",
       " 'ARG': 0,\n",
       " 'ARH': 0,\n",
       " 'ARI': 0,\n",
       " 'ARL': 0,\n",
       " 'ARK': 0,\n",
       " 'ARM': 0,\n",
       " 'ARF': 0,\n",
       " 'ARP': 0,\n",
       " 'ARS': 0,\n",
       " 'ART': 0,\n",
       " 'ARW': 0,\n",
       " 'ARY': 0,\n",
       " 'ARV': 0,\n",
       " 'ANA': 0,\n",
       " 'ANR': 0,\n",
       " 'ANN': 0,\n",
       " 'AND': 0,\n",
       " 'ANC': 0,\n",
       " 'ANE': 0,\n",
       " 'ANQ': 0,\n",
       " 'ANG': 0,\n",
       " 'ANH': 0,\n",
       " 'ANI': 0,\n",
       " 'ANL': 0,\n",
       " 'ANK': 0,\n",
       " 'ANM': 0,\n",
       " 'ANF': 0,\n",
       " 'ANP': 0,\n",
       " 'ANS': 0,\n",
       " 'ANT': 0,\n",
       " 'ANW': 0,\n",
       " 'ANY': 0,\n",
       " 'ANV': 0,\n",
       " 'ADA': 0,\n",
       " 'ADR': 0,\n",
       " 'ADN': 0,\n",
       " 'ADD': 0,\n",
       " 'ADC': 0,\n",
       " 'ADE': 3,\n",
       " 'ADQ': 0,\n",
       " 'ADG': 1,\n",
       " 'ADH': 0,\n",
       " 'ADI': 0,\n",
       " 'ADL': 1,\n",
       " 'ADK': 0,\n",
       " 'ADM': 0,\n",
       " 'ADF': 0,\n",
       " 'ADP': 0,\n",
       " 'ADS': 0,\n",
       " 'ADT': 0,\n",
       " 'ADW': 0,\n",
       " 'ADY': 0,\n",
       " 'ADV': 0,\n",
       " 'ACA': 0,\n",
       " 'ACR': 0,\n",
       " 'ACN': 0,\n",
       " 'ACD': 0,\n",
       " 'ACC': 0,\n",
       " 'ACE': 0,\n",
       " 'ACQ': 0,\n",
       " 'ACG': 0,\n",
       " 'ACH': 0,\n",
       " 'ACI': 0,\n",
       " 'ACL': 0,\n",
       " 'ACK': 0,\n",
       " 'ACM': 0,\n",
       " 'ACF': 0,\n",
       " 'ACP': 0,\n",
       " 'ACS': 0,\n",
       " 'ACT': 0,\n",
       " 'ACW': 0,\n",
       " 'ACY': 0,\n",
       " 'ACV': 0,\n",
       " 'AEA': 0,\n",
       " 'AER': 0,\n",
       " 'AEN': 0,\n",
       " 'AED': 0,\n",
       " 'AEC': 0,\n",
       " 'AEE': 0,\n",
       " 'AEQ': 0,\n",
       " 'AEG': 0,\n",
       " 'AEH': 0,\n",
       " 'AEI': 0,\n",
       " 'AEL': 0,\n",
       " 'AEK': 0,\n",
       " 'AEM': 0,\n",
       " 'AEF': 0,\n",
       " 'AEP': 0,\n",
       " 'AES': 0,\n",
       " 'AET': 0,\n",
       " 'AEW': 0,\n",
       " 'AEY': 0,\n",
       " 'AEV': 0,\n",
       " 'AQA': 0,\n",
       " 'AQR': 0,\n",
       " 'AQN': 0,\n",
       " 'AQD': 0,\n",
       " 'AQC': 0,\n",
       " 'AQE': 0,\n",
       " 'AQQ': 0,\n",
       " 'AQG': 0,\n",
       " 'AQH': 0,\n",
       " 'AQI': 0,\n",
       " 'AQL': 0,\n",
       " 'AQK': 0,\n",
       " 'AQM': 0,\n",
       " 'AQF': 0,\n",
       " 'AQP': 0,\n",
       " 'AQS': 0,\n",
       " 'AQT': 0,\n",
       " 'AQW': 0,\n",
       " 'AQY': 0,\n",
       " 'AQV': 0,\n",
       " 'AGA': 0,\n",
       " 'AGR': 0,\n",
       " 'AGN': 0,\n",
       " 'AGD': 0,\n",
       " 'AGC': 0,\n",
       " 'AGE': 0,\n",
       " 'AGQ': 0,\n",
       " 'AGG': 0,\n",
       " 'AGH': 0,\n",
       " 'AGI': 0,\n",
       " 'AGL': 0,\n",
       " 'AGK': 0,\n",
       " 'AGM': 0,\n",
       " 'AGF': 0,\n",
       " 'AGP': 0,\n",
       " 'AGS': 0,\n",
       " 'AGT': 0,\n",
       " 'AGW': 0,\n",
       " 'AGY': 0,\n",
       " 'AGV': 0,\n",
       " 'AHA': 0,\n",
       " 'AHR': 0,\n",
       " 'AHN': 0,\n",
       " 'AHD': 0,\n",
       " 'AHC': 0,\n",
       " 'AHE': 0,\n",
       " 'AHQ': 0,\n",
       " 'AHG': 0,\n",
       " 'AHH': 0,\n",
       " 'AHI': 0,\n",
       " 'AHL': 0,\n",
       " 'AHK': 0,\n",
       " 'AHM': 0,\n",
       " 'AHF': 0,\n",
       " 'AHP': 0,\n",
       " 'AHS': 0,\n",
       " 'AHT': 0,\n",
       " 'AHW': 0,\n",
       " 'AHY': 0,\n",
       " 'AHV': 0,\n",
       " 'AIA': 0,\n",
       " 'AIR': 0,\n",
       " 'AIN': 0,\n",
       " 'AID': 0,\n",
       " 'AIC': 0,\n",
       " 'AIE': 0,\n",
       " 'AIQ': 0,\n",
       " 'AIG': 0,\n",
       " 'AIH': 0,\n",
       " 'AII': 0,\n",
       " 'AIL': 0,\n",
       " 'AIK': 0,\n",
       " 'AIM': 0,\n",
       " 'AIF': 0,\n",
       " 'AIP': 0,\n",
       " 'AIS': 0,\n",
       " 'AIT': 0,\n",
       " 'AIW': 0,\n",
       " 'AIY': 0,\n",
       " 'AIV': 0,\n",
       " 'ALA': 0,\n",
       " 'ALR': 0,\n",
       " 'ALN': 0,\n",
       " 'ALD': 0,\n",
       " 'ALC': 0,\n",
       " 'ALE': 0,\n",
       " 'ALQ': 0,\n",
       " 'ALG': 0,\n",
       " 'ALH': 0,\n",
       " 'ALI': 0,\n",
       " 'ALL': 0,\n",
       " 'ALK': 0,\n",
       " 'ALM': 0,\n",
       " 'ALF': 0,\n",
       " 'ALP': 0,\n",
       " 'ALS': 0,\n",
       " 'ALT': 0,\n",
       " 'ALW': 0,\n",
       " 'ALY': 0,\n",
       " 'ALV': 0,\n",
       " 'AKA': 0,\n",
       " 'AKR': 0,\n",
       " 'AKN': 0,\n",
       " 'AKD': 0,\n",
       " 'AKC': 0,\n",
       " 'AKE': 0,\n",
       " 'AKQ': 0,\n",
       " 'AKG': 0,\n",
       " 'AKH': 0,\n",
       " 'AKI': 0,\n",
       " 'AKL': 0,\n",
       " 'AKK': 0,\n",
       " 'AKM': 0,\n",
       " 'AKF': 0,\n",
       " 'AKP': 0,\n",
       " 'AKS': 0,\n",
       " 'AKT': 0,\n",
       " 'AKW': 0,\n",
       " 'AKY': 0,\n",
       " 'AKV': 0,\n",
       " 'AMA': 0,\n",
       " 'AMR': 0,\n",
       " 'AMN': 0,\n",
       " 'AMD': 0,\n",
       " 'AMC': 0,\n",
       " 'AME': 0,\n",
       " 'AMQ': 0,\n",
       " 'AMG': 0,\n",
       " 'AMH': 0,\n",
       " 'AMI': 0,\n",
       " 'AML': 0,\n",
       " 'AMK': 0,\n",
       " 'AMM': 0,\n",
       " 'AMF': 0,\n",
       " 'AMP': 0,\n",
       " 'AMS': 0,\n",
       " 'AMT': 0,\n",
       " 'AMW': 0,\n",
       " 'AMY': 0,\n",
       " 'AMV': 0,\n",
       " 'AFA': 0,\n",
       " 'AFR': 0,\n",
       " 'AFN': 0,\n",
       " 'AFD': 0,\n",
       " 'AFC': 0,\n",
       " 'AFE': 0,\n",
       " 'AFQ': 0,\n",
       " 'AFG': 0,\n",
       " 'AFH': 0,\n",
       " 'AFI': 0,\n",
       " 'AFL': 0,\n",
       " 'AFK': 0,\n",
       " 'AFM': 0,\n",
       " 'AFF': 0,\n",
       " 'AFP': 0,\n",
       " 'AFS': 0,\n",
       " 'AFT': 0,\n",
       " 'AFW': 0,\n",
       " 'AFY': 0,\n",
       " 'AFV': 0,\n",
       " 'APA': 0,\n",
       " 'APR': 0,\n",
       " 'APN': 0,\n",
       " 'APD': 0,\n",
       " 'APC': 0,\n",
       " 'APE': 0,\n",
       " 'APQ': 0,\n",
       " 'APG': 0,\n",
       " 'APH': 0,\n",
       " 'API': 0,\n",
       " 'APL': 0,\n",
       " 'APK': 0,\n",
       " 'APM': 0,\n",
       " 'APF': 0,\n",
       " 'APP': 0,\n",
       " 'APS': 0,\n",
       " 'APT': 0,\n",
       " 'APW': 0,\n",
       " 'APY': 0,\n",
       " 'APV': 0,\n",
       " 'ASA': 0,\n",
       " 'ASR': 0,\n",
       " 'ASN': 0,\n",
       " 'ASD': 0,\n",
       " 'ASC': 0,\n",
       " 'ASE': 0,\n",
       " 'ASQ': 0,\n",
       " 'ASG': 0,\n",
       " 'ASH': 0,\n",
       " 'ASI': 0,\n",
       " 'ASL': 1,\n",
       " 'ASK': 0,\n",
       " 'ASM': 0,\n",
       " 'ASF': 0,\n",
       " 'ASP': 0,\n",
       " 'ASS': 0,\n",
       " 'AST': 0,\n",
       " 'ASW': 0,\n",
       " 'ASY': 0,\n",
       " 'ASV': 0,\n",
       " 'ATA': 0,\n",
       " 'ATR': 0,\n",
       " 'ATN': 0,\n",
       " 'ATD': 0,\n",
       " 'ATC': 0,\n",
       " 'ATE': 0,\n",
       " 'ATQ': 0,\n",
       " 'ATG': 0,\n",
       " 'ATH': 0,\n",
       " 'ATI': 0,\n",
       " 'ATL': 0,\n",
       " 'ATK': 0,\n",
       " 'ATM': 0,\n",
       " 'ATF': 0,\n",
       " 'ATP': 0,\n",
       " 'ATS': 0,\n",
       " 'ATT': 0,\n",
       " 'ATW': 0,\n",
       " 'ATY': 0,\n",
       " 'ATV': 0,\n",
       " 'AWA': 0,\n",
       " 'AWR': 0,\n",
       " 'AWN': 0,\n",
       " 'AWD': 0,\n",
       " 'AWC': 0,\n",
       " 'AWE': 0,\n",
       " 'AWQ': 0,\n",
       " 'AWG': 0,\n",
       " 'AWH': 0,\n",
       " 'AWI': 0,\n",
       " 'AWL': 0,\n",
       " 'AWK': 0,\n",
       " 'AWM': 0,\n",
       " 'AWF': 0,\n",
       " 'AWP': 0,\n",
       " 'AWS': 0,\n",
       " 'AWT': 0,\n",
       " 'AWW': 0,\n",
       " 'AWY': 0,\n",
       " 'AWV': 0,\n",
       " 'AYA': 0,\n",
       " 'AYR': 0,\n",
       " 'AYN': 0,\n",
       " 'AYD': 0,\n",
       " 'AYC': 0,\n",
       " 'AYE': 0,\n",
       " 'AYQ': 0,\n",
       " 'AYG': 0,\n",
       " 'AYH': 0,\n",
       " 'AYI': 0,\n",
       " 'AYL': 0,\n",
       " 'AYK': 0,\n",
       " 'AYM': 0,\n",
       " 'AYF': 0,\n",
       " 'AYP': 0,\n",
       " 'AYS': 0,\n",
       " 'AYT': 0,\n",
       " 'AYW': 0,\n",
       " 'AYY': 0,\n",
       " 'AYV': 0,\n",
       " 'AVA': 0,\n",
       " 'AVR': 0,\n",
       " 'AVN': 0,\n",
       " 'AVD': 0,\n",
       " 'AVC': 0,\n",
       " 'AVE': 0,\n",
       " 'AVQ': 0,\n",
       " 'AVG': 0,\n",
       " 'AVH': 0,\n",
       " 'AVI': 0,\n",
       " 'AVL': 0,\n",
       " 'AVK': 0,\n",
       " 'AVM': 0,\n",
       " 'AVF': 0,\n",
       " 'AVP': 0,\n",
       " 'AVS': 0,\n",
       " 'AVT': 0,\n",
       " 'AVW': 0,\n",
       " 'AVY': 0,\n",
       " 'AVV': 0,\n",
       " 'RAA': 0,\n",
       " 'RAR': 0,\n",
       " 'RAN': 0,\n",
       " 'RAD': 0,\n",
       " 'RAC': 0,\n",
       " 'RAE': 0,\n",
       " 'RAQ': 0,\n",
       " 'RAG': 0,\n",
       " 'RAH': 0,\n",
       " 'RAI': 0,\n",
       " 'RAL': 0,\n",
       " 'RAK': 0,\n",
       " 'RAM': 0,\n",
       " 'RAF': 0,\n",
       " 'RAP': 0,\n",
       " 'RAS': 0,\n",
       " 'RAT': 0,\n",
       " 'RAW': 0,\n",
       " 'RAY': 0,\n",
       " 'RAV': 0,\n",
       " 'RRA': 0,\n",
       " 'RRR': 0,\n",
       " 'RRN': 0,\n",
       " 'RRD': 0,\n",
       " 'RRC': 0,\n",
       " 'RRE': 0,\n",
       " 'RRQ': 0,\n",
       " 'RRG': 0,\n",
       " 'RRH': 0,\n",
       " 'RRI': 0,\n",
       " 'RRL': 0,\n",
       " 'RRK': 0,\n",
       " 'RRM': 0,\n",
       " 'RRF': 0,\n",
       " 'RRP': 0,\n",
       " 'RRS': 0,\n",
       " 'RRT': 0,\n",
       " 'RRW': 0,\n",
       " 'RRY': 0,\n",
       " 'RRV': 0,\n",
       " 'RNA': 0,\n",
       " 'RNR': 0,\n",
       " 'RNN': 0,\n",
       " 'RND': 0,\n",
       " 'RNC': 0,\n",
       " 'RNE': 0,\n",
       " 'RNQ': 0,\n",
       " 'RNG': 0,\n",
       " 'RNH': 0,\n",
       " 'RNI': 0,\n",
       " 'RNL': 0,\n",
       " 'RNK': 0,\n",
       " 'RNM': 0,\n",
       " 'RNF': 0,\n",
       " 'RNP': 0,\n",
       " 'RNS': 0,\n",
       " 'RNT': 0,\n",
       " 'RNW': 0,\n",
       " 'RNY': 0,\n",
       " 'RNV': 0,\n",
       " 'RDA': 0,\n",
       " 'RDR': 0,\n",
       " 'RDN': 0,\n",
       " 'RDD': 0,\n",
       " 'RDC': 0,\n",
       " 'RDE': 0,\n",
       " 'RDQ': 0,\n",
       " 'RDG': 0,\n",
       " 'RDH': 0,\n",
       " 'RDI': 0,\n",
       " 'RDL': 0,\n",
       " 'RDK': 0,\n",
       " 'RDM': 0,\n",
       " 'RDF': 0,\n",
       " 'RDP': 0,\n",
       " 'RDS': 0,\n",
       " 'RDT': 0,\n",
       " 'RDW': 0,\n",
       " 'RDY': 0,\n",
       " 'RDV': 0,\n",
       " 'RCA': 0,\n",
       " 'RCR': 0,\n",
       " 'RCN': 0,\n",
       " 'RCD': 0,\n",
       " 'RCC': 0,\n",
       " 'RCE': 0,\n",
       " 'RCQ': 0,\n",
       " 'RCG': 0,\n",
       " 'RCH': 0,\n",
       " 'RCI': 0,\n",
       " 'RCL': 0,\n",
       " 'RCK': 0,\n",
       " 'RCM': 0,\n",
       " 'RCF': 0,\n",
       " 'RCP': 0,\n",
       " 'RCS': 0,\n",
       " 'RCT': 0,\n",
       " 'RCW': 0,\n",
       " 'RCY': 0,\n",
       " 'RCV': 0,\n",
       " 'REA': 0,\n",
       " 'RER': 0,\n",
       " 'REN': 0,\n",
       " 'RED': 0,\n",
       " 'REC': 0,\n",
       " 'REE': 0,\n",
       " 'REQ': 0,\n",
       " 'REG': 0,\n",
       " 'REH': 0,\n",
       " 'REI': 0,\n",
       " 'REL': 0,\n",
       " 'REK': 0,\n",
       " 'REM': 0,\n",
       " 'REF': 0,\n",
       " 'REP': 0,\n",
       " 'RES': 0,\n",
       " 'RET': 0,\n",
       " 'REW': 0,\n",
       " 'REY': 0,\n",
       " 'REV': 0,\n",
       " 'RQA': 0,\n",
       " 'RQR': 0,\n",
       " 'RQN': 0,\n",
       " 'RQD': 0,\n",
       " 'RQC': 0,\n",
       " 'RQE': 0,\n",
       " 'RQQ': 0,\n",
       " 'RQG': 0,\n",
       " 'RQH': 0,\n",
       " 'RQI': 0,\n",
       " 'RQL': 0,\n",
       " 'RQK': 0,\n",
       " 'RQM': 0,\n",
       " 'RQF': 0,\n",
       " 'RQP': 0,\n",
       " 'RQS': 0,\n",
       " 'RQT': 0,\n",
       " 'RQW': 0,\n",
       " 'RQY': 0,\n",
       " 'RQV': 0,\n",
       " 'RGA': 0,\n",
       " 'RGR': 0,\n",
       " 'RGN': 0,\n",
       " 'RGD': 0,\n",
       " 'RGC': 0,\n",
       " 'RGE': 0,\n",
       " 'RGQ': 0,\n",
       " 'RGG': 0,\n",
       " 'RGH': 0,\n",
       " 'RGI': 0,\n",
       " 'RGL': 0,\n",
       " 'RGK': 0,\n",
       " 'RGM': 0,\n",
       " 'RGF': 0,\n",
       " 'RGP': 0,\n",
       " 'RGS': 0,\n",
       " 'RGT': 0,\n",
       " 'RGW': 0,\n",
       " 'RGY': 0,\n",
       " 'RGV': 0,\n",
       " 'RHA': 0,\n",
       " 'RHR': 0,\n",
       " 'RHN': 0,\n",
       " 'RHD': 0,\n",
       " 'RHC': 0,\n",
       " 'RHE': 0,\n",
       " 'RHQ': 0,\n",
       " 'RHG': 0,\n",
       " 'RHH': 0,\n",
       " 'RHI': 0,\n",
       " 'RHL': 0,\n",
       " 'RHK': 0,\n",
       " 'RHM': 0,\n",
       " 'RHF': 0,\n",
       " 'RHP': 0,\n",
       " 'RHS': 0,\n",
       " 'RHT': 0,\n",
       " 'RHW': 0,\n",
       " 'RHY': 0,\n",
       " 'RHV': 0,\n",
       " ...}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51289511",
   "metadata": {},
   "outputs": [],
   "source": [
    "tripept = protein_class.GetTPComp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf8d2756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tripept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ff03cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tripept_list = list(tripept.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1062c29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9880"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptors = list(desc.values())\n",
    "len(descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae9a0fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 419 last dipeptide\n",
    "descriptors = descriptors[:420] + tripept_list + descriptors[8420:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8f8c18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9880"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19709e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f1ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_descriptors(sequence):\n",
    "    protein = Pyprotein.PyProtein(sequence)\n",
    "    desc = list(protein.GetALL().values())\n",
    "    tripept = list(protein.GetTPComp().values())\n",
    "    all_desc = desc[:420] + tripept + desc[8420:]\n",
    "    return all_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb3c04dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_excess(seq):\n",
    "    seq = seq.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    seq = seq.replace(\"'\", \"\")\n",
    "    return seq.replace(\",\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0f15cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptors_for_ab(seqs):\n",
    "    heavy, light = seqs.split()\n",
    "    heavy = remove_excess(heavy)\n",
    "    light = remove_excess(light)\n",
    "    desc_heavy = calculate_all_descriptors(heavy)\n",
    "    desc_light = calculate_all_descriptors(light)\n",
    "    all_desc = desc_heavy + desc_light\n",
    "    return np.asarray(all_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59f1f07d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21.739,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 26.087,\n",
       " 0.0,\n",
       " 13.043,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.348,\n",
       " 4.348,\n",
       " 0.0,\n",
       " 4.348,\n",
       " 0.0,\n",
       " 13.043,\n",
       " 0.0,\n",
       " 4.348,\n",
       " 4.348,\n",
       " 4.348,\n",
       " 4.55,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 13.64,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.55,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 9.09,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 9.09,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.55,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.55,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 9.09,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.55,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.55,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.55,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.55,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.55,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.55,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.55,\n",
       " 4.55,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.55,\n",
       " 0.0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = calculate_all_descriptors(\"KWVYADEDAADLESDSFADEDAS\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d9c0c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>Antibody</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12e8</td>\n",
       "      <td>['EVQLQQSGAEVVRSGASVKLSCTASGFNIKDYYIHWVKQRPEKG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15c8</td>\n",
       "      <td>['EVQLQQSGAELVKPGASVKLSCTASGFNIKDTYMHWVKQKPEQG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a0q</td>\n",
       "      <td>['EVQLQESDAELVKPGASVKISCKASGYTFTDHVIHWVKQKPEQG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a14</td>\n",
       "      <td>['QVQLQQSGAELVKPGASVRMSCKASGYTFTNYNMYWVKQSPGQG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a2y</td>\n",
       "      <td>['QVQLQESGPGLVAPSQSLSITCTVSGFSLTGYGVNWVRQPPGKG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>6rcs</td>\n",
       "      <td>['QVQLVQSGAEVKKPGASVRVSCKASGYTFTSYGISWVRQAPGQG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>6s5a</td>\n",
       "      <td>['EVKLLESGGGLVQPGGSLKLSCAASGFDFSRYWMNWVRQAPGKG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>6u1t</td>\n",
       "      <td>['EVQLVESGGGLVKPGGSLKLSCAASGFTFSSYDMSWVRQTPEKR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>7fab</td>\n",
       "      <td>['AVQLEQSGPGLVRPSQTLSLTCTVSGTSFDDYYWTWVRQPPGRG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>8fab</td>\n",
       "      <td>['AVKLVQAGGGVVQPGRSLRLSCIASGFTFSNYGMHWVRQAPGKG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Antibody_ID                                           Antibody  Y\n",
       "0           12e8  ['EVQLQQSGAEVVRSGASVKLSCTASGFNIKDYYIHWVKQRPEKG...  0\n",
       "1           15c8  ['EVQLQQSGAELVKPGASVKLSCTASGFNIKDTYMHWVKQKPEQG...  0\n",
       "2           1a0q  ['EVQLQESDAELVKPGASVKISCKASGYTFTDHVIHWVKQKPEQG...  1\n",
       "3           1a14  ['QVQLQQSGAELVKPGASVRMSCKASGYTFTNYNMYWVKQSPGQG...  0\n",
       "4           1a2y  ['QVQLQESGPGLVAPSQSLSITCTVSGFSLTGYGVNWVRQPPGKG...  0\n",
       "...          ...                                                ... ..\n",
       "1681        6rcs  ['QVQLVQSGAEVKKPGASVRVSCKASGYTFTSYGISWVRQAPGQG...  0\n",
       "1682        6s5a  ['EVKLLESGGGLVQPGGSLKLSCAASGFDFSRYWMNWVRQAPGKG...  0\n",
       "1683        6u1t  ['EVQLVESGGGLVKPGGSLKLSCAASGFTFSSYDMSWVRQTPEKR...  0\n",
       "1684        7fab  ['AVQLEQSGPGLVRPSQTLSLTCTVSGTSFDDYYWTWVRQPPGRG...  0\n",
       "1685        8fab  ['AVKLVQAGGGVVQPGRSLRLSCIASGFTFSNYGMHWVRQAPGKG...  0\n",
       "\n",
       "[1686 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a722588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [7.5, 3.333, 2.5, 5.833, 1.667, 5.833, 5.833, ...\n",
       "1    [9.244, 0.0, 3.361, 5.882, 1.681, 4.202, 6.723...\n",
       "2    [5.882, 1.681, 3.361, 5.042, 1.681, 5.882, 5.0...\n",
       "3    [6.667, 2.5, 4.167, 5.0, 1.667, 2.5, 7.5, 11.6...\n",
       "4    [3.448, 5.172, 4.31, 6.034, 1.724, 2.586, 6.03...\n",
       "Name: Antibody, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = split[\"train\"][\"Antibody\"].apply(descriptors_for_ab)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe3f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc1217a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X.to_list())\n",
    "\n",
    "X_train_df.columns = X_train_df.columns.astype(str)\n",
    "X_train_df.to_feather(\"X_train_data.ftr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "318c06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da181e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [5.785, 6.612, 1.653, 3.306, 1.653, 4.132, 2.4...\n",
       "1    [4.202, 2.521, 5.882, 3.361, 1.681, 1.681, 7.5...\n",
       "2    [3.448, 3.448, 3.448, 1.724, 1.724, 2.586, 5.1...\n",
       "3    [5.042, 2.521, 6.723, 4.202, 1.681, 4.202, 5.0...\n",
       "4    [1.709, 3.419, 2.564, 5.983, 1.709, 3.419, 5.9...\n",
       "Name: Antibody, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = split[\"test\"][\"Antibody\"].apply(descriptors_for_ab)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb54aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = pd.DataFrame(X_test.to_list())\n",
    "\n",
    "X_test_df.columns = X_test_df.columns.astype(str)\n",
    "X_test_df.to_feather(\"X_test_data.ftr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aae15237",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = split['train'][\"Y\"]\n",
    "y_test = split['test'][\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b270d63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d74ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90a47f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100,\n",
    "                           criterion=\"gini\",\n",
    "                           bootstrap=True,\n",
    "                           random_state=42)\n",
    "rf.fit(X_train_df, y_train)\n",
    "y_pred = rf.predict(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b042cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "311246c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[350,  16],\n",
       "       [ 66,  50]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "deda240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       366\n",
      "           1       0.76      0.43      0.55       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.80      0.69      0.72       482\n",
      "weighted avg       0.82      0.83      0.81       482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e934694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_test(n, criterion):\n",
    "    rf_n = RandomForestClassifier(n_estimators=n,\n",
    "                           criterion=criterion,\n",
    "                           bootstrap=True,\n",
    "                           random_state=42)\n",
    "    rf_n.fit(X_train_df, y_train)\n",
    "    y_pred = rf_n.predict(X_test_df)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4211ab55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 150; criterion: gini\n",
      "[[350  16]\n",
      " [ 65  51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       366\n",
      "           1       0.76      0.44      0.56       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.80      0.70      0.73       482\n",
      "weighted avg       0.82      0.83      0.81       482\n",
      "\n",
      "============\n",
      "n_estimators: 150; criterion: entropy\n",
      "[[350  16]\n",
      " [ 66  50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       366\n",
      "           1       0.76      0.43      0.55       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.80      0.69      0.72       482\n",
      "weighted avg       0.82      0.83      0.81       482\n",
      "\n",
      "============\n",
      "n_estimators: 200; criterion: gini\n",
      "[[350  16]\n",
      " [ 67  49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89       366\n",
      "           1       0.75      0.42      0.54       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.80      0.69      0.72       482\n",
      "weighted avg       0.82      0.83      0.81       482\n",
      "\n",
      "============\n",
      "n_estimators: 200; criterion: entropy\n",
      "[[350  16]\n",
      " [ 67  49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89       366\n",
      "           1       0.75      0.42      0.54       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.80      0.69      0.72       482\n",
      "weighted avg       0.82      0.83      0.81       482\n",
      "\n",
      "============\n",
      "n_estimators: 300; criterion: gini\n",
      "[[350  16]\n",
      " [ 69  47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89       366\n",
      "           1       0.75      0.41      0.53       116\n",
      "\n",
      "    accuracy                           0.82       482\n",
      "   macro avg       0.79      0.68      0.71       482\n",
      "weighted avg       0.81      0.82      0.80       482\n",
      "\n",
      "============\n",
      "n_estimators: 300; criterion: entropy\n",
      "[[350  16]\n",
      " [ 69  47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89       366\n",
      "           1       0.75      0.41      0.53       116\n",
      "\n",
      "    accuracy                           0.82       482\n",
      "   macro avg       0.79      0.68      0.71       482\n",
      "weighted avg       0.81      0.82      0.80       482\n",
      "\n",
      "============\n"
     ]
    }
   ],
   "source": [
    "for num in [150, 200, 300]:\n",
    "    for crit in [\"gini\", \"entropy\"]:\n",
    "        print(f\"n_estimators: {num}; criterion: {crit}\")\n",
    "        random_forest_test(num, crit)\n",
    "        print(\"============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "111d3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33d55c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_SVM_test(penalty, loss):\n",
    "    lsvc = LinearSVC(penalty=penalty,\n",
    "                     loss=loss,\n",
    "                     random_state=42,\n",
    "                     class_weight='balanced')\n",
    "    lsvc.fit(X_train_df, y_train)\n",
    "    y_pred = lsvc.predict(X_test_df)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c448dc4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty: l2; loss: hinge\n",
      "[[365   1]\n",
      " [103  13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88       366\n",
      "           1       0.93      0.11      0.20       116\n",
      "\n",
      "    accuracy                           0.78       482\n",
      "   macro avg       0.85      0.55      0.54       482\n",
      "weighted avg       0.82      0.78      0.71       482\n",
      "\n",
      "============\n",
      "penalty: l2; loss: squared_hinge\n",
      "[[365   1]\n",
      " [103  13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88       366\n",
      "           1       0.93      0.11      0.20       116\n",
      "\n",
      "    accuracy                           0.78       482\n",
      "   macro avg       0.85      0.55      0.54       482\n",
      "weighted avg       0.82      0.78      0.71       482\n",
      "\n",
      "============\n"
     ]
    }
   ],
   "source": [
    "for pen in ['l2']:   # The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True\n",
    "    for loss in [\"hinge\", \"squared_hinge\"]:\n",
    "        print(f\"penalty: {pen}; loss: {loss}\")\n",
    "        linear_SVM_test(pen, loss)\n",
    "        print(\"============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbd14cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def C_SVM_test(c, kernel, degree=3):\n",
    "    svc = SVC(C=c,\n",
    "               kernel=kernel,\n",
    "               random_state=42,\n",
    "               degree=degree)\n",
    "    svc.fit(X_train_df, y_train)\n",
    "    y_pred = svc.predict(X_test_df)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2865aef2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.5; kernel: linear\n",
      "[[330  36]\n",
      " [ 44  72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       366\n",
      "           1       0.67      0.62      0.64       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.77      0.76      0.77       482\n",
      "weighted avg       0.83      0.83      0.83       482\n",
      "\n",
      "============\n",
      "C: 0.5; kernel: poly; degree: 2\n",
      "[[366   0]\n",
      " [116   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       366\n",
      "           1       0.00      0.00      0.00       116\n",
      "\n",
      "    accuracy                           0.76       482\n",
      "   macro avg       0.38      0.50      0.43       482\n",
      "weighted avg       0.58      0.76      0.66       482\n",
      "\n",
      "============\n",
      "C: 0.5; kernel: poly; degree: 3\n",
      "[[366   0]\n",
      " [116   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       366\n",
      "           1       0.00      0.00      0.00       116\n",
      "\n",
      "    accuracy                           0.76       482\n",
      "   macro avg       0.38      0.50      0.43       482\n",
      "weighted avg       0.58      0.76      0.66       482\n",
      "\n",
      "============\n",
      "C: 0.5; kernel: poly; degree: 4\n",
      "[[366   0]\n",
      " [116   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       366\n",
      "           1       0.00      0.00      0.00       116\n",
      "\n",
      "    accuracy                           0.76       482\n",
      "   macro avg       0.38      0.50      0.43       482\n",
      "weighted avg       0.58      0.76      0.66       482\n",
      "\n",
      "============\n",
      "C: 0.5; kernel: rbf\n",
      "[[366   0]\n",
      " [116   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       366\n",
      "           1       0.00      0.00      0.00       116\n",
      "\n",
      "    accuracy                           0.76       482\n",
      "   macro avg       0.38      0.50      0.43       482\n",
      "weighted avg       0.58      0.76      0.66       482\n",
      "\n",
      "============\n",
      "C: 0.5; kernel: sigmoid\n",
      "[[366   0]\n",
      " [116   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       366\n",
      "           1       0.00      0.00      0.00       116\n",
      "\n",
      "    accuracy                           0.76       482\n",
      "   macro avg       0.38      0.50      0.43       482\n",
      "weighted avg       0.58      0.76      0.66       482\n",
      "\n",
      "============\n",
      "C: 1; kernel: linear\n",
      "[[330  36]\n",
      " [ 44  72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       366\n",
      "           1       0.67      0.62      0.64       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.77      0.76      0.77       482\n",
      "weighted avg       0.83      0.83      0.83       482\n",
      "\n",
      "============\n",
      "C: 1; kernel: poly; degree: 2\n",
      "[[366   0]\n",
      " [116   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       366\n",
      "           1       0.00      0.00      0.00       116\n",
      "\n",
      "    accuracy                           0.76       482\n",
      "   macro avg       0.38      0.50      0.43       482\n",
      "weighted avg       0.58      0.76      0.66       482\n",
      "\n",
      "============\n",
      "C: 1; kernel: poly; degree: 3\n",
      "[[366   0]\n",
      " [116   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       366\n",
      "           1       0.00      0.00      0.00       116\n",
      "\n",
      "    accuracy                           0.76       482\n",
      "   macro avg       0.38      0.50      0.43       482\n",
      "weighted avg       0.58      0.76      0.66       482\n",
      "\n",
      "============\n",
      "C: 1; kernel: poly; degree: 4\n",
      "[[366   0]\n",
      " [116   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       366\n",
      "           1       0.00      0.00      0.00       116\n",
      "\n",
      "    accuracy                           0.76       482\n",
      "   macro avg       0.38      0.50      0.43       482\n",
      "weighted avg       0.58      0.76      0.66       482\n",
      "\n",
      "============\n",
      "C: 1; kernel: rbf\n",
      "[[366   0]\n",
      " [116   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       366\n",
      "           1       0.00      0.00      0.00       116\n",
      "\n",
      "    accuracy                           0.76       482\n",
      "   macro avg       0.38      0.50      0.43       482\n",
      "weighted avg       0.58      0.76      0.66       482\n",
      "\n",
      "============\n",
      "C: 1; kernel: sigmoid\n",
      "[[366   0]\n",
      " [116   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       366\n",
      "           1       0.00      0.00      0.00       116\n",
      "\n",
      "    accuracy                           0.76       482\n",
      "   macro avg       0.38      0.50      0.43       482\n",
      "weighted avg       0.58      0.76      0.66       482\n",
      "\n",
      "============\n",
      "C: 1.5; kernel: linear\n",
      "[[330  36]\n",
      " [ 44  72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       366\n",
      "           1       0.67      0.62      0.64       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.77      0.76      0.77       482\n",
      "weighted avg       0.83      0.83      0.83       482\n",
      "\n",
      "============\n",
      "C: 1.5; kernel: poly; degree: 2\n",
      "[[366   0]\n",
      " [116   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       366\n",
      "           1       0.00      0.00      0.00       116\n",
      "\n",
      "    accuracy                           0.76       482\n",
      "   macro avg       0.38      0.50      0.43       482\n",
      "weighted avg       0.58      0.76      0.66       482\n",
      "\n",
      "============\n",
      "C: 1.5; kernel: poly; degree: 3\n",
      "[[366   0]\n",
      " [116   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       366\n",
      "           1       0.00      0.00      0.00       116\n",
      "\n",
      "    accuracy                           0.76       482\n",
      "   macro avg       0.38      0.50      0.43       482\n",
      "weighted avg       0.58      0.76      0.66       482\n",
      "\n",
      "============\n",
      "C: 1.5; kernel: poly; degree: 4\n",
      "[[366   0]\n",
      " [116   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       366\n",
      "           1       0.00      0.00      0.00       116\n",
      "\n",
      "    accuracy                           0.76       482\n",
      "   macro avg       0.38      0.50      0.43       482\n",
      "weighted avg       0.58      0.76      0.66       482\n",
      "\n",
      "============\n",
      "C: 1.5; kernel: rbf\n",
      "[[366   0]\n",
      " [116   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       366\n",
      "           1       0.00      0.00      0.00       116\n",
      "\n",
      "    accuracy                           0.76       482\n",
      "   macro avg       0.38      0.50      0.43       482\n",
      "weighted avg       0.58      0.76      0.66       482\n",
      "\n",
      "============\n",
      "C: 1.5; kernel: sigmoid\n",
      "[[366   0]\n",
      " [116   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       366\n",
      "           1       0.00      0.00      0.00       116\n",
      "\n",
      "    accuracy                           0.76       482\n",
      "   macro avg       0.38      0.50      0.43       482\n",
      "weighted avg       0.58      0.76      0.66       482\n",
      "\n",
      "============\n"
     ]
    }
   ],
   "source": [
    "for c in [0.5, 1, 1.5]:   \n",
    "    for kernel in [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]:\n",
    "        if kernel == 'poly':\n",
    "            for deg in [2, 3, 4]:\n",
    "                print(f\"C: {c}; kernel: {kernel}; degree: {deg}\")\n",
    "                C_SVM_test(c, kernel, deg)\n",
    "                print(\"============\")\n",
    "        else:\n",
    "            print(f\"C: {c}; kernel: {kernel}\")\n",
    "            C_SVM_test(c, kernel)\n",
    "            print(\"============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "627f5379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4c822e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_test(penalty, c, solver):\n",
    "    lr = LogisticRegression(C=c,\n",
    "               penalty=penalty,\n",
    "               class_weight='balanced',\n",
    "               random_state=42,\n",
    "               solver=solver)\n",
    "    lr.fit(X_train_df, y_train)\n",
    "    y_pred = lr.predict(X_test_df)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2d5f9d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.5; penalty: l1; solver: newton-cg\n",
      "Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "============\n",
      "C: 0.5; penalty: l1; solver: lbfgs\n",
      "Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "============\n",
      "C: 0.5; penalty: l1; solver: liblinear\n",
      "[[323  43]\n",
      " [ 39  77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89       366\n",
      "           1       0.64      0.66      0.65       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.77      0.77      0.77       482\n",
      "weighted avg       0.83      0.83      0.83       482\n",
      "\n",
      "============\n",
      "C: 0.5; penalty: l1; solver: sag\n",
      "Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "============\n",
      "C: 0.5; penalty: l1; solver: saga\n",
      "[[291  75]\n",
      " [ 27  89]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.85       366\n",
      "           1       0.54      0.77      0.64       116\n",
      "\n",
      "    accuracy                           0.79       482\n",
      "   macro avg       0.73      0.78      0.74       482\n",
      "weighted avg       0.83      0.79      0.80       482\n",
      "\n",
      "============\n",
      "C: 0.5; penalty: l2; solver: newton-cg\n",
      "[[326  40]\n",
      " [ 41  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       366\n",
      "           1       0.65      0.65      0.65       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.77      0.77      0.77       482\n",
      "weighted avg       0.83      0.83      0.83       482\n",
      "\n",
      "============\n",
      "C: 0.5; penalty: l2; solver: lbfgs\n",
      "[[301  65]\n",
      " [ 33  83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86       366\n",
      "           1       0.56      0.72      0.63       116\n",
      "\n",
      "    accuracy                           0.80       482\n",
      "   macro avg       0.73      0.77      0.74       482\n",
      "weighted avg       0.82      0.80      0.80       482\n",
      "\n",
      "============\n",
      "C: 0.5; penalty: l2; solver: liblinear\n",
      "[[325  41]\n",
      " [ 41  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       366\n",
      "           1       0.65      0.65      0.65       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.77      0.77      0.77       482\n",
      "weighted avg       0.83      0.83      0.83       482\n",
      "\n",
      "============\n",
      "C: 0.5; penalty: l2; solver: sag\n",
      "[[288  78]\n",
      " [ 26  90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85       366\n",
      "           1       0.54      0.78      0.63       116\n",
      "\n",
      "    accuracy                           0.78       482\n",
      "   macro avg       0.73      0.78      0.74       482\n",
      "weighted avg       0.83      0.78      0.80       482\n",
      "\n",
      "============\n",
      "C: 0.5; penalty: l2; solver: saga\n",
      "[[291  75]\n",
      " [ 26  90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.85       366\n",
      "           1       0.55      0.78      0.64       116\n",
      "\n",
      "    accuracy                           0.79       482\n",
      "   macro avg       0.73      0.79      0.75       482\n",
      "weighted avg       0.83      0.79      0.80       482\n",
      "\n",
      "============\n",
      "C: 0.5; penalty: elasticnet; solver: newton-cg\n",
      "Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "============\n",
      "C: 0.5; penalty: elasticnet; solver: lbfgs\n",
      "Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "============\n",
      "C: 0.5; penalty: elasticnet; solver: liblinear\n",
      "Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "============\n",
      "C: 0.5; penalty: elasticnet; solver: sag\n",
      "Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "============\n",
      "C: 0.5; penalty: elasticnet; solver: saga\n",
      "l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "============\n",
      "C: 0.5; penalty: none; solver: newton-cg\n",
      "[[326  40]\n",
      " [ 41  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       366\n",
      "           1       0.65      0.65      0.65       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.77      0.77      0.77       482\n",
      "weighted avg       0.83      0.83      0.83       482\n",
      "\n",
      "============\n",
      "C: 0.5; penalty: none; solver: lbfgs\n",
      "[[294  72]\n",
      " [ 28  88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85       366\n",
      "           1       0.55      0.76      0.64       116\n",
      "\n",
      "    accuracy                           0.79       482\n",
      "   macro avg       0.73      0.78      0.75       482\n",
      "weighted avg       0.83      0.79      0.80       482\n",
      "\n",
      "============\n",
      "C: 0.5; penalty: none; solver: liblinear\n",
      "penalty='none' is not supported for the liblinear solver\n",
      "============\n",
      "C: 0.5; penalty: none; solver: sag\n",
      "[[288  78]\n",
      " [ 26  90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85       366\n",
      "           1       0.54      0.78      0.63       116\n",
      "\n",
      "    accuracy                           0.78       482\n",
      "   macro avg       0.73      0.78      0.74       482\n",
      "weighted avg       0.83      0.78      0.80       482\n",
      "\n",
      "============\n",
      "C: 0.5; penalty: none; solver: saga\n",
      "[[291  75]\n",
      " [ 26  90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.85       366\n",
      "           1       0.55      0.78      0.64       116\n",
      "\n",
      "    accuracy                           0.79       482\n",
      "   macro avg       0.73      0.79      0.75       482\n",
      "weighted avg       0.83      0.79      0.80       482\n",
      "\n",
      "============\n",
      "C: 1; penalty: l1; solver: newton-cg\n",
      "Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "============\n",
      "C: 1; penalty: l1; solver: lbfgs\n",
      "Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "============\n",
      "C: 1; penalty: l1; solver: liblinear\n",
      "[[323  43]\n",
      " [ 41  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88       366\n",
      "           1       0.64      0.65      0.64       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.76      0.76      0.76       482\n",
      "weighted avg       0.83      0.83      0.83       482\n",
      "\n",
      "============\n",
      "C: 1; penalty: l1; solver: sag\n",
      "Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "============\n",
      "C: 1; penalty: l1; solver: saga\n",
      "[[291  75]\n",
      " [ 26  90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.85       366\n",
      "           1       0.55      0.78      0.64       116\n",
      "\n",
      "    accuracy                           0.79       482\n",
      "   macro avg       0.73      0.79      0.75       482\n",
      "weighted avg       0.83      0.79      0.80       482\n",
      "\n",
      "============\n",
      "C: 1; penalty: l2; solver: newton-cg\n",
      "[[325  41]\n",
      " [ 41  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       366\n",
      "           1       0.65      0.65      0.65       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.77      0.77      0.77       482\n",
      "weighted avg       0.83      0.83      0.83       482\n",
      "\n",
      "============\n",
      "C: 1; penalty: l2; solver: lbfgs\n",
      "[[294  72]\n",
      " [ 35  81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.85       366\n",
      "           1       0.53      0.70      0.60       116\n",
      "\n",
      "    accuracy                           0.78       482\n",
      "   macro avg       0.71      0.75      0.72       482\n",
      "weighted avg       0.81      0.78      0.79       482\n",
      "\n",
      "============\n",
      "C: 1; penalty: l2; solver: liblinear\n",
      "[[325  41]\n",
      " [ 41  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       366\n",
      "           1       0.65      0.65      0.65       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.77      0.77      0.77       482\n",
      "weighted avg       0.83      0.83      0.83       482\n",
      "\n",
      "============\n",
      "C: 1; penalty: l2; solver: sag\n",
      "[[288  78]\n",
      " [ 26  90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85       366\n",
      "           1       0.54      0.78      0.63       116\n",
      "\n",
      "    accuracy                           0.78       482\n",
      "   macro avg       0.73      0.78      0.74       482\n",
      "weighted avg       0.83      0.78      0.80       482\n",
      "\n",
      "============\n",
      "C: 1; penalty: l2; solver: saga\n",
      "[[291  75]\n",
      " [ 26  90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.85       366\n",
      "           1       0.55      0.78      0.64       116\n",
      "\n",
      "    accuracy                           0.79       482\n",
      "   macro avg       0.73      0.79      0.75       482\n",
      "weighted avg       0.83      0.79      0.80       482\n",
      "\n",
      "============\n",
      "C: 1; penalty: elasticnet; solver: newton-cg\n",
      "Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "============\n",
      "C: 1; penalty: elasticnet; solver: lbfgs\n",
      "Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "============\n",
      "C: 1; penalty: elasticnet; solver: liblinear\n",
      "Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "============\n",
      "C: 1; penalty: elasticnet; solver: sag\n",
      "Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "============\n",
      "C: 1; penalty: elasticnet; solver: saga\n",
      "l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "============\n",
      "C: 1; penalty: none; solver: newton-cg\n",
      "[[326  40]\n",
      " [ 41  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       366\n",
      "           1       0.65      0.65      0.65       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.77      0.77      0.77       482\n",
      "weighted avg       0.83      0.83      0.83       482\n",
      "\n",
      "============\n",
      "C: 1; penalty: none; solver: lbfgs\n",
      "[[294  72]\n",
      " [ 28  88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85       366\n",
      "           1       0.55      0.76      0.64       116\n",
      "\n",
      "    accuracy                           0.79       482\n",
      "   macro avg       0.73      0.78      0.75       482\n",
      "weighted avg       0.83      0.79      0.80       482\n",
      "\n",
      "============\n",
      "C: 1; penalty: none; solver: liblinear\n",
      "penalty='none' is not supported for the liblinear solver\n",
      "============\n",
      "C: 1; penalty: none; solver: sag\n",
      "[[288  78]\n",
      " [ 26  90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85       366\n",
      "           1       0.54      0.78      0.63       116\n",
      "\n",
      "    accuracy                           0.78       482\n",
      "   macro avg       0.73      0.78      0.74       482\n",
      "weighted avg       0.83      0.78      0.80       482\n",
      "\n",
      "============\n",
      "C: 1; penalty: none; solver: saga\n",
      "[[291  75]\n",
      " [ 26  90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.85       366\n",
      "           1       0.55      0.78      0.64       116\n",
      "\n",
      "    accuracy                           0.79       482\n",
      "   macro avg       0.73      0.79      0.75       482\n",
      "weighted avg       0.83      0.79      0.80       482\n",
      "\n",
      "============\n",
      "C: 1.5; penalty: l1; solver: newton-cg\n",
      "Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "============\n",
      "C: 1.5; penalty: l1; solver: lbfgs\n",
      "Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "============\n",
      "C: 1.5; penalty: l1; solver: liblinear\n",
      "[[322  44]\n",
      " [ 41  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88       366\n",
      "           1       0.63      0.65      0.64       116\n",
      "\n",
      "    accuracy                           0.82       482\n",
      "   macro avg       0.76      0.76      0.76       482\n",
      "weighted avg       0.83      0.82      0.82       482\n",
      "\n",
      "============\n",
      "C: 1.5; penalty: l1; solver: sag\n",
      "Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "============\n",
      "C: 1.5; penalty: l1; solver: saga\n",
      "[[291  75]\n",
      " [ 26  90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.85       366\n",
      "           1       0.55      0.78      0.64       116\n",
      "\n",
      "    accuracy                           0.79       482\n",
      "   macro avg       0.73      0.79      0.75       482\n",
      "weighted avg       0.83      0.79      0.80       482\n",
      "\n",
      "============\n",
      "C: 1.5; penalty: l2; solver: newton-cg\n",
      "[[327  39]\n",
      " [ 41  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       366\n",
      "           1       0.66      0.65      0.65       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.77      0.77      0.77       482\n",
      "weighted avg       0.83      0.83      0.83       482\n",
      "\n",
      "============\n",
      "C: 1.5; penalty: l2; solver: lbfgs\n",
      "[[293  73]\n",
      " [ 33  83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.85       366\n",
      "           1       0.53      0.72      0.61       116\n",
      "\n",
      "    accuracy                           0.78       482\n",
      "   macro avg       0.72      0.76      0.73       482\n",
      "weighted avg       0.81      0.78      0.79       482\n",
      "\n",
      "============\n",
      "C: 1.5; penalty: l2; solver: liblinear\n",
      "[[327  39]\n",
      " [ 41  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       366\n",
      "           1       0.66      0.65      0.65       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.77      0.77      0.77       482\n",
      "weighted avg       0.83      0.83      0.83       482\n",
      "\n",
      "============\n",
      "C: 1.5; penalty: l2; solver: sag\n",
      "[[288  78]\n",
      " [ 26  90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85       366\n",
      "           1       0.54      0.78      0.63       116\n",
      "\n",
      "    accuracy                           0.78       482\n",
      "   macro avg       0.73      0.78      0.74       482\n",
      "weighted avg       0.83      0.78      0.80       482\n",
      "\n",
      "============\n",
      "C: 1.5; penalty: l2; solver: saga\n",
      "[[291  75]\n",
      " [ 26  90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.85       366\n",
      "           1       0.55      0.78      0.64       116\n",
      "\n",
      "    accuracy                           0.79       482\n",
      "   macro avg       0.73      0.79      0.75       482\n",
      "weighted avg       0.83      0.79      0.80       482\n",
      "\n",
      "============\n",
      "C: 1.5; penalty: elasticnet; solver: newton-cg\n",
      "Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "============\n",
      "C: 1.5; penalty: elasticnet; solver: lbfgs\n",
      "Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "============\n",
      "C: 1.5; penalty: elasticnet; solver: liblinear\n",
      "Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "============\n",
      "C: 1.5; penalty: elasticnet; solver: sag\n",
      "Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "============\n",
      "C: 1.5; penalty: elasticnet; solver: saga\n",
      "l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "============\n",
      "C: 1.5; penalty: none; solver: newton-cg\n",
      "[[326  40]\n",
      " [ 41  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       366\n",
      "           1       0.65      0.65      0.65       116\n",
      "\n",
      "    accuracy                           0.83       482\n",
      "   macro avg       0.77      0.77      0.77       482\n",
      "weighted avg       0.83      0.83      0.83       482\n",
      "\n",
      "============\n",
      "C: 1.5; penalty: none; solver: lbfgs\n",
      "[[294  72]\n",
      " [ 28  88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85       366\n",
      "           1       0.55      0.76      0.64       116\n",
      "\n",
      "    accuracy                           0.79       482\n",
      "   macro avg       0.73      0.78      0.75       482\n",
      "weighted avg       0.83      0.79      0.80       482\n",
      "\n",
      "============\n",
      "C: 1.5; penalty: none; solver: liblinear\n",
      "penalty='none' is not supported for the liblinear solver\n",
      "============\n",
      "C: 1.5; penalty: none; solver: sag\n",
      "[[288  78]\n",
      " [ 26  90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85       366\n",
      "           1       0.54      0.78      0.63       116\n",
      "\n",
      "    accuracy                           0.78       482\n",
      "   macro avg       0.73      0.78      0.74       482\n",
      "weighted avg       0.83      0.78      0.80       482\n",
      "\n",
      "============\n",
      "C: 1.5; penalty: none; solver: saga\n",
      "[[291  75]\n",
      " [ 26  90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.85       366\n",
      "           1       0.55      0.78      0.64       116\n",
      "\n",
      "    accuracy                           0.79       482\n",
      "   macro avg       0.73      0.79      0.75       482\n",
      "weighted avg       0.83      0.79      0.80       482\n",
      "\n",
      "============\n"
     ]
    }
   ],
   "source": [
    "for c in [0.5, 1, 1.5]:   \n",
    "    for penalty in [\"l1\", \"l2\", \"elasticnet\", \"none\"]:\n",
    "        for solver in [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]:\n",
    "        \n",
    "            print(f\"C: {c}; penalty: {penalty}; solver: {solver}\")\n",
    "            try:\n",
    "                logistic_regression_test(penalty, c, solver)\n",
    "            except ValueError as e:\n",
    "                print(e)\n",
    "            print(\"============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "931bc92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19098457888493475"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split['train'][\"Y\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e477ee5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [8.036, 1.786, 0.893, 4.464, 1.786, 4.464, 6.2...\n",
       "1    [3.906, 3.906, 0.781, 2.344, 1.562, 3.906, 4.6...\n",
       "2    [3.448, 1.724, 5.172, 2.586, 1.724, 4.31, 5.17...\n",
       "3    [6.667, 6.667, 4.167, 5.0, 1.667, 3.333, 3.333...\n",
       "4    [4.545, 6.061, 2.273, 5.303, 1.515, 1.515, 3.0...\n",
       "Name: Antibody, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = split[\"valid\"][\"Antibody\"].apply(descriptors_for_ab)\n",
    "X_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "badcef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.DataFrame(X_valid.to_list())\n",
    "\n",
    "df_valid.columns = df_valid.columns.astype(str)\n",
    "df_valid.to_feather(\"X_valid_data.ftr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c08665",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "Load data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb79bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff5208b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_feather(\"data/X_train_data.ftr\")\n",
    "X_test = pd.read_feather(\"data/X_test_data.ftr\")\n",
    "X_valid = pd.read_feather(\"data/X_valid_data.ftr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "455a2f02-989d-46eb-812e-6443beaa0c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>19750</th>\n",
       "      <th>19751</th>\n",
       "      <th>19752</th>\n",
       "      <th>19753</th>\n",
       "      <th>19754</th>\n",
       "      <th>19755</th>\n",
       "      <th>19756</th>\n",
       "      <th>19757</th>\n",
       "      <th>19758</th>\n",
       "      <th>19759</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12e8</td>\n",
       "      <td>7.500</td>\n",
       "      <td>3.333</td>\n",
       "      <td>2.500</td>\n",
       "      <td>5.833</td>\n",
       "      <td>1.667</td>\n",
       "      <td>5.833</td>\n",
       "      <td>5.833</td>\n",
       "      <td>9.167</td>\n",
       "      <td>1.667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15c8</td>\n",
       "      <td>9.244</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.882</td>\n",
       "      <td>1.681</td>\n",
       "      <td>4.202</td>\n",
       "      <td>6.723</td>\n",
       "      <td>8.403</td>\n",
       "      <td>2.521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a0q</td>\n",
       "      <td>5.882</td>\n",
       "      <td>1.681</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.042</td>\n",
       "      <td>1.681</td>\n",
       "      <td>5.882</td>\n",
       "      <td>5.042</td>\n",
       "      <td>9.244</td>\n",
       "      <td>1.681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a14</td>\n",
       "      <td>6.667</td>\n",
       "      <td>2.500</td>\n",
       "      <td>4.167</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.667</td>\n",
       "      <td>2.500</td>\n",
       "      <td>7.500</td>\n",
       "      <td>11.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a2y</td>\n",
       "      <td>3.448</td>\n",
       "      <td>5.172</td>\n",
       "      <td>4.310</td>\n",
       "      <td>6.034</td>\n",
       "      <td>1.724</td>\n",
       "      <td>2.586</td>\n",
       "      <td>6.034</td>\n",
       "      <td>10.345</td>\n",
       "      <td>0.862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 19761 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ab_ID      0      1      2      3      4      5      6       7      8  ...  \\\n",
       "0  12e8  7.500  3.333  2.500  5.833  1.667  5.833  5.833   9.167  1.667  ...   \n",
       "1  15c8  9.244  0.000  3.361  5.882  1.681  4.202  6.723   8.403  2.521  ...   \n",
       "2  1a0q  5.882  1.681  3.361  5.042  1.681  5.882  5.042   9.244  1.681  ...   \n",
       "3  1a14  6.667  2.500  4.167  5.000  1.667  2.500  7.500  11.667  0.000  ...   \n",
       "4  1a2y  3.448  5.172  4.310  6.034  1.724  2.586  6.034  10.345  0.862  ...   \n",
       "\n",
       "   19750  19751  19752  19753  19754  19755  19756  19757  19758  19759  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 19761 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a09d000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"data/chen_train_data.csv\", sep=\";\")\n",
    "data_valid = pd.read_csv(\"data/chen_valid_data.csv\", sep=\";\")\n",
    "data_test = pd.read_csv(\"data/chen_test_data.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3616c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings_reproduction import embedding_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aac037dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = [\"ACVMSTRDA\", \"FTSDACPLMTSST\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75b51baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = embedding_tools.get_embeddings_new('../embed_models/original_3_1.pkl', seqs, k=5, overlap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f37acdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.014781</td>\n",
       "      <td>-0.001247</td>\n",
       "      <td>0.268215</td>\n",
       "      <td>-0.027002</td>\n",
       "      <td>0.237463</td>\n",
       "      <td>-0.252756</td>\n",
       "      <td>-0.163913</td>\n",
       "      <td>-0.184446</td>\n",
       "      <td>0.089368</td>\n",
       "      <td>-0.120450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.21672</td>\n",
       "      <td>0.169656</td>\n",
       "      <td>-0.027164</td>\n",
       "      <td>-0.114215</td>\n",
       "      <td>0.051775</td>\n",
       "      <td>-0.236802</td>\n",
       "      <td>0.023171</td>\n",
       "      <td>-0.096376</td>\n",
       "      <td>0.160871</td>\n",
       "      <td>0.031065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.103935</td>\n",
       "      <td>-0.168398</td>\n",
       "      <td>-0.267852</td>\n",
       "      <td>0.095176</td>\n",
       "      <td>-0.052804</td>\n",
       "      <td>-0.036648</td>\n",
       "      <td>-0.306973</td>\n",
       "      <td>0.048839</td>\n",
       "      <td>0.099976</td>\n",
       "      <td>-0.174751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00361</td>\n",
       "      <td>0.022153</td>\n",
       "      <td>-0.147477</td>\n",
       "      <td>0.180707</td>\n",
       "      <td>-0.061898</td>\n",
       "      <td>0.054925</td>\n",
       "      <td>-0.154312</td>\n",
       "      <td>-0.003939</td>\n",
       "      <td>0.071967</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.014781 -0.001247  0.268215 -0.027002  0.237463 -0.252756 -0.163913   \n",
       "1 -0.103935 -0.168398 -0.267852  0.095176 -0.052804 -0.036648 -0.306973   \n",
       "\n",
       "         7         8         9   ...       54        55        56        57  \\\n",
       "0 -0.184446  0.089368 -0.120450  ... -0.21672  0.169656 -0.027164 -0.114215   \n",
       "1  0.048839  0.099976 -0.174751  ...  0.00361  0.022153 -0.147477  0.180707   \n",
       "\n",
       "         58        59        60        61        62        63  \n",
       "0  0.051775 -0.236802  0.023171 -0.096376  0.160871  0.031065  \n",
       "1 -0.061898  0.054925 -0.154312 -0.003939  0.071967  0.054054  \n",
       "\n",
       "[2 rows x 64 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08ea1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sequences(data, model_path, out_path, k=5, overlap=False):\n",
    "    embeds_data = []\n",
    "    split = data[\"Antibody\"].str.split()\n",
    "    heavy = [remove_excess(seqs[0]) for seqs in split]\n",
    "    light = [remove_excess(seqs[1]) for seqs in split]\n",
    "    for seqlist in [heavy, light]:\n",
    "        embeds = embedding_tools.get_embeddings(model_path, seqlist, k, overlap)\n",
    "        embeds_data.append(pd.DataFrame.from_records(embeds))\n",
    "    ncols = len(embeds_data[0].columns)\n",
    "    embeds_pd = pd.concat(embeds_data, axis=1)\n",
    "    embeds_pd.columns = [str(i) for i in range(ncols)] + [str(i) + \"_2\" for i in range(ncols)]\n",
    "    embeds_pd.insert(0, \"Ab_ID\", data[\"Antibody_ID\"])\n",
    "    #embeds_pd.to_csv(out_path, index=False)\n",
    "    embeds_pd.to_feather(out_path)\n",
    "    return embeds_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "424c21a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [mod_file for mod_file in os.listdir(\"../embed_models\") if mod_file.endswith(\".pkl\")]\n",
    "for model in models:\n",
    "    mod_name = model.split(\".\")[0]\n",
    "    outfile = f\"data/embeddings/embeddings_train_{mod_name}.ftr\"\n",
    "    k = int(mod_name.split(\"_\")[1])\n",
    "    w = int(mod_name.split(\"_\")[2])\n",
    "    df = embed_sequences(data_train, f\"../embed_models/{model}\", outfile, k=k)\n",
    "    #print(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cfcbfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    mod_name = model.split(\".\")[0]\n",
    "    outfile = f\"data/embeddings/embeddings_test_{mod_name}.ftr\"\n",
    "    k = int(mod_name.split(\"_\")[1])\n",
    "    w = int(mod_name.split(\"_\")[2])\n",
    "    df = embed_sequences(data_test, f\"../embed_models/{model}\", outfile, k=k)\n",
    "    #print(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c7d08b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    mod_name = model.split(\".\")[0]\n",
    "    outfile = f\"data/embeddings/embeddings_valid_{mod_name}.ftr\"\n",
    "    k = int(mod_name.split(\"_\")[1])\n",
    "    w = int(mod_name.split(\"_\")[2])\n",
    "    df = embed_sequences(data_valid, f\"../embed_models/{model}\", outfile, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30496672-c648-48aa-a44e-0e4dc4ab1182",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_train = pd.read_feather(\"data/embeddings/embeddings_train_original_3_1.ftr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5976559e-5b6d-414b-96ef-3b3507be2d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>54_2</th>\n",
       "      <th>55_2</th>\n",
       "      <th>56_2</th>\n",
       "      <th>57_2</th>\n",
       "      <th>58_2</th>\n",
       "      <th>59_2</th>\n",
       "      <th>60_2</th>\n",
       "      <th>61_2</th>\n",
       "      <th>62_2</th>\n",
       "      <th>63_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12e8</td>\n",
       "      <td>-0.119551</td>\n",
       "      <td>-0.081851</td>\n",
       "      <td>-0.074167</td>\n",
       "      <td>0.152037</td>\n",
       "      <td>0.129428</td>\n",
       "      <td>0.085095</td>\n",
       "      <td>-0.030417</td>\n",
       "      <td>-0.110267</td>\n",
       "      <td>0.075634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200469</td>\n",
       "      <td>-0.046869</td>\n",
       "      <td>-0.001064</td>\n",
       "      <td>0.103459</td>\n",
       "      <td>0.151518</td>\n",
       "      <td>-0.026898</td>\n",
       "      <td>-0.233277</td>\n",
       "      <td>0.051276</td>\n",
       "      <td>-0.014353</td>\n",
       "      <td>-0.304066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15c8</td>\n",
       "      <td>0.021530</td>\n",
       "      <td>-0.304652</td>\n",
       "      <td>-0.132556</td>\n",
       "      <td>0.061507</td>\n",
       "      <td>0.150677</td>\n",
       "      <td>0.098915</td>\n",
       "      <td>0.041480</td>\n",
       "      <td>-0.203386</td>\n",
       "      <td>0.016552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045949</td>\n",
       "      <td>-0.127985</td>\n",
       "      <td>0.078211</td>\n",
       "      <td>0.220624</td>\n",
       "      <td>-0.137954</td>\n",
       "      <td>-0.084574</td>\n",
       "      <td>-0.039934</td>\n",
       "      <td>0.067366</td>\n",
       "      <td>-0.051279</td>\n",
       "      <td>-0.253232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a0q</td>\n",
       "      <td>0.039578</td>\n",
       "      <td>-0.165334</td>\n",
       "      <td>-0.022410</td>\n",
       "      <td>-0.080268</td>\n",
       "      <td>0.047611</td>\n",
       "      <td>0.048944</td>\n",
       "      <td>0.080545</td>\n",
       "      <td>-0.236821</td>\n",
       "      <td>0.112831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057385</td>\n",
       "      <td>-0.050525</td>\n",
       "      <td>0.202889</td>\n",
       "      <td>0.261739</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>-0.052941</td>\n",
       "      <td>-0.150026</td>\n",
       "      <td>0.250437</td>\n",
       "      <td>0.170185</td>\n",
       "      <td>-0.221552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a14</td>\n",
       "      <td>0.120464</td>\n",
       "      <td>-0.081033</td>\n",
       "      <td>-0.107538</td>\n",
       "      <td>0.061656</td>\n",
       "      <td>0.173956</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>0.124448</td>\n",
       "      <td>-0.198621</td>\n",
       "      <td>0.236676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143312</td>\n",
       "      <td>-0.143539</td>\n",
       "      <td>0.047924</td>\n",
       "      <td>0.310107</td>\n",
       "      <td>0.048446</td>\n",
       "      <td>-0.046024</td>\n",
       "      <td>-0.050520</td>\n",
       "      <td>-0.020289</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>-0.186632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a2y</td>\n",
       "      <td>0.014664</td>\n",
       "      <td>-0.076477</td>\n",
       "      <td>-0.047139</td>\n",
       "      <td>0.041975</td>\n",
       "      <td>0.182140</td>\n",
       "      <td>0.069364</td>\n",
       "      <td>0.023516</td>\n",
       "      <td>-0.239836</td>\n",
       "      <td>-0.025285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028963</td>\n",
       "      <td>-0.108840</td>\n",
       "      <td>0.098158</td>\n",
       "      <td>0.180053</td>\n",
       "      <td>0.178013</td>\n",
       "      <td>0.103138</td>\n",
       "      <td>-0.067108</td>\n",
       "      <td>0.154135</td>\n",
       "      <td>0.236273</td>\n",
       "      <td>-0.290542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ab_ID         0         1         2         3         4         5         6  \\\n",
       "0  12e8 -0.119551 -0.081851 -0.074167  0.152037  0.129428  0.085095 -0.030417   \n",
       "1  15c8  0.021530 -0.304652 -0.132556  0.061507  0.150677  0.098915  0.041480   \n",
       "2  1a0q  0.039578 -0.165334 -0.022410 -0.080268  0.047611  0.048944  0.080545   \n",
       "3  1a14  0.120464 -0.081033 -0.107538  0.061656  0.173956  0.004049  0.124448   \n",
       "4  1a2y  0.014664 -0.076477 -0.047139  0.041975  0.182140  0.069364  0.023516   \n",
       "\n",
       "          7         8  ...      54_2      55_2      56_2      57_2      58_2  \\\n",
       "0 -0.110267  0.075634  ...  0.200469 -0.046869 -0.001064  0.103459  0.151518   \n",
       "1 -0.203386  0.016552  ... -0.045949 -0.127985  0.078211  0.220624 -0.137954   \n",
       "2 -0.236821  0.112831  ...  0.057385 -0.050525  0.202889  0.261739  0.002610   \n",
       "3 -0.198621  0.236676  ... -0.143312 -0.143539  0.047924  0.310107  0.048446   \n",
       "4 -0.239836 -0.025285  ... -0.028963 -0.108840  0.098158  0.180053  0.178013   \n",
       "\n",
       "       59_2      60_2      61_2      62_2      63_2  \n",
       "0 -0.026898 -0.233277  0.051276 -0.014353 -0.304066  \n",
       "1 -0.084574 -0.039934  0.067366 -0.051279 -0.253232  \n",
       "2 -0.052941 -0.150026  0.250437  0.170185 -0.221552  \n",
       "3 -0.046024 -0.050520 -0.020289  0.010511 -0.186632  \n",
       "4  0.103138 -0.067108  0.154135  0.236273 -0.290542  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec7f09a0-cc36-48c7-9fc2-7ca7ccdd04ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19750</th>\n",
       "      <th>19751</th>\n",
       "      <th>19752</th>\n",
       "      <th>19753</th>\n",
       "      <th>19754</th>\n",
       "      <th>19755</th>\n",
       "      <th>19756</th>\n",
       "      <th>19757</th>\n",
       "      <th>19758</th>\n",
       "      <th>19759</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.500</td>\n",
       "      <td>3.333</td>\n",
       "      <td>2.500</td>\n",
       "      <td>5.833</td>\n",
       "      <td>1.667</td>\n",
       "      <td>5.833</td>\n",
       "      <td>5.833</td>\n",
       "      <td>9.167</td>\n",
       "      <td>1.667</td>\n",
       "      <td>4.167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.244</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.882</td>\n",
       "      <td>1.681</td>\n",
       "      <td>4.202</td>\n",
       "      <td>6.723</td>\n",
       "      <td>8.403</td>\n",
       "      <td>2.521</td>\n",
       "      <td>3.361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.882</td>\n",
       "      <td>1.681</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.042</td>\n",
       "      <td>1.681</td>\n",
       "      <td>5.882</td>\n",
       "      <td>5.042</td>\n",
       "      <td>9.244</td>\n",
       "      <td>1.681</td>\n",
       "      <td>4.202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.667</td>\n",
       "      <td>2.500</td>\n",
       "      <td>4.167</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.667</td>\n",
       "      <td>2.500</td>\n",
       "      <td>7.500</td>\n",
       "      <td>11.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.448</td>\n",
       "      <td>5.172</td>\n",
       "      <td>4.310</td>\n",
       "      <td>6.034</td>\n",
       "      <td>1.724</td>\n",
       "      <td>2.586</td>\n",
       "      <td>6.034</td>\n",
       "      <td>10.345</td>\n",
       "      <td>0.862</td>\n",
       "      <td>2.586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 19760 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6       7      8      9  ...  \\\n",
       "0  7.500  3.333  2.500  5.833  1.667  5.833  5.833   9.167  1.667  4.167  ...   \n",
       "1  9.244  0.000  3.361  5.882  1.681  4.202  6.723   8.403  2.521  3.361  ...   \n",
       "2  5.882  1.681  3.361  5.042  1.681  5.882  5.042   9.244  1.681  4.202  ...   \n",
       "3  6.667  2.500  4.167  5.000  1.667  2.500  7.500  11.667  0.000  1.667  ...   \n",
       "4  3.448  5.172  4.310  6.034  1.724  2.586  6.034  10.345  0.862  2.586  ...   \n",
       "\n",
       "   19750  19751  19752  19753  19754  19755  19756  19757  19758  19759  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 19760 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5c71f48-bd0d-4c8b-a510-3dc475cd59fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>19750</th>\n",
       "      <th>19751</th>\n",
       "      <th>19752</th>\n",
       "      <th>19753</th>\n",
       "      <th>19754</th>\n",
       "      <th>19755</th>\n",
       "      <th>19756</th>\n",
       "      <th>19757</th>\n",
       "      <th>19758</th>\n",
       "      <th>19759</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12e8</td>\n",
       "      <td>7.500</td>\n",
       "      <td>3.333</td>\n",
       "      <td>2.500</td>\n",
       "      <td>5.833</td>\n",
       "      <td>1.667</td>\n",
       "      <td>5.833</td>\n",
       "      <td>5.833</td>\n",
       "      <td>9.167</td>\n",
       "      <td>1.667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15c8</td>\n",
       "      <td>9.244</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.882</td>\n",
       "      <td>1.681</td>\n",
       "      <td>4.202</td>\n",
       "      <td>6.723</td>\n",
       "      <td>8.403</td>\n",
       "      <td>2.521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a0q</td>\n",
       "      <td>5.882</td>\n",
       "      <td>1.681</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.042</td>\n",
       "      <td>1.681</td>\n",
       "      <td>5.882</td>\n",
       "      <td>5.042</td>\n",
       "      <td>9.244</td>\n",
       "      <td>1.681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a14</td>\n",
       "      <td>6.667</td>\n",
       "      <td>2.500</td>\n",
       "      <td>4.167</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.667</td>\n",
       "      <td>2.500</td>\n",
       "      <td>7.500</td>\n",
       "      <td>11.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a2y</td>\n",
       "      <td>3.448</td>\n",
       "      <td>5.172</td>\n",
       "      <td>4.310</td>\n",
       "      <td>6.034</td>\n",
       "      <td>1.724</td>\n",
       "      <td>2.586</td>\n",
       "      <td>6.034</td>\n",
       "      <td>10.345</td>\n",
       "      <td>0.862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 19761 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ab_ID      0      1      2      3      4      5      6       7      8  ...  \\\n",
       "0  12e8  7.500  3.333  2.500  5.833  1.667  5.833  5.833   9.167  1.667  ...   \n",
       "1  15c8  9.244  0.000  3.361  5.882  1.681  4.202  6.723   8.403  2.521  ...   \n",
       "2  1a0q  5.882  1.681  3.361  5.042  1.681  5.882  5.042   9.244  1.681  ...   \n",
       "3  1a14  6.667  2.500  4.167  5.000  1.667  2.500  7.500  11.667  0.000  ...   \n",
       "4  1a2y  3.448  5.172  4.310  6.034  1.724  2.586  6.034  10.345  0.862  ...   \n",
       "\n",
       "   19750  19751  19752  19753  19754  19755  19756  19757  19758  19759  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 19761 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.insert(0, \"Ab_ID\", data_train[\"Antibody_ID\"])\n",
    "X_test.insert(0, \"Ab_ID\", data_test[\"Antibody_ID\"])\n",
    "X_valid.insert(0, \"Ab_ID\", data_valid[\"Antibody_ID\"])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4d9d47e-d4d8-4dff-8eab-402878273160",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_feather(\"data/X_train_data.ftr\")\n",
    "X_test.to_feather(\"data/X_test_data.ftr\")\n",
    "X_valid.to_feather(\"data/X_valid_data.ftr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93590f8-0f27-4eab-98c6-d1e665e390e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334ee06c-ff85-4613-a38f-af965b01f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abnumber import Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f955e-770e-4753-a37c-63a4b41a8da7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
