{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aaac5ca7-e11d-4cef-8594-dc61e039f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.fixes import loguniform    \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e4ae71e-a22d-4cb6-919a-2d8e8cfad1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9a0b37d-bdb0-4a78-8caa-03ff89c08072",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_DIR = \"2021-12-03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "604e7e5b-1fac-49b4-b2a5-764ed1d46e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...</td>\n",
       "      <td>DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...</td>\n",
       "      <td>DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Antibody_ID                                              heavy  \\\n",
       "2073        6aod  EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...   \n",
       "1517        4yny  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2025        5xcv  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2070        6and  EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...   \n",
       "666         2xqy  QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...   \n",
       "\n",
       "                                                  light  Y  \n",
       "2073  DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...  0  \n",
       "1517  EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2025  QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2070  DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...  1  \n",
       "666   DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...  0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_train = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_train_data.csv\"), index_col=0)\n",
    "chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afda5620-8cda-4a38-b06e-1a3b0659e0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>Y</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>6ct7</td>\n",
       "      <td>EVQLVESGGGLVEPGGSLRLSCAVSGFDFEKAWMSWVRQAPGQGLQ...</td>\n",
       "      <td>SYELTQPPSVSVSPGQTARITCSGEALPMQFAHWYQQRPGKAPVIV...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>4nzu</td>\n",
       "      <td>AVSLVESGGGTVEPGSTLRLSCAASGFTFGSYAFHWVRQAPGDGLE...</td>\n",
       "      <td>DIEMTQSPSSLSASTGDKVTITCQASQDIAKFLDWYQQRPGKTPKL...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>5i8c</td>\n",
       "      <td>QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...</td>\n",
       "      <td>DIQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNL...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>5i8e</td>\n",
       "      <td>QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...</td>\n",
       "      <td>IQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNLL...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>6bb4</td>\n",
       "      <td>QVQLQQSDAELVKPGASVKISCKASGYTFTDRTIHWVKQRPEQGLE...</td>\n",
       "      <td>DVQMIQSPSSLSASLGDIVTMTCQASQDTSINLNWFQQKPGKAPKL...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Antibody_ID                                              heavy  \\\n",
       "2169        6ct7  EVQLVESGGGLVEPGGSLRLSCAVSGFDFEKAWMSWVRQAPGQGLQ...   \n",
       "1342        4nzu  AVSLVESGGGTVEPGSTLRLSCAASGFTFGSYAFHWVRQAPGDGLE...   \n",
       "1728        5i8c  QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...   \n",
       "1729        5i8e  QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...   \n",
       "2114        6bb4  QVQLQQSDAELVKPGASVKISCKASGYTFTDRTIHWVKQRPEQGLE...   \n",
       "\n",
       "                                                  light  Y  Unnamed: 0  \n",
       "2169  SYELTQPPSVSVSPGQTARITCSGEALPMQFAHWYQQRPGKAPVIV...  0         NaN  \n",
       "1342  DIEMTQSPSSLSASTGDKVTITCQASQDIAKFLDWYQQRPGKTPKL...  0         NaN  \n",
       "1728  DIQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNL...  1         NaN  \n",
       "1729  IQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNLL...  0         NaN  \n",
       "2114  DVQMIQSPSSLSASLGDIVTMTCQASQDTSINLNWFQQKPGKAPKL...  0         NaN  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_valid = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_valid_data.csv\"), index_col=0)\n",
    "chen_test = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_test_data.csv\"))\n",
    "chen_valid = pd.concat([chen_valid, chen_test])\n",
    "chen_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "083e69c0-1ebf-41c8-a4d3-782f364696d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>CDR_length</th>\n",
       "      <th>PSH</th>\n",
       "      <th>PPC</th>\n",
       "      <th>PNC</th>\n",
       "      <th>SFvCSP</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abagovomab</td>\n",
       "      <td>QVKLQESGAELARPGASVKLSCKASGYTFTNYWMQWVKQRPGQGLD...</td>\n",
       "      <td>DIELTQSPASLSASVGETVTITCQASENIYSYLAWHQQKQGKSPQL...</td>\n",
       "      <td>46</td>\n",
       "      <td>129.7603</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abituzumab</td>\n",
       "      <td>QVQLQQSGGELAKPGASVKVSCKASGYTFSSFWMHWVRQAPGQGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQDISNYLAWYQQKPGKAPKL...</td>\n",
       "      <td>45</td>\n",
       "      <td>115.9106</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>-3.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrilumab</td>\n",
       "      <td>QVQLVQSGAEVKKPGASVKVSCKVSGYTLSDLSIHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQQKPGKAPKL...</td>\n",
       "      <td>45</td>\n",
       "      <td>109.6995</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actoxumab</td>\n",
       "      <td>QVQLVESGGGVVQPGRSLRLSCAASGFSFSNYGMHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQHKPGKAPKL...</td>\n",
       "      <td>49</td>\n",
       "      <td>112.6290</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.1247</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adalimumab</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLRLSCAASGFTFDDYAMHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQGIRNYLAWYQQKPGKAPKL...</td>\n",
       "      <td>48</td>\n",
       "      <td>111.2512</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>1.1364</td>\n",
       "      <td>-19.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Antibody_ID                                              heavy  \\\n",
       "0  Abagovomab  QVKLQESGAELARPGASVKLSCKASGYTFTNYWMQWVKQRPGQGLD...   \n",
       "1  Abituzumab  QVQLQQSGGELAKPGASVKVSCKASGYTFSSFWMHWVRQAPGQGLE...   \n",
       "2   Abrilumab  QVQLVQSGAEVKKPGASVKVSCKVSGYTLSDLSIHWVRQAPGKGLE...   \n",
       "3   Actoxumab  QVQLVESGGGVVQPGRSLRLSCAASGFSFSNYGMHWVRQAPGKGLE...   \n",
       "4  Adalimumab  EVQLVESGGGLVQPGRSLRLSCAASGFTFDDYAMHWVRQAPGKGLE...   \n",
       "\n",
       "                                               light  CDR_length       PSH  \\\n",
       "0  DIELTQSPASLSASVGETVTITCQASENIYSYLAWHQQKQGKSPQL...          46  129.7603   \n",
       "1  DIQMTQSPSSLSASVGDRVTITCRASQDISNYLAWYQQKPGKAPKL...          45  115.9106   \n",
       "2  DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQQKPGKAPKL...          45  109.6995   \n",
       "3  DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQHKPGKAPKL...          49  112.6290   \n",
       "4  DIQMTQSPSSLSASVGDRVTITCRASQGIRNYLAWYQQKPGKAPKL...          48  111.2512   \n",
       "\n",
       "      PPC     PNC  SFvCSP  Y  \n",
       "0  0.0000  0.0000   16.32  1  \n",
       "1  0.0954  0.0421   -3.10  1  \n",
       "2  0.0000  0.8965   -4.00  1  \n",
       "3  0.0000  1.1247    3.10  1  \n",
       "4  0.0485  1.1364  -19.50  1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tap_data = pd.read_csv(path.join(DATA_DIR, \"tap/TAP_data.csv\"))\n",
    "tap_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78bcad1b-5d12-4db8-b944-a7ef47b0051e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>2398</th>\n",
       "      <th>2400</th>\n",
       "      <th>2401</th>\n",
       "      <th>2402</th>\n",
       "      <th>2403</th>\n",
       "      <th>2404</th>\n",
       "      <th>2405</th>\n",
       "      <th>2406</th>\n",
       "      <th>2407</th>\n",
       "      <th>2408</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.77700</td>\n",
       "      <td>0.70350</td>\n",
       "      <td>0.69995</td>\n",
       "      <td>0.65085</td>\n",
       "      <td>0.67350</td>\n",
       "      <td>0.66915</td>\n",
       "      <td>0.66915</td>\n",
       "      <td>0.76100</td>\n",
       "      <td>0.71800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59250</td>\n",
       "      <td>0.63185</td>\n",
       "      <td>0.65150</td>\n",
       "      <td>0.61850</td>\n",
       "      <td>0.70070</td>\n",
       "      <td>0.60550</td>\n",
       "      <td>0.54015</td>\n",
       "      <td>0.70460</td>\n",
       "      <td>0.61020</td>\n",
       "      <td>0.62840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.77700</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>0.69315</td>\n",
       "      <td>0.70240</td>\n",
       "      <td>0.65570</td>\n",
       "      <td>0.65570</td>\n",
       "      <td>0.74785</td>\n",
       "      <td>0.79775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59600</td>\n",
       "      <td>0.65265</td>\n",
       "      <td>0.67200</td>\n",
       "      <td>0.63085</td>\n",
       "      <td>0.69350</td>\n",
       "      <td>0.60750</td>\n",
       "      <td>0.55310</td>\n",
       "      <td>0.71665</td>\n",
       "      <td>0.63920</td>\n",
       "      <td>0.63185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.70350</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.76100</td>\n",
       "      <td>0.69315</td>\n",
       "      <td>0.68970</td>\n",
       "      <td>0.64550</td>\n",
       "      <td>0.64550</td>\n",
       "      <td>0.70850</td>\n",
       "      <td>0.72070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.55975</td>\n",
       "      <td>0.60500</td>\n",
       "      <td>0.65050</td>\n",
       "      <td>0.62120</td>\n",
       "      <td>0.69350</td>\n",
       "      <td>0.58815</td>\n",
       "      <td>0.55555</td>\n",
       "      <td>0.69965</td>\n",
       "      <td>0.57580</td>\n",
       "      <td>0.60875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.69995</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>0.76100</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.66160</td>\n",
       "      <td>0.68700</td>\n",
       "      <td>0.65500</td>\n",
       "      <td>0.65500</td>\n",
       "      <td>0.68315</td>\n",
       "      <td>0.71335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57800</td>\n",
       "      <td>0.63665</td>\n",
       "      <td>0.65900</td>\n",
       "      <td>0.61900</td>\n",
       "      <td>0.70700</td>\n",
       "      <td>0.59300</td>\n",
       "      <td>0.54950</td>\n",
       "      <td>0.67185</td>\n",
       "      <td>0.58200</td>\n",
       "      <td>0.61370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.65085</td>\n",
       "      <td>0.69315</td>\n",
       "      <td>0.69315</td>\n",
       "      <td>0.66160</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.63025</td>\n",
       "      <td>0.64000</td>\n",
       "      <td>0.64000</td>\n",
       "      <td>0.64965</td>\n",
       "      <td>0.68375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62485</td>\n",
       "      <td>0.64180</td>\n",
       "      <td>0.60255</td>\n",
       "      <td>0.60010</td>\n",
       "      <td>0.67985</td>\n",
       "      <td>0.61990</td>\n",
       "      <td>0.54340</td>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.62135</td>\n",
       "      <td>0.63570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1577 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2        3        4        5        7        8  \\\n",
       "0  1.00000  0.77700  0.70350  0.69995  0.65085  0.67350  0.66915  0.66915   \n",
       "1  0.77700  1.00000  0.75000  0.73500  0.69315  0.70240  0.65570  0.65570   \n",
       "2  0.70350  0.75000  1.00000  0.76100  0.69315  0.68970  0.64550  0.64550   \n",
       "3  0.69995  0.73500  0.76100  1.00000  0.66160  0.68700  0.65500  0.65500   \n",
       "4  0.65085  0.69315  0.69315  0.66160  1.00000  0.63025  0.64000  0.64000   \n",
       "\n",
       "         9       10  ...     2398     2400     2401     2402     2403  \\\n",
       "0  0.76100  0.71800  ...  0.59250  0.63185  0.65150  0.61850  0.70070   \n",
       "1  0.74785  0.79775  ...  0.59600  0.65265  0.67200  0.63085  0.69350   \n",
       "2  0.70850  0.72070  ...  0.55975  0.60500  0.65050  0.62120  0.69350   \n",
       "3  0.68315  0.71335  ...  0.57800  0.63665  0.65900  0.61900  0.70700   \n",
       "4  0.64965  0.68375  ...  0.62485  0.64180  0.60255  0.60010  0.67985   \n",
       "\n",
       "      2404     2405     2406     2407     2408  \n",
       "0  0.60550  0.54015  0.70460  0.61020  0.62840  \n",
       "1  0.60750  0.55310  0.71665  0.63920  0.63185  \n",
       "2  0.58815  0.55555  0.69965  0.57580  0.60875  \n",
       "3  0.59300  0.54950  0.67185  0.58200  0.61370  \n",
       "4  0.61990  0.54340  0.76250  0.62135  0.63570  \n",
       "\n",
       "[5 rows x 1577 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_similarity = pd.read_csv(path.join(DATA_DIR, \"chen/distances/deduplicated_anarci_similarity.csv\"), index_col=0)\n",
    "chen_similarity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a446fa1e-23fa-4fe8-b050-cf63068babaa",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6932d103-cb55-4cee-ad8e-57ac473e1e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "chen_train = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_train_data_w_clusters.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48e54805-8fec-472f-a4c9-fcc2f15022ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    3\n",
       "2    3\n",
       "3    4\n",
       "4    4\n",
       "Name: cluster_merged, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_train[\"cluster_merged\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de8365-c6c4-4b79-837e-e6211b19382f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38f59f95-95e6-4674-91f2-0c0ec62cc977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different usage from the other models\n",
    "def knn(n):\n",
    "    model = NearestNeighbors(metric=\"precomputed\")\n",
    "    parameters = {'n_neighbors': [1,3,5]}\n",
    "    return model, parameters, \"kNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf100a-6da8-4b89-a9be-8259631741db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "abcd2b91-90cc-44cb-bd99-6d7f5ddada56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(n):\n",
    "    lr = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "    parameters = {'C':loguniform(0.001, 1000), 'penalty': [\"l2\"], \"solver\": [\"lbfgs\", \"sag\"]}\n",
    "    return lr, parameters, \"logistic_regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a4026c4-0b4f-4c6e-b1f1-4f72640506d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(n):\n",
    "    rf = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "    parameters = {'n_estimators': np.arange(1, 200, 10), 'max_depth': np.arange(1, min(50,n), 2), \n",
    "                  'max_features': np.arange(0.1, 0.75, 0.05)}\n",
    "    return rf, parameters, \"random_forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee462921-baee-4031-81ab-70a55154c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(n):\n",
    "    mlp = MLPClassifier(random_state=42, max_iter=int(1000))\n",
    "    parameters = {'hidden_layer_sizes': [(100,), (50,), (100, 100)], \"activation\": [\"relu\", \"logistic\"]}\n",
    "    return mlp, parameters, \"multilayer_perceptron\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de36f9d6-9b40-4420-b4eb-27f540feb1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(n):\n",
    "    svc = SVC(max_iter=8000, probability=True, class_weight='balanced')\n",
    "    parameters = {'C': loguniform(0.001, 100), 'kernel':[\"linear\", \"rbf\"], 'gamma': loguniform(1e-3, 1e0)}\n",
    "    return svc, parameters, \"SVM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11c6c12c-77ad-4b1c-96a0-b0190535f978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting(n):\n",
    "    gb = GradientBoostingClassifier(random_state=42, n_iter_no_change=70)\n",
    "    parameters = {'learning_rate': loguniform(0.01, 0.5), \n",
    "                  'n_estimators': np.arange(1, 200, 10), \n",
    "                  'max_depth': np.arange(1, min(20,n), 2), \n",
    "                  'max_features': np.arange(0.1, 0.6, 0.1)}\n",
    "    return gb, parameters, \"gradient_boosting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522bdca9-8b15-41b5-ba27-4043bae9924a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f49eab4-1c92-401f-8aca-ef05d4e52ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_evaluation(model_type, params, best_params, metrics, data, outpath, preprocessing=None):\n",
    "    prepro = \"_\"+preprocessing if preprocessing is not None else \"\"\n",
    "    filename = os.path.join(DATA_DIR, \"evaluations\", outpath, f\"{model_type}_{data}{prepro}.json\")\n",
    "    out_dict = {\n",
    "        \"model_type\": model_type,\n",
    "        \"data\": data\n",
    "    }\n",
    "    out_dict[\"params\"] = {}\n",
    "    out_dict[\"best_params\"] = {}\n",
    "    for key, value in params.items():\n",
    "        out_dict[\"params\"][key] = str(value)\n",
    "    for key, value in best_params.items():\n",
    "        out_dict[\"best_params\"][key] = str(value)\n",
    "    out_dict[\"metrics\"] = metrics\n",
    "    out_dict[\"preprocessing\"] = \"none\" if preprocessing is None else preprocessing\n",
    "    \n",
    "    json.dump(out_dict, open(filename, \"w\"))\n",
    "    \n",
    "    filename_sum = os.path.join(DATA_DIR, f\"evaluations/{outpath}/all.csv\")\n",
    "    #\"../evaluations/all.csv\"\n",
    "    line = [model_type, data, out_dict[\"preprocessing\"], metrics[\"f1\"], metrics[\"mcc\"], metrics[\"acc\"],metrics[\"precision\"],metrics[\"recall\"],metrics[\"auc\"], filename]\n",
    "    with open(filename_sum, 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter='\\t')\n",
    "        csvwriter.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96bd4c58-b7dd-49f2-bf3d-39b3938f6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(model_name, classifier, parameters, X_train, y_train, X_valid, y_valid, groups,\n",
    "                   data_name, outpath, preprocessing=None):\n",
    "    splitter = LeaveOneGroupOut()\n",
    "    split = splitter.split(X_train, y_train, groups=groups)\n",
    "    grid = RandomizedSearchCV(classifier, parameters, verbose=1, scoring=\"f1\", cv=split)\n",
    "    grid.fit(X_train, y_train)\n",
    "    estimator = grid.best_estimator_\n",
    "    best_params = grid.best_params_\n",
    "    y_pred = estimator.predict(X_valid)\n",
    "    prepro = \"_\"+preprocessing if preprocessing is not None else \"\"\n",
    "    filename = path.join(DATA_DIR, \"evaluations\", outpath, \"models\", f\"{model_name}_{data_name}{prepro}.pkl\")\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(estimator, f)\n",
    "    #pickle.dump(estimator, open(filename, \"w\"))\n",
    "    metric_dict = {\n",
    "        \"f1\": float(metrics.f1_score(y_valid, y_pred)),\n",
    "        \"acc\": float(metrics.accuracy_score(y_valid, y_pred)),\n",
    "        \"mcc\": float(metrics.matthews_corrcoef(y_valid, y_pred)),\n",
    "        \"auc\": float(metrics.roc_auc_score(y_valid, y_pred)),\n",
    "        \"precision\": float(metrics.precision_score(y_valid, y_pred)),\n",
    "        \"recall\": float(metrics.recall_score(y_valid, y_pred))\n",
    "    }\n",
    "    \n",
    "    print(f\"{model_name}, {data_name}\")\n",
    "    print(f\"F1: {metric_dict['f1']}\")\n",
    "    print(f\"MCC: {metric_dict['mcc']}\")\n",
    "    print(f\"Accuracy: {metric_dict['acc']}\")\n",
    "    print(f\"Precision: {metric_dict['precision']}\")\n",
    "    print(f\"Recall: {metric_dict['recall']}\")\n",
    "    print(f\"AUC: {metric_dict['auc']}\")\n",
    "    print(f\"-----\")\n",
    "    \n",
    "    output_evaluation(model_name, parameters, best_params, metric_dict, data_name, outpath, preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e30d50ba-ac70-40e7-9664-72a812e09efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all(X_train, y_train, X_valid, y_valid, groups, data_name, outpath, preprocessing=None):\n",
    "    n = len(y_train)\n",
    "    for model_creator in [logistic_regression, random_forest, gradient_boosting, svm, multilayer_perceptron]:\n",
    "        classifier, params, model_label = model_creator(n)\n",
    "        print(\"\\n\")\n",
    "        print(f'Training model {model_label} on data {data_name} \\n')\n",
    "        train_and_eval(model_label, classifier, params, X_train, y_train, X_valid, y_valid, groups, \n",
    "                   data_name, outpath, preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d4f9391-7024-44ed-894b-94977569f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_tap(model_name, x_test, y_test,\n",
    "                   data_name, outpath, preprocessing=None):\n",
    "    prepro = \"_\"+preprocessing if preprocessing is not None else \"\"\n",
    "    filename = path.join(DATA_DIR, \"evaluations\", outpath, \"models\", f\"{model_name}_{data_name}{prepro}.pkl\")\n",
    "    with open(filename, 'rb') as f:\n",
    "        estimator = pickle.load(f)\n",
    "    y_pred = estimator.predict(x_test)\n",
    "    metric_dict = {\n",
    "        \"f1\": float(metrics.f1_score(y_test, y_pred)),\n",
    "        \"acc\": float(metrics.accuracy_score(y_test, y_pred)),\n",
    "        \"mcc\": float(metrics.matthews_corrcoef(y_test, y_pred)),\n",
    "        \"auc\": float(metrics.roc_auc_score(y_test, y_pred)),\n",
    "        \"precision\": float(metrics.precision_score(y_test, y_pred)),\n",
    "        \"recall\": float(metrics.recall_score(y_test, y_pred))\n",
    "    }\n",
    "    filename_sum = os.path.join(DATA_DIR, f\"evaluations/{outpath}/tap.csv\")\n",
    "    line = [model_name, data_name, prepro, metric_dict[\"f1\"], metric_dict[\"mcc\"], metric_dict[\"acc\"],metric_dict[\"precision\"],metric_dict[\"recall\"],metric_dict[\"auc\"], filename]\n",
    "    with open(filename_sum, 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter='\\t')\n",
    "        csvwriter.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6513aa7-f94c-4eb9-820d-510782accecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all(x_test, y_test, data_name, outpath, preprocessing=None):\n",
    "    for model in [\"logistic_regression\", \"random_forest\", \"gradient_boosting\", \"SVM\", \"multilayer_perceptron\"]:\n",
    "        print(f\"Testing model {model} on {data_name}...\")\n",
    "        test_on_tap(model, x_test, y_test, data_name, outpath, preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a14fdc-99e4-4748-822d-88fddfb49f52",
   "metadata": {},
   "source": [
    "# PyBioMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "544a4e36-4667-41e9-9602-f418aa27a636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>19750</th>\n",
       "      <th>19751</th>\n",
       "      <th>19752</th>\n",
       "      <th>19753</th>\n",
       "      <th>19754</th>\n",
       "      <th>19755</th>\n",
       "      <th>19756</th>\n",
       "      <th>19757</th>\n",
       "      <th>19758</th>\n",
       "      <th>19759</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12e8</td>\n",
       "      <td>7.500</td>\n",
       "      <td>3.333</td>\n",
       "      <td>2.500</td>\n",
       "      <td>5.833</td>\n",
       "      <td>1.667</td>\n",
       "      <td>5.833</td>\n",
       "      <td>5.833</td>\n",
       "      <td>9.167</td>\n",
       "      <td>1.667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15c8</td>\n",
       "      <td>9.244</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.882</td>\n",
       "      <td>1.681</td>\n",
       "      <td>4.202</td>\n",
       "      <td>6.723</td>\n",
       "      <td>8.403</td>\n",
       "      <td>2.521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a0q</td>\n",
       "      <td>5.882</td>\n",
       "      <td>1.681</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.042</td>\n",
       "      <td>1.681</td>\n",
       "      <td>5.882</td>\n",
       "      <td>5.042</td>\n",
       "      <td>9.244</td>\n",
       "      <td>1.681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a14</td>\n",
       "      <td>6.667</td>\n",
       "      <td>2.500</td>\n",
       "      <td>4.167</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.667</td>\n",
       "      <td>2.500</td>\n",
       "      <td>7.500</td>\n",
       "      <td>11.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a2y</td>\n",
       "      <td>3.448</td>\n",
       "      <td>5.172</td>\n",
       "      <td>4.310</td>\n",
       "      <td>6.034</td>\n",
       "      <td>1.724</td>\n",
       "      <td>2.586</td>\n",
       "      <td>6.034</td>\n",
       "      <td>10.345</td>\n",
       "      <td>0.862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19761 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ab_ID      0      1      2      3      4      5      6       7      8  ...  \\\n",
       "0  12e8  7.500  3.333  2.500  5.833  1.667  5.833  5.833   9.167  1.667  ...   \n",
       "1  15c8  9.244  0.000  3.361  5.882  1.681  4.202  6.723   8.403  2.521  ...   \n",
       "2  1a0q  5.882  1.681  3.361  5.042  1.681  5.882  5.042   9.244  1.681  ...   \n",
       "3  1a14  6.667  2.500  4.167  5.000  1.667  2.500  7.500  11.667  0.000  ...   \n",
       "4  1a2y  3.448  5.172  4.310  6.034  1.724  2.586  6.034  10.345  0.862  ...   \n",
       "\n",
       "   19750  19751  19752  19753  19754  19755  19756  19757  19758  19759  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 19761 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chen = pd.read_feather(path.join(DATA_DIR, \"chen/pybiomed/X_data.ftr\"))\n",
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_valid = x_chen.merge(chen_valid[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d85f8765-ebcc-4cc9-8738-5caa197679d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_chen_train.drop(\"Ab_ID\", axis=1))\n",
    "x_chen_train_tr = scaler.transform(x_chen_train.drop([\"Ab_ID\", \"Y\", \"cluster_merged\"], axis=1))\n",
    "x_chen_valid_tr = scaler.transform(x_chen_valid.drop([\"Ab_ID\", \"Y\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70f1926e-51a4-4f47-b9e2-ca3759a51d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19750</th>\n",
       "      <th>19751</th>\n",
       "      <th>19752</th>\n",
       "      <th>19753</th>\n",
       "      <th>19754</th>\n",
       "      <th>19755</th>\n",
       "      <th>19756</th>\n",
       "      <th>19757</th>\n",
       "      <th>19758</th>\n",
       "      <th>19759</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.084</td>\n",
       "      <td>3.361</td>\n",
       "      <td>2.521</td>\n",
       "      <td>3.361</td>\n",
       "      <td>1.681</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.882</td>\n",
       "      <td>11.765</td>\n",
       "      <td>0.840</td>\n",
       "      <td>1.681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.627</td>\n",
       "      <td>4.237</td>\n",
       "      <td>1.695</td>\n",
       "      <td>3.390</td>\n",
       "      <td>1.695</td>\n",
       "      <td>5.085</td>\n",
       "      <td>5.932</td>\n",
       "      <td>10.169</td>\n",
       "      <td>0.847</td>\n",
       "      <td>2.542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.932</td>\n",
       "      <td>1.695</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.932</td>\n",
       "      <td>1.695</td>\n",
       "      <td>5.085</td>\n",
       "      <td>6.780</td>\n",
       "      <td>10.169</td>\n",
       "      <td>0.847</td>\n",
       "      <td>1.695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.738</td>\n",
       "      <td>6.557</td>\n",
       "      <td>4.098</td>\n",
       "      <td>5.738</td>\n",
       "      <td>1.639</td>\n",
       "      <td>3.279</td>\n",
       "      <td>4.918</td>\n",
       "      <td>11.475</td>\n",
       "      <td>0.820</td>\n",
       "      <td>3.279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.091</td>\n",
       "      <td>4.959</td>\n",
       "      <td>3.306</td>\n",
       "      <td>5.785</td>\n",
       "      <td>1.653</td>\n",
       "      <td>4.132</td>\n",
       "      <td>4.132</td>\n",
       "      <td>9.091</td>\n",
       "      <td>1.653</td>\n",
       "      <td>2.479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19760 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5      6       7      8      9  \\\n",
       "0  10.084  3.361  2.521  3.361  1.681  3.361  5.882  11.765  0.840  1.681   \n",
       "1   7.627  4.237  1.695  3.390  1.695  5.085  5.932  10.169  0.847  2.542   \n",
       "2   5.932  1.695  0.000  5.932  1.695  5.085  6.780  10.169  0.847  1.695   \n",
       "3   5.738  6.557  4.098  5.738  1.639  3.279  4.918  11.475  0.820  3.279   \n",
       "4   9.091  4.959  3.306  5.785  1.653  4.132  4.132   9.091  1.653  2.479   \n",
       "\n",
       "   ...  19750  19751  19752  19753  19754  19755  19756  19757  19758  19759  \n",
       "0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 19760 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tap = pd.read_feather(path.join(DATA_DIR, \"tap/pybiomed/X_TAP_data.ftr\"))\n",
    "x_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e12c841-12e0-491d-90d3-210ce8de9f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#scaler.fit(x_tap)\n",
    "x_tap = scaler.transform(x_tap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f4a96-fb3a-4daf-bb81-92817b5e393e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data pybiomed \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train_tr, x_chen_train[\"Y\"], x_chen_valid_tr, x_chen_valid[\"Y\"], x_chen_train[\"cluster_merged\"], \"pybiomed\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f655a5d7-44b3-4668-9212-14274181202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all(x_tap, tap_data[\"Y\"], \"pybiomed\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77646694-01c8-4a7f-af38-15c2afc8f59a",
   "metadata": {},
   "source": [
    "# Protparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42310c2b-2bbf-4f1a-8507-174b3bf6173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_chen = pd.read_csv(path.join(DATA_DIR, \"chen/protparam/protparam_features.csv\"))\n",
    "x_chen.rename({\"Unnamed: 0\": \"Ab_ID\"}, axis=1, inplace=True)\n",
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_valid = x_chen.merge(chen_valid[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e31a9f-f557-48c5-9600-d3b42ba258a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_chen_train.drop([\"Ab_ID\", \"name\", \"cluster_merged\", \"Y\"], axis=1))\n",
    "x_chen_train = scaler.transform(x_chen_train.drop([\"Ab_ID\", \"name\", \"cluster_merged\", \"Y\"], axis=1))\n",
    "x_chen_valid = scaler.transform(x_chen_valid.drop([\"Ab_ID\", \"name\", \"Y\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad9974e-c757-4f91-800f-b2bb9daed827",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "try_all(x_chen_train, x_chen_train[\"Y\"], x_chen_valid, x_chen_valid[\"Y\"], x_chen_train[\"cluster_merged\"], \"protparam\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7985406b-d9db-4979-960e-5e1264c6d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tap = pd.read_csv(path.join(DATA_DIR, \"tap/protparam/protparam_features_tap.csv\"))\n",
    "x_tap.rename({\"Unnamed: 0\": \"Ab_ID\"}, axis=1, inplace=True)\n",
    "x_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db71a3e0-b2bf-48ce-bc4a-21be518445b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tap = scaler.transform(x_tap.drop(\"Ab_ID\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e92f207-70c2-4db4-ae35-33644248d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all(x_tap, tap_data[\"Y\"], \"protparam\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca554f3e-5877-44b1-9fc8-f80b1dbcbc44",
   "metadata": {},
   "source": [
    "# BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a16dceef-1516-4b03-b681-194070178a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>0.020196</td>\n",
       "      <td>-0.020793</td>\n",
       "      <td>-0.010549</td>\n",
       "      <td>-0.038375</td>\n",
       "      <td>0.066936</td>\n",
       "      <td>-0.022921</td>\n",
       "      <td>0.017874</td>\n",
       "      <td>-0.088493</td>\n",
       "      <td>-0.018926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>-0.003466</td>\n",
       "      <td>-0.014579</td>\n",
       "      <td>0.007682</td>\n",
       "      <td>-0.027888</td>\n",
       "      <td>0.026192</td>\n",
       "      <td>-0.040531</td>\n",
       "      <td>-0.010679</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>-0.027332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>-0.007447</td>\n",
       "      <td>-0.058638</td>\n",
       "      <td>0.013139</td>\n",
       "      <td>-0.029136</td>\n",
       "      <td>0.074901</td>\n",
       "      <td>-0.025573</td>\n",
       "      <td>0.035983</td>\n",
       "      <td>-0.105274</td>\n",
       "      <td>-0.014490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008387</td>\n",
       "      <td>0.007312</td>\n",
       "      <td>-0.013750</td>\n",
       "      <td>-0.003369</td>\n",
       "      <td>0.007132</td>\n",
       "      <td>0.042410</td>\n",
       "      <td>-0.044542</td>\n",
       "      <td>-0.034221</td>\n",
       "      <td>-0.023036</td>\n",
       "      <td>-0.013044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>-0.005372</td>\n",
       "      <td>-0.056795</td>\n",
       "      <td>0.012577</td>\n",
       "      <td>-0.031566</td>\n",
       "      <td>0.071131</td>\n",
       "      <td>-0.023377</td>\n",
       "      <td>0.037339</td>\n",
       "      <td>-0.102565</td>\n",
       "      <td>-0.009340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>0.003619</td>\n",
       "      <td>-0.015327</td>\n",
       "      <td>-0.003542</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.043285</td>\n",
       "      <td>-0.046977</td>\n",
       "      <td>-0.033989</td>\n",
       "      <td>-0.025775</td>\n",
       "      <td>-0.012205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>-0.004229</td>\n",
       "      <td>-0.043975</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>-0.031739</td>\n",
       "      <td>0.070902</td>\n",
       "      <td>-0.022174</td>\n",
       "      <td>0.038274</td>\n",
       "      <td>-0.111665</td>\n",
       "      <td>-0.030382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>-0.016125</td>\n",
       "      <td>-0.021334</td>\n",
       "      <td>-0.005837</td>\n",
       "      <td>-0.025217</td>\n",
       "      <td>0.024086</td>\n",
       "      <td>-0.032259</td>\n",
       "      <td>-0.023480</td>\n",
       "      <td>-0.013043</td>\n",
       "      <td>-0.035664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>-0.018278</td>\n",
       "      <td>-0.001506</td>\n",
       "      <td>-0.037899</td>\n",
       "      <td>0.050809</td>\n",
       "      <td>-0.026173</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>-0.090757</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003720</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>-0.036547</td>\n",
       "      <td>-0.009119</td>\n",
       "      <td>-0.038372</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>-0.030063</td>\n",
       "      <td>-0.003554</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>-0.041985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ab_ID         0         1         2         3         4         5  \\\n",
       "2073  6aod  0.020196 -0.020793 -0.010549 -0.038375  0.066936 -0.022921   \n",
       "1517  4yny -0.007447 -0.058638  0.013139 -0.029136  0.074901 -0.025573   \n",
       "2025  5xcv -0.005372 -0.056795  0.012577 -0.031566  0.071131 -0.023377   \n",
       "2070  6and -0.004229 -0.043975  0.003673 -0.031739  0.070902 -0.022174   \n",
       "666   2xqy  0.003754 -0.018278 -0.001506 -0.037899  0.050809 -0.026173   \n",
       "\n",
       "             6         7         8  ...      2038      2039      2040  \\\n",
       "2073  0.017874 -0.088493 -0.018926  ...  0.001973 -0.003466 -0.014579   \n",
       "1517  0.035983 -0.105274 -0.014490  ...  0.008387  0.007312 -0.013750   \n",
       "2025  0.037339 -0.102565 -0.009340  ...  0.008306  0.003619 -0.015327   \n",
       "2070  0.038274 -0.111665 -0.030382  ...  0.006203 -0.016125 -0.021334   \n",
       "666   0.003026 -0.090757  0.005515  ... -0.003720  0.004341 -0.036547   \n",
       "\n",
       "          2041      2042      2043      2044      2045      2046      2047  \n",
       "2073  0.007682 -0.027888  0.026192 -0.040531 -0.010679  0.007133 -0.027332  \n",
       "1517 -0.003369  0.007132  0.042410 -0.044542 -0.034221 -0.023036 -0.013044  \n",
       "2025 -0.003542  0.003720  0.043285 -0.046977 -0.033989 -0.025775 -0.012205  \n",
       "2070 -0.005837 -0.025217  0.024086 -0.032259 -0.023480 -0.013043 -0.035664  \n",
       "666  -0.009119 -0.038372  0.023391 -0.030063 -0.003554  0.000142 -0.041985  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chen = pd.read_feather(path.join(DATA_DIR, \"chen/embeddings/bert/bert_chen_embeddings.ftr\"))\n",
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_valid = x_chen.merge(chen_valid[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9502338a-a819-4ad5-bf07-d8e11af8aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_chen_train.drop(\"Ab_ID\", axis=1))\n",
    "x_chen_train_tr = scaler.transform(x_chen_train.drop([\"Ab_ID\", \"Y\", \"cluster_merged\"], axis=1))\n",
    "x_chen_valid_tr = scaler.transform(x_chen_valid.drop([\"Ab_ID\", \"Y\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "169edc1a-15ba-48a7-b707-9c8117a795e1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data bert \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression, bert\n",
      "F1: 0.38095238095238093\n",
      "MCC: 0.18215562599463012\n",
      "Accuracy: 0.6736401673640168\n",
      "Precision: 0.3116883116883117\n",
      "Recall: 0.4897959183673469\n",
      "AUC: 0.6054242749731472\n",
      "-----\n",
      "\n",
      "\n",
      "Training model random_forest on data bert \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "random_forest, bert\n",
      "F1: 0.3703703703703704\n",
      "MCC: 0.14183612246217095\n",
      "Accuracy: 0.5732217573221757\n",
      "Precision: 0.26548672566371684\n",
      "Recall: 0.6122448979591837\n",
      "AUC: 0.5877013963480129\n",
      "-----\n",
      "\n",
      "\n",
      "Training model gradient_boosting on data bert \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "gradient_boosting, bert\n",
      "F1: 0.1702127659574468\n",
      "MCC: -0.032500171896566385\n",
      "Accuracy: 0.6736401673640168\n",
      "Precision: 0.17777777777777778\n",
      "Recall: 0.16326530612244897\n",
      "AUC: 0.4842642320085929\n",
      "-----\n",
      "\n",
      "\n",
      "Training model SVM on data bert \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, bert\n",
      "F1: 0.37313432835820903\n",
      "MCC: 0.16395849043023675\n",
      "Accuracy: 0.6485355648535565\n",
      "Precision: 0.29411764705882354\n",
      "Recall: 0.5102040816326531\n",
      "AUC: 0.5972073039742213\n",
      "-----\n",
      "\n",
      "\n",
      "Training model multilayer_perceptron on data bert \n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron, bert\n",
      "F1: 0.3404255319148936\n",
      "MCC: 0.17958286109399652\n",
      "Accuracy: 0.7405857740585774\n",
      "Precision: 0.35555555555555557\n",
      "Recall: 0.32653061224489793\n",
      "AUC: 0.5869495166487647\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train_tr, x_chen_train[\"Y\"], x_chen_valid_tr, x_chen_valid[\"Y\"], \n",
    "        x_chen_train[\"cluster_merged\"], \"bert\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b24bcce-1674-4fa5-9998-61020acbce9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abagovomab</td>\n",
       "      <td>-0.004248</td>\n",
       "      <td>-0.024501</td>\n",
       "      <td>-0.011330</td>\n",
       "      <td>-0.027170</td>\n",
       "      <td>0.062747</td>\n",
       "      <td>-0.024793</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>-0.083316</td>\n",
       "      <td>-0.005339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008674</td>\n",
       "      <td>-0.002387</td>\n",
       "      <td>-0.021563</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>-0.020986</td>\n",
       "      <td>0.047104</td>\n",
       "      <td>-0.038736</td>\n",
       "      <td>-0.021780</td>\n",
       "      <td>-0.022153</td>\n",
       "      <td>-0.024539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abituzumab</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>-0.013591</td>\n",
       "      <td>-0.008454</td>\n",
       "      <td>-0.043601</td>\n",
       "      <td>0.065095</td>\n",
       "      <td>-0.016896</td>\n",
       "      <td>-0.001596</td>\n",
       "      <td>-0.090935</td>\n",
       "      <td>-0.002940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>-0.013063</td>\n",
       "      <td>-0.021852</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>-0.024620</td>\n",
       "      <td>0.027387</td>\n",
       "      <td>-0.041001</td>\n",
       "      <td>-0.025708</td>\n",
       "      <td>-0.016437</td>\n",
       "      <td>-0.034342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrilumab</td>\n",
       "      <td>0.019445</td>\n",
       "      <td>-0.002642</td>\n",
       "      <td>-0.011395</td>\n",
       "      <td>-0.058757</td>\n",
       "      <td>0.060623</td>\n",
       "      <td>-0.015046</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>-0.083772</td>\n",
       "      <td>-0.006775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>-0.017189</td>\n",
       "      <td>-0.014557</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>-0.035368</td>\n",
       "      <td>0.020287</td>\n",
       "      <td>-0.033941</td>\n",
       "      <td>-0.023549</td>\n",
       "      <td>-0.008720</td>\n",
       "      <td>-0.044038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actoxumab</td>\n",
       "      <td>-0.006365</td>\n",
       "      <td>-0.043729</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>-0.025613</td>\n",
       "      <td>0.067748</td>\n",
       "      <td>-0.009542</td>\n",
       "      <td>0.017723</td>\n",
       "      <td>-0.096801</td>\n",
       "      <td>-0.007752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.012986</td>\n",
       "      <td>-0.019753</td>\n",
       "      <td>-0.004326</td>\n",
       "      <td>-0.044124</td>\n",
       "      <td>0.019544</td>\n",
       "      <td>-0.039559</td>\n",
       "      <td>-0.015679</td>\n",
       "      <td>-0.008837</td>\n",
       "      <td>-0.043877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adalimumab</td>\n",
       "      <td>-0.012995</td>\n",
       "      <td>-0.035269</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>-0.042136</td>\n",
       "      <td>0.080592</td>\n",
       "      <td>-0.012831</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>-0.091308</td>\n",
       "      <td>-0.018166</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>-0.022957</td>\n",
       "      <td>-0.021145</td>\n",
       "      <td>-0.002762</td>\n",
       "      <td>-0.058199</td>\n",
       "      <td>0.026781</td>\n",
       "      <td>-0.046815</td>\n",
       "      <td>-0.010110</td>\n",
       "      <td>-0.008785</td>\n",
       "      <td>-0.041761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ab_ID         0         1         2         3         4         5  \\\n",
       "0  Abagovomab -0.004248 -0.024501 -0.011330 -0.027170  0.062747 -0.024793   \n",
       "1  Abituzumab  0.006593 -0.013591 -0.008454 -0.043601  0.065095 -0.016896   \n",
       "2   Abrilumab  0.019445 -0.002642 -0.011395 -0.058757  0.060623 -0.015046   \n",
       "3   Actoxumab -0.006365 -0.043729  0.005978 -0.025613  0.067748 -0.009542   \n",
       "4  Adalimumab -0.012995 -0.035269  0.014127 -0.042136  0.080592 -0.012831   \n",
       "\n",
       "          6         7         8  ...      2038      2039      2040      2041  \\\n",
       "0  0.009313 -0.083316 -0.005339  ... -0.008674 -0.002387 -0.021563  0.001087   \n",
       "1 -0.001596 -0.090935 -0.002940  ...  0.000486 -0.013063 -0.021852 -0.003531   \n",
       "2  0.006317 -0.083772 -0.006775  ...  0.005834 -0.017189 -0.014557  0.003359   \n",
       "3  0.017723 -0.096801 -0.007752  ... -0.000024 -0.012986 -0.019753 -0.004326   \n",
       "4  0.031889 -0.091308 -0.018166  ... -0.002067 -0.022957 -0.021145 -0.002762   \n",
       "\n",
       "       2042      2043      2044      2045      2046      2047  \n",
       "0 -0.020986  0.047104 -0.038736 -0.021780 -0.022153 -0.024539  \n",
       "1 -0.024620  0.027387 -0.041001 -0.025708 -0.016437 -0.034342  \n",
       "2 -0.035368  0.020287 -0.033941 -0.023549 -0.008720 -0.044038  \n",
       "3 -0.044124  0.019544 -0.039559 -0.015679 -0.008837 -0.043877  \n",
       "4 -0.058199  0.026781 -0.046815 -0.010110 -0.008785 -0.041761  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tap = pd.read_feather(path.join(DATA_DIR, \"tap/embeddings/bert/bert_tap_embeddings.ftr\"))\n",
    "x_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "caf7768e-3dd2-41d9-8a91-d0cf9760b3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tap = scaler.transform(x_tap.drop(\"Ab_ID\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d5db8ae-38b9-4947-9717-5cd937b73fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on bert...\n",
      "Testing model random_forest on bert...\n",
      "Testing model gradient_boosting on bert...\n",
      "Testing model SVM on bert...\n",
      "Testing model multilayer_perceptron on bert...\n"
     ]
    }
   ],
   "source": [
    "test_all(x_tap, tap_data[\"Y\"], \"bert\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b72f0-8d1e-49b2-af8c-5f8e40d79114",
   "metadata": {},
   "source": [
    "# SeqVec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "242800ab-9c9f-40bc-8833-2d43e2cfe302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>0.031640</td>\n",
       "      <td>-0.191203</td>\n",
       "      <td>-0.268825</td>\n",
       "      <td>-0.134525</td>\n",
       "      <td>0.097435</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.019496</td>\n",
       "      <td>0.118835</td>\n",
       "      <td>-0.136518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>-0.013639</td>\n",
       "      <td>0.135580</td>\n",
       "      <td>0.059035</td>\n",
       "      <td>-0.006357</td>\n",
       "      <td>-0.085073</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>-0.000886</td>\n",
       "      <td>-0.016590</td>\n",
       "      <td>-0.071586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>0.063575</td>\n",
       "      <td>-0.219689</td>\n",
       "      <td>-0.285444</td>\n",
       "      <td>-0.134554</td>\n",
       "      <td>0.089054</td>\n",
       "      <td>-0.023122</td>\n",
       "      <td>0.004502</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>-0.047376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005196</td>\n",
       "      <td>-0.113235</td>\n",
       "      <td>0.048879</td>\n",
       "      <td>0.061190</td>\n",
       "      <td>-0.005911</td>\n",
       "      <td>-0.104957</td>\n",
       "      <td>0.026941</td>\n",
       "      <td>0.016444</td>\n",
       "      <td>-0.065021</td>\n",
       "      <td>-0.105957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>0.060840</td>\n",
       "      <td>-0.227532</td>\n",
       "      <td>-0.280555</td>\n",
       "      <td>-0.136953</td>\n",
       "      <td>0.091411</td>\n",
       "      <td>-0.028528</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.166315</td>\n",
       "      <td>-0.045701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005788</td>\n",
       "      <td>-0.112651</td>\n",
       "      <td>0.049541</td>\n",
       "      <td>0.063261</td>\n",
       "      <td>-0.005133</td>\n",
       "      <td>-0.104734</td>\n",
       "      <td>0.027340</td>\n",
       "      <td>0.017490</td>\n",
       "      <td>-0.064584</td>\n",
       "      <td>-0.105592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>0.062686</td>\n",
       "      <td>-0.220758</td>\n",
       "      <td>-0.278071</td>\n",
       "      <td>-0.137741</td>\n",
       "      <td>0.086655</td>\n",
       "      <td>-0.016114</td>\n",
       "      <td>-0.027874</td>\n",
       "      <td>0.158912</td>\n",
       "      <td>-0.119345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041290</td>\n",
       "      <td>-0.032623</td>\n",
       "      <td>0.144864</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>-0.014455</td>\n",
       "      <td>-0.080329</td>\n",
       "      <td>-0.049089</td>\n",
       "      <td>0.033029</td>\n",
       "      <td>-0.017042</td>\n",
       "      <td>-0.044416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>-0.000458</td>\n",
       "      <td>-0.200469</td>\n",
       "      <td>-0.269982</td>\n",
       "      <td>-0.138054</td>\n",
       "      <td>0.112663</td>\n",
       "      <td>-0.007346</td>\n",
       "      <td>0.037440</td>\n",
       "      <td>0.075526</td>\n",
       "      <td>-0.178788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020374</td>\n",
       "      <td>-0.059074</td>\n",
       "      <td>0.133179</td>\n",
       "      <td>0.018044</td>\n",
       "      <td>0.066013</td>\n",
       "      <td>-0.061189</td>\n",
       "      <td>-0.029644</td>\n",
       "      <td>-0.050942</td>\n",
       "      <td>-0.035482</td>\n",
       "      <td>-0.058019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ab_ID         0         1         2         3         4         5  \\\n",
       "2073  6aod  0.031640 -0.191203 -0.268825 -0.134525  0.097435  0.001770   \n",
       "1517  4yny  0.063575 -0.219689 -0.285444 -0.134554  0.089054 -0.023122   \n",
       "2025  5xcv  0.060840 -0.227532 -0.280555 -0.136953  0.091411 -0.028528   \n",
       "2070  6and  0.062686 -0.220758 -0.278071 -0.137741  0.086655 -0.016114   \n",
       "666   2xqy -0.000458 -0.200469 -0.269982 -0.138054  0.112663 -0.007346   \n",
       "\n",
       "             6         7         8  ...      2038      2039      2040  \\\n",
       "2073  0.019496  0.118835 -0.136518  ...  0.104400 -0.013639  0.135580   \n",
       "1517  0.004502  0.162193 -0.047376  ... -0.005196 -0.113235  0.048879   \n",
       "2025  0.001440  0.166315 -0.045701  ... -0.005788 -0.112651  0.049541   \n",
       "2070 -0.027874  0.158912 -0.119345  ...  0.041290 -0.032623  0.144864   \n",
       "666   0.037440  0.075526 -0.178788  ... -0.020374 -0.059074  0.133179   \n",
       "\n",
       "          2041      2042      2043      2044      2045      2046      2047  \n",
       "2073  0.059035 -0.006357 -0.085073  0.009538 -0.000886 -0.016590 -0.071586  \n",
       "1517  0.061190 -0.005911 -0.104957  0.026941  0.016444 -0.065021 -0.105957  \n",
       "2025  0.063261 -0.005133 -0.104734  0.027340  0.017490 -0.064584 -0.105592  \n",
       "2070  0.008824 -0.014455 -0.080329 -0.049089  0.033029 -0.017042 -0.044416  \n",
       "666   0.018044  0.066013 -0.061189 -0.029644 -0.050942 -0.035482 -0.058019  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chen = pd.read_feather(path.join(DATA_DIR, \"chen/embeddings/seqvec/seqvec_chen_embeddings.ftr\"))\n",
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_valid = x_chen.merge(chen_valid[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0730c305-3d8c-45ec-8d18-fd9f577aba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_chen_train.drop(\"Ab_ID\", axis=1))\n",
    "x_chen_train_tr = scaler.transform(x_chen_train.drop([\"Ab_ID\", \"Y\", \"cluster_merged\"], axis=1))\n",
    "x_chen_valid_tr = scaler.transform(x_chen_valid.drop([\"Ab_ID\", \"Y\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40df67f1-1c9a-419b-816f-87d21b10882c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression, seqvec\n",
      "F1: 0.3909774436090226\n",
      "MCC: 0.1905571071905387\n",
      "Accuracy: 0.6610878661087866\n",
      "Precision: 0.30952380952380953\n",
      "Recall: 0.5306122448979592\n",
      "AUC: 0.6126745435016112\n",
      "-----\n",
      "\n",
      "\n",
      "Training model random_forest on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "random_forest, seqvec\n",
      "F1: 0.42519685039370075\n",
      "MCC: 0.24332445999849997\n",
      "Accuracy: 0.694560669456067\n",
      "Precision: 0.34615384615384615\n",
      "Recall: 0.5510204081632653\n",
      "AUC: 0.6412996777658432\n",
      "-----\n",
      "\n",
      "\n",
      "Training model gradient_boosting on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "gradient_boosting, seqvec\n",
      "F1: 0.09090909090909091\n",
      "MCC: -0.01956961135502369\n",
      "Accuracy: 0.7489539748953975\n",
      "Precision: 0.17647058823529413\n",
      "Recall: 0.061224489795918366\n",
      "AUC: 0.4937701396348013\n",
      "-----\n",
      "\n",
      "\n",
      "Training model SVM on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, seqvec\n",
      "F1: 0.31067961165048547\n",
      "MCC: 0.12214837841247742\n",
      "Accuracy: 0.702928870292887\n",
      "Precision: 0.2962962962962963\n",
      "Recall: 0.32653061224489793\n",
      "AUC: 0.563265306122449\n",
      "-----\n",
      "\n",
      "\n",
      "Training model multilayer_perceptron on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron, seqvec\n",
      "F1: 0.2916666666666667\n",
      "MCC: 0.1137915268000298\n",
      "Accuracy: 0.7154811715481172\n",
      "Precision: 0.2978723404255319\n",
      "Recall: 0.2857142857142857\n",
      "AUC: 0.5560150375939849\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train_tr, x_chen_train[\"Y\"], x_chen_valid_tr, x_chen_valid[\"Y\"], \n",
    "        x_chen_train[\"cluster_merged\"], \"seqvec\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50dd5635-2548-4aa9-ba29-2c84aaa34c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abagovomab</td>\n",
       "      <td>-0.004248</td>\n",
       "      <td>-0.024501</td>\n",
       "      <td>-0.011330</td>\n",
       "      <td>-0.027170</td>\n",
       "      <td>0.062747</td>\n",
       "      <td>-0.024793</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>-0.083316</td>\n",
       "      <td>-0.005339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008674</td>\n",
       "      <td>-0.002387</td>\n",
       "      <td>-0.021563</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>-0.020986</td>\n",
       "      <td>0.047104</td>\n",
       "      <td>-0.038736</td>\n",
       "      <td>-0.021780</td>\n",
       "      <td>-0.022153</td>\n",
       "      <td>-0.024539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abituzumab</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>-0.013591</td>\n",
       "      <td>-0.008454</td>\n",
       "      <td>-0.043601</td>\n",
       "      <td>0.065095</td>\n",
       "      <td>-0.016896</td>\n",
       "      <td>-0.001596</td>\n",
       "      <td>-0.090935</td>\n",
       "      <td>-0.002940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>-0.013063</td>\n",
       "      <td>-0.021852</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>-0.024620</td>\n",
       "      <td>0.027387</td>\n",
       "      <td>-0.041001</td>\n",
       "      <td>-0.025708</td>\n",
       "      <td>-0.016437</td>\n",
       "      <td>-0.034342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrilumab</td>\n",
       "      <td>0.019445</td>\n",
       "      <td>-0.002642</td>\n",
       "      <td>-0.011395</td>\n",
       "      <td>-0.058757</td>\n",
       "      <td>0.060623</td>\n",
       "      <td>-0.015046</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>-0.083772</td>\n",
       "      <td>-0.006775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>-0.017189</td>\n",
       "      <td>-0.014557</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>-0.035368</td>\n",
       "      <td>0.020287</td>\n",
       "      <td>-0.033941</td>\n",
       "      <td>-0.023549</td>\n",
       "      <td>-0.008720</td>\n",
       "      <td>-0.044038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actoxumab</td>\n",
       "      <td>-0.006365</td>\n",
       "      <td>-0.043729</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>-0.025613</td>\n",
       "      <td>0.067748</td>\n",
       "      <td>-0.009542</td>\n",
       "      <td>0.017723</td>\n",
       "      <td>-0.096801</td>\n",
       "      <td>-0.007752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.012986</td>\n",
       "      <td>-0.019753</td>\n",
       "      <td>-0.004326</td>\n",
       "      <td>-0.044124</td>\n",
       "      <td>0.019544</td>\n",
       "      <td>-0.039559</td>\n",
       "      <td>-0.015679</td>\n",
       "      <td>-0.008837</td>\n",
       "      <td>-0.043877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adalimumab</td>\n",
       "      <td>-0.012995</td>\n",
       "      <td>-0.035269</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>-0.042136</td>\n",
       "      <td>0.080592</td>\n",
       "      <td>-0.012831</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>-0.091308</td>\n",
       "      <td>-0.018166</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>-0.022957</td>\n",
       "      <td>-0.021145</td>\n",
       "      <td>-0.002762</td>\n",
       "      <td>-0.058199</td>\n",
       "      <td>0.026781</td>\n",
       "      <td>-0.046815</td>\n",
       "      <td>-0.010110</td>\n",
       "      <td>-0.008785</td>\n",
       "      <td>-0.041761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ab_ID         0         1         2         3         4         5  \\\n",
       "0  Abagovomab -0.004248 -0.024501 -0.011330 -0.027170  0.062747 -0.024793   \n",
       "1  Abituzumab  0.006593 -0.013591 -0.008454 -0.043601  0.065095 -0.016896   \n",
       "2   Abrilumab  0.019445 -0.002642 -0.011395 -0.058757  0.060623 -0.015046   \n",
       "3   Actoxumab -0.006365 -0.043729  0.005978 -0.025613  0.067748 -0.009542   \n",
       "4  Adalimumab -0.012995 -0.035269  0.014127 -0.042136  0.080592 -0.012831   \n",
       "\n",
       "          6         7         8  ...      2038      2039      2040      2041  \\\n",
       "0  0.009313 -0.083316 -0.005339  ... -0.008674 -0.002387 -0.021563  0.001087   \n",
       "1 -0.001596 -0.090935 -0.002940  ...  0.000486 -0.013063 -0.021852 -0.003531   \n",
       "2  0.006317 -0.083772 -0.006775  ...  0.005834 -0.017189 -0.014557  0.003359   \n",
       "3  0.017723 -0.096801 -0.007752  ... -0.000024 -0.012986 -0.019753 -0.004326   \n",
       "4  0.031889 -0.091308 -0.018166  ... -0.002067 -0.022957 -0.021145 -0.002762   \n",
       "\n",
       "       2042      2043      2044      2045      2046      2047  \n",
       "0 -0.020986  0.047104 -0.038736 -0.021780 -0.022153 -0.024539  \n",
       "1 -0.024620  0.027387 -0.041001 -0.025708 -0.016437 -0.034342  \n",
       "2 -0.035368  0.020287 -0.033941 -0.023549 -0.008720 -0.044038  \n",
       "3 -0.044124  0.019544 -0.039559 -0.015679 -0.008837 -0.043877  \n",
       "4 -0.058199  0.026781 -0.046815 -0.010110 -0.008785 -0.041761  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tap = pd.read_feather(path.join(DATA_DIR, \"tap/embeddings/seqvec/seqvec_tap_embeddings.ftr\"))\n",
    "x_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7be0003-dc87-4e08-99d5-a5f2220dc25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tap = scaler.transform(x_tap.drop(\"Ab_ID\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ea9d66e-6b32-4273-804f-b9e9c4f65ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on seqvec...\n",
      "Testing model random_forest on seqvec...\n",
      "Testing model gradient_boosting on seqvec...\n",
      "Testing model SVM on seqvec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model multilayer_perceptron on seqvec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_all(x_tap, tap_data[\"Y\"], \"seqvec\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b33319-5954-466b-b667-bbdc6c9c56e8",
   "metadata": {},
   "source": [
    "# One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7845fcbf-58f1-4e99-9994-8cc3a276782c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID_h</th>\n",
       "      <th>A_1_h</th>\n",
       "      <th>C_1_h</th>\n",
       "      <th>D_1_h</th>\n",
       "      <th>E_1_h</th>\n",
       "      <th>F_1_h</th>\n",
       "      <th>G_1_h</th>\n",
       "      <th>H_1_h</th>\n",
       "      <th>I_1_h</th>\n",
       "      <th>K_1_h</th>\n",
       "      <th>...</th>\n",
       "      <th>O_138_l</th>\n",
       "      <th>P_138_l</th>\n",
       "      <th>Q_138_l</th>\n",
       "      <th>R_138_l</th>\n",
       "      <th>S_138_l</th>\n",
       "      <th>T_138_l</th>\n",
       "      <th>U_138_l</th>\n",
       "      <th>V_138_l</th>\n",
       "      <th>W_138_l</th>\n",
       "      <th>Y_138_l</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7526 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ab_ID_h  A_1_h  C_1_h  D_1_h  E_1_h  F_1_h  G_1_h  H_1_h  I_1_h  K_1_h  \\\n",
       "index                                                                          \n",
       "2073     6aod      0      0      0      1      0      0      0      0      0   \n",
       "1517     4yny      0      0      0      1      0      0      0      0      0   \n",
       "2025     5xcv      0      0      0      1      0      0      0      0      0   \n",
       "2070     6and      0      0      0      1      0      0      0      0      0   \n",
       "666      2xqy      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "       ...  O_138_l  P_138_l  Q_138_l  R_138_l  S_138_l  T_138_l  U_138_l  \\\n",
       "index  ...                                                                  \n",
       "2073   ...        0        0        0        0        0        0        0   \n",
       "1517   ...        0        0        0        0        0        0        0   \n",
       "2025   ...        0        0        0        0        0        0        0   \n",
       "2070   ...        0        0        0        0        0        0        0   \n",
       "666    ...        0        0        0        0        0        0        0   \n",
       "\n",
       "       V_138_l  W_138_l  Y_138_l  \n",
       "index                             \n",
       "2073         0        0        0  \n",
       "1517         0        0        0  \n",
       "2025         0        0        0  \n",
       "2070         0        0        0  \n",
       "666          0        0        0  \n",
       "\n",
       "[5 rows x 7526 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_heavy = pd.read_feather(path.join(DATA_DIR, \"chen/abnumber/chen_heavy_one_hot.ftr\")).set_index(\"index\")\n",
    "# rows 1921 and 2097 could not be encoded\n",
    "x_light = pd.read_feather(path.join(DATA_DIR, \"chen/abnumber/chen_light_one_hot.ftr\")).set_index(\"Id\")\n",
    "x_chen = x_heavy.merge(x_light, left_index=True, right_index=True, suffixes=[\"_h\", \"_l\"])\n",
    "x_chen.index = x_heavy.index\n",
    "train_idx = list(chen_train.index)\n",
    "train_idx.remove(1921)\n",
    "train_idx.remove(2097)\n",
    "x_chen_train = x_chen.loc[train_idx]\n",
    "x_chen_valid = x_chen.loc[chen_valid.index]\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b379646-e416-40de-b8c4-fc391b8fc436",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = chen_train.loc[train_idx][\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd109a6b-f264-44da-bddc-b60a6612716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_chen_train.drop([\"Ab_ID_h\", \"Ab_ID_l\"], axis=1))\n",
    "x_chen_train = scaler.transform(x_chen_train.drop([\"Ab_ID_h\", \"Ab_ID_l\"], axis=1))\n",
    "x_chen_valid = scaler.transform(x_chen_valid.drop([\"Ab_ID_h\", \"Ab_ID_l\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eda173ac-767c-4fc5-825a-7b6749fb0425",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data onehot \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression, onehot\n",
      "F1: 0.375\n",
      "MCC: 0.19015409084172083\n",
      "Accuracy: 0.7071129707112971\n",
      "Precision: 0.3333333333333333\n",
      "Recall: 0.42857142857142855\n",
      "AUC: 0.6037593984962406\n",
      "-----\n",
      "\n",
      "\n",
      "Training model random_forest on data onehot \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "random_forest, onehot\n",
      "F1: 0.3943661971830986\n",
      "MCC: 0.18989133017294033\n",
      "Accuracy: 0.6401673640167364\n",
      "Precision: 0.3010752688172043\n",
      "Recall: 0.5714285714285714\n",
      "AUC: 0.6146616541353385\n",
      "-----\n",
      "\n",
      "\n",
      "Training model gradient_boosting on data onehot \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "gradient_boosting, onehot\n",
      "F1: 0.22988505747126436\n",
      "MCC: 0.06261368369902223\n",
      "Accuracy: 0.7196652719665272\n",
      "Precision: 0.2631578947368421\n",
      "Recall: 0.20408163265306123\n",
      "AUC: 0.5283566058002148\n",
      "-----\n",
      "\n",
      "\n",
      "Training model SVM on data onehot \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "SVM, onehot\n",
      "F1: 0.25490196078431376\n",
      "MCC: 0.05323544989970825\n",
      "Accuracy: 0.6820083682008368\n",
      "Precision: 0.24528301886792453\n",
      "Recall: 0.2653061224489796\n",
      "AUC: 0.527389903329753\n",
      "-----\n",
      "\n",
      "\n",
      "Training model multilayer_perceptron on data onehot \n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron, onehot\n",
      "F1: 0.3035714285714286\n",
      "MCC: 0.09606127984550701\n",
      "Accuracy: 0.6736401673640168\n",
      "Precision: 0.2698412698412698\n",
      "Recall: 0.3469387755102041\n",
      "AUC: 0.5524167561761547\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# add groups for data split\n",
    "try_all(x_chen_train, train_labels, x_chen_valid, chen_valid[\"Y\"], \"onehot\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "efb17f26-97ce-451f-aa63-08f5f138fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tap_heavy = pd.read_feather(path.join(DATA_DIR, \"tap/abnumber/tap_heavy_one_hot.ftr\"))\n",
    "x_tap_light = pd.read_feather(path.join(DATA_DIR, \"tap/abnumber/tap_light_one_hot.ftr\"))\n",
    "x_tap = x_tap_heavy.merge(x_tap_light, left_index=True, right_index=True, suffixes=[\"_h\", \"_l\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "637e217d-2a01-4e91-a3a0-2599a4437468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- A_121\n",
      "- A_122\n",
      "- A_123\n",
      "- A_124\n",
      "- A_125\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- A_121_h\n",
      "- A_121_l\n",
      "- A_122_h\n",
      "- A_122_l\n",
      "- A_123_h\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 5634 features, but StandardScaler is expecting 7524 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/pbs.31293.lich-compute.vscht.cz/ipykernel_510/3223408165.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_tap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Ab_ID_h\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Ab_ID_l\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    978\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m         )\n\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             raise ValueError(\n\u001b[0;32m--> 396\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 5634 features, but StandardScaler is expecting 7524 features as input."
     ]
    }
   ],
   "source": [
    "x_tap = scaler.transform(x_tap.drop([\"Ab_ID_h\", \"Ab_ID_l\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a64dbdc7-0ffa-4042-a7a3-660e3cbe0b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on onehot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:439: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Abagovomab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/pbs.31293.lich-compute.vscht.cz/ipykernel_510/1287004508.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtap_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"onehot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVAL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"StandardScaler\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.31293.lich-compute.vscht.cz/ipykernel_510/202172768.py\u001b[0m in \u001b[0;36mtest_all\u001b[0;34m(x_test, y_test, data_name, outpath, preprocessing)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"logistic_regression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"random_forest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gradient_boosting\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SVM\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilayer_perceptron\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Testing model {model} on {data_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtest_on_tap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.31293.lich-compute.vscht.cz/ipykernel_510/2610498457.py\u001b[0m in \u001b[0;36mtest_on_tap\u001b[0;34m(model_name, x_test, y_test, data_name, outpath, preprocessing)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     metric_dict = {\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \"\"\"\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    736\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Abagovomab'"
     ]
    }
   ],
   "source": [
    "test_all(x_tap, tap_data[\"Y\"], \"onehot\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e6bec-c3f6-47a4-94ca-f3bd01fc0220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
