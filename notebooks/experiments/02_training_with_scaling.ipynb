{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaac5ca7-e11d-4cef-8594-dc61e039f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.fixes import loguniform    \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e4ae71e-a22d-4cb6-919a-2d8e8cfad1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a0b37d-bdb0-4a78-8caa-03ff89c08072",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_DIR = \"2021-12-03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "604e7e5b-1fac-49b4-b2a5-764ed1d46e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...</td>\n",
       "      <td>DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...</td>\n",
       "      <td>DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Antibody_ID                                              heavy  \\\n",
       "2073        6aod  EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...   \n",
       "1517        4yny  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2025        5xcv  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2070        6and  EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...   \n",
       "666         2xqy  QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...   \n",
       "\n",
       "                                                  light  Y  \n",
       "2073  DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...  0  \n",
       "1517  EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2025  QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2070  DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...  1  \n",
       "666   DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_train = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_train_data.csv\"), index_col=0)\n",
    "chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afda5620-8cda-4a38-b06e-1a3b0659e0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>Y</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>6ct7</td>\n",
       "      <td>EVQLVESGGGLVEPGGSLRLSCAVSGFDFEKAWMSWVRQAPGQGLQ...</td>\n",
       "      <td>SYELTQPPSVSVSPGQTARITCSGEALPMQFAHWYQQRPGKAPVIV...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>4nzu</td>\n",
       "      <td>AVSLVESGGGTVEPGSTLRLSCAASGFTFGSYAFHWVRQAPGDGLE...</td>\n",
       "      <td>DIEMTQSPSSLSASTGDKVTITCQASQDIAKFLDWYQQRPGKTPKL...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>5i8c</td>\n",
       "      <td>QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...</td>\n",
       "      <td>DIQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNL...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>5i8e</td>\n",
       "      <td>QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...</td>\n",
       "      <td>IQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNLL...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>6bb4</td>\n",
       "      <td>QVQLQQSDAELVKPGASVKISCKASGYTFTDRTIHWVKQRPEQGLE...</td>\n",
       "      <td>DVQMIQSPSSLSASLGDIVTMTCQASQDTSINLNWFQQKPGKAPKL...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Antibody_ID                                              heavy  \\\n",
       "2169        6ct7  EVQLVESGGGLVEPGGSLRLSCAVSGFDFEKAWMSWVRQAPGQGLQ...   \n",
       "1342        4nzu  AVSLVESGGGTVEPGSTLRLSCAASGFTFGSYAFHWVRQAPGDGLE...   \n",
       "1728        5i8c  QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...   \n",
       "1729        5i8e  QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...   \n",
       "2114        6bb4  QVQLQQSDAELVKPGASVKISCKASGYTFTDRTIHWVKQRPEQGLE...   \n",
       "\n",
       "                                                  light  Y  Unnamed: 0  \n",
       "2169  SYELTQPPSVSVSPGQTARITCSGEALPMQFAHWYQQRPGKAPVIV...  0         NaN  \n",
       "1342  DIEMTQSPSSLSASTGDKVTITCQASQDIAKFLDWYQQRPGKTPKL...  0         NaN  \n",
       "1728  DIQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNL...  1         NaN  \n",
       "1729  IQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNLL...  0         NaN  \n",
       "2114  DVQMIQSPSSLSASLGDIVTMTCQASQDTSINLNWFQQKPGKAPKL...  0         NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_valid = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_valid_data.csv\"), index_col=0)\n",
    "chen_test = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_test_data.csv\"))\n",
    "chen_valid = pd.concat([chen_valid, chen_test])\n",
    "chen_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "083e69c0-1ebf-41c8-a4d3-782f364696d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>CDR_length</th>\n",
       "      <th>PSH</th>\n",
       "      <th>PPC</th>\n",
       "      <th>PNC</th>\n",
       "      <th>SFvCSP</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abagovomab</td>\n",
       "      <td>QVKLQESGAELARPGASVKLSCKASGYTFTNYWMQWVKQRPGQGLD...</td>\n",
       "      <td>DIELTQSPASLSASVGETVTITCQASENIYSYLAWHQQKQGKSPQL...</td>\n",
       "      <td>46</td>\n",
       "      <td>129.7603</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abituzumab</td>\n",
       "      <td>QVQLQQSGGELAKPGASVKVSCKASGYTFSSFWMHWVRQAPGQGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQDISNYLAWYQQKPGKAPKL...</td>\n",
       "      <td>45</td>\n",
       "      <td>115.9106</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>-3.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrilumab</td>\n",
       "      <td>QVQLVQSGAEVKKPGASVKVSCKVSGYTLSDLSIHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQQKPGKAPKL...</td>\n",
       "      <td>45</td>\n",
       "      <td>109.6995</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actoxumab</td>\n",
       "      <td>QVQLVESGGGVVQPGRSLRLSCAASGFSFSNYGMHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQHKPGKAPKL...</td>\n",
       "      <td>49</td>\n",
       "      <td>112.6290</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.1247</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adalimumab</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLRLSCAASGFTFDDYAMHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQGIRNYLAWYQQKPGKAPKL...</td>\n",
       "      <td>48</td>\n",
       "      <td>111.2512</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>1.1364</td>\n",
       "      <td>-19.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Antibody_ID                                              heavy  \\\n",
       "0  Abagovomab  QVKLQESGAELARPGASVKLSCKASGYTFTNYWMQWVKQRPGQGLD...   \n",
       "1  Abituzumab  QVQLQQSGGELAKPGASVKVSCKASGYTFSSFWMHWVRQAPGQGLE...   \n",
       "2   Abrilumab  QVQLVQSGAEVKKPGASVKVSCKVSGYTLSDLSIHWVRQAPGKGLE...   \n",
       "3   Actoxumab  QVQLVESGGGVVQPGRSLRLSCAASGFSFSNYGMHWVRQAPGKGLE...   \n",
       "4  Adalimumab  EVQLVESGGGLVQPGRSLRLSCAASGFTFDDYAMHWVRQAPGKGLE...   \n",
       "\n",
       "                                               light  CDR_length       PSH  \\\n",
       "0  DIELTQSPASLSASVGETVTITCQASENIYSYLAWHQQKQGKSPQL...          46  129.7603   \n",
       "1  DIQMTQSPSSLSASVGDRVTITCRASQDISNYLAWYQQKPGKAPKL...          45  115.9106   \n",
       "2  DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQQKPGKAPKL...          45  109.6995   \n",
       "3  DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQHKPGKAPKL...          49  112.6290   \n",
       "4  DIQMTQSPSSLSASVGDRVTITCRASQGIRNYLAWYQQKPGKAPKL...          48  111.2512   \n",
       "\n",
       "      PPC     PNC  SFvCSP  Y  \n",
       "0  0.0000  0.0000   16.32  1  \n",
       "1  0.0954  0.0421   -3.10  1  \n",
       "2  0.0000  0.8965   -4.00  1  \n",
       "3  0.0000  1.1247    3.10  1  \n",
       "4  0.0485  1.1364  -19.50  1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tap_data = pd.read_csv(path.join(DATA_DIR, \"tap/TAP_data.csv\"))\n",
    "tap_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78bcad1b-5d12-4db8-b944-a7ef47b0051e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>2398</th>\n",
       "      <th>2400</th>\n",
       "      <th>2401</th>\n",
       "      <th>2402</th>\n",
       "      <th>2403</th>\n",
       "      <th>2404</th>\n",
       "      <th>2405</th>\n",
       "      <th>2406</th>\n",
       "      <th>2407</th>\n",
       "      <th>2408</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.77700</td>\n",
       "      <td>0.70350</td>\n",
       "      <td>0.69995</td>\n",
       "      <td>0.65085</td>\n",
       "      <td>0.67350</td>\n",
       "      <td>0.66915</td>\n",
       "      <td>0.66915</td>\n",
       "      <td>0.76100</td>\n",
       "      <td>0.71800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59250</td>\n",
       "      <td>0.63185</td>\n",
       "      <td>0.65150</td>\n",
       "      <td>0.61850</td>\n",
       "      <td>0.70070</td>\n",
       "      <td>0.60550</td>\n",
       "      <td>0.54015</td>\n",
       "      <td>0.70460</td>\n",
       "      <td>0.61020</td>\n",
       "      <td>0.62840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.77700</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>0.69315</td>\n",
       "      <td>0.70240</td>\n",
       "      <td>0.65570</td>\n",
       "      <td>0.65570</td>\n",
       "      <td>0.74785</td>\n",
       "      <td>0.79775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59600</td>\n",
       "      <td>0.65265</td>\n",
       "      <td>0.67200</td>\n",
       "      <td>0.63085</td>\n",
       "      <td>0.69350</td>\n",
       "      <td>0.60750</td>\n",
       "      <td>0.55310</td>\n",
       "      <td>0.71665</td>\n",
       "      <td>0.63920</td>\n",
       "      <td>0.63185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.70350</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.76100</td>\n",
       "      <td>0.69315</td>\n",
       "      <td>0.68970</td>\n",
       "      <td>0.64550</td>\n",
       "      <td>0.64550</td>\n",
       "      <td>0.70850</td>\n",
       "      <td>0.72070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.55975</td>\n",
       "      <td>0.60500</td>\n",
       "      <td>0.65050</td>\n",
       "      <td>0.62120</td>\n",
       "      <td>0.69350</td>\n",
       "      <td>0.58815</td>\n",
       "      <td>0.55555</td>\n",
       "      <td>0.69965</td>\n",
       "      <td>0.57580</td>\n",
       "      <td>0.60875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.69995</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>0.76100</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.66160</td>\n",
       "      <td>0.68700</td>\n",
       "      <td>0.65500</td>\n",
       "      <td>0.65500</td>\n",
       "      <td>0.68315</td>\n",
       "      <td>0.71335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57800</td>\n",
       "      <td>0.63665</td>\n",
       "      <td>0.65900</td>\n",
       "      <td>0.61900</td>\n",
       "      <td>0.70700</td>\n",
       "      <td>0.59300</td>\n",
       "      <td>0.54950</td>\n",
       "      <td>0.67185</td>\n",
       "      <td>0.58200</td>\n",
       "      <td>0.61370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.65085</td>\n",
       "      <td>0.69315</td>\n",
       "      <td>0.69315</td>\n",
       "      <td>0.66160</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.63025</td>\n",
       "      <td>0.64000</td>\n",
       "      <td>0.64000</td>\n",
       "      <td>0.64965</td>\n",
       "      <td>0.68375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62485</td>\n",
       "      <td>0.64180</td>\n",
       "      <td>0.60255</td>\n",
       "      <td>0.60010</td>\n",
       "      <td>0.67985</td>\n",
       "      <td>0.61990</td>\n",
       "      <td>0.54340</td>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.62135</td>\n",
       "      <td>0.63570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1577 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2        3        4        5        7        8  \\\n",
       "0  1.00000  0.77700  0.70350  0.69995  0.65085  0.67350  0.66915  0.66915   \n",
       "1  0.77700  1.00000  0.75000  0.73500  0.69315  0.70240  0.65570  0.65570   \n",
       "2  0.70350  0.75000  1.00000  0.76100  0.69315  0.68970  0.64550  0.64550   \n",
       "3  0.69995  0.73500  0.76100  1.00000  0.66160  0.68700  0.65500  0.65500   \n",
       "4  0.65085  0.69315  0.69315  0.66160  1.00000  0.63025  0.64000  0.64000   \n",
       "\n",
       "         9       10  ...     2398     2400     2401     2402     2403  \\\n",
       "0  0.76100  0.71800  ...  0.59250  0.63185  0.65150  0.61850  0.70070   \n",
       "1  0.74785  0.79775  ...  0.59600  0.65265  0.67200  0.63085  0.69350   \n",
       "2  0.70850  0.72070  ...  0.55975  0.60500  0.65050  0.62120  0.69350   \n",
       "3  0.68315  0.71335  ...  0.57800  0.63665  0.65900  0.61900  0.70700   \n",
       "4  0.64965  0.68375  ...  0.62485  0.64180  0.60255  0.60010  0.67985   \n",
       "\n",
       "      2404     2405     2406     2407     2408  \n",
       "0  0.60550  0.54015  0.70460  0.61020  0.62840  \n",
       "1  0.60750  0.55310  0.71665  0.63920  0.63185  \n",
       "2  0.58815  0.55555  0.69965  0.57580  0.60875  \n",
       "3  0.59300  0.54950  0.67185  0.58200  0.61370  \n",
       "4  0.61990  0.54340  0.76250  0.62135  0.63570  \n",
       "\n",
       "[5 rows x 1577 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_similarity = pd.read_csv(path.join(DATA_DIR, \"chen/distances/deduplicated_anarci_similarity.csv\"), index_col=0)\n",
    "chen_similarity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a446fa1e-23fa-4fe8-b050-cf63068babaa",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6932d103-cb55-4cee-ad8e-57ac473e1e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "chen_train = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_train_data_w_clusters.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48e54805-8fec-472f-a4c9-fcc2f15022ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    3\n",
       "2    3\n",
       "3    4\n",
       "4    4\n",
       "Name: cluster_merged, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_train[\"cluster_merged\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de8365-c6c4-4b79-837e-e6211b19382f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38f59f95-95e6-4674-91f2-0c0ec62cc977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different usage from the other models\n",
    "def knn(n):\n",
    "    model = NearestNeighbors(metric=\"precomputed\")\n",
    "    parameters = {'n_neighbors': [1,3,5]}\n",
    "    return model, parameters, \"kNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf100a-6da8-4b89-a9be-8259631741db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abcd2b91-90cc-44cb-bd99-6d7f5ddada56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(n):\n",
    "    lr = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "    parameters = {'C':loguniform(0.001, 1000), 'penalty': [\"l2\"], \"solver\": [\"lbfgs\", \"sag\"]}\n",
    "    return lr, parameters, \"logistic_regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a4026c4-0b4f-4c6e-b1f1-4f72640506d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(n):\n",
    "    rf = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "    parameters = {'n_estimators': np.arange(1, 200, 10), 'max_depth': np.arange(1, min(50,n), 2), \n",
    "                  'max_features': np.arange(0.1, 0.75, 0.05)}\n",
    "    return rf, parameters, \"random_forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee462921-baee-4031-81ab-70a55154c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(n):\n",
    "    mlp = MLPClassifier(random_state=42, max_iter=int(1000))\n",
    "    parameters = {'hidden_layer_sizes': [(100,), (50,), (100, 100)], \"activation\": [\"relu\", \"logistic\"]}\n",
    "    return mlp, parameters, \"multilayer_perceptron\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de36f9d6-9b40-4420-b4eb-27f540feb1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(n):\n",
    "    svc = SVC(max_iter=8000, probability=True, class_weight='balanced')\n",
    "    parameters = {'C': loguniform(0.001, 100), 'kernel':[\"linear\", \"rbf\"], 'gamma': loguniform(1e-3, 1e0)}\n",
    "    return svc, parameters, \"SVM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11c6c12c-77ad-4b1c-96a0-b0190535f978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting(n):\n",
    "    gb = GradientBoostingClassifier(random_state=42, n_iter_no_change=70)\n",
    "    parameters = {'learning_rate': loguniform(0.01, 0.5), \n",
    "                  'n_estimators': np.arange(1, 200, 10), \n",
    "                  'max_depth': np.arange(1, min(20,n), 2), \n",
    "                  'max_features': np.arange(0.1, 0.6, 0.1)}\n",
    "    return gb, parameters, \"gradient_boosting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522bdca9-8b15-41b5-ba27-4043bae9924a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f49eab4-1c92-401f-8aca-ef05d4e52ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_evaluation(model_type, params, best_params, metrics, data, outpath, preprocessing=None):\n",
    "    prepro = \"_\"+preprocessing if preprocessing is not None else \"\"\n",
    "    filename = os.path.join(DATA_DIR, \"evaluations\", outpath, f\"{model_type}_{data}{prepro}.json\")\n",
    "    out_dict = {\n",
    "        \"model_type\": model_type,\n",
    "        \"data\": data\n",
    "    }\n",
    "    out_dict[\"params\"] = {}\n",
    "    out_dict[\"best_params\"] = {}\n",
    "    for key, value in params.items():\n",
    "        out_dict[\"params\"][key] = str(value)\n",
    "    for key, value in best_params.items():\n",
    "        out_dict[\"best_params\"][key] = str(value)\n",
    "    out_dict[\"metrics\"] = metrics\n",
    "    out_dict[\"preprocessing\"] = \"none\" if preprocessing is None else preprocessing\n",
    "    \n",
    "    json.dump(out_dict, open(filename, \"w\"))\n",
    "    \n",
    "    filename_sum = os.path.join(DATA_DIR, f\"evaluations/{outpath}/all.csv\")\n",
    "    #\"../evaluations/all.csv\"\n",
    "    line = [model_type, data, out_dict[\"preprocessing\"], metrics[\"f1\"], metrics[\"mcc\"], metrics[\"acc\"],metrics[\"precision\"],metrics[\"recall\"],metrics[\"auc\"], filename]\n",
    "    with open(filename_sum, 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter='\\t')\n",
    "        csvwriter.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96bd4c58-b7dd-49f2-bf3d-39b3938f6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(model_name, classifier, parameters, X_train, y_train, X_valid, y_valid, groups,\n",
    "                   data_name, outpath, preprocessing=None):\n",
    "    splitter = LeaveOneGroupOut()\n",
    "    split = splitter.split(X_train, y_train, groups=groups)\n",
    "    grid = RandomizedSearchCV(classifier, parameters, verbose=1, scoring=\"f1\", cv=split)\n",
    "    grid.fit(X_train, y_train)\n",
    "    estimator = grid.best_estimator_\n",
    "    best_params = grid.best_params_\n",
    "    y_pred = estimator.predict(X_valid)\n",
    "    prepro = \"_\"+preprocessing if preprocessing is not None else \"\"\n",
    "    filename = path.join(DATA_DIR, \"evaluations\", outpath, \"models\", f\"{model_name}_{data_name}{prepro}.pkl\")\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(estimator, f)\n",
    "    #pickle.dump(estimator, open(filename, \"w\"))\n",
    "    metric_dict = {\n",
    "        \"f1\": float(metrics.f1_score(y_valid, y_pred)),\n",
    "        \"acc\": float(metrics.accuracy_score(y_valid, y_pred)),\n",
    "        \"mcc\": float(metrics.matthews_corrcoef(y_valid, y_pred)),\n",
    "        \"auc\": float(metrics.roc_auc_score(y_valid, y_pred)),\n",
    "        \"precision\": float(metrics.precision_score(y_valid, y_pred)),\n",
    "        \"recall\": float(metrics.recall_score(y_valid, y_pred))\n",
    "    }\n",
    "    \n",
    "    print(f\"{model_name}, {data_name}\")\n",
    "    print(f\"F1: {metric_dict['f1']}\")\n",
    "    print(f\"MCC: {metric_dict['mcc']}\")\n",
    "    print(f\"Accuracy: {metric_dict['acc']}\")\n",
    "    print(f\"Precision: {metric_dict['precision']}\")\n",
    "    print(f\"Recall: {metric_dict['recall']}\")\n",
    "    print(f\"AUC: {metric_dict['auc']}\")\n",
    "    print(f\"-----\")\n",
    "    \n",
    "    output_evaluation(model_name, parameters, best_params, metric_dict, data_name, outpath, preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e30d50ba-ac70-40e7-9664-72a812e09efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all(X_train, y_train, X_valid, y_valid, groups, data_name, outpath, preprocessing=None):\n",
    "    n = len(y_train)\n",
    "    for model_creator in [logistic_regression, random_forest, gradient_boosting, svm, multilayer_perceptron]:\n",
    "        classifier, params, model_label = model_creator(n)\n",
    "        print(\"\\n\")\n",
    "        print(f'Training model {model_label} on data {data_name} \\n')\n",
    "        train_and_eval(model_label, classifier, params, X_train, y_train, X_valid, y_valid, groups, \n",
    "                   data_name, outpath, preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d4f9391-7024-44ed-894b-94977569f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_tap(model_name, x_test, y_test,\n",
    "                   data_name, outpath, preprocessing=None):\n",
    "    prepro = \"_\"+preprocessing if preprocessing is not None else \"\"\n",
    "    filename = path.join(DATA_DIR, \"evaluations\", outpath, \"models\", f\"{model_name}_{data_name}{prepro}.pkl\")\n",
    "    with open(filename, 'rb') as f:\n",
    "        estimator = pickle.load(f)\n",
    "    y_pred = estimator.predict(x_test)\n",
    "    metric_dict = {\n",
    "        \"f1\": float(metrics.f1_score(y_test, y_pred)),\n",
    "        \"acc\": float(metrics.accuracy_score(y_test, y_pred)),\n",
    "        \"mcc\": float(metrics.matthews_corrcoef(y_test, y_pred)),\n",
    "        \"auc\": float(metrics.roc_auc_score(y_test, y_pred)),\n",
    "        \"precision\": float(metrics.precision_score(y_test, y_pred)),\n",
    "        \"recall\": float(metrics.recall_score(y_test, y_pred))\n",
    "    }\n",
    "    filename_sum = os.path.join(DATA_DIR, f\"evaluations/{outpath}/tap.csv\")\n",
    "    line = [model_name, data_name, prepro, metric_dict[\"f1\"], metric_dict[\"mcc\"], metric_dict[\"acc\"],metric_dict[\"precision\"],metric_dict[\"recall\"],metric_dict[\"auc\"], filename]\n",
    "    with open(filename_sum, 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter='\\t')\n",
    "        csvwriter.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6513aa7-f94c-4eb9-820d-510782accecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all(x_test, y_test, data_name, outpath, preprocessing=None):\n",
    "    for model in [\"logistic_regression\", \"random_forest\", \"gradient_boosting\", \"SVM\", \"multilayer_perceptron\"]:\n",
    "        print(f\"Testing model {model} on {data_name}...\")\n",
    "        test_on_tap(model, x_test, y_test, data_name, outpath, preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a14fdc-99e4-4748-822d-88fddfb49f52",
   "metadata": {},
   "source": [
    "# PyBioMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "544a4e36-4667-41e9-9602-f418aa27a636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>19752</th>\n",
       "      <th>19753</th>\n",
       "      <th>19754</th>\n",
       "      <th>19755</th>\n",
       "      <th>19756</th>\n",
       "      <th>19757</th>\n",
       "      <th>19758</th>\n",
       "      <th>19759</th>\n",
       "      <th>Y</th>\n",
       "      <th>cluster_merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1a0q</td>\n",
       "      <td>5.882</td>\n",
       "      <td>1.681</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.042</td>\n",
       "      <td>1.681</td>\n",
       "      <td>5.882</td>\n",
       "      <td>5.042</td>\n",
       "      <td>9.244</td>\n",
       "      <td>1.681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1a14</td>\n",
       "      <td>6.667</td>\n",
       "      <td>2.500</td>\n",
       "      <td>4.167</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.667</td>\n",
       "      <td>2.500</td>\n",
       "      <td>7.500</td>\n",
       "      <td>11.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a2y</td>\n",
       "      <td>3.448</td>\n",
       "      <td>5.172</td>\n",
       "      <td>4.310</td>\n",
       "      <td>6.034</td>\n",
       "      <td>1.724</td>\n",
       "      <td>2.586</td>\n",
       "      <td>6.034</td>\n",
       "      <td>10.345</td>\n",
       "      <td>0.862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a3l</td>\n",
       "      <td>5.882</td>\n",
       "      <td>3.361</td>\n",
       "      <td>2.521</td>\n",
       "      <td>3.361</td>\n",
       "      <td>1.681</td>\n",
       "      <td>5.882</td>\n",
       "      <td>3.361</td>\n",
       "      <td>13.445</td>\n",
       "      <td>0.840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a4j</td>\n",
       "      <td>7.563</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.042</td>\n",
       "      <td>3.361</td>\n",
       "      <td>1.681</td>\n",
       "      <td>5.882</td>\n",
       "      <td>4.202</td>\n",
       "      <td>9.244</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19763 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ab_ID      0      1      2      3      4      5      6       7      8  ...  \\\n",
       "0  1a0q  5.882  1.681  3.361  5.042  1.681  5.882  5.042   9.244  1.681  ...   \n",
       "1  1a14  6.667  2.500  4.167  5.000  1.667  2.500  7.500  11.667  0.000  ...   \n",
       "2  1a2y  3.448  5.172  4.310  6.034  1.724  2.586  6.034  10.345  0.862  ...   \n",
       "3  1a3l  5.882  3.361  2.521  3.361  1.681  5.882  3.361  13.445  0.840  ...   \n",
       "4  1a4j  7.563  3.361  5.042  3.361  1.681  5.882  4.202   9.244  0.000  ...   \n",
       "\n",
       "   19752  19753  19754  19755  19756  19757  19758  19759  Y  cluster_merged  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  1               2  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0               4  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0               1  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0               4  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0               7  \n",
       "\n",
       "[5 rows x 19763 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chen = pd.read_feather(path.join(DATA_DIR, \"chen/pybiomed/X_data.ftr\"))\n",
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_valid = x_chen.merge(chen_valid[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdd0618a-a7d2-489e-b317-c87a2b0b9b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>19751</th>\n",
       "      <th>19752</th>\n",
       "      <th>19753</th>\n",
       "      <th>19754</th>\n",
       "      <th>19755</th>\n",
       "      <th>19756</th>\n",
       "      <th>19757</th>\n",
       "      <th>19758</th>\n",
       "      <th>19759</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12e8</td>\n",
       "      <td>7.500</td>\n",
       "      <td>3.333</td>\n",
       "      <td>2.500</td>\n",
       "      <td>5.833</td>\n",
       "      <td>1.667</td>\n",
       "      <td>5.833</td>\n",
       "      <td>5.833</td>\n",
       "      <td>9.167</td>\n",
       "      <td>1.667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15c8</td>\n",
       "      <td>9.244</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.882</td>\n",
       "      <td>1.681</td>\n",
       "      <td>4.202</td>\n",
       "      <td>6.723</td>\n",
       "      <td>8.403</td>\n",
       "      <td>2.521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1aqk</td>\n",
       "      <td>7.317</td>\n",
       "      <td>5.691</td>\n",
       "      <td>4.878</td>\n",
       "      <td>4.065</td>\n",
       "      <td>1.626</td>\n",
       "      <td>3.252</td>\n",
       "      <td>5.691</td>\n",
       "      <td>8.943</td>\n",
       "      <td>0.813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1ar1</td>\n",
       "      <td>5.085</td>\n",
       "      <td>5.085</td>\n",
       "      <td>3.390</td>\n",
       "      <td>4.237</td>\n",
       "      <td>1.695</td>\n",
       "      <td>5.085</td>\n",
       "      <td>4.237</td>\n",
       "      <td>9.322</td>\n",
       "      <td>0.847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1bfv</td>\n",
       "      <td>5.882</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.042</td>\n",
       "      <td>4.202</td>\n",
       "      <td>1.681</td>\n",
       "      <td>4.202</td>\n",
       "      <td>5.042</td>\n",
       "      <td>9.244</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19762 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ab_ID      0      1      2      3      4      5      6      7      8  ...  \\\n",
       "0  12e8  7.500  3.333  2.500  5.833  1.667  5.833  5.833  9.167  1.667  ...   \n",
       "1  15c8  9.244  0.000  3.361  5.882  1.681  4.202  6.723  8.403  2.521  ...   \n",
       "2  1aqk  7.317  5.691  4.878  4.065  1.626  3.252  5.691  8.943  0.813  ...   \n",
       "3  1ar1  5.085  5.085  3.390  4.237  1.695  5.085  4.237  9.322  0.847  ...   \n",
       "4  1bfv  5.882  3.361  5.042  4.202  1.681  4.202  5.042  9.244  0.000  ...   \n",
       "\n",
       "   19751  19752  19753  19754  19755  19756  19757  19758  19759  Y  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0  \n",
       "\n",
       "[5 rows x 19762 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chen_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d85f8765-ebcc-4cc9-8738-5caa197679d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_chen_train.drop([\"Ab_ID\", \"Y\", \"cluster_merged\"], axis=1))\n",
    "x_chen_train_tr = scaler.transform(x_chen_train.drop([\"Ab_ID\", \"Y\", \"cluster_merged\"], axis=1))\n",
    "x_chen_valid_tr = scaler.transform(x_chen_valid.drop([\"Ab_ID\", \"Y\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70f1926e-51a4-4f47-b9e2-ca3759a51d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19750</th>\n",
       "      <th>19751</th>\n",
       "      <th>19752</th>\n",
       "      <th>19753</th>\n",
       "      <th>19754</th>\n",
       "      <th>19755</th>\n",
       "      <th>19756</th>\n",
       "      <th>19757</th>\n",
       "      <th>19758</th>\n",
       "      <th>19759</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.084</td>\n",
       "      <td>3.361</td>\n",
       "      <td>2.521</td>\n",
       "      <td>3.361</td>\n",
       "      <td>1.681</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.882</td>\n",
       "      <td>11.765</td>\n",
       "      <td>0.840</td>\n",
       "      <td>1.681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.627</td>\n",
       "      <td>4.237</td>\n",
       "      <td>1.695</td>\n",
       "      <td>3.390</td>\n",
       "      <td>1.695</td>\n",
       "      <td>5.085</td>\n",
       "      <td>5.932</td>\n",
       "      <td>10.169</td>\n",
       "      <td>0.847</td>\n",
       "      <td>2.542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.932</td>\n",
       "      <td>1.695</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.932</td>\n",
       "      <td>1.695</td>\n",
       "      <td>5.085</td>\n",
       "      <td>6.780</td>\n",
       "      <td>10.169</td>\n",
       "      <td>0.847</td>\n",
       "      <td>1.695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.738</td>\n",
       "      <td>6.557</td>\n",
       "      <td>4.098</td>\n",
       "      <td>5.738</td>\n",
       "      <td>1.639</td>\n",
       "      <td>3.279</td>\n",
       "      <td>4.918</td>\n",
       "      <td>11.475</td>\n",
       "      <td>0.820</td>\n",
       "      <td>3.279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.091</td>\n",
       "      <td>4.959</td>\n",
       "      <td>3.306</td>\n",
       "      <td>5.785</td>\n",
       "      <td>1.653</td>\n",
       "      <td>4.132</td>\n",
       "      <td>4.132</td>\n",
       "      <td>9.091</td>\n",
       "      <td>1.653</td>\n",
       "      <td>2.479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19760 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5      6       7      8      9  \\\n",
       "0  10.084  3.361  2.521  3.361  1.681  3.361  5.882  11.765  0.840  1.681   \n",
       "1   7.627  4.237  1.695  3.390  1.695  5.085  5.932  10.169  0.847  2.542   \n",
       "2   5.932  1.695  0.000  5.932  1.695  5.085  6.780  10.169  0.847  1.695   \n",
       "3   5.738  6.557  4.098  5.738  1.639  3.279  4.918  11.475  0.820  3.279   \n",
       "4   9.091  4.959  3.306  5.785  1.653  4.132  4.132   9.091  1.653  2.479   \n",
       "\n",
       "   ...  19750  19751  19752  19753  19754  19755  19756  19757  19758  19759  \n",
       "0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 19760 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tap = pd.read_feather(path.join(DATA_DIR, \"tap/pybiomed/X_TAP_data.ftr\"))\n",
    "x_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e12c841-12e0-491d-90d3-210ce8de9f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#scaler.fit(x_tap)\n",
    "x_tap = scaler.transform(x_tap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e1f4a96-fb3a-4daf-bb81-92817b5e393e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data pybiomed \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression, pybiomed\n",
      "F1: 0.5116279069767442\n",
      "MCC: 0.4129883863185677\n",
      "Accuracy: 0.8242677824267782\n",
      "Precision: 0.5945945945945946\n",
      "Recall: 0.4489795918367347\n",
      "AUC: 0.685016111707841\n",
      "-----\n",
      "\n",
      "\n",
      "Training model random_forest on data pybiomed \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "random_forest, pybiomed\n",
      "F1: 0.5040650406504065\n",
      "MCC: 0.3548163866360956\n",
      "Accuracy: 0.7447698744769874\n",
      "Precision: 0.4189189189189189\n",
      "Recall: 0.6326530612244898\n",
      "AUC: 0.7031686358754028\n",
      "-----\n",
      "\n",
      "\n",
      "Training model gradient_boosting on data pybiomed \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "gradient_boosting, pybiomed\n",
      "F1: 0.28125\n",
      "MCC: 0.25317380815700374\n",
      "Accuracy: 0.8075313807531381\n",
      "Precision: 0.6\n",
      "Recall: 0.1836734693877551\n",
      "AUC: 0.576047261009667\n",
      "-----\n",
      "\n",
      "\n",
      "Training model SVM on data pybiomed \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "SVM, pybiomed\n",
      "F1: 0.5161290322580645\n",
      "MCC: 0.4005571996862699\n",
      "Accuracy: 0.8117154811715481\n",
      "Precision: 0.5454545454545454\n",
      "Recall: 0.4897959183673469\n",
      "AUC: 0.6922663802363052\n",
      "-----\n",
      "\n",
      "\n",
      "Training model multilayer_perceptron on data pybiomed \n",
      "\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron, pybiomed\n",
      "F1: 0.46511627906976744\n",
      "MCC: 0.3556854984636256\n",
      "Accuracy: 0.8075313807531381\n",
      "Precision: 0.5405405405405406\n",
      "Recall: 0.40816326530612246\n",
      "AUC: 0.659344790547798\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train_tr, x_chen_train[\"Y\"], x_chen_valid_tr, x_chen_valid[\"Y\"], x_chen_train[\"cluster_merged\"], \"pybiomed\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f655a5d7-44b3-4668-9212-14274181202c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on pybiomed...\n",
      "Testing model random_forest on pybiomed...\n",
      "Testing model gradient_boosting on pybiomed...\n",
      "Testing model SVM on pybiomed...\n",
      "Testing model multilayer_perceptron on pybiomed...\n"
     ]
    }
   ],
   "source": [
    "test_all(x_tap, tap_data[\"Y\"], \"pybiomed\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77646694-01c8-4a7f-af38-15c2afc8f59a",
   "metadata": {},
   "source": [
    "# Protparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42310c2b-2bbf-4f1a-8507-174b3bf6173d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>aa_percent0_x</th>\n",
       "      <th>aa_percent1_x</th>\n",
       "      <th>aa_percent2_x</th>\n",
       "      <th>aa_percent3_x</th>\n",
       "      <th>aa_percent4_x</th>\n",
       "      <th>aa_percent5_x</th>\n",
       "      <th>aa_percent6_x</th>\n",
       "      <th>aa_percent7_x</th>\n",
       "      <th>aa_percent8_x</th>\n",
       "      <th>...</th>\n",
       "      <th>mol_extinct1_y</th>\n",
       "      <th>mol_extinct2_y</th>\n",
       "      <th>mw_y</th>\n",
       "      <th>gravy_y</th>\n",
       "      <th>ss_faction1_y</th>\n",
       "      <th>ss_faction2_y</th>\n",
       "      <th>ss_faction3_y</th>\n",
       "      <th>name</th>\n",
       "      <th>Y</th>\n",
       "      <th>cluster_merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3okd</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.106557</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>...</td>\n",
       "      <td>19940</td>\n",
       "      <td>20065</td>\n",
       "      <td>12297.7329</td>\n",
       "      <td>-0.427679</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.294643</td>\n",
       "      <td>0.205357</td>\n",
       "      <td>3okd</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5fb8</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.041322</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>0.033058</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>...</td>\n",
       "      <td>15930</td>\n",
       "      <td>16055</td>\n",
       "      <td>12046.3419</td>\n",
       "      <td>-0.344144</td>\n",
       "      <td>0.279279</td>\n",
       "      <td>0.306306</td>\n",
       "      <td>0.225225</td>\n",
       "      <td>5fb8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4olz</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>...</td>\n",
       "      <td>21430</td>\n",
       "      <td>21555</td>\n",
       "      <td>11093.1436</td>\n",
       "      <td>-0.370297</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.158416</td>\n",
       "      <td>4olz</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5i19</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.134454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>...</td>\n",
       "      <td>14440</td>\n",
       "      <td>14565</td>\n",
       "      <td>11531.7166</td>\n",
       "      <td>-0.316822</td>\n",
       "      <td>0.271028</td>\n",
       "      <td>0.327103</td>\n",
       "      <td>0.158879</td>\n",
       "      <td>5i19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2xqb</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>...</td>\n",
       "      <td>26930</td>\n",
       "      <td>27055</td>\n",
       "      <td>11672.8413</td>\n",
       "      <td>-0.599057</td>\n",
       "      <td>0.273585</td>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.179245</td>\n",
       "      <td>2xqb</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ab_ID  aa_percent0_x  aa_percent1_x  aa_percent2_x  aa_percent3_x  \\\n",
       "0  3okd       0.081967       0.016393       0.040984       0.049180   \n",
       "1  5fb8       0.049587       0.016529       0.049587       0.041322   \n",
       "2  4olz       0.056000       0.032000       0.048000       0.040000   \n",
       "3  5i19       0.075630       0.016807       0.042017       0.042017   \n",
       "4  2xqb       0.096000       0.016000       0.048000       0.024000   \n",
       "\n",
       "   aa_percent4_x  aa_percent5_x  aa_percent6_x  aa_percent7_x  aa_percent8_x  \\\n",
       "0       0.040984       0.106557       0.008197       0.016393       0.040984   \n",
       "1       0.024793       0.074380       0.016529       0.033058       0.074380   \n",
       "2       0.032000       0.088000       0.008000       0.032000       0.040000   \n",
       "3       0.033613       0.134454       0.000000       0.025210       0.033613   \n",
       "4       0.040000       0.080000       0.000000       0.016000       0.048000   \n",
       "\n",
       "   ...  mol_extinct1_y  mol_extinct2_y        mw_y   gravy_y  ss_faction1_y  \\\n",
       "0  ...           19940           20065  12297.7329 -0.427679       0.276786   \n",
       "1  ...           15930           16055  12046.3419 -0.344144       0.279279   \n",
       "2  ...           21430           21555  11093.1436 -0.370297       0.306931   \n",
       "3  ...           14440           14565  11531.7166 -0.316822       0.271028   \n",
       "4  ...           26930           27055  11672.8413 -0.599057       0.273585   \n",
       "\n",
       "   ss_faction2_y  ss_faction3_y  name  Y  cluster_merged  \n",
       "0       0.294643       0.205357  3okd  1               1  \n",
       "1       0.306306       0.225225  5fb8  1               0  \n",
       "2       0.316832       0.158416  4olz  0               1  \n",
       "3       0.327103       0.158879  5i19  1               0  \n",
       "4       0.330189       0.179245  2xqb  0               7  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chen = pd.read_csv(path.join(DATA_DIR, \"chen/protparam/protparam_features.csv\"))\n",
    "x_chen.rename({\"Unnamed: 0\": \"Ab_ID\"}, axis=1, inplace=True)\n",
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_valid = x_chen.merge(chen_valid[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4e31a9f-f557-48c5-9600-d3b42ba258a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_chen_train.drop([\"Ab_ID\", \"name\", \"Y\", \"cluster_merged\"], axis=1))\n",
    "x_chen_train_tr = scaler.transform(x_chen_train.drop([\"Ab_ID\", \"name\", \"Y\", \"cluster_merged\"], axis=1))\n",
    "x_chen_valid_tr = scaler.transform(x_chen_valid.drop([\"Ab_ID\", \"name\", \"Y\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ad9974e-c757-4f91-800f-b2bb9daed827",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data protparam \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression, protparam\n",
      "F1: 0.5483870967741935\n",
      "MCC: 0.4159395312743193\n",
      "Accuracy: 0.7656903765690377\n",
      "Precision: 0.4533333333333333\n",
      "Recall: 0.6938775510204082\n",
      "AUC: 0.7390440386680988\n",
      "-----\n",
      "\n",
      "\n",
      "Training model random_forest on data protparam \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest, protparam\n",
      "F1: 0.5245901639344263\n",
      "MCC: 0.38327526078061885\n",
      "Accuracy: 0.7573221757322176\n",
      "Precision: 0.4383561643835616\n",
      "Recall: 0.6530612244897959\n",
      "AUC: 0.7186358754027926\n",
      "-----\n",
      "\n",
      "\n",
      "Training model gradient_boosting on data protparam \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "gradient_boosting, protparam\n",
      "F1: 0.36363636363636365\n",
      "MCC: 0.2661656853192727\n",
      "Accuracy: 0.7949790794979079\n",
      "Precision: 0.5\n",
      "Recall: 0.2857142857142857\n",
      "AUC: 0.6060150375939849\n",
      "-----\n",
      "\n",
      "\n",
      "Training model SVM on data protparam \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, protparam\n",
      "F1: 0.556390977443609\n",
      "MCC: 0.4293438730646694\n",
      "Accuracy: 0.7531380753138075\n",
      "Precision: 0.44047619047619047\n",
      "Recall: 0.7551020408163265\n",
      "AUC: 0.7538668098818475\n",
      "-----\n",
      "\n",
      "\n",
      "Training model multilayer_perceptron on data protparam \n",
      "\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron, protparam\n",
      "F1: 0.49411764705882355\n",
      "MCC: 0.3946179926516897\n",
      "Accuracy: 0.8200836820083682\n",
      "Precision: 0.5833333333333334\n",
      "Recall: 0.42857142857142855\n",
      "AUC: 0.674812030075188\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train_tr, x_chen_train[\"Y\"], x_chen_valid_tr, x_chen_valid[\"Y\"], x_chen_train[\"cluster_merged\"], \n",
    "        \"protparam\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7985406b-d9db-4979-960e-5e1264c6d6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>aa_percent0_x</th>\n",
       "      <th>aa_percent1_x</th>\n",
       "      <th>aa_percent2_x</th>\n",
       "      <th>aa_percent3_x</th>\n",
       "      <th>aa_percent4_x</th>\n",
       "      <th>aa_percent5_x</th>\n",
       "      <th>aa_percent6_x</th>\n",
       "      <th>aa_percent7_x</th>\n",
       "      <th>aa_percent8_x</th>\n",
       "      <th>...</th>\n",
       "      <th>instability_y</th>\n",
       "      <th>flexibility_y</th>\n",
       "      <th>isoelectric_y</th>\n",
       "      <th>mol_extinct1_y</th>\n",
       "      <th>mol_extinct2_y</th>\n",
       "      <th>mw_y</th>\n",
       "      <th>gravy_y</th>\n",
       "      <th>ss_faction1_y</th>\n",
       "      <th>ss_faction2_y</th>\n",
       "      <th>ss_faction3_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abagovomab</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>...</td>\n",
       "      <td>53.693458</td>\n",
       "      <td>0.999564</td>\n",
       "      <td>7.973724</td>\n",
       "      <td>14440</td>\n",
       "      <td>14565</td>\n",
       "      <td>11556.8384</td>\n",
       "      <td>-0.257009</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>0.196262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abituzumab</td>\n",
       "      <td>0.076271</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>...</td>\n",
       "      <td>42.514019</td>\n",
       "      <td>1.001379</td>\n",
       "      <td>8.586625</td>\n",
       "      <td>17420</td>\n",
       "      <td>17545</td>\n",
       "      <td>11762.9686</td>\n",
       "      <td>-0.452336</td>\n",
       "      <td>0.280374</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>0.121495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrilumab</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>...</td>\n",
       "      <td>40.151402</td>\n",
       "      <td>1.002818</td>\n",
       "      <td>7.970307</td>\n",
       "      <td>22460</td>\n",
       "      <td>22585</td>\n",
       "      <td>11548.7104</td>\n",
       "      <td>-0.335514</td>\n",
       "      <td>0.271028</td>\n",
       "      <td>0.336449</td>\n",
       "      <td>0.158879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actoxumab</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.024590</td>\n",
       "      <td>...</td>\n",
       "      <td>51.517757</td>\n",
       "      <td>1.000328</td>\n",
       "      <td>8.682102</td>\n",
       "      <td>22460</td>\n",
       "      <td>22585</td>\n",
       "      <td>11530.7383</td>\n",
       "      <td>-0.260748</td>\n",
       "      <td>0.271028</td>\n",
       "      <td>0.317757</td>\n",
       "      <td>0.158879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adalimumab</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>0.057851</td>\n",
       "      <td>0.041322</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>...</td>\n",
       "      <td>46.585047</td>\n",
       "      <td>1.000522</td>\n",
       "      <td>9.428646</td>\n",
       "      <td>15930</td>\n",
       "      <td>16055</td>\n",
       "      <td>11664.9632</td>\n",
       "      <td>-0.402804</td>\n",
       "      <td>0.271028</td>\n",
       "      <td>0.289720</td>\n",
       "      <td>0.168224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ab_ID  aa_percent0_x  aa_percent1_x  aa_percent2_x  aa_percent3_x  \\\n",
       "0  Abagovomab       0.100840       0.016807       0.033613       0.033613   \n",
       "1  Abituzumab       0.076271       0.016949       0.033898       0.050847   \n",
       "2   Abrilumab       0.059322       0.016949       0.059322       0.050847   \n",
       "3   Actoxumab       0.057377       0.016393       0.057377       0.032787   \n",
       "4  Adalimumab       0.090909       0.016529       0.057851       0.041322   \n",
       "\n",
       "   aa_percent4_x  aa_percent5_x  aa_percent6_x  aa_percent7_x  aa_percent8_x  \\\n",
       "0       0.025210       0.117647       0.008403       0.016807       0.067227   \n",
       "1       0.033898       0.101695       0.008475       0.025424       0.033898   \n",
       "2       0.025424       0.101695       0.008475       0.016949       0.059322   \n",
       "3       0.032787       0.114754       0.008197       0.032787       0.024590   \n",
       "4       0.024793       0.090909       0.016529       0.024793       0.024793   \n",
       "\n",
       "   ...  instability_y  flexibility_y  isoelectric_y  mol_extinct1_y  \\\n",
       "0  ...      53.693458       0.999564       7.973724           14440   \n",
       "1  ...      42.514019       1.001379       8.586625           17420   \n",
       "2  ...      40.151402       1.002818       7.970307           22460   \n",
       "3  ...      51.517757       1.000328       8.682102           22460   \n",
       "4  ...      46.585047       1.000522       9.428646           15930   \n",
       "\n",
       "   mol_extinct2_y        mw_y   gravy_y  ss_faction1_y  ss_faction2_y  \\\n",
       "0           14565  11556.8384 -0.257009       0.299065       0.299065   \n",
       "1           17545  11762.9686 -0.452336       0.280374       0.299065   \n",
       "2           22585  11548.7104 -0.335514       0.271028       0.336449   \n",
       "3           22585  11530.7383 -0.260748       0.271028       0.317757   \n",
       "4           16055  11664.9632 -0.402804       0.271028       0.289720   \n",
       "\n",
       "   ss_faction3_y  \n",
       "0       0.196262  \n",
       "1       0.121495  \n",
       "2       0.158879  \n",
       "3       0.158879  \n",
       "4       0.168224  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tap = pd.read_csv(path.join(DATA_DIR, \"tap/protparam/protparam_features_tap.csv\"))\n",
    "x_tap.rename({\"Unnamed: 0\": \"Ab_ID\"}, axis=1, inplace=True)\n",
    "x_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db71a3e0-b2bf-48ce-bc4a-21be518445b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tap = scaler.transform(x_tap.drop(\"Ab_ID\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e92f207-70c2-4db4-ae35-33644248d8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on protparam...\n",
      "Testing model random_forest on protparam...\n",
      "Testing model gradient_boosting on protparam...\n",
      "Testing model SVM on protparam...\n",
      "Testing model multilayer_perceptron on protparam...\n"
     ]
    }
   ],
   "source": [
    "test_all(x_tap, tap_data[\"Y\"], \"protparam\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca554f3e-5877-44b1-9fc8-f80b1dbcbc44",
   "metadata": {},
   "source": [
    "# BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16dceef-1516-4b03-b681-194070178a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_chen = pd.read_feather(path.join(DATA_DIR, \"chen/embeddings/bert/bert_chen_embeddings.ftr\"))\n",
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_valid = x_chen.merge(chen_valid[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9502338a-a819-4ad5-bf07-d8e11af8aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_chen_train.drop([\"Ab_ID\", \"Y\", \"cluster_merged\"], axis=1))\n",
    "x_chen_train_tr = scaler.transform(x_chen_train.drop([\"Ab_ID\", \"Y\", \"cluster_merged\"], axis=1))\n",
    "x_chen_valid_tr = scaler.transform(x_chen_valid.drop([\"Ab_ID\", \"Y\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169edc1a-15ba-48a7-b707-9c8117a795e1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data bert \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression, bert\n",
      "F1: 0.6218487394957983\n",
      "MCC: 0.5157875016520946\n",
      "Accuracy: 0.8117154811715481\n",
      "Precision: 0.5285714285714286\n",
      "Recall: 0.7551020408163265\n",
      "AUC: 0.7907089151450053\n",
      "-----\n",
      "\n",
      "\n",
      "Training model random_forest on data bert \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train_tr, x_chen_train[\"Y\"], x_chen_valid_tr, x_chen_valid[\"Y\"], \n",
    "        x_chen_train[\"cluster_merged\"], \"bert\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24bcce-1674-4fa5-9998-61020acbce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tap = pd.read_feather(path.join(DATA_DIR, \"tap/embeddings/bert/bert_tap_embeddings.ftr\"))\n",
    "x_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7768e-3dd2-41d9-8a91-d0cf9760b3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tap = scaler.transform(x_tap.drop(\"Ab_ID\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5db8ae-38b9-4947-9717-5cd937b73fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all(x_tap, tap_data[\"Y\"], \"bert\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b72f0-8d1e-49b2-af8c-5f8e40d79114",
   "metadata": {},
   "source": [
    "# SeqVec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "242800ab-9c9f-40bc-8833-2d43e2cfe302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>Y</th>\n",
       "      <th>cluster_merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1a0q</td>\n",
       "      <td>0.073347</td>\n",
       "      <td>-0.186018</td>\n",
       "      <td>-0.233184</td>\n",
       "      <td>-0.165189</td>\n",
       "      <td>0.064193</td>\n",
       "      <td>-0.030149</td>\n",
       "      <td>0.043134</td>\n",
       "      <td>0.111651</td>\n",
       "      <td>-0.120727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138852</td>\n",
       "      <td>0.049886</td>\n",
       "      <td>-0.044254</td>\n",
       "      <td>-0.012993</td>\n",
       "      <td>-0.032100</td>\n",
       "      <td>-0.005154</td>\n",
       "      <td>-0.035896</td>\n",
       "      <td>-0.053616</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1a14</td>\n",
       "      <td>0.066646</td>\n",
       "      <td>-0.216164</td>\n",
       "      <td>-0.275053</td>\n",
       "      <td>-0.124785</td>\n",
       "      <td>0.051032</td>\n",
       "      <td>-0.010701</td>\n",
       "      <td>0.042427</td>\n",
       "      <td>0.123428</td>\n",
       "      <td>-0.098271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141865</td>\n",
       "      <td>-0.114347</td>\n",
       "      <td>0.011103</td>\n",
       "      <td>-0.044319</td>\n",
       "      <td>-0.028007</td>\n",
       "      <td>0.020282</td>\n",
       "      <td>-0.050135</td>\n",
       "      <td>-0.095745</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a2y</td>\n",
       "      <td>0.089280</td>\n",
       "      <td>-0.191509</td>\n",
       "      <td>-0.165287</td>\n",
       "      <td>-0.087335</td>\n",
       "      <td>0.067743</td>\n",
       "      <td>-0.043121</td>\n",
       "      <td>0.027767</td>\n",
       "      <td>0.232575</td>\n",
       "      <td>-0.080467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216815</td>\n",
       "      <td>0.082564</td>\n",
       "      <td>0.016979</td>\n",
       "      <td>-0.003557</td>\n",
       "      <td>-0.081891</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>-0.041633</td>\n",
       "      <td>-0.220336</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a3l</td>\n",
       "      <td>0.007294</td>\n",
       "      <td>-0.190514</td>\n",
       "      <td>-0.289291</td>\n",
       "      <td>-0.150268</td>\n",
       "      <td>0.056585</td>\n",
       "      <td>0.023869</td>\n",
       "      <td>-0.016217</td>\n",
       "      <td>0.094631</td>\n",
       "      <td>-0.208477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179691</td>\n",
       "      <td>-0.022877</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>-0.055541</td>\n",
       "      <td>-0.035867</td>\n",
       "      <td>-0.030935</td>\n",
       "      <td>-0.006666</td>\n",
       "      <td>0.009036</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a4j</td>\n",
       "      <td>-0.016434</td>\n",
       "      <td>-0.144044</td>\n",
       "      <td>-0.292733</td>\n",
       "      <td>-0.124054</td>\n",
       "      <td>0.080313</td>\n",
       "      <td>-0.051480</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.087235</td>\n",
       "      <td>-0.182320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267914</td>\n",
       "      <td>0.044216</td>\n",
       "      <td>0.020647</td>\n",
       "      <td>0.060805</td>\n",
       "      <td>-0.116175</td>\n",
       "      <td>0.111569</td>\n",
       "      <td>0.045578</td>\n",
       "      <td>-0.108075</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2051 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ab_ID         0         1         2         3         4         5         6  \\\n",
       "0  1a0q  0.073347 -0.186018 -0.233184 -0.165189  0.064193 -0.030149  0.043134   \n",
       "1  1a14  0.066646 -0.216164 -0.275053 -0.124785  0.051032 -0.010701  0.042427   \n",
       "2  1a2y  0.089280 -0.191509 -0.165287 -0.087335  0.067743 -0.043121  0.027767   \n",
       "3  1a3l  0.007294 -0.190514 -0.289291 -0.150268  0.056585  0.023869 -0.016217   \n",
       "4  1a4j -0.016434 -0.144044 -0.292733 -0.124054  0.080313 -0.051480  0.000747   \n",
       "\n",
       "          7         8  ...      2040      2041      2042      2043      2044  \\\n",
       "0  0.111651 -0.120727  ...  0.138852  0.049886 -0.044254 -0.012993 -0.032100   \n",
       "1  0.123428 -0.098271  ...  0.141865 -0.114347  0.011103 -0.044319 -0.028007   \n",
       "2  0.232575 -0.080467  ...  0.216815  0.082564  0.016979 -0.003557 -0.081891   \n",
       "3  0.094631 -0.208477  ...  0.179691 -0.022877  0.003620 -0.055541 -0.035867   \n",
       "4  0.087235 -0.182320  ...  0.267914  0.044216  0.020647  0.060805 -0.116175   \n",
       "\n",
       "       2045      2046      2047  Y  cluster_merged  \n",
       "0 -0.005154 -0.035896 -0.053616  1               2  \n",
       "1  0.020282 -0.050135 -0.095745  0               4  \n",
       "2  0.005624 -0.041633 -0.220336  0               1  \n",
       "3 -0.030935 -0.006666  0.009036  0               4  \n",
       "4  0.111569  0.045578 -0.108075  0               7  \n",
       "\n",
       "[5 rows x 2051 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chen = pd.read_feather(path.join(DATA_DIR, \"chen/embeddings/seqvec/seqvec_chen_embeddings.ftr\"))\n",
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_valid = x_chen.merge(chen_valid[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0730c305-3d8c-45ec-8d18-fd9f577aba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_chen_train.drop([\"Ab_ID\", \"Y\", \"cluster_merged\"], axis=1))\n",
    "x_chen_train_tr = scaler.transform(x_chen_train.drop([\"Ab_ID\", \"Y\", \"cluster_merged\"], axis=1))\n",
    "x_chen_valid_tr = scaler.transform(x_chen_valid.drop([\"Ab_ID\", \"Y\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40df67f1-1c9a-419b-816f-87d21b10882c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data seqvec \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression, seqvec\n",
      "F1: 0.5585585585585586\n",
      "MCC: 0.4324376395222651\n",
      "Accuracy: 0.7949790794979079\n",
      "Precision: 0.5\n",
      "Recall: 0.6326530612244898\n",
      "AUC: 0.7347475832438238\n",
      "-----\n",
      "\n",
      "\n",
      "Training model random_forest on data seqvec \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "random_forest, seqvec\n",
      "F1: 0.4444444444444445\n",
      "MCC: 0.34814768192383505\n",
      "Accuracy: 0.8117154811715481\n",
      "Precision: 0.5625\n",
      "Recall: 0.3673469387755102\n",
      "AUC: 0.6468313641245972\n",
      "-----\n",
      "\n",
      "\n",
      "Training model gradient_boosting on data seqvec \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "gradient_boosting, seqvec\n",
      "F1: 0.23333333333333328\n",
      "MCC: 0.23467911835588212\n",
      "Accuracy: 0.8075313807531381\n",
      "Precision: 0.6363636363636364\n",
      "Recall: 0.14285714285714285\n",
      "AUC: 0.5609022556390977\n",
      "-----\n",
      "\n",
      "\n",
      "Training model SVM on data seqvec \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, seqvec\n",
      "F1: 0.5050505050505051\n",
      "MCC: 0.375810038454702\n",
      "Accuracy: 0.7949790794979079\n",
      "Precision: 0.5\n",
      "Recall: 0.5102040816326531\n",
      "AUC: 0.689312567132116\n",
      "-----\n",
      "\n",
      "\n",
      "Training model multilayer_perceptron on data seqvec \n",
      "\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron, seqvec\n",
      "F1: 0.4719101123595506\n",
      "MCC: 0.3553432765947676\n",
      "Accuracy: 0.803347280334728\n",
      "Precision: 0.525\n",
      "Recall: 0.42857142857142855\n",
      "AUC: 0.6642857142857144\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train_tr, x_chen_train[\"Y\"], x_chen_valid_tr, x_chen_valid[\"Y\"], \n",
    "        x_chen_train[\"cluster_merged\"], \"seqvec\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50dd5635-2548-4aa9-ba29-2c84aaa34c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abagovomab</td>\n",
       "      <td>-0.004248</td>\n",
       "      <td>-0.024501</td>\n",
       "      <td>-0.011330</td>\n",
       "      <td>-0.027170</td>\n",
       "      <td>0.062747</td>\n",
       "      <td>-0.024793</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>-0.083316</td>\n",
       "      <td>-0.005339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008674</td>\n",
       "      <td>-0.002387</td>\n",
       "      <td>-0.021563</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>-0.020986</td>\n",
       "      <td>0.047104</td>\n",
       "      <td>-0.038736</td>\n",
       "      <td>-0.021780</td>\n",
       "      <td>-0.022153</td>\n",
       "      <td>-0.024539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abituzumab</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>-0.013591</td>\n",
       "      <td>-0.008454</td>\n",
       "      <td>-0.043601</td>\n",
       "      <td>0.065095</td>\n",
       "      <td>-0.016896</td>\n",
       "      <td>-0.001596</td>\n",
       "      <td>-0.090935</td>\n",
       "      <td>-0.002940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>-0.013063</td>\n",
       "      <td>-0.021852</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>-0.024620</td>\n",
       "      <td>0.027387</td>\n",
       "      <td>-0.041001</td>\n",
       "      <td>-0.025708</td>\n",
       "      <td>-0.016437</td>\n",
       "      <td>-0.034342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrilumab</td>\n",
       "      <td>0.019445</td>\n",
       "      <td>-0.002642</td>\n",
       "      <td>-0.011395</td>\n",
       "      <td>-0.058757</td>\n",
       "      <td>0.060623</td>\n",
       "      <td>-0.015046</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>-0.083772</td>\n",
       "      <td>-0.006775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>-0.017189</td>\n",
       "      <td>-0.014557</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>-0.035368</td>\n",
       "      <td>0.020287</td>\n",
       "      <td>-0.033941</td>\n",
       "      <td>-0.023549</td>\n",
       "      <td>-0.008720</td>\n",
       "      <td>-0.044038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actoxumab</td>\n",
       "      <td>-0.006365</td>\n",
       "      <td>-0.043729</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>-0.025613</td>\n",
       "      <td>0.067748</td>\n",
       "      <td>-0.009542</td>\n",
       "      <td>0.017723</td>\n",
       "      <td>-0.096801</td>\n",
       "      <td>-0.007752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.012986</td>\n",
       "      <td>-0.019753</td>\n",
       "      <td>-0.004326</td>\n",
       "      <td>-0.044124</td>\n",
       "      <td>0.019544</td>\n",
       "      <td>-0.039559</td>\n",
       "      <td>-0.015679</td>\n",
       "      <td>-0.008837</td>\n",
       "      <td>-0.043877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adalimumab</td>\n",
       "      <td>-0.012995</td>\n",
       "      <td>-0.035269</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>-0.042136</td>\n",
       "      <td>0.080592</td>\n",
       "      <td>-0.012831</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>-0.091308</td>\n",
       "      <td>-0.018166</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>-0.022957</td>\n",
       "      <td>-0.021145</td>\n",
       "      <td>-0.002762</td>\n",
       "      <td>-0.058199</td>\n",
       "      <td>0.026781</td>\n",
       "      <td>-0.046815</td>\n",
       "      <td>-0.010110</td>\n",
       "      <td>-0.008785</td>\n",
       "      <td>-0.041761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ab_ID         0         1         2         3         4         5  \\\n",
       "0  Abagovomab -0.004248 -0.024501 -0.011330 -0.027170  0.062747 -0.024793   \n",
       "1  Abituzumab  0.006593 -0.013591 -0.008454 -0.043601  0.065095 -0.016896   \n",
       "2   Abrilumab  0.019445 -0.002642 -0.011395 -0.058757  0.060623 -0.015046   \n",
       "3   Actoxumab -0.006365 -0.043729  0.005978 -0.025613  0.067748 -0.009542   \n",
       "4  Adalimumab -0.012995 -0.035269  0.014127 -0.042136  0.080592 -0.012831   \n",
       "\n",
       "          6         7         8  ...      2038      2039      2040      2041  \\\n",
       "0  0.009313 -0.083316 -0.005339  ... -0.008674 -0.002387 -0.021563  0.001087   \n",
       "1 -0.001596 -0.090935 -0.002940  ...  0.000486 -0.013063 -0.021852 -0.003531   \n",
       "2  0.006317 -0.083772 -0.006775  ...  0.005834 -0.017189 -0.014557  0.003359   \n",
       "3  0.017723 -0.096801 -0.007752  ... -0.000024 -0.012986 -0.019753 -0.004326   \n",
       "4  0.031889 -0.091308 -0.018166  ... -0.002067 -0.022957 -0.021145 -0.002762   \n",
       "\n",
       "       2042      2043      2044      2045      2046      2047  \n",
       "0 -0.020986  0.047104 -0.038736 -0.021780 -0.022153 -0.024539  \n",
       "1 -0.024620  0.027387 -0.041001 -0.025708 -0.016437 -0.034342  \n",
       "2 -0.035368  0.020287 -0.033941 -0.023549 -0.008720 -0.044038  \n",
       "3 -0.044124  0.019544 -0.039559 -0.015679 -0.008837 -0.043877  \n",
       "4 -0.058199  0.026781 -0.046815 -0.010110 -0.008785 -0.041761  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tap = pd.read_feather(path.join(DATA_DIR, \"tap/embeddings/seqvec/seqvec_tap_embeddings.ftr\"))\n",
    "x_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7be0003-dc87-4e08-99d5-a5f2220dc25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tap = scaler.transform(x_tap.drop(\"Ab_ID\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ea9d66e-6b32-4273-804f-b9e9c4f65ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on seqvec...\n",
      "Testing model random_forest on seqvec...\n",
      "Testing model gradient_boosting on seqvec...\n",
      "Testing model SVM on seqvec...\n",
      "Testing model multilayer_perceptron on seqvec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_all(x_tap, tap_data[\"Y\"], \"seqvec\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b33319-5954-466b-b667-bbdc6c9c56e8",
   "metadata": {},
   "source": [
    "# One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7845fcbf-58f1-4e99-9994-8cc3a276782c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID_h</th>\n",
       "      <th>A_1_h</th>\n",
       "      <th>C_1_h</th>\n",
       "      <th>D_1_h</th>\n",
       "      <th>E_1_h</th>\n",
       "      <th>F_1_h</th>\n",
       "      <th>G_1_h</th>\n",
       "      <th>H_1_h</th>\n",
       "      <th>I_1_h</th>\n",
       "      <th>K_1_h</th>\n",
       "      <th>...</th>\n",
       "      <th>O_138_l</th>\n",
       "      <th>P_138_l</th>\n",
       "      <th>Q_138_l</th>\n",
       "      <th>R_138_l</th>\n",
       "      <th>S_138_l</th>\n",
       "      <th>T_138_l</th>\n",
       "      <th>U_138_l</th>\n",
       "      <th>V_138_l</th>\n",
       "      <th>W_138_l</th>\n",
       "      <th>Y_138_l</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7526 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ab_ID_h  A_1_h  C_1_h  D_1_h  E_1_h  F_1_h  G_1_h  H_1_h  I_1_h  K_1_h  \\\n",
       "index                                                                          \n",
       "2073     6aod      0      0      0      1      0      0      0      0      0   \n",
       "1517     4yny      0      0      0      1      0      0      0      0      0   \n",
       "2025     5xcv      0      0      0      1      0      0      0      0      0   \n",
       "2070     6and      0      0      0      1      0      0      0      0      0   \n",
       "666      2xqy      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "       ...  O_138_l  P_138_l  Q_138_l  R_138_l  S_138_l  T_138_l  U_138_l  \\\n",
       "index  ...                                                                  \n",
       "2073   ...        0        0        0        0        0        0        0   \n",
       "1517   ...        0        0        0        0        0        0        0   \n",
       "2025   ...        0        0        0        0        0        0        0   \n",
       "2070   ...        0        0        0        0        0        0        0   \n",
       "666    ...        0        0        0        0        0        0        0   \n",
       "\n",
       "       V_138_l  W_138_l  Y_138_l  \n",
       "index                             \n",
       "2073         0        0        0  \n",
       "1517         0        0        0  \n",
       "2025         0        0        0  \n",
       "2070         0        0        0  \n",
       "666          0        0        0  \n",
       "\n",
       "[5 rows x 7526 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_heavy = pd.read_feather(path.join(DATA_DIR, \"chen/abnumber/chen_heavy_one_hot.ftr\")).set_index(\"index\")\n",
    "# rows 1921 and 2097 could not be encoded\n",
    "x_light = pd.read_feather(path.join(DATA_DIR, \"chen/abnumber/chen_light_one_hot.ftr\")).set_index(\"Id\")\n",
    "x_chen = x_heavy.merge(x_light, left_index=True, right_index=True, suffixes=[\"_h\", \"_l\"])\n",
    "x_chen.index = x_heavy.index\n",
    "train_idx = list(chen_train.index)\n",
    "train_idx.remove(1921)\n",
    "train_idx.remove(2097)\n",
    "x_chen_train = x_chen.loc[train_idx]\n",
    "x_chen_valid = x_chen.loc[chen_valid.index]\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b379646-e416-40de-b8c4-fc391b8fc436",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = chen_train.loc[train_idx][\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd109a6b-f264-44da-bddc-b60a6612716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_chen_train.drop([\"Ab_ID_h\", \"Ab_ID_l\"], axis=1))\n",
    "x_chen_train = scaler.transform(x_chen_train.drop([\"Ab_ID_h\", \"Ab_ID_l\"], axis=1))\n",
    "x_chen_valid = scaler.transform(x_chen_valid.drop([\"Ab_ID_h\", \"Ab_ID_l\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eda173ac-767c-4fc5-825a-7b6749fb0425",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data onehot \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression, onehot\n",
      "F1: 0.375\n",
      "MCC: 0.19015409084172083\n",
      "Accuracy: 0.7071129707112971\n",
      "Precision: 0.3333333333333333\n",
      "Recall: 0.42857142857142855\n",
      "AUC: 0.6037593984962406\n",
      "-----\n",
      "\n",
      "\n",
      "Training model random_forest on data onehot \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "random_forest, onehot\n",
      "F1: 0.3943661971830986\n",
      "MCC: 0.18989133017294033\n",
      "Accuracy: 0.6401673640167364\n",
      "Precision: 0.3010752688172043\n",
      "Recall: 0.5714285714285714\n",
      "AUC: 0.6146616541353385\n",
      "-----\n",
      "\n",
      "\n",
      "Training model gradient_boosting on data onehot \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "gradient_boosting, onehot\n",
      "F1: 0.22988505747126436\n",
      "MCC: 0.06261368369902223\n",
      "Accuracy: 0.7196652719665272\n",
      "Precision: 0.2631578947368421\n",
      "Recall: 0.20408163265306123\n",
      "AUC: 0.5283566058002148\n",
      "-----\n",
      "\n",
      "\n",
      "Training model SVM on data onehot \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "SVM, onehot\n",
      "F1: 0.25490196078431376\n",
      "MCC: 0.05323544989970825\n",
      "Accuracy: 0.6820083682008368\n",
      "Precision: 0.24528301886792453\n",
      "Recall: 0.2653061224489796\n",
      "AUC: 0.527389903329753\n",
      "-----\n",
      "\n",
      "\n",
      "Training model multilayer_perceptron on data onehot \n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron, onehot\n",
      "F1: 0.3035714285714286\n",
      "MCC: 0.09606127984550701\n",
      "Accuracy: 0.6736401673640168\n",
      "Precision: 0.2698412698412698\n",
      "Recall: 0.3469387755102041\n",
      "AUC: 0.5524167561761547\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# add groups for data split\n",
    "try_all(x_chen_train, train_labels, x_chen_valid, chen_valid[\"Y\"], \"onehot\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "efb17f26-97ce-451f-aa63-08f5f138fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tap_heavy = pd.read_feather(path.join(DATA_DIR, \"tap/abnumber/tap_heavy_one_hot.ftr\"))\n",
    "x_tap_light = pd.read_feather(path.join(DATA_DIR, \"tap/abnumber/tap_light_one_hot.ftr\"))\n",
    "x_tap = x_tap_heavy.merge(x_tap_light, left_index=True, right_index=True, suffixes=[\"_h\", \"_l\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "637e217d-2a01-4e91-a3a0-2599a4437468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- A_121\n",
      "- A_122\n",
      "- A_123\n",
      "- A_124\n",
      "- A_125\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- A_121_h\n",
      "- A_121_l\n",
      "- A_122_h\n",
      "- A_122_l\n",
      "- A_123_h\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 5634 features, but StandardScaler is expecting 7524 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/pbs.31293.lich-compute.vscht.cz/ipykernel_510/3223408165.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_tap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Ab_ID_h\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Ab_ID_l\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    978\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m         )\n\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             raise ValueError(\n\u001b[0;32m--> 396\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 5634 features, but StandardScaler is expecting 7524 features as input."
     ]
    }
   ],
   "source": [
    "x_tap = scaler.transform(x_tap.drop([\"Ab_ID_h\", \"Ab_ID_l\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a64dbdc7-0ffa-4042-a7a3-660e3cbe0b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on onehot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:439: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Abagovomab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/pbs.31293.lich-compute.vscht.cz/ipykernel_510/1287004508.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtap_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"onehot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVAL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"StandardScaler\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.31293.lich-compute.vscht.cz/ipykernel_510/202172768.py\u001b[0m in \u001b[0;36mtest_all\u001b[0;34m(x_test, y_test, data_name, outpath, preprocessing)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"logistic_regression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"random_forest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gradient_boosting\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SVM\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilayer_perceptron\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Testing model {model} on {data_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtest_on_tap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.31293.lich-compute.vscht.cz/ipykernel_510/2610498457.py\u001b[0m in \u001b[0;36mtest_on_tap\u001b[0;34m(model_name, x_test, y_test, data_name, outpath, preprocessing)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     metric_dict = {\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \"\"\"\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    736\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Abagovomab'"
     ]
    }
   ],
   "source": [
    "test_all(x_tap, tap_data[\"Y\"], \"onehot\", EVAL_DIR, preprocessing=\"StandardScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e6bec-c3f6-47a4-94ca-f3bd01fc0220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
