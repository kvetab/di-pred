{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91890b4d-226c-45b5-839e-0c83b3b2feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from os import path\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from numpy import hstack\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa5f595a-dadf-40e3-825e-565ffa374f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b269f8b-4c91-46dc-ae7d-89561f42817f",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef47abb-218a-4b06-8615-2d35dcb1afe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...</td>\n",
       "      <td>DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...</td>\n",
       "      <td>DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Antibody_ID                                              heavy  \\\n",
       "2073        6aod  EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...   \n",
       "1517        4yny  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2025        5xcv  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2070        6and  EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...   \n",
       "666         2xqy  QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...   \n",
       "\n",
       "                                                  light  Y  \n",
       "2073  DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...  0  \n",
       "1517  EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2025  QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2070  DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...  1  \n",
       "666   DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_train = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_train_data.csv\"), index_col=0)\n",
    "chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be3c2a46-9a70-4fcd-ad0f-175155f3a723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>6ct7</td>\n",
       "      <td>EVQLVESGGGLVEPGGSLRLSCAVSGFDFEKAWMSWVRQAPGQGLQ...</td>\n",
       "      <td>SYELTQPPSVSVSPGQTARITCSGEALPMQFAHWYQQRPGKAPVIV...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>4nzu</td>\n",
       "      <td>AVSLVESGGGTVEPGSTLRLSCAASGFTFGSYAFHWVRQAPGDGLE...</td>\n",
       "      <td>DIEMTQSPSSLSASTGDKVTITCQASQDIAKFLDWYQQRPGKTPKL...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>5i8c</td>\n",
       "      <td>QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...</td>\n",
       "      <td>DIQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>5i8e</td>\n",
       "      <td>QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...</td>\n",
       "      <td>IQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNLL...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>6bb4</td>\n",
       "      <td>QVQLQQSDAELVKPGASVKISCKASGYTFTDRTIHWVKQRPEQGLE...</td>\n",
       "      <td>DVQMIQSPSSLSASLGDIVTMTCQASQDTSINLNWFQQKPGKAPKL...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Antibody_ID                                              heavy  \\\n",
       "2169        6ct7  EVQLVESGGGLVEPGGSLRLSCAVSGFDFEKAWMSWVRQAPGQGLQ...   \n",
       "1342        4nzu  AVSLVESGGGTVEPGSTLRLSCAASGFTFGSYAFHWVRQAPGDGLE...   \n",
       "1728        5i8c  QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...   \n",
       "1729        5i8e  QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...   \n",
       "2114        6bb4  QVQLQQSDAELVKPGASVKISCKASGYTFTDRTIHWVKQRPEQGLE...   \n",
       "\n",
       "                                                  light  Y  \n",
       "2169  SYELTQPPSVSVSPGQTARITCSGEALPMQFAHWYQQRPGKAPVIV...  0  \n",
       "1342  DIEMTQSPSSLSASTGDKVTITCQASQDIAKFLDWYQQRPGKTPKL...  0  \n",
       "1728  DIQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNL...  1  \n",
       "1729  IQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNLL...  0  \n",
       "2114  DVQMIQSPSSLSASLGDIVTMTCQASQDTSINLNWFQQKPGKAPKL...  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_valid = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_valid_data.csv\"), index_col=0)\n",
    "chen_test = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_test_data.csv\"), index_col=0)\n",
    "chen_valid = pd.concat([chen_valid, chen_test])\n",
    "chen_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4318d85e-94bc-413f-a8d4-b18996b63f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ab_ID   0   1   2   3   4   5   6  7  8  ...  271  272  273  274  275  \\\n",
       "2073  6aod   4  18  14  10  18  14  16  6  1  ...    0    0    0    0    0   \n",
       "1517  4yny   4  18  14  10  18   4  16  6  6  ...    0    0    0    0    0   \n",
       "2025  5xcv   4  18  14  10  18   4  16  6  6  ...    0    0    0    0    0   \n",
       "2070  6and   4  18  14  10  18   4  16  6  6  ...    0    0    0    0    0   \n",
       "666   2xqy  14  18  14  10  14  14  13  6  1  ...    0    0    0    0    0   \n",
       "\n",
       "      276  277  278  279  280  \n",
       "2073    0    0    0    0    0  \n",
       "1517    0    0    0    0    0  \n",
       "2025    0    0    0    0    0  \n",
       "2070    0    0    0    0    0  \n",
       "666     0    0    0    0    0  \n",
       "\n",
       "[5 rows x 282 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chen = pd.read_csv(path.join(DATA_DIR, \"chen/integer_encoding/chen_integer_encoded.csv\"), index_col=0)\n",
    "x_chen_train = x_chen.loc[chen_train.index]\n",
    "x_chen_test = x_chen.loc[chen_valid.index]\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc938cdf-ef94-47af-8b96-14d1dff94661",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_chen_train.drop(\"Ab_ID\", axis=1).to_numpy()\n",
    "X_test = x_chen_test.drop(\"Ab_ID\", axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fba5116c-1ba9-405b-b961-12660916f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = chen_train[\"Y\"].to_numpy()\n",
    "y_test = chen_valid[\"Y\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c01d7de1-baf9-4736-a145-366df2780350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_ohe = to_categorical(X_train)\n",
    "#test_ohe = to_categorical(X_test)\n",
    "#train_ohe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c518304b-0137-48c3-ba89-45edfeff30da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281, 21)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_ohe[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d53dde92-9a07-4338-9c2a-4768fb811ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281\n"
     ]
    }
   ],
   "source": [
    "max_length = len(train_ohe[0])\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96597863-f3bd-48ab-a0ae-6b3f671963f0",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84fccc85-e7c9-4b37-a59f-884cd22b169b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 09:58:35.298624: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "    50, activation='sigmoid', return_sequences=True, input_shape=(max_length, 1), kernel_regularizer=\"l2\",\n",
    "    recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"\n",
    "))\n",
    "model.add(LSTM(50, activation='sigmoid', kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9da5ed78-c3cf-4379-af8f-a305a6802839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 281, 50)           10400     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,651\n",
      "Trainable params: 30,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dfc5358c-9cad-4885-b179-990f1eb3cb9a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11/11 [==============================] - 6s 317ms/step - loss: 3.2986\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 3s 317ms/step - loss: 2.8671\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 4s 319ms/step - loss: 2.5602\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 3s 308ms/step - loss: 2.3076\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 3s 316ms/step - loss: 2.1045\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 3s 316ms/step - loss: 1.9381\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 4s 320ms/step - loss: 1.8027\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 4s 317ms/step - loss: 1.6919\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 3s 318ms/step - loss: 1.6005\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 3s 311ms/step - loss: 1.5245\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 3s 313ms/step - loss: 1.4613\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 3s 311ms/step - loss: 1.4079\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 3s 313ms/step - loss: 1.3623\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 3s 312ms/step - loss: 1.3228\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 3s 317ms/step - loss: 1.2889\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 3s 310ms/step - loss: 1.2585\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 3s 310ms/step - loss: 1.2316\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 3s 312ms/step - loss: 1.2071\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 3s 310ms/step - loss: 1.1849\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 1.1644\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 1.1452\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 1.1270\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 1.1097\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 4s 344ms/step - loss: 1.0935\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 1.0776\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 1.0628\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 4s 322ms/step - loss: 1.0476\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 4s 340ms/step - loss: 1.0336\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 4s 378ms/step - loss: 1.0198\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 1.0058\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 4s 333ms/step - loss: 0.9932\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 0.9810\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.9681\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 4s 335ms/step - loss: 0.9576\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.9438\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 4s 338ms/step - loss: 0.9320\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 4s 343ms/step - loss: 0.9207\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 4s 339ms/step - loss: 0.9091\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 4s 334ms/step - loss: 0.8982\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.8875\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 4s 330ms/step - loss: 0.8770\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 4s 334ms/step - loss: 0.8668\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.8569\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 0.8470\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 0.8379\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 4s 330ms/step - loss: 0.8285\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.8192\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.8102\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 0.8017\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.7933\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.7848\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.7792\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 0.7723\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 4s 333ms/step - loss: 0.7617\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.7540\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 0.7468\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.7410\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.7324\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.7253\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.7186\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 4s 353ms/step - loss: 0.7120\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 4s 339ms/step - loss: 0.7058\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.7001\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.6937\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 0.6876\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 4s 340ms/step - loss: 0.6819\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.6775\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 4s 323ms/step - loss: 0.6721\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 4s 323ms/step - loss: 0.6658\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 4s 333ms/step - loss: 0.6608\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.6558\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 3s 315ms/step - loss: 0.6518\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.6462\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 0.6439\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.6372\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.6338\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.6287\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 0.6248\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 4s 336ms/step - loss: 0.6216\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.6167\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 0.6133\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 4s 334ms/step - loss: 0.6095\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.6058\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 4s 341ms/step - loss: 0.6028\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.5993\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5964\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 4s 321ms/step - loss: 0.5929\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.5905\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.5883\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 4s 323ms/step - loss: 0.5849\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 0.5816\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.5791\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 4s 338ms/step - loss: 0.5766\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.5741\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5717\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 4s 356ms/step - loss: 0.5692\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 0.5675\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 4s 330ms/step - loss: 0.5647\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 4s 333ms/step - loss: 0.5628\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.5606\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 4s 333ms/step - loss: 0.5588\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 4s 336ms/step - loss: 0.5571\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 4s 351ms/step - loss: 0.5551\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 4s 356ms/step - loss: 0.5534\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 4s 346ms/step - loss: 0.5524\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 4s 322ms/step - loss: 0.5504\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.5485\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 4s 339ms/step - loss: 0.5470\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 4s 336ms/step - loss: 0.5458\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 4s 335ms/step - loss: 0.5445\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.5441\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 0.5424\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.5402\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 4s 333ms/step - loss: 0.5395\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.5384\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.5368\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.5358\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5349\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.5340\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5329\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 4s 334ms/step - loss: 0.5320\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.5311\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.5312\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.5295\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5290\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 4s 339ms/step - loss: 0.5280\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.5275\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.5266\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 4s 340ms/step - loss: 0.5262\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5257\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 0.5248\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 4s 332ms/step - loss: 0.5244\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 4s 333ms/step - loss: 0.5238\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5235\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 4s 321ms/step - loss: 0.5232\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5225\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 4s 341ms/step - loss: 0.5220\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 4s 334ms/step - loss: 0.5224\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 4s 333ms/step - loss: 0.5213\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 4s 333ms/step - loss: 0.5212\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 4s 335ms/step - loss: 0.5204\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.5200\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 4s 334ms/step - loss: 0.5197\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 4s 321ms/step - loss: 0.5212\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 4s 332ms/step - loss: 0.5192\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5190\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 4s 335ms/step - loss: 0.5185\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 0.5183\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 0.5181\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.5178\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 4s 323ms/step - loss: 0.5179\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 0.5178\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.5172\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 4s 330ms/step - loss: 0.5179\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 0.5180\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5166\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 4s 333ms/step - loss: 0.5173\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.5161\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 4s 330ms/step - loss: 0.5168\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5165\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.5160\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5160\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.5157\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 0.5159\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.5158\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.5155\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.5158\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5158\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 4s 333ms/step - loss: 0.5159\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.5156\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 4s 322ms/step - loss: 0.5151\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 4s 336ms/step - loss: 0.5151\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 4s 334ms/step - loss: 0.5149\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 4s 320ms/step - loss: 0.5151\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 4s 323ms/step - loss: 0.5149\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5152\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 4s 330ms/step - loss: 0.5150\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 4s 336ms/step - loss: 0.5147\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 4s 323ms/step - loss: 0.5149\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.5156\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 4s 334ms/step - loss: 0.5144\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.5154\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.5145\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 4s 323ms/step - loss: 0.5146\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.5146\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.5146\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 4s 334ms/step - loss: 0.5144\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 4s 334ms/step - loss: 0.5148\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 4s 334ms/step - loss: 0.5146\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5146\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 4s 330ms/step - loss: 0.5141\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 0.5157\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.5147\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.5148\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.5142\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 4s 346ms/step - loss: 0.5149\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 4s 337ms/step - loss: 0.5143\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5148\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5156\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 4s 335ms/step - loss: 0.5141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fecb7595650>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5bc67358-36e0-4877-b5a2-6f684fdc6261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 7s 29ms/step - loss: 0.5075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5074639916419983"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "88b271b9-db57-47e3-9728-33783b6bfc7f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347],\n",
       "       [0.20581347]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7158cab-f78a-448d-a2d1-e5908981ea9c",
   "metadata": {},
   "source": [
    "Apparently all the predictions are the same :( Quite understandable, when the dataset is imbalanced. What to do about it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92e54e8-4e7c-445e-b791-c56db22e77fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.accuracy_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920e77e6-e7de-4089-ba87-2e6f2dd7a430",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c043f9ee-c144-4dbe-83d9-4e0295e64dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "    50, activation='relu', return_sequences=True, input_shape=(max_length, 1), kernel_regularizer=\"l2\",\n",
    "    recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"\n",
    "))\n",
    "model.add(LSTM(50, activation='relu', kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "515ce017-9ea5-4efd-a967-96b5e5a7d39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 281, 50)           10400     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,651\n",
      "Trainable params: 30,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71645c09-d1f2-4c05-80b5-fd755cde9519",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "21/21 [==============================] - 7s 244ms/step - loss: 612956672.0000\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 5s 236ms/step - loss: 3.4039\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 5s 238ms/step - loss: 3.3552\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 5s 245ms/step - loss: 3.3202\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 5s 237ms/step - loss: 3.2948\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 5s 241ms/step - loss: 3.2754\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 5s 247ms/step - loss: 3.2599\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 5s 236ms/step - loss: 3.2471\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 5s 240ms/step - loss: 3.2353\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 5s 241ms/step - loss: 3.2236\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 5s 237ms/step - loss: 3.2103\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 3.1900\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 5s 236ms/step - loss: 3.1368\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 5s 238ms/step - loss: 3.1114\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 5s 242ms/step - loss: 3.1047\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 5s 234ms/step - loss: 3.1004\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 5s 238ms/step - loss: 3.0975\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 5s 236ms/step - loss: 3.0943\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 5s 241ms/step - loss: 3.0922\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 5s 241ms/step - loss: 3.0918\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 5s 238ms/step - loss: 3.0885\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 5s 233ms/step - loss: 3.0863\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 5s 242ms/step - loss: 3.0850\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 5s 238ms/step - loss: 3.0825\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 5s 241ms/step - loss: 3.0804\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 5s 247ms/step - loss: 3.0784\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 5s 242ms/step - loss: 3.0771\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 5s 241ms/step - loss: 3.0754\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 3.0736\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 5s 238ms/step - loss: 3.0732\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 5s 244ms/step - loss: 3.0738\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 5s 241ms/step - loss: 3.0712\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 5s 235ms/step - loss: 3.0681\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 5s 236ms/step - loss: 3.0736\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 5s 235ms/step - loss: 3.0667\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 5s 240ms/step - loss: 3.0642\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 5s 244ms/step - loss: 3.0645\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 5s 250ms/step - loss: 3.0632\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 5s 255ms/step - loss: 3.0632\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 5s 251ms/step - loss: 3.0738\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 5s 252ms/step - loss: 3.0651\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 5s 243ms/step - loss: 3.0625\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 3.0611\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 3.0605\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 3.0602\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 5s 238ms/step - loss: 3.0576\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 3.0560\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 5s 241ms/step - loss: 3.0537\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 3.0530\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 5s 240ms/step - loss: 3.0547\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 5s 240ms/step - loss: 3.0513\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 3.1732\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 5s 242ms/step - loss: 3.0965\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 5s 243ms/step - loss: 3.0998\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 5s 243ms/step - loss: 3.0886\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 3.0738\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 5s 240ms/step - loss: 3.0654\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 5s 242ms/step - loss: 3.0645\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 5s 237ms/step - loss: 3.0634\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 5s 238ms/step - loss: 3.0619\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 5s 238ms/step - loss: 3.0613\n",
      "Epoch 62/200\n",
      " 7/21 [=========>....................] - ETA: 3s - loss: 3.0385"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/pbs.32262.lich-compute.vscht.cz/ipykernel_26906/2886491785.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, verbose=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdb5ad67-e4e8-4ade-ad3d-e8304e9e5fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 7s 29ms/step - loss: 3.0515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.0515201091766357"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2963b620-cedc-4c9e-9dc8-fe39f6626fc5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20992106],\n",
       "       [0.20791924],\n",
       "       [0.20984468],\n",
       "       [0.21016249],\n",
       "       [0.21216676],\n",
       "       [0.21036375],\n",
       "       [0.21095589],\n",
       "       [0.21002048],\n",
       "       [0.20772734],\n",
       "       [0.20795539],\n",
       "       [0.21061528],\n",
       "       [0.21096697],\n",
       "       [0.19717345],\n",
       "       [0.19761881],\n",
       "       [0.21084765],\n",
       "       [0.211494  ],\n",
       "       [0.21031821],\n",
       "       [0.21067479],\n",
       "       [0.20984936],\n",
       "       [0.21006978],\n",
       "       [0.20541656],\n",
       "       [0.20973724],\n",
       "       [0.20973724],\n",
       "       [0.21127683],\n",
       "       [0.21076229],\n",
       "       [0.21076572],\n",
       "       [0.20804015],\n",
       "       [0.18784446],\n",
       "       [0.21132302],\n",
       "       [0.21070066],\n",
       "       [0.2109569 ],\n",
       "       [0.21123934],\n",
       "       [0.20929185],\n",
       "       [0.21117595],\n",
       "       [0.21117586],\n",
       "       [0.21108863],\n",
       "       [0.21083713],\n",
       "       [0.21036819],\n",
       "       [0.2104238 ],\n",
       "       [0.21092072],\n",
       "       [0.21110901],\n",
       "       [0.21186692],\n",
       "       [0.20862168],\n",
       "       [0.21096504],\n",
       "       [0.20865539],\n",
       "       [0.20658135],\n",
       "       [0.1993657 ],\n",
       "       [0.21072653],\n",
       "       [0.21072647],\n",
       "       [0.20941553],\n",
       "       [0.20909801],\n",
       "       [0.21243897],\n",
       "       [0.21125904],\n",
       "       [0.20456883],\n",
       "       [0.20229614],\n",
       "       [0.20965597],\n",
       "       [0.21218029],\n",
       "       [0.2121802 ],\n",
       "       [0.21213487],\n",
       "       [0.21220547],\n",
       "       [0.21215892],\n",
       "       [0.20927688],\n",
       "       [0.21142489],\n",
       "       [0.21100864],\n",
       "       [0.21092954],\n",
       "       [0.21000877],\n",
       "       [0.21126801],\n",
       "       [0.21035644],\n",
       "       [0.21206713],\n",
       "       [0.20799977],\n",
       "       [0.20283198],\n",
       "       [0.20100191],\n",
       "       [0.21025383],\n",
       "       [0.21032953],\n",
       "       [0.21189848],\n",
       "       [0.2035    ],\n",
       "       [0.1992738 ],\n",
       "       [0.2098195 ],\n",
       "       [0.21135646],\n",
       "       [0.21143621],\n",
       "       [0.21194929],\n",
       "       [0.2105366 ],\n",
       "       [0.21158385],\n",
       "       [0.2082245 ],\n",
       "       [0.20846575],\n",
       "       [0.20738298],\n",
       "       [0.18499148],\n",
       "       [0.18499199],\n",
       "       [0.21119213],\n",
       "       [0.20892072],\n",
       "       [0.20552701],\n",
       "       [0.20742819],\n",
       "       [0.21232933],\n",
       "       [0.21247068],\n",
       "       [0.20032793],\n",
       "       [0.20301688],\n",
       "       [0.20032793],\n",
       "       [0.20966506],\n",
       "       [0.21068957],\n",
       "       [0.21072984],\n",
       "       [0.2117554 ],\n",
       "       [0.2117554 ],\n",
       "       [0.21150541],\n",
       "       [0.20590511],\n",
       "       [0.21093622],\n",
       "       [0.20055899],\n",
       "       [0.19750252],\n",
       "       [0.19758302],\n",
       "       [0.21074253],\n",
       "       [0.21172214],\n",
       "       [0.20971131],\n",
       "       [0.20921773],\n",
       "       [0.21143314],\n",
       "       [0.19916943],\n",
       "       [0.39586365],\n",
       "       [0.2108056 ],\n",
       "       [0.20917192],\n",
       "       [0.20986801],\n",
       "       [0.21108627],\n",
       "       [0.20667061],\n",
       "       [0.21171212],\n",
       "       [0.20815578],\n",
       "       [0.20815584],\n",
       "       [0.21079448],\n",
       "       [0.19609529],\n",
       "       [0.21096352],\n",
       "       [0.21188691],\n",
       "       [0.21070424],\n",
       "       [0.21158409],\n",
       "       [0.21036676],\n",
       "       [0.21036893],\n",
       "       [0.21064967],\n",
       "       [0.21036643],\n",
       "       [0.20676911],\n",
       "       [0.20666447],\n",
       "       [0.20923874],\n",
       "       [0.20116991],\n",
       "       [0.21035713],\n",
       "       [0.21054092],\n",
       "       [0.21128854],\n",
       "       [0.21226174],\n",
       "       [0.20947096],\n",
       "       [0.21156839],\n",
       "       [0.20925394],\n",
       "       [0.21150365],\n",
       "       [0.20149788],\n",
       "       [0.20149654],\n",
       "       [0.19318333],\n",
       "       [0.19318333],\n",
       "       [0.19318333],\n",
       "       [0.21042088],\n",
       "       [0.21078983],\n",
       "       [0.21126312],\n",
       "       [0.21240887],\n",
       "       [0.20459154],\n",
       "       [0.20994574],\n",
       "       [0.21020734],\n",
       "       [0.21120554],\n",
       "       [0.20805463],\n",
       "       [0.20822197],\n",
       "       [0.2113826 ],\n",
       "       [0.20959648],\n",
       "       [0.20603591],\n",
       "       [0.20605004],\n",
       "       [0.19753999],\n",
       "       [0.21174997],\n",
       "       [0.21056303],\n",
       "       [0.20680463],\n",
       "       [0.2114844 ],\n",
       "       [0.20824012],\n",
       "       [0.20603624],\n",
       "       [0.21020752],\n",
       "       [0.21081403],\n",
       "       [0.20919648],\n",
       "       [0.20995271],\n",
       "       [0.21128193],\n",
       "       [0.21104455],\n",
       "       [0.21144241],\n",
       "       [0.2110995 ],\n",
       "       [0.21102124],\n",
       "       [0.2110995 ],\n",
       "       [0.20965895],\n",
       "       [0.21016705],\n",
       "       [0.2095361 ],\n",
       "       [0.20841745],\n",
       "       [0.21016523],\n",
       "       [0.20951512],\n",
       "       [0.19475445],\n",
       "       [0.19418675],\n",
       "       [0.21112469],\n",
       "       [0.21189734],\n",
       "       [0.21057594],\n",
       "       [0.20410535],\n",
       "       [0.20876685],\n",
       "       [0.2087956 ],\n",
       "       [0.2016645 ],\n",
       "       [0.19253877],\n",
       "       [0.20950359],\n",
       "       [0.2112824 ],\n",
       "       [0.20642298],\n",
       "       [0.20643428],\n",
       "       [0.20751172],\n",
       "       [0.20894045],\n",
       "       [0.21035415],\n",
       "       [0.20664507],\n",
       "       [0.20664507],\n",
       "       [0.20967755],\n",
       "       [0.21178004],\n",
       "       [0.20845637],\n",
       "       [0.20870447],\n",
       "       [0.20747995],\n",
       "       [0.20876521],\n",
       "       [0.2113412 ],\n",
       "       [0.20518297],\n",
       "       [0.20865539],\n",
       "       [0.2090643 ],\n",
       "       [0.21042922],\n",
       "       [0.21108982],\n",
       "       [0.2121706 ],\n",
       "       [0.21070468],\n",
       "       [0.20916855],\n",
       "       [0.20916855],\n",
       "       [0.2108843 ],\n",
       "       [0.21085069],\n",
       "       [0.21023962],\n",
       "       [0.21135303],\n",
       "       [0.21021762],\n",
       "       [0.2018021 ],\n",
       "       [0.21131614],\n",
       "       [0.20418787],\n",
       "       [0.20418686],\n",
       "       [0.21118161],\n",
       "       [0.21193668],\n",
       "       [0.20657796],\n",
       "       [0.20974097],\n",
       "       [0.20975563],\n",
       "       [0.20717663],\n",
       "       [0.20686454],\n",
       "       [0.21038017]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750c4b01-0370-4da9-a89f-6299e620e50e",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ced16c71-7883-4daa-871c-a82c6b0cfe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, activation=\"relu\", input_shape=(max_length, 1), return_sequences=True))  \n",
    "model.add(Dropout(0.2))  \n",
    "model.add(LSTM(200, activation=\"relu\", return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fdacb2a0-eebf-44b1-9d98-135ddbf2cc62",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 9.4642\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 11.9568\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0353\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0467\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0467\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0353\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0353\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0354\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0467\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0467\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0353\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0353\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0239\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 31s 3s/step - loss: 12.0467\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0353\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0239\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0468\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0582\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0467\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0467\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0353\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0467\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0467\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0353\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0467\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0467\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0467\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0467\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0467\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0467\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0467\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0467\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0353\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0467\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0467\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0353\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0467\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0353\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0353\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0467\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0467\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0353\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0353\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0353\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0467\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0467\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 32s 3s/step - loss: 12.0353\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0353\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0354\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0353\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0353\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0353\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0353\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0467\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0353\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0353\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 33s 3s/step - loss: 12.0011\n",
      "Epoch 58/200\n",
      " 1/11 [=>............................] - ETA: 33s - loss: 11.9135"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/pbs.32262.lich-compute.vscht.cz/ipykernel_23219/3061335457.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a01fd0-3888-4ae2-959b-1e02cb68dc60",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2e7dfa6c-11ec-4854-b7cc-625bb8c6ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, activation=\"relu\", input_shape=(max_length, 1), return_sequences=True,\n",
    "              kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))  \n",
    "model.add(Dropout(0.1))  \n",
    "model.add(LSTM(200, activation=\"relu\", return_sequences=False,\n",
    "              kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f999f194-c736-4ad7-8ace-1b877192e95c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 33s 3s/step - loss: 11.3796\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 8.6393\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 7.1998\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 6.2318\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 5.5878\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 5.1504\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 4.8413\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 4.6171\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 4.4382\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 4.2898\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 4.1615\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 32s 3s/step - loss: 4.0487\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.9419\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.8440\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.7528\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.6620\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.5759\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.4940\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 32s 3s/step - loss: 3.4156\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.3397\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.2663\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.1937\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.1244\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.0572\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.9949\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.9313\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.8657\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.8043\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.7447\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.6870\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.6292\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.5746\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.5192\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 32s 3s/step - loss: 2.4670\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.4148\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.3654\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.3158\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 2.2686\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.2216\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.1771\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.1329\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.0886\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.0459\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.0043\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.9628\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.9231\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.8855\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.8419\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.8971\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.8064\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.7460\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 32s 3s/step - loss: 1.6998\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.6580\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.6208\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.5831\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.5539\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.5200\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.4887\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.4585\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.4281\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.4003\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.3730\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 1.3466\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.3208\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.2939\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.2702\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.2453\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.2223\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.1984\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 1.1789\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.1553\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.1363\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.1141\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.0956\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.0743\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.0568\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.0397\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.0205\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.0040\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.9892\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.9710\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.9554\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.9386\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.9277\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.9124\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.9008\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.8851\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.8726\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.8581\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.8448\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.8314\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.8221\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.8081\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.7985\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.7892\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.7802\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.7672\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.7595\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.7497\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.7405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fecb71d2d90>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181226ff-7c38-48a0-af60-056f6ab84954",
   "metadata": {},
   "source": [
    "## Over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d95f240-f012-4a7a-bcb0-81b6253aeca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 1057, 1: 1057})\n"
     ]
    }
   ],
   "source": [
    "sampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_train_os, y_train_os = sampler.fit_resample(X_train, y_train) \n",
    "print('Resampled dataset shape %s' % Counter(y_train_os)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2007cb18-0218-47cd-a8e6-74fb3c7d57d9",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6410156-4b7a-4dc3-9b8d-e7b8ee78b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "    50, activation='sigmoid', return_sequences=True, input_shape=(max_length, 1), kernel_regularizer=\"l2\",\n",
    "    recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"\n",
    "))\n",
    "model.add(LSTM(50, activation='sigmoid', kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b3b732a-ca50-4b09-a936-81758174f9fe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 6s 329ms/step - loss: 3.1067\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 6s 337ms/step - loss: 2.6443\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 6s 328ms/step - loss: 2.3104\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 2.0626\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 6s 338ms/step - loss: 1.8793\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 6s 329ms/step - loss: 1.7428\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 1.6398\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 6s 326ms/step - loss: 1.5603\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 1.4975\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 1.4471\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 1.4052\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 6s 365ms/step - loss: 1.3683\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 6s 366ms/step - loss: 1.3368\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 6s 363ms/step - loss: 1.3088\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 6s 335ms/step - loss: 1.2813\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 6s 328ms/step - loss: 1.2565\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 1.2336\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 6s 340ms/step - loss: 1.2119\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 6s 329ms/step - loss: 1.1927\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 6s 332ms/step - loss: 1.1709\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 6s 333ms/step - loss: 1.1492\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 6s 337ms/step - loss: 1.1314\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 6s 326ms/step - loss: 1.1134\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 6s 331ms/step - loss: 1.0955\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 6s 335ms/step - loss: 1.0783\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 6s 339ms/step - loss: 1.0627\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 6s 328ms/step - loss: 1.0468\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 6s 333ms/step - loss: 1.0333\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 6s 335ms/step - loss: 1.0169\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 6s 335ms/step - loss: 1.0019\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 6s 332ms/step - loss: 0.9883\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 6s 332ms/step - loss: 0.9753\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 6s 324ms/step - loss: 0.9630\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.9504\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 6s 335ms/step - loss: 0.9385\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 6s 342ms/step - loss: 0.9269\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 6s 328ms/step - loss: 0.9155\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 6s 328ms/step - loss: 0.9046\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.8948\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 6s 336ms/step - loss: 0.8853\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 6s 334ms/step - loss: 0.8756\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 6s 334ms/step - loss: 0.8663\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.8576\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 6s 326ms/step - loss: 0.8508\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 6s 342ms/step - loss: 0.8424\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 6s 334ms/step - loss: 0.8356\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 6s 326ms/step - loss: 0.8271\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.8203\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 6s 334ms/step - loss: 0.8124\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.8061\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 6s 329ms/step - loss: 0.8003\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 6s 329ms/step - loss: 0.7949\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 6s 330ms/step - loss: 0.7886\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 6s 330ms/step - loss: 0.7831\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.7787\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 6s 330ms/step - loss: 0.7742\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 6s 334ms/step - loss: 0.7694\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 6s 333ms/step - loss: 0.7647\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.7604\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 6s 334ms/step - loss: 0.7568\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 6s 331ms/step - loss: 0.7531\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 6s 323ms/step - loss: 0.7491\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 0.7457\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 0.7421\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 6s 330ms/step - loss: 0.7389\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.7361\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 6s 331ms/step - loss: 0.7331\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 6s 338ms/step - loss: 0.7306\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 6s 330ms/step - loss: 0.7283\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 6s 330ms/step - loss: 0.7261\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.7237\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 6s 330ms/step - loss: 0.7215\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 6s 326ms/step - loss: 0.7196\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.7181\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 6s 338ms/step - loss: 0.7172\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 6s 328ms/step - loss: 0.7148\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 0.7132\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 6s 339ms/step - loss: 0.7116\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 6s 329ms/step - loss: 0.7107\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 6s 332ms/step - loss: 0.7098\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 6s 334ms/step - loss: 0.7079\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 6s 330ms/step - loss: 0.7069\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 6s 336ms/step - loss: 0.7061\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 6s 340ms/step - loss: 0.7049\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.7043\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 6s 341ms/step - loss: 0.7033\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.7020\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 6s 331ms/step - loss: 0.7018\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.7016\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 6s 342ms/step - loss: 0.7004\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 6s 329ms/step - loss: 0.7003\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 6s 335ms/step - loss: 0.6994\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 6s 335ms/step - loss: 0.6998\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 6s 330ms/step - loss: 0.6988\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 6s 331ms/step - loss: 0.6979\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 6s 334ms/step - loss: 0.6976\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 6s 326ms/step - loss: 0.6970\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.6967\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 6s 329ms/step - loss: 0.6969\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 6s 335ms/step - loss: 0.6963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f04a80e7810>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_os, y_train_os, epochs=100, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee248914-8f4e-4f51-9811-cf68e84a24e9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 52ms/step - loss: 0.7067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901204],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216],\n",
       "       [0.50901216]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80618471-2587-4b02-9f4f-cd5c0815d559",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d00c8a0-cfb5-4a5e-8bf1-35a61cd6d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, activation=\"relu\", input_shape=(max_length, 1), return_sequences=True,\n",
    "              kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))  \n",
    "model.add(Dropout(0.1))  \n",
    "model.add(LSTM(200, activation=\"relu\", return_sequences=False,\n",
    "              kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96080868-11c9-431f-9453-3b64e4e41779",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 134s 3s/step - loss: 16.8643\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 13.8616\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 12.3750\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 11.6591\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 11.2934\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 11.0774\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 10.9232\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 10.7946\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 10.6777\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 10.5672\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 10.4611\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 10.3585\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 50s 3s/step - loss: 10.2591\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 10.1627\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 10.0691\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 9.9784\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 9.8903\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 9.8048\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 9.7219\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 9.6416\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 9.5638\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 9.4884\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 9.4153\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 9.3446\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 9.2762\n",
      "Epoch 26/100\n",
      "10/17 [================>.............] - ETA: 20s - loss: 9.4153"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/pbs.32262.lich-compute.vscht.cz/ipykernel_26906/610107383.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_os\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_os\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.conda/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train_os, y_train_os, epochs=100, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93bfddb9-2230-4ff3-95d7-4553d8705f72",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 346ms/step - loss: 4.6476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877],\n",
       "       [-0.00703877]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d80965b-c468-4089-9902-78f5ff4299f0",
   "metadata": {},
   "source": [
    "So it looks like over-sampling didn't help :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf8cae-00a0-4915-a5ea-a2f33d67b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e6d5d7-67f1-4053-8265-3e995e48b6eb",
   "metadata": {},
   "source": [
    "### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54ccea96-a6d7-4a96-a678-3c93c0e7143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, activation=\"relu\", input_shape=(max_length, 1), return_sequences=True,\n",
    "              kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))  \n",
    "model.add(LSTM(128, activation=\"relu\", return_sequences=False,\n",
    "              kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "762f79a6-d1e5-458e-a6f3-2f92faebfd9f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 17s 1s/step - loss: 7.1326\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 5.6832\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 4.7034\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 4.0404\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 3.5787\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 3.2596\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 3.0345\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 16s 1s/step - loss: 2.8718\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 2.7510\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 2.6568\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 2.5803\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 2.5151\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 16s 1s/step - loss: 2.4576\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 16s 1s/step - loss: 2.4050\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 16s 1s/step - loss: 2.3575\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 16s 1s/step - loss: 2.3109\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 2.2661\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 16s 1s/step - loss: 2.2207\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 2.1788\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 2.1374\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 2.0969\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 14s 1s/step - loss: 2.0579\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 2.0196\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 14s 1s/step - loss: 1.9809\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.9438\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.9076\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.8727\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.8372\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 16s 1s/step - loss: 1.8028\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.7696\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.7364\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.7062\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.6731\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.6418\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 16s 1s/step - loss: 1.6126\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.5827\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.5540\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.5247\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.4973\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.4696\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.4447\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.4192\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.3920\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 16s 1s/step - loss: 1.3668\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 16s 1s/step - loss: 1.3424\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.3188\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.2973\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.2725\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.2514\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.2285\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.2094\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.1871\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.1666\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.1466\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.1275\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.1086\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 16s 1s/step - loss: 1.0914\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 16s 1s/step - loss: 1.0722\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 16s 1s/step - loss: 1.0556\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.0380\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.0213\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.0063\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.9910\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.9737\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 17s 2s/step - loss: 0.9600\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 16s 1s/step - loss: 0.9446\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.9300\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.9177\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.9041\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.8898\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.8775\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.8650\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.8539\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.8416\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.8298\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.8183\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.8083\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.7993\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.7879\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.7779\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.7677\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.7597\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.7500\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.7409\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.7324\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 16s 1s/step - loss: 0.7243\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.7159\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.7087\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.7014\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.6938\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.6868\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.6801\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.6734\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.6686\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.6620\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.6549\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.6500\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.6442\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.6387\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.6346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f04b415cfd0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a47e1d94-a953-4a13-b807-367a9f03fa60",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 207ms/step - loss: 0.6243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.28220424],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855009],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006],\n",
       "       [0.21855006]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb269c69-c7ae-40e4-b668-f6dd937dc725",
   "metadata": {},
   "source": [
    "### Model 5 w/os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c27a226-7174-4997-a292-277b3cef6116",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, activation=\"relu\", input_shape=(max_length, 1), return_sequences=True,\n",
    "              kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))  \n",
    "model.add(LSTM(128, activation=\"relu\", return_sequences=False,\n",
    "              kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d59fc91-867b-4394-a9aa-bbe5575324c7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 25s 1s/step - loss: 6.7897\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 5.0410\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 4.0339\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 3.4642\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 3.1340\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 2.9322\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 2.7932\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 2.6893\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 2.6033\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 2.5267\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 2.4558\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 2.3885\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 2.3242\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 2.2637\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 2.2022\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 2.1435\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 2.0870\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 2.0327\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.9797\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.9277\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.8778\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.8296\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.7833\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.7385\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.6938\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.6514\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 1.6106\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.5712\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.5331\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 1.4956\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 1.4602\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 1.4257\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 1.3924\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.3603\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.3294\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.2997\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.2710\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.2436\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.2171\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 1.1915\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.1672\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 1.1437\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 26s 2s/step - loss: 1.1210\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 1.0993\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.0786\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.0585\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.0395\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.0211\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 1.0039\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.9871\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.9713\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.9559\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 25s 1s/step - loss: 0.9414\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.9271\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.9138\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.9013\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.8890\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.8777\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.8666\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.8565\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 25s 1s/step - loss: 0.8462\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.8370\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 25s 1s/step - loss: 0.8284\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.8196\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.8116\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.8040\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.7970\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.7904\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 25s 1s/step - loss: 0.7836\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.7778\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.7720\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.7670\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.7619\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.7573\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.7523\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.7483\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.7446\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.7403\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.7371\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.7336\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.7306\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.7279\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.7250\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.7226\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 25s 1s/step - loss: 0.7205\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 25s 1s/step - loss: 0.7182\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.7160\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.7144\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.7125\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.7113\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.7094\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.7082\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 25s 1s/step - loss: 0.7068\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.7054\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.7046\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.7035\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 24s 1s/step - loss: 0.7024\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.7015\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.7009\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 23s 1s/step - loss: 0.7003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f04b4eab110>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_os, y_train_os, epochs=100, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ca54408-0691-4a71-a02b-a35fb539d6e7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 182ms/step - loss: 0.6943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.5447197],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502],\n",
       "       [0.4949502]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c743842-c0d9-4d4f-8c10-5ee93be4ed45",
   "metadata": {},
   "source": [
    "### Model 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62f5064f-9639-4727-8ced-1cee95c1255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "    50, activation='sigmoid', return_sequences=True, input_shape=(max_length, 1), kernel_regularizer=\"l2\",\n",
    "    recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"\n",
    "))\n",
    "model.add(LSTM(50, activation='sigmoid', kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57b566a6-3f4b-4377-a1a6-9f8439dc4bbd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 6s 313ms/step - loss: 3.1964\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 3s 308ms/step - loss: 2.8004\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 3s 318ms/step - loss: 2.4956\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 4s 341ms/step - loss: 2.2466\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 2.0482\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 3s 307ms/step - loss: 1.8891\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 4s 316ms/step - loss: 1.7646\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 3s 311ms/step - loss: 1.6602\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 3s 316ms/step - loss: 1.5692\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 4s 321ms/step - loss: 1.4965\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 1.4369\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 1.3875\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 4s 323ms/step - loss: 1.3457\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 1.3087\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 1.2768\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 1.2502\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 4s 332ms/step - loss: 1.2277\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 4s 334ms/step - loss: 1.2030\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 4s 333ms/step - loss: 1.1805\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 4s 321ms/step - loss: 1.1620\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 4s 323ms/step - loss: 1.1435\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 4s 330ms/step - loss: 1.1254\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 3s 317ms/step - loss: 1.1071\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 4s 319ms/step - loss: 1.0945\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 4s 350ms/step - loss: 1.0784\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 4s 349ms/step - loss: 1.0642\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 4s 345ms/step - loss: 1.0485\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 4s 348ms/step - loss: 1.0341\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 4s 354ms/step - loss: 1.0192\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 4s 346ms/step - loss: 1.0074\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 4s 352ms/step - loss: 0.9953\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 4s 350ms/step - loss: 0.9823\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 4s 360ms/step - loss: 0.9684\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 4s 350ms/step - loss: 0.9596\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 4s 338ms/step - loss: 0.9460\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 4s 322ms/step - loss: 0.9321\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 4s 319ms/step - loss: 0.9221\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 4s 321ms/step - loss: 0.9135\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.9008\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 0.8877\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 4s 316ms/step - loss: 0.8776\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.8699\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 4s 323ms/step - loss: 0.8589\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 4s 351ms/step - loss: 0.8494\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 4s 349ms/step - loss: 0.8406\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 4s 339ms/step - loss: 0.8307\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 4s 333ms/step - loss: 0.8208\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.8130\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 0.8031\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 4s 323ms/step - loss: 0.7947\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.7861\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 4s 322ms/step - loss: 0.7780\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.7719\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 4s 322ms/step - loss: 0.7627\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 4s 332ms/step - loss: 0.7543\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 0.7471\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 4s 345ms/step - loss: 0.7406\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 0.7347\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.7255\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 4s 319ms/step - loss: 0.7249\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.7137\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 4s 323ms/step - loss: 0.7082\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.7014\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 4s 320ms/step - loss: 0.6953\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 4s 321ms/step - loss: 0.6903\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 0.6835\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.6779\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 4s 319ms/step - loss: 0.6743\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 4s 330ms/step - loss: 0.6665\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 4s 330ms/step - loss: 0.6622\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.6576\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 4s 347ms/step - loss: 0.6535\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 4s 350ms/step - loss: 0.6477\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 4s 354ms/step - loss: 0.6432\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 4s 350ms/step - loss: 0.6385\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 4s 353ms/step - loss: 0.6338\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.6300\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.6276\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.6231\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.6200\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 4s 323ms/step - loss: 0.6161\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.6111\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 0.6074\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.6036\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 4s 319ms/step - loss: 0.6050\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 4s 318ms/step - loss: 0.5980\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 4s 336ms/step - loss: 0.5943\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 4s 327ms/step - loss: 0.5927\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.5882\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.5844\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 4s 322ms/step - loss: 0.5834\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 0.5830\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 4s 323ms/step - loss: 0.5774\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 4s 324ms/step - loss: 0.5753\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 4s 326ms/step - loss: 0.5718\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.5701\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 0.5677\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 4s 328ms/step - loss: 0.5662\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 0.5674\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 4s 329ms/step - loss: 0.5678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0488a88fd0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95adcadd-d959-4ab2-ac27-f1d7a21a2de3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 54ms/step - loss: 0.5532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823],\n",
       "       [0.20958823]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c8366725-8a4d-4573-9c79-938a2ae322b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "    50, activation='sigmoid', return_sequences=True, input_shape=(max_length, 1), kernel_regularizer=\"l2\",\n",
    "    recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"\n",
    "))\n",
    "model.add(LSTM(50, activation='sigmoid', kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "729c9ce2-c8a4-4682-a604-cd5c03a00e43",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "17/17 [==============================] - 9s 369ms/step - loss: 3.2422\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 6s 370ms/step - loss: 2.7200\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 6s 370ms/step - loss: 2.3442\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 6s 370ms/step - loss: 2.0761\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 6s 376ms/step - loss: 1.8831\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 6s 366ms/step - loss: 1.7435\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 6s 340ms/step - loss: 1.6408\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 1.5637\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 6s 323ms/step - loss: 1.5006\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 1.4506\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 6s 355ms/step - loss: 1.4140\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 6s 323ms/step - loss: 1.3769\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 5s 320ms/step - loss: 1.3424\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 1.3198\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 6s 323ms/step - loss: 1.2882\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 1.2669\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 6s 324ms/step - loss: 1.2420\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 1.2215\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 1.1991\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 1.1804\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 5s 316ms/step - loss: 1.1655\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 5s 321ms/step - loss: 1.1427\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 5s 320ms/step - loss: 1.1225\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 6s 326ms/step - loss: 1.1042\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 1.0853\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 1.0683\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 5s 316ms/step - loss: 1.0539\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 1.0365\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 5s 317ms/step - loss: 1.0222\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 1.0078\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 0.9969\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.9847\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 0.9697\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 5s 318ms/step - loss: 0.9558\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.9437\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 5s 315ms/step - loss: 0.9309\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 0.9194\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.9097\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 5s 316ms/step - loss: 0.8984\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 6s 326ms/step - loss: 0.8884\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 6s 334ms/step - loss: 0.8800\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 5s 321ms/step - loss: 0.8702\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 6s 337ms/step - loss: 0.8640\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.8539\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 5s 321ms/step - loss: 0.8456\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.8376\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.8295\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 6s 343ms/step - loss: 0.8220\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.8156\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 6s 340ms/step - loss: 0.8084\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 0.8024\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.7959\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 0.7909\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 0.7855\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.7803\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 6s 331ms/step - loss: 0.7756\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 6s 328ms/step - loss: 0.7725\n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 6s 330ms/step - loss: 0.7663\n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 6s 330ms/step - loss: 0.7626\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 6s 338ms/step - loss: 0.7576\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.7539\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 5s 320ms/step - loss: 0.7527\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.7476\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 6s 334ms/step - loss: 0.7461\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 6s 339ms/step - loss: 0.7419\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.7375\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 6s 324ms/step - loss: 0.7344\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 5s 313ms/step - loss: 0.7316\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 5s 321ms/step - loss: 0.7289\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 6s 330ms/step - loss: 0.7274\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 5s 314ms/step - loss: 0.7263\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 5s 313ms/step - loss: 0.7235\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.7222\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 6s 324ms/step - loss: 0.7201\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.7214\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 5s 317ms/step - loss: 0.7160\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.7137\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 0.7129\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.7106\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 5s 316ms/step - loss: 0.7110\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 5s 312ms/step - loss: 0.7106\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 5s 311ms/step - loss: 0.7105\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.7074\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 0.7064\n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 5s 317ms/step - loss: 0.7048\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 5s 317ms/step - loss: 0.7041\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 5s 315ms/step - loss: 0.7036\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 5s 316ms/step - loss: 0.7021\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 6s 326ms/step - loss: 0.7028\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 6s 330ms/step - loss: 0.7009\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.7007\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 0.6996\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 5s 320ms/step - loss: 0.6992\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 0.6989\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 5s 316ms/step - loss: 0.6991\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.6977\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.6977\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 5s 315ms/step - loss: 0.6971\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 5s 314ms/step - loss: 0.6968\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.6974\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.6968\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 6s 324ms/step - loss: 0.6958\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 6s 326ms/step - loss: 0.6958\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6964\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.6954\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.6950\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 5s 321ms/step - loss: 0.6948\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 5s 317ms/step - loss: 0.6949\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 5s 318ms/step - loss: 0.6947\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 5s 316ms/step - loss: 0.6946\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 5s 318ms/step - loss: 0.6941\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 5s 317ms/step - loss: 0.6945\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 5s 317ms/step - loss: 0.6942\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 6s 322ms/step - loss: 0.6941\n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 5s 320ms/step - loss: 0.6939\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.6946\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.6944\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 5s 318ms/step - loss: 0.6943\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 5s 315ms/step - loss: 0.6943\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 6s 329ms/step - loss: 0.6942\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 6s 333ms/step - loss: 0.6939\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 6s 331ms/step - loss: 0.6935\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 6s 340ms/step - loss: 0.6936\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 6s 334ms/step - loss: 0.6944\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.6939\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 6s 330ms/step - loss: 0.6952\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 0.6947\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 5s 320ms/step - loss: 0.6942\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6940\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 6s 329ms/step - loss: 0.6935\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 5s 317ms/step - loss: 0.6945\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 5s 320ms/step - loss: 0.6942\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.6933\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 0.6934\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 6s 328ms/step - loss: 0.6936\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 6s 326ms/step - loss: 0.6940\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 0.6935\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 0.6933\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 6s 333ms/step - loss: 0.6938\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.6934\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 6s 355ms/step - loss: 0.6939\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.6933\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 6s 337ms/step - loss: 0.6938\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 5s 320ms/step - loss: 0.6937\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 6s 355ms/step - loss: 0.6933\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.6935\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.6934\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 6s 338ms/step - loss: 0.6940\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 5s 318ms/step - loss: 0.6935\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 5s 316ms/step - loss: 0.6935\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 5s 313ms/step - loss: 0.6936\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 0.6937\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 5s 321ms/step - loss: 0.6935\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 5s 320ms/step - loss: 0.6934\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 6s 329ms/step - loss: 0.6935\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 5s 312ms/step - loss: 0.6933\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.6935\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 5s 313ms/step - loss: 0.6933\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 5s 324ms/step - loss: 0.6936\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 6s 341ms/step - loss: 0.6932\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 6s 323ms/step - loss: 0.6934\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6934\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.6938\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 6s 339ms/step - loss: 0.6941\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 5s 321ms/step - loss: 0.6935\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 0.6933\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 5s 321ms/step - loss: 0.6935\n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6934\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6933\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6937\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 6s 329ms/step - loss: 0.6943\n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 5s 321ms/step - loss: 0.6936\n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6938\n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 5s 316ms/step - loss: 0.6936\n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.6939\n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 6s 334ms/step - loss: 0.6938\n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 6s 323ms/step - loss: 0.6933\n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 5s 320ms/step - loss: 0.6934\n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6931\n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 5s 317ms/step - loss: 0.6933\n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.6933\n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 5s 317ms/step - loss: 0.6940\n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 5s 321ms/step - loss: 0.6935\n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 0.6939\n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 0.6933\n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 6s 338ms/step - loss: 0.6934\n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6932\n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 6s 330ms/step - loss: 0.6933\n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.6937\n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6939\n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 5s 320ms/step - loss: 0.6933\n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 5s 321ms/step - loss: 0.6933\n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 6s 333ms/step - loss: 0.6935\n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 5s 317ms/step - loss: 0.6935\n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 5s 316ms/step - loss: 0.6933\n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 6s 324ms/step - loss: 0.6934\n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 6s 328ms/step - loss: 0.6933\n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6934\n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6936\n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 6s 324ms/step - loss: 0.6934\n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 5s 315ms/step - loss: 0.6933\n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6935\n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 5s 321ms/step - loss: 0.6934\n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.6934\n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6933\n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 6s 326ms/step - loss: 0.6935\n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 0.6935\n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 0.6933\n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 6s 330ms/step - loss: 0.6934\n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 5s 320ms/step - loss: 0.6935\n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.6936\n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 5s 320ms/step - loss: 0.6933\n",
      "Epoch 213/300\n",
      "17/17 [==============================] - 5s 313ms/step - loss: 0.6933\n",
      "Epoch 214/300\n",
      "17/17 [==============================] - 5s 317ms/step - loss: 0.6932\n",
      "Epoch 215/300\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 0.6934\n",
      "Epoch 216/300\n",
      "17/17 [==============================] - 6s 332ms/step - loss: 0.6932\n",
      "Epoch 217/300\n",
      "17/17 [==============================] - 6s 345ms/step - loss: 0.6933\n",
      "Epoch 218/300\n",
      "17/17 [==============================] - 6s 363ms/step - loss: 0.6934\n",
      "Epoch 219/300\n",
      "17/17 [==============================] - 6s 380ms/step - loss: 0.6934\n",
      "Epoch 220/300\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.6932\n",
      "Epoch 221/300\n",
      "17/17 [==============================] - 6s 347ms/step - loss: 0.6933\n",
      "Epoch 222/300\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.6933\n",
      "Epoch 223/300\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.6935\n",
      "Epoch 224/300\n",
      "17/17 [==============================] - 6s 356ms/step - loss: 0.6940\n",
      "Epoch 225/300\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.6934\n",
      "Epoch 226/300\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.6935\n",
      "Epoch 227/300\n",
      "17/17 [==============================] - 6s 366ms/step - loss: 0.6936\n",
      "Epoch 228/300\n",
      "17/17 [==============================] - 6s 348ms/step - loss: 0.6933\n",
      "Epoch 229/300\n",
      "17/17 [==============================] - 6s 328ms/step - loss: 0.6935\n",
      "Epoch 230/300\n",
      "17/17 [==============================] - 5s 315ms/step - loss: 0.6937\n",
      "Epoch 231/300\n",
      "17/17 [==============================] - 6s 331ms/step - loss: 0.6933\n",
      "Epoch 232/300\n",
      "17/17 [==============================] - 6s 337ms/step - loss: 0.6932\n",
      "Epoch 233/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.6934\n",
      "Epoch 234/300\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 0.6937\n",
      "Epoch 235/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6934\n",
      "Epoch 236/300\n",
      "17/17 [==============================] - 5s 314ms/step - loss: 0.6933\n",
      "Epoch 237/300\n",
      "17/17 [==============================] - 6s 331ms/step - loss: 0.6936\n",
      "Epoch 238/300\n",
      "17/17 [==============================] - 6s 329ms/step - loss: 0.6931\n",
      "Epoch 239/300\n",
      "17/17 [==============================] - 6s 329ms/step - loss: 0.6935\n",
      "Epoch 240/300\n",
      "17/17 [==============================] - 6s 326ms/step - loss: 0.6936\n",
      "Epoch 241/300\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.6943\n",
      "Epoch 242/300\n",
      "17/17 [==============================] - 6s 336ms/step - loss: 0.6934\n",
      "Epoch 243/300\n",
      "17/17 [==============================] - 6s 339ms/step - loss: 0.6936\n",
      "Epoch 244/300\n",
      "17/17 [==============================] - 6s 350ms/step - loss: 0.6932\n",
      "Epoch 245/300\n",
      "17/17 [==============================] - 6s 349ms/step - loss: 0.6933\n",
      "Epoch 246/300\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.6935\n",
      "Epoch 247/300\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.6933\n",
      "Epoch 248/300\n",
      "17/17 [==============================] - 6s 339ms/step - loss: 0.6934\n",
      "Epoch 249/300\n",
      "17/17 [==============================] - 6s 338ms/step - loss: 0.6933\n",
      "Epoch 250/300\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.6932\n",
      "Epoch 251/300\n",
      "17/17 [==============================] - 6s 356ms/step - loss: 0.6933\n",
      "Epoch 252/300\n",
      "17/17 [==============================] - 6s 335ms/step - loss: 0.6934\n",
      "Epoch 253/300\n",
      "17/17 [==============================] - 6s 328ms/step - loss: 0.6933\n",
      "Epoch 254/300\n",
      "17/17 [==============================] - 6s 331ms/step - loss: 0.6932\n",
      "Epoch 255/300\n",
      "17/17 [==============================] - 6s 331ms/step - loss: 0.6936\n",
      "Epoch 256/300\n",
      "17/17 [==============================] - 5s 316ms/step - loss: 0.6933\n",
      "Epoch 257/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.6934\n",
      "Epoch 258/300\n",
      "17/17 [==============================] - 6s 322ms/step - loss: 0.6932\n",
      "Epoch 259/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.6932\n",
      "Epoch 260/300\n",
      "17/17 [==============================] - 6s 352ms/step - loss: 0.6936\n",
      "Epoch 261/300\n",
      "17/17 [==============================] - 6s 346ms/step - loss: 0.6932\n",
      "Epoch 262/300\n",
      "17/17 [==============================] - 6s 354ms/step - loss: 0.6933\n",
      "Epoch 263/300\n",
      "17/17 [==============================] - 6s 357ms/step - loss: 0.6937\n",
      "Epoch 264/300\n",
      "17/17 [==============================] - 6s 358ms/step - loss: 0.6935\n",
      "Epoch 265/300\n",
      "17/17 [==============================] - 6s 357ms/step - loss: 0.6932\n",
      "Epoch 266/300\n",
      "17/17 [==============================] - 6s 351ms/step - loss: 0.6933\n",
      "Epoch 267/300\n",
      "17/17 [==============================] - 6s 356ms/step - loss: 0.6934\n",
      "Epoch 268/300\n",
      "17/17 [==============================] - 6s 353ms/step - loss: 0.6932\n",
      "Epoch 269/300\n",
      "17/17 [==============================] - 6s 361ms/step - loss: 0.6932\n",
      "Epoch 270/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.6933\n",
      "Epoch 271/300\n",
      "17/17 [==============================] - 6s 329ms/step - loss: 0.6932\n",
      "Epoch 272/300\n",
      "17/17 [==============================] - 5s 321ms/step - loss: 0.6932\n",
      "Epoch 273/300\n",
      "17/17 [==============================] - 5s 321ms/step - loss: 0.6932\n",
      "Epoch 274/300\n",
      "17/17 [==============================] - 5s 323ms/step - loss: 0.6932\n",
      "Epoch 275/300\n",
      "17/17 [==============================] - 6s 328ms/step - loss: 0.6933\n",
      "Epoch 276/300\n",
      "17/17 [==============================] - 5s 319ms/step - loss: 0.6932\n",
      "Epoch 277/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6933\n",
      "Epoch 278/300\n",
      "17/17 [==============================] - 5s 321ms/step - loss: 0.6932\n",
      "Epoch 279/300\n",
      "17/17 [==============================] - 5s 320ms/step - loss: 0.6932\n",
      "Epoch 280/300\n",
      "17/17 [==============================] - 5s 320ms/step - loss: 0.6932\n",
      "Epoch 281/300\n",
      "17/17 [==============================] - 5s 320ms/step - loss: 0.6931\n",
      "Epoch 282/300\n",
      "17/17 [==============================] - 5s 316ms/step - loss: 0.6933\n",
      "Epoch 283/300\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 0.6937\n",
      "Epoch 284/300\n",
      "17/17 [==============================] - 5s 318ms/step - loss: 0.6933\n",
      "Epoch 285/300\n",
      "17/17 [==============================] - 5s 314ms/step - loss: 0.6936\n",
      "Epoch 286/300\n",
      "17/17 [==============================] - 5s 316ms/step - loss: 0.6932\n",
      "Epoch 287/300\n",
      "17/17 [==============================] - 6s 326ms/step - loss: 0.6932\n",
      "Epoch 288/300\n",
      "17/17 [==============================] - 6s 328ms/step - loss: 0.6932\n",
      "Epoch 289/300\n",
      "17/17 [==============================] - 6s 329ms/step - loss: 0.6932\n",
      "Epoch 290/300\n",
      "17/17 [==============================] - 5s 321ms/step - loss: 0.6932\n",
      "Epoch 291/300\n",
      "17/17 [==============================] - 5s 318ms/step - loss: 0.6933\n",
      "Epoch 292/300\n",
      "17/17 [==============================] - 6s 339ms/step - loss: 0.6932\n",
      "Epoch 293/300\n",
      "17/17 [==============================] - 5s 316ms/step - loss: 0.6934\n",
      "Epoch 294/300\n",
      "17/17 [==============================] - 6s 324ms/step - loss: 0.6933\n",
      "Epoch 295/300\n",
      "17/17 [==============================] - 5s 321ms/step - loss: 0.6933\n",
      "Epoch 296/300\n",
      "17/17 [==============================] - 5s 315ms/step - loss: 0.6933\n",
      "Epoch 297/300\n",
      "17/17 [==============================] - 5s 320ms/step - loss: 0.6933\n",
      "Epoch 298/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6934\n",
      "Epoch 299/300\n",
      "17/17 [==============================] - 5s 322ms/step - loss: 0.6933\n",
      "Epoch 300/300\n",
      "17/17 [==============================] - 5s 314ms/step - loss: 0.6934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f048bfb7250>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_os, y_train_os, epochs=300, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6e8af23-cd5a-42c4-8710-5b24b6939278",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 54ms/step - loss: 0.6979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608],\n",
       "       [0.5039608]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8861b7-1db9-40e3-b52b-dd90ebb73f20",
   "metadata": {},
   "source": [
    "### Model 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb70024c-32da-4547-afa4-9f920e1834bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, activation=\"relu\", input_shape=(max_length, 1), return_sequences=True,\n",
    "              kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))  \n",
    "model.add(Dropout(0.1))  \n",
    "model.add(LSTM(200, activation=\"relu\", return_sequences=False,\n",
    "              kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "452ef0d8-e8e5-4ce8-a630-9009930988d6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 33s 3s/step - loss: 10.5423\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 7.9961\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 6.4224\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 5.4357\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 4.8218\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 4.4360\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 4.1834\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 4.0097\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.8825\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.7773\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.6868\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.6036\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 3.5269\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.4539\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 3.3855\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 3.3125\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.2451\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.1787\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 3.1122\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 3.0497\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.9885\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.9257\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.8652\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 2.8064\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.7482\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 2.6926\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 2.6382\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.5859\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.5283\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.4766\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 2.4252\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 2.3753\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 2.3256\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 2.2771\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.2294\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.1843\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.1383\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.0932\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.0499\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 2.0078\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.9664\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.9261\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.8865\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 1.8467\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.8090\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.7717\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.7355\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.6996\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.6650\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.6318\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 1.5986\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.5661\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.5351\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.5033\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.4729\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 1.4441\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.4144\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.3869\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.3599\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.3326\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.3077\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.2824\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.2563\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.2327\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.2094\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.1872\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.1658\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.1429\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.1220\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.1016\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.0820\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.0624\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.0434\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.0246\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 1.0073\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.9903\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.9732\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.9571\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.9412\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.9261\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.9111\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.8988\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.8826\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.8689\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.8567\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.8427\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.8312\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.8185\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.8066\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.7965\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.7840\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.7739\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.7639\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.7530\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.7439\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.7349\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.7257\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.7177\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.7087\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 30s 3s/step - loss: 0.7007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f04788cea50>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "51bed85d-f73d-480b-91fb-9d3dda270bac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 323ms/step - loss: 0.6891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466086],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.29249224],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466089],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083],\n",
       "       [0.20466083]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2fecc3cc-051b-4cdd-869f-7f8cce108e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, activation=\"relu\", input_shape=(max_length, 1), return_sequences=True,\n",
    "              kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))  \n",
    "model.add(Dropout(0.1))  \n",
    "model.add(LSTM(200, activation=\"relu\", return_sequences=False,\n",
    "              kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad2f844d-5e06-4057-b532-70037864d451",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 50s 3s/step - loss: 9.8821\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 47s 3s/step - loss: 6.8623\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 5.3686\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 47s 3s/step - loss: 4.6465\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 4.2778\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 4.0596\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 3.9050\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 3.7761\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 3.6594\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 3.5483\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 3.4419\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 3.3395\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 3.2400\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 3.1434\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 47s 3s/step - loss: 3.0499\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 2.9592\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 2.8710\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 2.7856\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 2.7026\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 2.6228\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 2.5445\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 2.4691\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 2.3960\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 2.3254\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 2.2572\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 2.1906\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 2.1270\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 2.0653\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 47s 3s/step - loss: 2.0050\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.9476\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.8916\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.8376\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.7858\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.7361\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.6876\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.6414\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.5969\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.5538\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.5128\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.4721\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 1.4343\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.3975\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.3621\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.3285\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.2958\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.2646\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.2350\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.2061\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.1787\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.1526\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.1280\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.1039\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.0808\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.0590\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.0388\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.0184\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.9997\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.9815\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.9646\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.9479\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.9333\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.9183\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.9043\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.8913\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.8787\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 0.8674\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.8555\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.8450\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.8354\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.8256\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.8167\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.8082\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.8006\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7928\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7862\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 0.7794\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7730\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7669\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7628\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.7571\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7517\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.7478\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7432\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7399\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.7359\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7326\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7293\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7267\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 0.7245\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7215\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7191\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.7167\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7146\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7130\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7112\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7099\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 0.7078\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7063\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 49s 3s/step - loss: 0.7057\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f048b701a90>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_os, y_train_os, epochs=100, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5410e81e-01d7-483b-8675-16600c1867ee",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 305ms/step - loss: 0.7039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.5463071 ],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126],\n",
       "       [0.49974126]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cecc335-2083-449c-b570-a79df300402b",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "\n",
    "### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6085c-b76c-4d05-b0b6-f12eda9826cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a16a929a-1b5c-4da3-ab84-5ba4ca0fe87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, activation=\"relu\", input_shape=(max_length, 1), return_sequences=True,\n",
    "              kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))  \n",
    "model.add(LSTM(128, activation=\"relu\", return_sequences=False,\n",
    "              kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a256575f-b9db-41b4-bc19-845791024360",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 7.3776 - val_loss: 6.6472\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 6.2244 - val_loss: 5.6264\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 5.3372 - val_loss: 4.9049\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 4.6828 - val_loss: 4.3465\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 4.1796 - val_loss: 3.9246\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 3.7991 - val_loss: 3.5998\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 3.5061 - val_loss: 3.3495\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 3.2825 - val_loss: 3.1576\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 3.1080 - val_loss: 3.0124\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 2.9726 - val_loss: 2.8928\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 2.8611 - val_loss: 2.7932\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 2.7738 - val_loss: 2.7142\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 2.6994 - val_loss: 2.6486\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 2.6373 - val_loss: 2.5909\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 2.5831 - val_loss: 2.5407\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 2.5345 - val_loss: 2.4953\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 2.4907 - val_loss: 2.4538\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 2.4509 - val_loss: 2.4168\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 2.4129 - val_loss: 2.3781\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 2.3766 - val_loss: 2.3423\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 2.3422 - val_loss: 2.3094\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 2.3073 - val_loss: 2.2756\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 2.2752 - val_loss: 2.2422\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 2.2432 - val_loss: 2.2107\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 2.2115 - val_loss: 2.1808\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 2.1808 - val_loss: 2.1512\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 2.1508 - val_loss: 2.1209\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 2.1214 - val_loss: 2.0910\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 2.0923 - val_loss: 2.0623\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 2.0650 - val_loss: 2.0351\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 2.0353 - val_loss: 2.0057\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 2.0086 - val_loss: 1.9781\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 1.9804 - val_loss: 1.9511\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 1.9535 - val_loss: 1.9252\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 1.9268 - val_loss: 1.8985\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 1.9008 - val_loss: 1.8738\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 1.8756 - val_loss: 1.8469\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 1.8498 - val_loss: 1.8227\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 1.8244 - val_loss: 1.7976\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 1.7995 - val_loss: 1.7725\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 1.7754 - val_loss: 1.7483\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 1.7512 - val_loss: 1.7240\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 1.7284 - val_loss: 1.7006\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 1.7044 - val_loss: 1.6776\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 1.6809 - val_loss: 1.6564\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 1.6584 - val_loss: 1.6338\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 13052.7412 - val_loss: 1.6130\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 1.6332 - val_loss: 1.6312\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 1.6488 - val_loss: 1.6365\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 1.6493 - val_loss: 1.6293\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.6400Restoring model weights from the end of the best epoch: 47.\n",
      "8/8 [==============================] - 12s 1s/step - loss: 1.6400 - val_loss: 1.6166\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f04b42a5150>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=4, verbose=1, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1, batch_size=128, validation_split=0.3, callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5d030392-6072-407b-953a-dc2832c47718",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 190ms/step - loss: 1.6144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.21184444],\n",
       "       [0.21184433],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.21184525],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.21184427],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.21184433],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.21185115],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.21184751],\n",
       "       [0.21184751],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118443 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118443 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.21184441],\n",
       "       [0.21184441],\n",
       "       [0.21184441],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118443 ],\n",
       "       [0.3752784 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.21184427],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.21184471],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.21184427],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.21184465],\n",
       "       [0.21184465],\n",
       "       [0.21184465],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.21184444],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118445 ],\n",
       "       [0.21184453],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.21184427],\n",
       "       [0.21186331],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.21184427],\n",
       "       [0.2118442 ],\n",
       "       [0.21184444],\n",
       "       [0.21184444],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ],\n",
       "       [0.2118442 ]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d7943236-ef2d-4e50-b30e-78be76319587",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, activation=\"relu\", input_shape=(max_length, 1), return_sequences=True,\n",
    "              kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))  \n",
    "model.add(LSTM(128, activation=\"relu\", return_sequences=False,\n",
    "              kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3b3ed3e-fab9-4b9f-a72b-9c6e58571c1c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 23s 2s/step - loss: 7.0680 - val_loss: 6.5489\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 5.5926 - val_loss: 5.7582\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 4.6087 - val_loss: 4.7859\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 3.9531 - val_loss: 4.3299\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 18s 2s/step - loss: 3.5155 - val_loss: 3.9886\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 18s 2s/step - loss: 3.2196 - val_loss: 3.7645\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 3.0155 - val_loss: 3.5850\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 2.8688 - val_loss: 3.4322\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 2.7595 - val_loss: 3.3866\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 2.6731 - val_loss: 3.2940\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 2.6020 - val_loss: 3.2263\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 2.5384 - val_loss: 3.1387\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 2.4817 - val_loss: 3.1190\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 21s 2s/step - loss: 2.4281 - val_loss: 3.0448\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 2.3782 - val_loss: 2.9794\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 2.3299 - val_loss: 2.9761\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 2.2830 - val_loss: 2.9001\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 18s 2s/step - loss: 2.2384 - val_loss: 2.8981\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 2.1942 - val_loss: 2.8174\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 2.1499 - val_loss: 2.7892\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 2.1075 - val_loss: 2.7116\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 18s 2s/step - loss: 2.0674 - val_loss: 2.7281\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 18s 2s/step - loss: 2.0259 - val_loss: 2.6288\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.9863 - val_loss: 2.6322\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 18s 2s/step - loss: 1.9476 - val_loss: 2.5613\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.9095 - val_loss: 2.5586\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 1.8725 - val_loss: 2.5038\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 1.8379 - val_loss: 2.4842\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.8018 - val_loss: 2.4127\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.7659 - val_loss: 2.4449\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 1.7326 - val_loss: 2.3483\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 1.6996 - val_loss: 2.3500\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.6666 - val_loss: 2.2736\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.6362 - val_loss: 2.3074\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.6040 - val_loss: 2.2146\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.5750 - val_loss: 2.2188\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 1.5457 - val_loss: 2.2156\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.5154 - val_loss: 2.1101\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 18s 2s/step - loss: 1.4890 - val_loss: 2.1081\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.4604 - val_loss: 2.1292\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.4338 - val_loss: 2.0874\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 18s 2s/step - loss: 1.4071 - val_loss: 2.0388\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.3820 - val_loss: 2.0092\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 1.3575 - val_loss: 1.9830\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.3329 - val_loss: 2.0002\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.3093 - val_loss: 1.9738\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.2862 - val_loss: 1.8918\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 1.2638 - val_loss: 1.9375\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.2418 - val_loss: 1.8554\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.2214 - val_loss: 1.8775\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.1995 - val_loss: 1.8137\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 18s 2s/step - loss: 1.1799 - val_loss: 1.8104\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.1607 - val_loss: 1.8478\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.1410 - val_loss: 1.7681\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 18s 2s/step - loss: 1.1222 - val_loss: 1.7692\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 1.1044 - val_loss: 1.7571\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 18s 2s/step - loss: 1.0865 - val_loss: 1.7358\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 1.0695 - val_loss: 1.7337\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 24s 2s/step - loss: 1.0529 - val_loss: 1.6483\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 21s 2s/step - loss: 1.0377 - val_loss: 1.7396\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 22s 2s/step - loss: 1.0208 - val_loss: 1.6587\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 23s 2s/step - loss: 1.0062 - val_loss: 1.6294\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.9904 - val_loss: 1.6668\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.9766 - val_loss: 1.6371\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.9639 - val_loss: 1.5920\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.9487 - val_loss: 1.6079\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.9356 - val_loss: 1.5799\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.9227 - val_loss: 1.5856\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.9109 - val_loss: 1.5659\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 18s 2s/step - loss: 0.8993 - val_loss: 1.5750\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 18s 2s/step - loss: 0.8866 - val_loss: 1.5036\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 18s 2s/step - loss: 0.8757 - val_loss: 1.5348\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.8648 - val_loss: 1.5171\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.8550 - val_loss: 1.4659\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 18s 2s/step - loss: 0.8441 - val_loss: 1.5432\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 21s 2s/step - loss: 0.8342 - val_loss: 1.4878\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.8254 - val_loss: 1.4776\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.8157 - val_loss: 1.4611\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.8069 - val_loss: 1.4143\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.7976 - val_loss: 1.4789\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.7902 - val_loss: 1.4577\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.7815 - val_loss: 1.4129\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.7738 - val_loss: 1.4217\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.7663 - val_loss: 1.4389\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.7591 - val_loss: 1.4205\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.7521 - val_loss: 1.3859\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.7456 - val_loss: 1.3968\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.7395 - val_loss: 1.4199\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.7325 - val_loss: 1.3661\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 19s 2s/step - loss: 0.7267 - val_loss: 1.3756\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.7213 - val_loss: 1.3797\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 20s 2s/step - loss: 0.7154 - val_loss: 1.3580\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.7101 - val_loss: 1.3873\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.7052 - val_loss: 1.3517\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 24s 2s/step - loss: 0.7000 - val_loss: 1.3741\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.6953 - val_loss: 1.3013\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.6916 - val_loss: 1.3785\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.6861 - val_loss: 1.3362\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 22s 2s/step - loss: 0.6821 - val_loss: 1.3215\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.6780Restoring model weights from the end of the best epoch: 96.\n",
      "12/12 [==============================] - 23s 2s/step - loss: 0.6780 - val_loss: 1.3546\n",
      "Epoch 00100: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0489b7c990>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=4, verbose=1, restore_best_weights=True)\n",
    "model.fit(X_train_os, y_train_os, epochs=100, verbose=1, batch_size=128, validation_split=0.3, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c9d6a2e3-dc64-4f1e-9b1f-6df73e52cdc1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 196ms/step - loss: 0.6244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.29800254],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.37517145],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.29800254],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ],\n",
       "       [0.2980025 ]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdbf0fd-ca38-494f-99ba-d0b0c3d5f7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7cfb11-9c13-415b-9167-0972b65d939c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6dbdea4-236f-4bc4-bcf0-8ff2686f15f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "    30, activation='sigmoid', return_sequences=True, input_shape=(max_length, 1), kernel_regularizer=\"l2\",\n",
    "    recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"\n",
    "))\n",
    "model.add(LSTM(40, activation='sigmoid', kernel_regularizer=\"l2\", recurrent_regularizer=\"l2\", bias_regularizer=\"l2\"))\n",
    "model.add(Dense(40))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eef3d532-5347-443f-b177-e79a2ecd5255",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 5s 259ms/step - loss: 2.3678\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 2.1332\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 3s 238ms/step - loss: 1.9393\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 3s 243ms/step - loss: 1.7842\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 1.6516\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 3s 248ms/step - loss: 1.5428\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 3s 248ms/step - loss: 1.4497\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 3s 243ms/step - loss: 1.3732\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 1.3081\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 3s 235ms/step - loss: 1.2535\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 3s 242ms/step - loss: 1.2062\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 1.1669\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 1.1310\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 3s 242ms/step - loss: 1.1004\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 3s 237ms/step - loss: 1.0738\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 3s 237ms/step - loss: 1.0506\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 3s 233ms/step - loss: 1.0324\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 1.0113\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 3s 236ms/step - loss: 0.9953\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 3s 236ms/step - loss: 0.9780\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 3s 238ms/step - loss: 0.9628\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 0.9485\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 0.9356\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.9231\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.9111\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 3s 240ms/step - loss: 0.9004\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 3s 235ms/step - loss: 0.8896\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.8794\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 3s 252ms/step - loss: 0.8693\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 3s 263ms/step - loss: 0.8602\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.8514\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.8412\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 0.8330\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.8241\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 0.8147\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.8078\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.7992\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 3s 235ms/step - loss: 0.7915\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 3s 236ms/step - loss: 0.7856\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 3s 238ms/step - loss: 0.7772\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 3s 237ms/step - loss: 0.7687\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 3s 238ms/step - loss: 0.7638\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 3s 237ms/step - loss: 0.7558\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 3s 234ms/step - loss: 0.7494\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.7424\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 0.7343\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 0.7287\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 0.7224\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 3s 263ms/step - loss: 0.7157\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.7100\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 3s 261ms/step - loss: 0.7042\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 0.6988\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.6937\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.6882\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 3s 271ms/step - loss: 0.6828\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.6783\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.6721\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.6676\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.6636\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 0.6576\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.6541\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.6490\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.6443\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 3s 261ms/step - loss: 0.6407\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 3s 234ms/step - loss: 0.6359\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.6326\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 3s 242ms/step - loss: 0.6282\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 3s 229ms/step - loss: 0.6248\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 3s 240ms/step - loss: 0.6213\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 3s 246ms/step - loss: 0.6184\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 0.6136\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 0.6106\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 0.6072\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.6040\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.6009\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 3s 243ms/step - loss: 0.5981\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 0.5951\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 3s 272ms/step - loss: 0.5917\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.5890\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.5867\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.5844\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.5823\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 3s 261ms/step - loss: 0.5803\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.5762\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.5748\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.5721\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 3s 263ms/step - loss: 0.5707\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.5695\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 0.5668\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.5646\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 3s 263ms/step - loss: 0.5635\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.5621\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 0.5587\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 3s 261ms/step - loss: 0.5568\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.5550\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.5529\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.5518\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 3s 238ms/step - loss: 0.5506\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 0.5489\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 0.5472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fba5b8af2d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "469bb6d2-132a-490a-aa2f-3ac9b272a5de",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 41ms/step - loss: 0.5397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438],\n",
       "       [0.21605438]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca5c51f-cdc9-407f-aee6-539850389fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c91db294-2fcf-4c9e-a5a7-9dc86eae1ed2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 338ms/step - loss: 2.3777 - val_loss: 2.2537\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 2s 296ms/step - loss: 2.2067 - val_loss: 2.0994\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 2s 294ms/step - loss: 2.0587 - val_loss: 1.9595\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 2s 288ms/step - loss: 1.9269 - val_loss: 1.8378\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 2s 284ms/step - loss: 1.8105 - val_loss: 1.7333\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 2s 273ms/step - loss: 1.7119 - val_loss: 1.6402\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 2s 282ms/step - loss: 1.6256 - val_loss: 1.5570\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 2s 287ms/step - loss: 1.5443 - val_loss: 1.4893\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 2s 264ms/step - loss: 1.4791 - val_loss: 1.4233\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 2s 288ms/step - loss: 1.4181 - val_loss: 1.3677\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 2s 287ms/step - loss: 1.3646 - val_loss: 1.3206\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 2s 296ms/step - loss: 1.3186 - val_loss: 1.2762\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 2s 287ms/step - loss: 1.2809 - val_loss: 1.2379\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 2s 281ms/step - loss: 1.2422 - val_loss: 1.2085\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 2s 270ms/step - loss: 1.2082 - val_loss: 1.1722\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 2s 283ms/step - loss: 1.1780 - val_loss: 1.1454\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 2s 275ms/step - loss: 1.1511 - val_loss: 1.1204\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 2s 277ms/step - loss: 1.1276 - val_loss: 1.0986\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 2s 278ms/step - loss: 1.1058 - val_loss: 1.0778\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 2s 285ms/step - loss: 1.0861 - val_loss: 1.0586\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 2s 278ms/step - loss: 1.0680 - val_loss: 1.0421\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 2s 297ms/step - loss: 1.0516 - val_loss: 1.0261\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 2s 302ms/step - loss: 1.0363 - val_loss: 1.0118\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 2s 298ms/step - loss: 1.0226 - val_loss: 0.9980\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 2s 283ms/step - loss: 1.0091 - val_loss: 0.9851\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 2s 281ms/step - loss: 0.9993 - val_loss: 0.9746\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 2s 280ms/step - loss: 0.9851 - val_loss: 0.9618\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 2s 285ms/step - loss: 0.9751 - val_loss: 0.9528\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 2s 279ms/step - loss: 0.9656 - val_loss: 0.9411\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 2s 275ms/step - loss: 0.9536 - val_loss: 0.9325\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 2s 272ms/step - loss: 0.9453 - val_loss: 0.9236\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 2s 280ms/step - loss: 0.9351 - val_loss: 0.9133\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 2s 304ms/step - loss: 0.9274 - val_loss: 0.9047\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 2s 271ms/step - loss: 0.9176 - val_loss: 0.8978\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 2s 272ms/step - loss: 0.9113 - val_loss: 0.8894\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 2s 274ms/step - loss: 0.9015 - val_loss: 0.8808\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 2s 273ms/step - loss: 0.8948 - val_loss: 0.8735\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 2s 271ms/step - loss: 0.8880 - val_loss: 0.8687\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 2s 274ms/step - loss: 0.8808 - val_loss: 0.8583\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 2s 275ms/step - loss: 0.8727 - val_loss: 0.8535\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 2s 282ms/step - loss: 0.8651 - val_loss: 0.8443\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 2s 289ms/step - loss: 0.8613 - val_loss: 0.8379\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 2s 277ms/step - loss: 0.8545 - val_loss: 0.8345\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 2s 275ms/step - loss: 0.8453 - val_loss: 0.8245\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 2s 282ms/step - loss: 0.8393 - val_loss: 0.8181\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 2s 275ms/step - loss: 0.8347 - val_loss: 0.8134\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 2s 273ms/step - loss: 0.8254 - val_loss: 0.8058\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 2s 306ms/step - loss: 0.8200 - val_loss: 0.8010\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 3s 397ms/step - loss: 0.8143 - val_loss: 0.7944\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 3s 414ms/step - loss: 0.8083 - val_loss: 0.7879\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 3s 333ms/step - loss: 0.8027 - val_loss: 0.7824\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 2s 279ms/step - loss: 0.7973 - val_loss: 0.7779\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 2s 267ms/step - loss: 0.7906 - val_loss: 0.7709\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 2s 278ms/step - loss: 0.7868 - val_loss: 0.7661\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 2s 278ms/step - loss: 0.7803 - val_loss: 0.7628\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 2s 277ms/step - loss: 0.7753 - val_loss: 0.7558\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 2s 282ms/step - loss: 0.7694 - val_loss: 0.7497\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 2s 292ms/step - loss: 0.7651 - val_loss: 0.7448\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 2s 279ms/step - loss: 0.7601 - val_loss: 0.7408\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 2s 270ms/step - loss: 0.7539 - val_loss: 0.7346\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 2s 275ms/step - loss: 0.7507 - val_loss: 0.7298\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 2s 279ms/step - loss: 0.7442 - val_loss: 0.7281\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 2s 265ms/step - loss: 0.7404 - val_loss: 0.7208\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 2s 282ms/step - loss: 0.7355 - val_loss: 0.7157\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 2s 295ms/step - loss: 0.7306 - val_loss: 0.7126\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 2s 276ms/step - loss: 0.7264 - val_loss: 0.7073\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 2s 281ms/step - loss: 0.7214 - val_loss: 0.7027\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 2s 275ms/step - loss: 0.7173 - val_loss: 0.6981\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 2s 284ms/step - loss: 0.7134 - val_loss: 0.6940\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 2s 268ms/step - loss: 0.7107 - val_loss: 0.6896\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 2s 275ms/step - loss: 0.7066 - val_loss: 0.6908\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 2s 274ms/step - loss: 0.7015 - val_loss: 0.6820\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 2s 282ms/step - loss: 0.6976 - val_loss: 0.6781\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 2s 273ms/step - loss: 0.6927 - val_loss: 0.6750\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 2s 279ms/step - loss: 0.6890 - val_loss: 0.6709\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 2s 268ms/step - loss: 0.6860 - val_loss: 0.6662\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 2s 274ms/step - loss: 0.6816 - val_loss: 0.6663\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 2s 289ms/step - loss: 0.6795 - val_loss: 0.6589\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 2s 283ms/step - loss: 0.6752 - val_loss: 0.6569\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 2s 279ms/step - loss: 0.6706 - val_loss: 0.6527\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 2s 283ms/step - loss: 0.6695 - val_loss: 0.6484\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 2s 277ms/step - loss: 0.6651 - val_loss: 0.6495\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 2s 275ms/step - loss: 0.6607 - val_loss: 0.6419\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 2s 276ms/step - loss: 0.6576 - val_loss: 0.6387\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 2s 273ms/step - loss: 0.6551 - val_loss: 0.6357\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 2s 278ms/step - loss: 0.6508 - val_loss: 0.6339\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 2s 277ms/step - loss: 0.6491 - val_loss: 0.6291\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 2s 282ms/step - loss: 0.6446 - val_loss: 0.6273\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 2s 280ms/step - loss: 0.6422 - val_loss: 0.6239\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 2s 278ms/step - loss: 0.6402 - val_loss: 0.6203\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 2s 271ms/step - loss: 0.6367 - val_loss: 0.6211\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 2s 281ms/step - loss: 0.6353 - val_loss: 0.6147\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 2s 299ms/step - loss: 0.6299 - val_loss: 0.6131\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 2s 289ms/step - loss: 0.6276 - val_loss: 0.6097\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 2s 294ms/step - loss: 0.6248 - val_loss: 0.6073\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 2s 277ms/step - loss: 0.6221 - val_loss: 0.6047\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 2s 279ms/step - loss: 0.6203 - val_loss: 0.6016\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 2s 286ms/step - loss: 0.6180 - val_loss: 0.5992\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 2s 281ms/step - loss: 0.6150 - val_loss: 0.5989\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 2s 278ms/step - loss: 0.6129 - val_loss: 0.5950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fba5b772750>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=4, verbose=1, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, epochs=100, verbose=1, batch_size=128, validation_split=0.3, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bbdc66e-e95f-4fad-a11a-50b28242172f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 38ms/step - loss: 0.5995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619311],\n",
       "       [0.21619311],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619311],\n",
       "       [0.21619311],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619311],\n",
       "       [0.21619311],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619311],\n",
       "       [0.21619311],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619311],\n",
       "       [0.21619311],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619311],\n",
       "       [0.21619311],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619311],\n",
       "       [0.21619311],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317],\n",
       "       [0.21619317]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b952d8-f2f2-4b3d-bac8-3a6ba74dc548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
