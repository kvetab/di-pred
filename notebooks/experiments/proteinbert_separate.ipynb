{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6957221-20a9-48b6-bf45-66b5bd8cdd5d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from os import path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "786d3969-dbf8-44c0-8f54-861ea4ced399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from proteinbert.finetuning import encode_train_and_valid_sets, encode_dataset\n",
    "from proteinbert import OutputType, OutputSpec, evaluate_by_len, load_pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a93abf-2788-4e44-a6f6-0673383b3d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, finetune\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e7d3caa-832a-44be-8afa-eac7a7b658ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6134f029-f8f2-45c1-98b2-2c6189cab990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cb66728-d510-40d0-aabc-daf656e6a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f71d310e-79d2-454e-9aca-cbe3fdb51624",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_TYPE = OutputType(False, 'binary')\n",
    "UNIQUE_LABELS = [0, 1]\n",
    "OUTPUT_SPEC = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13316d4d-7c04-42a6-9e3b-2ccf60b94b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_generator, input_encoder = load_pretrained_model(\"../../data/protein_bert/\", \"epoch_92400_sample_23500000.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c252f132-f742-4980-8fe8-cc764c0f9c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function = \\\n",
    "        get_model_with_hidden_layers_as_outputs, dropout_rate = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36728dc4-c7ba-4fda-8ec0-6b05d99cce20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkvetab\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/kvetab/Heavy/runs/22sc7vwt\" target=\"_blank\">skilled-energy-2</a></strong> to <a href=\"https://wandb.ai/kvetab/Heavy\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/kvetab/Heavy/runs/22sc7vwt?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f422fb7ccd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=f\"Heavy\", entity=\"kvetab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "288f85b7-8d60-443b-9907-4243fe33e26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...</td>\n",
       "      <td>DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...</td>\n",
       "      <td>DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Antibody_ID                                              heavy  \\\n",
       "2073        6aod  EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...   \n",
       "1517        4yny  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2025        5xcv  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2070        6and  EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...   \n",
       "666         2xqy  QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...   \n",
       "\n",
       "                                                  light  Y  \n",
       "2073  DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...  0  \n",
       "1517  EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2025  QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2070  DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...  1  \n",
       "666   DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...  0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_train_data.csv\"), index_col=0)\n",
    "valid_data = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_valid_data.csv\"), index_col=0)\n",
    "test_data = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_test_data.csv\"), index_col=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8afa325-5733-4abe-9f48-b94450638bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(patience = 3, factor = 0.25, min_lr = 1e-07, verbose = 1),\n",
    "    keras.callbacks.EarlyStopping(patience = 6, restore_best_weights = True),\n",
    "    WandbCallback()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30e5f009-8389-456f-9fd5-8f2089178687",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 100\n",
    "batch_size = 128\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ca80d7a-5543-4bbc-95b7-5814026ae04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "      \"learning_rate\": learning_rate,\n",
    "      \"epochs\": epoch_num * 2,\n",
    "      \"batch_size\": batch_size\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65107aae-e53c-4181-8930-643473db28ce",
   "metadata": {},
   "source": [
    "# Separate models\n",
    "## Heavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "448181bf-fc6d-42df-8149-3261505d76a7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022_03_09-16:08:28] Training set: Filtered out 0 of 1338 (0.0%) records of lengths exceeding 510.\n",
      "[2022_03_09-16:08:28] Validation set: Filtered out 0 of 120 (0.0%) records of lengths exceeding 510.\n",
      "[2022_03_09-16:08:28] Training with frozen pretrained layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 16:08:28.487074: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-09 16:08:29.046937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9656 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:21:00.0, compute capability: 7.5\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "2022-03-09 16:08:30.813657: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 16:08:38.600077: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 7605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 11s 324ms/step - loss: 0.8052 - val_loss: 0.6361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model, h5py returned error: Layer GlobalAttention has arguments in `__init__` and therefore must override `get_config`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.5626 - val_loss: 0.5395\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.5152 - val_loss: 0.4967\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.4739 - val_loss: 0.4947\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.4666 - val_loss: 0.4932\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4582 - val_loss: 0.4810\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.4596 - val_loss: 0.4902\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.4508 - val_loss: 0.5017\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4560 - val_loss: 0.4871\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4424 - val_loss: 0.4721\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4448 - val_loss: 0.4713\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4376 - val_loss: 0.4694\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.4368 - val_loss: 0.4682\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4479 - val_loss: 0.4790\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.4416 - val_loss: 0.4703\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4423 - val_loss: 0.4683\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.4290 - val_loss: 0.4666\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4285 - val_loss: 0.4661\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4301 - val_loss: 0.4660\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4315 - val_loss: 0.4659\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4383 - val_loss: 0.4660\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4325 - val_loss: 0.4658\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.4398 - val_loss: 0.4657\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.4351 - val_loss: 0.4661\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4281 - val_loss: 0.4659\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4302 - val_loss: 0.4658\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4349 - val_loss: 0.4659\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4269 - val_loss: 0.4658\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4364 - val_loss: 0.4657\n",
      "[2022_03_09-16:09:16] Training the entire fine-tuned model...\n",
      "[2022_03_09-16:09:26] Incompatible number of optimizer weights - will not initialize them.\n",
      "Epoch 1/100\n",
      " 6/11 [===============>..............] - ETA: 1s - loss: 0.4531WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1095s vs `on_train_batch_end` time: 0.1417s). Check your callbacks.\n",
      "11/11 [==============================] - 10s 428ms/step - loss: 0.4395 - val_loss: 0.4837\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 3s 252ms/step - loss: 0.4419 - val_loss: 0.4684\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.4266 - val_loss: 0.4663\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.4152 - val_loss: 0.4720\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.4190 - val_loss: 0.4675\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.4054 - val_loss: 0.4617\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.3963 - val_loss: 0.4886\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.3998 - val_loss: 0.4702\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.3824 - val_loss: 0.5024\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.3910 - val_loss: 0.4816\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.3733 - val_loss: 0.4776\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.3642 - val_loss: 0.4765\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "[2022_03_09-16:10:08] Training on final epochs of sequence length 1024...\n",
      "[2022_03_09-16:10:08] Training set: Filtered out 0 of 1338 (0.0%) records of lengths exceeding 1022.\n",
      "[2022_03_09-16:10:13] Validation set: Filtered out 0 of 120 (0.0%) records of lengths exceeding 1022.\n",
      " 6/21 [=======>......................] - ETA: 3s - loss: 0.4599WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1084s vs `on_train_batch_end` time: 0.1368s). Check your callbacks.\n",
      "21/21 [==============================] - 13s 374ms/step - loss: 0.4238 - val_loss: 0.4603\n"
     ]
    }
   ],
   "source": [
    "finetune(model_generator, input_encoder, OUTPUT_SPEC, train_data['heavy'], train_data['Y'], valid_data['heavy'], valid_data['Y'], \\\n",
    "        seq_len = 512, batch_size = batch_size, max_epochs_per_stage = epoch_num, lr = learning_rate, begin_with_frozen_pretrained_layers = True, \\\n",
    "        lr_with_frozen_pretrained_layers = 1e-02, n_final_epochs = 1, final_seq_len = 1024, final_lr = learning_rate / 10, callbacks = training_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc6f941c-f6c4-4ec0-9ba9-bdbbb942963d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0  83  13\n",
       "1  10  13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5306122448979592"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results, confusion_matrix = evaluate_by_len(model_generator, input_encoder, OUTPUT_SPEC, test_data['heavy'], test_data['Y'], \\\n",
    "        start_seq_len = 512, start_batch_size = 32)\n",
    "print('Confusion matrix:')\n",
    "display(confusion_matrix)\n",
    "fn_fp = confusion_matrix.loc[\"0\"][1] + confusion_matrix.loc[\"1\"][0]\n",
    "f1 = confusion_matrix.loc[\"1\"][1] / (confusion_matrix.loc[\"1\"][1] + 0.5 * fn_fp)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b52a48a5-ff77-497f-8b0f-798b8351a213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "2022-03-09 16:11:51.222381: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) input-seq, input-annotations with unsupported characters which will be renamed to input_seq, input_annotations in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../data/protein_bert/2022_03_09__01vh/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../data/protein_bert/2022_03_09__01vh/assets\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "mod = model_generator.create_model(seq_len = 512)\n",
    "mod.save(path.join(DATA_DIR, \"protein_bert/2022_03_09__01vh\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724046a2-1dbb-4e8e-9bb9-db4c5ac1ea16",
   "metadata": {},
   "source": [
    "## Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eee3e97-955b-453e-82a1-942c990aeab4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:22sc7vwt) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21807... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▇▇▇▇▇██▁▁▁▂▂▂▃▃▃▃▃▁</td></tr><tr><td>loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂</td></tr><tr><td>lr</td><td>█████████▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▂▂▂▂▂▃▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.46027</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.4238</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>val_loss</td><td>0.46027</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">skilled-energy-2</strong>: <a href=\"https://wandb.ai/kvetab/Heavy/runs/22sc7vwt\" target=\"_blank\">https://wandb.ai/kvetab/Heavy/runs/22sc7vwt</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220309_160820-22sc7vwt/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:22sc7vwt). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/kvetab/Heavy/runs/20f8kptk\" target=\"_blank\">skilled-eon-3</a></strong> to <a href=\"https://wandb.ai/kvetab/Heavy\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022_03_09-16:15:22] Training set: Filtered out 0 of 1338 (0.0%) records of lengths exceeding 510.\n",
      "[2022_03_09-16:15:22] Validation set: Filtered out 0 of 120 (0.0%) records of lengths exceeding 510.\n",
      "[2022_03_09-16:15:22] Training with frozen pretrained layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 10s 362ms/step - loss: 0.7843 - val_loss: 0.6729\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.5579 - val_loss: 0.4759\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4822 - val_loss: 0.4661\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4736 - val_loss: 0.4734\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4553 - val_loss: 0.4697\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.4520 - val_loss: 0.5260\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4480 - val_loss: 0.4723\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4359 - val_loss: 0.4666\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4284 - val_loss: 0.4767\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "[2022_03_09-16:15:44] Training the entire fine-tuned model...\n",
      "[2022_03_09-16:15:52] Incompatible number of optimizer weights - will not initialize them.\n",
      "Epoch 1/100\n",
      " 6/11 [===============>..............] - ETA: 1s - loss: 0.4500WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1106s vs `on_train_batch_end` time: 0.1469s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1106s vs `on_train_batch_end` time: 0.1469s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 10s 420ms/step - loss: 0.4577 - val_loss: 0.4656\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 3s 252ms/step - loss: 0.4455 - val_loss: 0.4692\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.4408 - val_loss: 0.4635\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.4423 - val_loss: 0.4699\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.4337 - val_loss: 0.4664\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.4370 - val_loss: 0.4632\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.4272 - val_loss: 0.4588\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.4211 - val_loss: 0.4625\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.4200 - val_loss: 0.4683\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.4072 - val_loss: 0.4793\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.3986 - val_loss: 0.4576\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.3975 - val_loss: 0.4664\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.3830 - val_loss: 0.4615\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.3929 - val_loss: 0.4660\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.3819 - val_loss: 0.4662\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.3864 - val_loss: 0.4654\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.3808 - val_loss: 0.4659\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "[2022_03_09-16:16:47] Training on final epochs of sequence length 1024...\n",
      "[2022_03_09-16:16:47] Training set: Filtered out 0 of 1338 (0.0%) records of lengths exceeding 1022.\n",
      "[2022_03_09-16:16:48] Validation set: Filtered out 0 of 120 (0.0%) records of lengths exceeding 1022.\n",
      " 6/21 [=======>......................] - ETA: 3s - loss: 0.4234WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1068s vs `on_train_batch_end` time: 0.1437s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1068s vs `on_train_batch_end` time: 0.1437s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 13s 371ms/step - loss: 0.4138 - val_loss: 0.4591\n"
     ]
    }
   ],
   "source": [
    "model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function = \\\n",
    "        get_model_with_hidden_layers_as_outputs, dropout_rate = 0.5)\n",
    "wandb.init(project=f\"Heavy\", entity=\"kvetab\")\n",
    "\n",
    "finetune(model_generator, input_encoder, OUTPUT_SPEC, train_data['light'], train_data['Y'], valid_data['light'], valid_data['Y'], \\\n",
    "        seq_len = 512, batch_size = batch_size, max_epochs_per_stage = epoch_num, lr = learning_rate, begin_with_frozen_pretrained_layers = True, \\\n",
    "        lr_with_frozen_pretrained_layers = 1e-02, n_final_epochs = 1, final_seq_len = 1024, final_lr = learning_rate / 10, callbacks = training_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9539ac6b-c260-4fde-b0ad-d4b2ee5509f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0  90   6\n",
       "1  12  11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results, confusion_matrix = evaluate_by_len(model_generator, input_encoder, OUTPUT_SPEC, test_data['light'], test_data['Y'], \\\n",
    "        start_seq_len = 512, start_batch_size = 32)\n",
    "print('Confusion matrix:')\n",
    "display(confusion_matrix)\n",
    "fn_fp = confusion_matrix.loc[\"0\"][1] + confusion_matrix.loc[\"1\"][0]\n",
    "f1 = confusion_matrix.loc[\"1\"][1] / (confusion_matrix.loc[\"1\"][1] + 0.5 * fn_fp)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91de65b6-a822-496d-aa63-767ae07b8f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) input-seq, input-annotations with unsupported characters which will be renamed to input_seq, input_annotations in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../data/protein_bert/2022_03_09__01vl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../data/protein_bert/2022_03_09__01vl/assets\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "mod = model_generator.create_model(seq_len = 512)\n",
    "mod.save(path.join(DATA_DIR, \"protein_bert/2022_03_09__01vl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043047bb-36d2-43a5-aead-5df9dfe234e2",
   "metadata": {},
   "source": [
    "# Over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37763f17-5c54-4dc0-90de-10f57cbd1fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomOverSampler(random_state=42)\n",
    "x_train, y_train = sampler.fit_resample(train_data.drop(\"Y\", axis=1), train_data['Y'])\n",
    "x_valid, y_valid = sampler.fit_resample(valid_data.drop(\"Y\", axis=1), valid_data['Y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcfbf81-78b8-435c-a992-471317af5d05",
   "metadata": {},
   "source": [
    "## Heavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccc24e81-7b69-4ad6-8203-15fe343a1ba0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022_03_09-16:30:35] Training set: Filtered out 0 of 2114 (0.0%) records of lengths exceeding 510.\n",
      "[2022_03_09-16:30:35] Validation set: Filtered out 0 of 188 (0.0%) records of lengths exceeding 510.\n",
      "[2022_03_09-16:30:35] Training with frozen pretrained layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 11s 214ms/step - loss: 0.8137 - val_loss: 0.6596\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.6372 - val_loss: 0.6400\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.6199 - val_loss: 0.6450\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.5988 - val_loss: 0.6131\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.5902 - val_loss: 0.6034\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.5769 - val_loss: 0.5946\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.5960 - val_loss: 0.6638\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.5724 - val_loss: 0.6130\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.5856 - val_loss: 0.5858\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.5506 - val_loss: 0.5810\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.5450 - val_loss: 0.6299\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.5431 - val_loss: 0.5697\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.5443 - val_loss: 0.5940\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 2s 118ms/step - loss: 0.5425 - val_loss: 0.5760\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.5462 - val_loss: 0.5766\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.5255 - val_loss: 0.5789\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.5193 - val_loss: 0.5859\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 2s 108ms/step - loss: 0.5275 - val_loss: 0.5871\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "[2022_03_09-16:31:20] Training the entire fine-tuned model...\n",
      "[2022_03_09-16:31:28] Incompatible number of optimizer weights - will not initialize them.\n",
      "Epoch 1/100\n",
      " 6/17 [=========>....................] - ETA: 2s - loss: 0.5354WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1129s vs `on_train_batch_end` time: 0.1462s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1129s vs `on_train_batch_end` time: 0.1462s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 12s 374ms/step - loss: 0.5541 - val_loss: 0.5637\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 4s 259ms/step - loss: 0.5153 - val_loss: 0.5625\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 4s 260ms/step - loss: 0.4911 - val_loss: 0.5674\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 4s 259ms/step - loss: 0.4726 - val_loss: 0.5684\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 4s 260ms/step - loss: 0.4745 - val_loss: 0.5933\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 4s 259ms/step - loss: 0.4592 - val_loss: 0.5824\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 4s 260ms/step - loss: 0.4408 - val_loss: 0.5837\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 4s 259ms/step - loss: 0.4268 - val_loss: 0.5855\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "[2022_03_09-16:32:12] Training on final epochs of sequence length 1024...\n",
      "[2022_03_09-16:32:12] Training set: Filtered out 0 of 2114 (0.0%) records of lengths exceeding 1022.\n",
      "[2022_03_09-16:32:15] Validation set: Filtered out 0 of 188 (0.0%) records of lengths exceeding 1022.\n",
      " 6/34 [====>.........................] - ETA: 6s - loss: 0.5974WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1073s vs `on_train_batch_end` time: 0.1423s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1073s vs `on_train_batch_end` time: 0.1423s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 16s 303ms/step - loss: 0.5444 - val_loss: 0.5631\n"
     ]
    }
   ],
   "source": [
    "model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function = \\\n",
    "        get_model_with_hidden_layers_as_outputs, dropout_rate = 0.5)\n",
    "\n",
    "finetune(model_generator, input_encoder, OUTPUT_SPEC, x_train['heavy'], y_train, x_valid['heavy'], y_valid, \\\n",
    "        seq_len = 512, batch_size = batch_size, max_epochs_per_stage = epoch_num, lr = learning_rate, begin_with_frozen_pretrained_layers = True, \\\n",
    "        lr_with_frozen_pretrained_layers = 1e-02, n_final_epochs = 1, final_seq_len = 1024, final_lr = learning_rate / 10, callbacks = training_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1c8e77c-f0ec-4c4e-97a8-a6f58614082b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0  51  45\n",
       "1   4  19"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.4367816091954023"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results, confusion_matrix = evaluate_by_len(model_generator, input_encoder, OUTPUT_SPEC, test_data['heavy'], test_data['Y'], \\\n",
    "        start_seq_len = 512, start_batch_size = 32)\n",
    "print('Confusion matrix:')\n",
    "display(confusion_matrix)\n",
    "fn_fp = confusion_matrix.loc[\"0\"][1] + confusion_matrix.loc[\"1\"][0]\n",
    "f1 = confusion_matrix.loc[\"1\"][1] / (confusion_matrix.loc[\"1\"][1] + 0.5 * fn_fp)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3928bfb4-c848-42c3-a1c8-90789984561e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) input-seq, input-annotations with unsupported characters which will be renamed to input_seq, input_annotations in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../data/protein_bert/2022_03_09__02vh/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../data/protein_bert/2022_03_09__02vh/assets\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "mod = model_generator.create_model(seq_len = 512)\n",
    "mod.save(path.join(DATA_DIR, \"protein_bert/2022_03_09__02vh\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcffa8d4-3cc9-4d6d-a667-f925b6a6a979",
   "metadata": {},
   "source": [
    "## Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2893e08-6e1a-4d45-b266-3a249ca2bdaa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022_03_09-16:34:47] Training set: Filtered out 0 of 2114 (0.0%) records of lengths exceeding 510.\n",
      "[2022_03_09-16:34:47] Validation set: Filtered out 0 of 188 (0.0%) records of lengths exceeding 510.\n",
      "[2022_03_09-16:34:47] Training with frozen pretrained layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 11s 222ms/step - loss: 0.7591 - val_loss: 0.6775\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.6622 - val_loss: 0.6939\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.6257 - val_loss: 0.6639\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 2s 111ms/step - loss: 0.6027 - val_loss: 0.6778\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.5721 - val_loss: 0.5941\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.5376 - val_loss: 0.5930\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.5442 - val_loss: 0.7018\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 2s 110ms/step - loss: 0.5298 - val_loss: 0.6017\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.5374 - val_loss: 0.5969\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.5099 - val_loss: 0.6105\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.5093 - val_loss: 0.5990\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 2s 109ms/step - loss: 0.4974 - val_loss: 0.6156\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "[2022_03_09-16:35:20] Training the entire fine-tuned model...\n",
      "[2022_03_09-16:35:45] Incompatible number of optimizer weights - will not initialize them.\n",
      "Epoch 1/100\n",
      " 6/17 [=========>....................] - ETA: 2s - loss: 0.5347WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1094s vs `on_train_batch_end` time: 0.1459s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1094s vs `on_train_batch_end` time: 0.1459s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 12s 363ms/step - loss: 0.5326 - val_loss: 0.5909\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 4s 258ms/step - loss: 0.5101 - val_loss: 0.6010\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 4s 260ms/step - loss: 0.5034 - val_loss: 0.6351\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 4s 259ms/step - loss: 0.4795 - val_loss: 0.6904\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 4s 260ms/step - loss: 0.4755 - val_loss: 0.6191\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 4s 259ms/step - loss: 0.4621 - val_loss: 0.6212\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 4s 259ms/step - loss: 0.4607 - val_loss: 0.6447\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "[2022_03_09-16:36:24] Training on final epochs of sequence length 1024...\n",
      "[2022_03_09-16:36:24] Training set: Filtered out 0 of 2114 (0.0%) records of lengths exceeding 1022.\n",
      "[2022_03_09-16:36:32] Validation set: Filtered out 0 of 188 (0.0%) records of lengths exceeding 1022.\n",
      " 6/34 [====>.........................] - ETA: 6s - loss: 0.5352WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1093s vs `on_train_batch_end` time: 0.1386s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1093s vs `on_train_batch_end` time: 0.1386s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 17s 314ms/step - loss: 0.5334 - val_loss: 0.6094\n"
     ]
    }
   ],
   "source": [
    "model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function = \\\n",
    "        get_model_with_hidden_layers_as_outputs, dropout_rate = 0.5)\n",
    "\n",
    "finetune(model_generator, input_encoder, OUTPUT_SPEC, x_train['light'], y_train, x_valid['light'], y_valid, \\\n",
    "        seq_len = 512, batch_size = batch_size, max_epochs_per_stage = epoch_num, lr = learning_rate, begin_with_frozen_pretrained_layers = True, \\\n",
    "        lr_with_frozen_pretrained_layers = 1e-02, n_final_epochs = 1, final_seq_len = 1024, final_lr = learning_rate / 10, callbacks = training_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "219205a3-c2f1-440b-9b8a-ffe4696b5864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0  69  27\n",
       "1   3  20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results, confusion_matrix = evaluate_by_len(model_generator, input_encoder, OUTPUT_SPEC, test_data['light'], test_data['Y'], \\\n",
    "        start_seq_len = 512, start_batch_size = 32)\n",
    "print('Confusion matrix:')\n",
    "display(confusion_matrix)\n",
    "fn_fp = confusion_matrix.loc[\"0\"][1] + confusion_matrix.loc[\"1\"][0]\n",
    "f1 = confusion_matrix.loc[\"1\"][1] / (confusion_matrix.loc[\"1\"][1] + 0.5 * fn_fp)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6de709d-f658-4d3c-8c00-f831be9ab13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) input-seq, input-annotations with unsupported characters which will be renamed to input_seq, input_annotations in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../data/protein_bert/2022_03_09__02vl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../data/protein_bert/2022_03_09__02vl/assets\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "mod = model_generator.create_model(seq_len = 512)\n",
    "mod.save(path.join(DATA_DIR, \"protein_bert/2022_03_09__02vl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c58586-611e-4bf9-93b9-9d16e6795427",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0a51191-ea3a-400b-a217-fd9d680f10eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_vh = path.join(DATA_DIR, \"protein_bert/2022_03_09__02vh\")\n",
    "model_vh = keras.models.load_model(model_path_vh)\n",
    "\n",
    "model_path_vl = path.join(DATA_DIR, \"protein_bert/2022_03_09__02vl\")\n",
    "model_vl = keras.models.load_model(model_path_vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80731a9f-eaf5-4cf0-85dd-d9b45b35e02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022_03_10-10:38:55] Heavy set: Filtered out 0 of 119 (0.0%) records of lengths exceeding 510.\n",
      "[2022_03_10-10:38:55] Light set: Filtered out 0 of 119 (0.0%) records of lengths exceeding 510.\n"
     ]
    }
   ],
   "source": [
    "seq_len = 512\n",
    "encoded_heavy_set = encode_dataset(test_data[\"heavy\"], test_data[\"Y\"], input_encoder, OUTPUT_SPEC, seq_len = seq_len, needs_filtering = True, \\\n",
    "            dataset_name = 'Heavy set')\n",
    "encoded_light_set = encode_dataset(test_data[\"light\"], test_data[\"Y\"], input_encoder, OUTPUT_SPEC, seq_len = seq_len, needs_filtering = True, \\\n",
    "            dataset_name = 'Light set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70b785d8-1c87-4526-8c7b-0af20ca8981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "test_X_h, test_Y_h, test_sample_weigths_h = encoded_heavy_set\n",
    "test_X_l, test_Y_l, test_sample_weigths_l = encoded_light_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b579d7d-e7f7-4c52-8eee-845d88d0def4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.547945205479452"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_h = model_vh.predict(test_X_h, batch_size=32)\n",
    "y_pred_l = model_vl.predict(test_X_l, batch_size=32)\n",
    "\n",
    "y_pred_classes = ((y_pred_h + y_pred_l) >= 1.0)\n",
    "f1_score(test_Y_h, y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39cced45-e1e3-4a1e-b799-445d19780344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92,  4],\n",
       "       [10, 13]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_Y_h, y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c66bc13-1cce-4022-8caa-0ef266130c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022_03_10-10:39:20] TAP set: Filtered out 0 of 241 (0.0%) records of lengths exceeding 510.\n",
      "[2022_03_10-10:39:20] TAP set: Filtered out 0 of 241 (0.0%) records of lengths exceeding 510.\n"
     ]
    }
   ],
   "source": [
    "tap_data = pd.read_csv(path.join(DATA_DIR, \"tap/TAP_data.csv\"))\n",
    "encoded_tap_heavy = encode_dataset(tap_data[\"heavy\"], tap_data[\"Y\"], input_encoder, OUTPUT_SPEC, seq_len = seq_len, needs_filtering = True, \\\n",
    "            dataset_name = 'TAP set')\n",
    "encoded_tap_light = encode_dataset(tap_data[\"light\"], tap_data[\"Y\"], input_encoder, OUTPUT_SPEC, seq_len = seq_len, needs_filtering = True, \\\n",
    "            dataset_name = 'TAP set')\n",
    "tap_X_h, tap_Y_h, tap_sample_weigths = encoded_tap_heavy\n",
    "tap_X_l, tap_Y_l, tap_sample_weigths = encoded_tap_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01ec38cf-a82c-4e28-bac8-4a33c521f8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8020050125313284"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_h = model_vh.predict(tap_X_h, batch_size=32)\n",
    "y_pred_l = model_vl.predict(tap_X_l, batch_size=32)\n",
    "\n",
    "y_pred_classes = ((y_pred_h + y_pred_l) >= 1.0)\n",
    "f1_score(tap_Y_h, y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64c3da86-3f33-47ae-9fc5-ae44cee4d2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6721991701244814"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(tap_Y_h, y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef0cc6-6817-4dcf-9952-43afd186659a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
