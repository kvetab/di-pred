{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aaac5ca7-e11d-4cef-8594-dc61e039f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.fixes import loguniform    \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6f5f3c13-ecb1-4e27-9bce-3d6cabd0db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4e4ae71e-a22d-4cb6-919a-2d8e8cfad1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "84ab88aa-e34d-4222-a5be-fff2db568111",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_DIR = \"2021-12-03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "604e7e5b-1fac-49b4-b2a5-764ed1d46e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...</td>\n",
       "      <td>DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...</td>\n",
       "      <td>DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Antibody_ID                                              heavy  \\\n",
       "2073        6aod  EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...   \n",
       "1517        4yny  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2025        5xcv  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2070        6and  EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...   \n",
       "666         2xqy  QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...   \n",
       "\n",
       "                                                  light  Y  \n",
       "2073  DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...  0  \n",
       "1517  EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2025  QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2070  DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...  1  \n",
       "666   DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...  0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_train = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_train_data.csv\"), index_col=0)\n",
    "chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3df718a2-0595-4139-b12c-7e1046969f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chen_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "afda5620-8cda-4a38-b06e-1a3b0659e0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>Y</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>6ct7</td>\n",
       "      <td>EVQLVESGGGLVEPGGSLRLSCAVSGFDFEKAWMSWVRQAPGQGLQ...</td>\n",
       "      <td>SYELTQPPSVSVSPGQTARITCSGEALPMQFAHWYQQRPGKAPVIV...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>4nzu</td>\n",
       "      <td>AVSLVESGGGTVEPGSTLRLSCAASGFTFGSYAFHWVRQAPGDGLE...</td>\n",
       "      <td>DIEMTQSPSSLSASTGDKVTITCQASQDIAKFLDWYQQRPGKTPKL...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>5i8c</td>\n",
       "      <td>QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...</td>\n",
       "      <td>DIQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNL...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>5i8e</td>\n",
       "      <td>QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...</td>\n",
       "      <td>IQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNLL...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>6bb4</td>\n",
       "      <td>QVQLQQSDAELVKPGASVKISCKASGYTFTDRTIHWVKQRPEQGLE...</td>\n",
       "      <td>DVQMIQSPSSLSASLGDIVTMTCQASQDTSINLNWFQQKPGKAPKL...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Antibody_ID                                              heavy  \\\n",
       "2169        6ct7  EVQLVESGGGLVEPGGSLRLSCAVSGFDFEKAWMSWVRQAPGQGLQ...   \n",
       "1342        4nzu  AVSLVESGGGTVEPGSTLRLSCAASGFTFGSYAFHWVRQAPGDGLE...   \n",
       "1728        5i8c  QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...   \n",
       "1729        5i8e  QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...   \n",
       "2114        6bb4  QVQLQQSDAELVKPGASVKISCKASGYTFTDRTIHWVKQRPEQGLE...   \n",
       "\n",
       "                                                  light  Y  Unnamed: 0  \n",
       "2169  SYELTQPPSVSVSPGQTARITCSGEALPMQFAHWYQQRPGKAPVIV...  0         NaN  \n",
       "1342  DIEMTQSPSSLSASTGDKVTITCQASQDIAKFLDWYQQRPGKTPKL...  0         NaN  \n",
       "1728  DIQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNL...  1         NaN  \n",
       "1729  IQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNLL...  0         NaN  \n",
       "2114  DVQMIQSPSSLSASLGDIVTMTCQASQDTSINLNWFQQKPGKAPKL...  0         NaN  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_valid = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_valid_data.csv\"), index_col=0)\n",
    "chen_test = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_test_data.csv\"))\n",
    "chen_valid = pd.concat([chen_valid, chen_test])\n",
    "chen_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3c0d59c6-5efa-4208-b4e6-4ea37490ce71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chen_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "083e69c0-1ebf-41c8-a4d3-782f364696d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>CDR_length</th>\n",
       "      <th>PSH</th>\n",
       "      <th>PPC</th>\n",
       "      <th>PNC</th>\n",
       "      <th>SFvCSP</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abagovomab</td>\n",
       "      <td>QVKLQESGAELARPGASVKLSCKASGYTFTNYWMQWVKQRPGQGLD...</td>\n",
       "      <td>DIELTQSPASLSASVGETVTITCQASENIYSYLAWHQQKQGKSPQL...</td>\n",
       "      <td>46</td>\n",
       "      <td>129.7603</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abituzumab</td>\n",
       "      <td>QVQLQQSGGELAKPGASVKVSCKASGYTFSSFWMHWVRQAPGQGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQDISNYLAWYQQKPGKAPKL...</td>\n",
       "      <td>45</td>\n",
       "      <td>115.9106</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>-3.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrilumab</td>\n",
       "      <td>QVQLVQSGAEVKKPGASVKVSCKVSGYTLSDLSIHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQQKPGKAPKL...</td>\n",
       "      <td>45</td>\n",
       "      <td>109.6995</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actoxumab</td>\n",
       "      <td>QVQLVESGGGVVQPGRSLRLSCAASGFSFSNYGMHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQHKPGKAPKL...</td>\n",
       "      <td>49</td>\n",
       "      <td>112.6290</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.1247</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adalimumab</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLRLSCAASGFTFDDYAMHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQGIRNYLAWYQQKPGKAPKL...</td>\n",
       "      <td>48</td>\n",
       "      <td>111.2512</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>1.1364</td>\n",
       "      <td>-19.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Antibody_ID                                              heavy  \\\n",
       "0  Abagovomab  QVKLQESGAELARPGASVKLSCKASGYTFTNYWMQWVKQRPGQGLD...   \n",
       "1  Abituzumab  QVQLQQSGGELAKPGASVKVSCKASGYTFSSFWMHWVRQAPGQGLE...   \n",
       "2   Abrilumab  QVQLVQSGAEVKKPGASVKVSCKVSGYTLSDLSIHWVRQAPGKGLE...   \n",
       "3   Actoxumab  QVQLVESGGGVVQPGRSLRLSCAASGFSFSNYGMHWVRQAPGKGLE...   \n",
       "4  Adalimumab  EVQLVESGGGLVQPGRSLRLSCAASGFTFDDYAMHWVRQAPGKGLE...   \n",
       "\n",
       "                                               light  CDR_length       PSH  \\\n",
       "0  DIELTQSPASLSASVGETVTITCQASENIYSYLAWHQQKQGKSPQL...          46  129.7603   \n",
       "1  DIQMTQSPSSLSASVGDRVTITCRASQDISNYLAWYQQKPGKAPKL...          45  115.9106   \n",
       "2  DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQQKPGKAPKL...          45  109.6995   \n",
       "3  DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQHKPGKAPKL...          49  112.6290   \n",
       "4  DIQMTQSPSSLSASVGDRVTITCRASQGIRNYLAWYQQKPGKAPKL...          48  111.2512   \n",
       "\n",
       "      PPC     PNC  SFvCSP  Y  \n",
       "0  0.0000  0.0000   16.32  1  \n",
       "1  0.0954  0.0421   -3.10  1  \n",
       "2  0.0000  0.8965   -4.00  1  \n",
       "3  0.0000  1.1247    3.10  1  \n",
       "4  0.0485  1.1364  -19.50  1  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tap_data = pd.read_csv(path.join(DATA_DIR, \"tap/TAP_data.csv\"))\n",
    "tap_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f9084d-b8ee-4254-bd3d-02ada5719d81",
   "metadata": {},
   "source": [
    "## Data clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1b99f8dd-2185-47a5-8efd-c96b8026d40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    276\n",
       "3    189\n",
       "7    147\n",
       "5    137\n",
       "1    132\n",
       "4    129\n",
       "6    120\n",
       "8    106\n",
       "9     59\n",
       "2     43\n",
       "Name: cluster_merged, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_train = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_train_data_w_clusters.csv\"), index_col=0)\n",
    "chen_train[\"cluster_merged\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de8365-c6c4-4b79-837e-e6211b19382f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "abcd2b91-90cc-44cb-bd99-6d7f5ddada56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(n):\n",
    "    lr = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "    parameters = {'C':loguniform(0.001, 1000), 'penalty': [\"l2\"], \"solver\": [\"lbfgs\", \"sag\"]}\n",
    "    return lr, parameters, \"logistic_regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8a4026c4-0b4f-4c6e-b1f1-4f72640506d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(n):\n",
    "    rf = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "    parameters = {'n_estimators': np.arange(1, 200, 10), 'max_depth': np.arange(1, min(50,n), 2), \n",
    "                  'max_features': np.arange(0.1, 0.75, 0.05)}\n",
    "    return rf, parameters, \"random_forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ee462921-baee-4031-81ab-70a55154c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(n):\n",
    "    mlp = MLPClassifier(random_state=42, max_iter=int(1000))\n",
    "    parameters = {'hidden_layer_sizes': [(100,), (50,), (100, 100)], \"activation\": [\"relu\", \"logistic\"]}\n",
    "    return mlp, parameters, \"multilayer_perceptron\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "de36f9d6-9b40-4420-b4eb-27f540feb1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(n):\n",
    "    svc = SVC(max_iter=8000, probability=True, class_weight='balanced')\n",
    "    parameters = {'C': loguniform(0.001, 100), 'kernel':[\"linear\", \"rbf\"], 'gamma': loguniform(1e-3, 1e0)}\n",
    "    return svc, parameters, \"SVM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "11c6c12c-77ad-4b1c-96a0-b0190535f978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting(n):\n",
    "    gb = GradientBoostingClassifier(random_state=42, n_iter_no_change=70)\n",
    "    parameters = {'learning_rate': loguniform(0.01, 0.5), \n",
    "                  'n_estimators': np.arange(1, 200, 10), \n",
    "                  'max_depth': np.arange(1, min(20,n), 2), \n",
    "                  'max_features': np.arange(0.1, 0.6, 0.1)}\n",
    "    return gb, parameters, \"gradient_boosting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522bdca9-8b15-41b5-ba27-4043bae9924a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6f49eab4-1c92-401f-8aca-ef05d4e52ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_evaluation(model_type, params, best_params, metrics, data, outpath, preprocessing=None, table=\"all\"):\n",
    "    prepro = \"_\"+preprocessing if preprocessing is not None else \"\"\n",
    "    filename = os.path.join(DATA_DIR, \"evaluations\", outpath, f\"{model_type}_{data}{prepro}.json\")\n",
    "    out_dict = {\n",
    "        \"model_type\": model_type,\n",
    "        \"data\": data\n",
    "    }\n",
    "    out_dict[\"params\"] = {}\n",
    "    out_dict[\"best_params\"] = {}\n",
    "    for key, value in params.items():\n",
    "        out_dict[\"params\"][key] = str(value)\n",
    "    for key, value in best_params.items():\n",
    "        out_dict[\"best_params\"][key] = str(value)\n",
    "    out_dict[\"metrics\"] = metrics\n",
    "    out_dict[\"preprocessing\"] = \"none\" if preprocessing is None else preprocessing\n",
    "    \n",
    "    json.dump(out_dict, open(filename, \"w\"))\n",
    "    \n",
    "    filename_sum = os.path.join(DATA_DIR, f\"evaluations/{outpath}/{table}.csv\")\n",
    "    #\"../evaluations/all.csv\"\n",
    "    line = [model_type, data, out_dict[\"preprocessing\"], metrics[\"f1\"], metrics[\"mcc\"], metrics[\"acc\"],metrics[\"precision\"],metrics[\"recall\"],metrics[\"auc\"], filename]\n",
    "    with open(filename_sum, 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter='\\t')\n",
    "        csvwriter.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "96bd4c58-b7dd-49f2-bf3d-39b3938f6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(model_name, classifier, parameters, X_train, y_train, X_valid, y_valid, groups,\n",
    "                   data_name, outpath, preprocessing=None):\n",
    "    splitter = LeaveOneGroupOut()\n",
    "    split = splitter.split(X_train, y_train, groups=groups)\n",
    "    grid = RandomizedSearchCV(classifier, parameters, verbose=1, scoring=\"f1\", cv=split)\n",
    "    grid.fit(X_train, y_train)\n",
    "    estimator = grid.best_estimator_\n",
    "    best_params = grid.best_params_\n",
    "    y_pred = estimator.predict(X_valid)\n",
    "    prepro = \"_\"+preprocessing if preprocessing is not None else \"\"\n",
    "    filename = path.join(DATA_DIR, \"evaluations\", outpath, \"models\", f\"{model_name}_{data_name}{prepro}.pkl\")\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(estimator, f)\n",
    "    #pickle.dump(estimator, open(filename, \"w\"))\n",
    "    metric_dict = {\n",
    "        \"f1\": float(metrics.f1_score(y_valid, y_pred)),\n",
    "        \"acc\": float(metrics.accuracy_score(y_valid, y_pred)),\n",
    "        \"mcc\": float(metrics.matthews_corrcoef(y_valid, y_pred)),\n",
    "        \"auc\": float(metrics.roc_auc_score(y_valid, y_pred)),\n",
    "        \"precision\": float(metrics.precision_score(y_valid, y_pred)),\n",
    "        \"recall\": float(metrics.recall_score(y_valid, y_pred))\n",
    "    }\n",
    "    \n",
    "    print(f\"{model_name}, {data_name}\")\n",
    "    print(f\"F1: {metric_dict['f1']}\")\n",
    "    print(f\"MCC: {metric_dict['mcc']}\")\n",
    "    print(f\"Accuracy: {metric_dict['acc']}\")\n",
    "    print(f\"Precision: {metric_dict['precision']}\")\n",
    "    print(f\"Recall: {metric_dict['recall']}\")\n",
    "    print(f\"AUC: {metric_dict['auc']}\")\n",
    "    print(f\"-----\")\n",
    "    \n",
    "    output_evaluation(model_name, parameters, best_params, metric_dict, data_name, outpath, preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e30d50ba-ac70-40e7-9664-72a812e09efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all(X_train, y_train, X_valid, y_valid, groups, data_name, outpath, preprocessing=None):\n",
    "    n = len(y_train)\n",
    "    for model_creator in [logistic_regression, random_forest, gradient_boosting, svm, multilayer_perceptron]:\n",
    "        classifier, params, model_label = model_creator(n)\n",
    "        print(\"\\n\")\n",
    "        print(f'Training model {model_label} on data {data_name} \\n')\n",
    "        train_and_eval(model_label, classifier, params, X_train, y_train, X_valid, y_valid, groups,\n",
    "                   data_name, outpath, preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7d4f9391-7024-44ed-894b-94977569f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_tap(model_name, x_test, y_test,\n",
    "                   data_name, outpath, preprocessing=None):\n",
    "    prepro = \"_\"+preprocessing if preprocessing is not None else \"\"\n",
    "    filename = path.join(DATA_DIR, \"evaluations\", outpath, \"models\", f\"{model_name}_{data_name}{prepro}.pkl\")\n",
    "    with open(filename, 'rb') as f:\n",
    "        estimator = pickle.load(f)\n",
    "    y_pred = estimator.predict(x_test)\n",
    "    metric_dict = {\n",
    "        \"f1\": float(metrics.f1_score(y_test, y_pred)),\n",
    "        \"acc\": float(metrics.accuracy_score(y_test, y_pred)),\n",
    "        \"mcc\": float(metrics.matthews_corrcoef(y_test, y_pred)),\n",
    "        \"auc\": float(metrics.roc_auc_score(y_test, y_pred)),\n",
    "        \"precision\": float(metrics.precision_score(y_test, y_pred)),\n",
    "        \"recall\": float(metrics.recall_score(y_test, y_pred))\n",
    "    }\n",
    "    filename_sum = os.path.join(DATA_DIR, f\"evaluations/{outpath}/tap.csv\")\n",
    "    line = [model_name, data_name, prepro, metric_dict[\"f1\"], metric_dict[\"mcc\"], metric_dict[\"acc\"],metric_dict[\"precision\"],metric_dict[\"recall\"],metric_dict[\"auc\"], filename]\n",
    "    with open(filename_sum, 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter='\\t')\n",
    "        csvwriter.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f6513aa7-f94c-4eb9-820d-510782accecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all(x_test, y_test, data_name, outpath, preprocessing=None):\n",
    "    for model in [\"logistic_regression\", \"random_forest\", \"gradient_boosting\", \"SVM\", \"multilayer_perceptron\"]:\n",
    "        print(f\"Testing model {model} on {data_name}...\")\n",
    "        test_on_tap(model, x_test, y_test, data_name, outpath, preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a14fdc-99e4-4748-822d-88fddfb49f52",
   "metadata": {},
   "source": [
    "# PyBioMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "544a4e36-4667-41e9-9602-f418aa27a636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>19750</th>\n",
       "      <th>19751</th>\n",
       "      <th>19752</th>\n",
       "      <th>19753</th>\n",
       "      <th>19754</th>\n",
       "      <th>19755</th>\n",
       "      <th>19756</th>\n",
       "      <th>19757</th>\n",
       "      <th>19758</th>\n",
       "      <th>19759</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>7.692</td>\n",
       "      <td>5.983</td>\n",
       "      <td>0.855</td>\n",
       "      <td>5.983</td>\n",
       "      <td>1.709</td>\n",
       "      <td>4.274</td>\n",
       "      <td>5.983</td>\n",
       "      <td>10.256</td>\n",
       "      <td>0.855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>6.838</td>\n",
       "      <td>5.128</td>\n",
       "      <td>1.709</td>\n",
       "      <td>5.128</td>\n",
       "      <td>1.709</td>\n",
       "      <td>3.419</td>\n",
       "      <td>4.274</td>\n",
       "      <td>11.111</td>\n",
       "      <td>0.855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>6.838</td>\n",
       "      <td>5.128</td>\n",
       "      <td>1.709</td>\n",
       "      <td>5.128</td>\n",
       "      <td>2.564</td>\n",
       "      <td>3.419</td>\n",
       "      <td>4.274</td>\n",
       "      <td>11.111</td>\n",
       "      <td>0.855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>6.667</td>\n",
       "      <td>5.833</td>\n",
       "      <td>2.500</td>\n",
       "      <td>5.833</td>\n",
       "      <td>1.667</td>\n",
       "      <td>4.167</td>\n",
       "      <td>5.000</td>\n",
       "      <td>13.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>3.390</td>\n",
       "      <td>3.390</td>\n",
       "      <td>2.542</td>\n",
       "      <td>5.932</td>\n",
       "      <td>1.695</td>\n",
       "      <td>3.390</td>\n",
       "      <td>6.780</td>\n",
       "      <td>9.322</td>\n",
       "      <td>0.847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19761 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ab_ID      0      1      2      3      4      5      6       7      8  \\\n",
       "2073  6aod  7.692  5.983  0.855  5.983  1.709  4.274  5.983  10.256  0.855   \n",
       "1517  4yny  6.838  5.128  1.709  5.128  1.709  3.419  4.274  11.111  0.855   \n",
       "2025  5xcv  6.838  5.128  1.709  5.128  2.564  3.419  4.274  11.111  0.855   \n",
       "2070  6and  6.667  5.833  2.500  5.833  1.667  4.167  5.000  13.333  0.000   \n",
       "666   2xqy  3.390  3.390  2.542  5.932  1.695  3.390  6.780   9.322  0.847   \n",
       "\n",
       "      ...  19750  19751  19752  19753  19754  19755  19756  19757  19758  \\\n",
       "2073  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1517  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2025  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2070  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "666   ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "      19759  \n",
       "2073    0.0  \n",
       "1517    0.0  \n",
       "2025    0.0  \n",
       "2070    0.0  \n",
       "666     0.0  \n",
       "\n",
       "[5 rows x 19761 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chen = pd.read_feather(path.join(DATA_DIR, \"chen/pybiomed/X_data.ftr\"))\n",
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_valid = x_chen.merge(chen_valid[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5978fc36-3459-4048-99f1-998d42783c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 1057, 1: 281})\n"
     ]
    }
   ],
   "source": [
    "print('Original dataset shape %s' % Counter(chen_train[\"Y\"])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d85f8765-ebcc-4cc9-8738-5caa197679d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 1057, 1: 1057})\n"
     ]
    }
   ],
   "source": [
    "sampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "x_chen_train, y_chen_train = sampler.fit_resample(x_chen_train.drop(\"Y\", axis=1), x_chen_train[\"Y\"]) \n",
    "print('Resampled dataset shape %s' % Counter(y_chen_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f4a96-fb3a-4daf-bb81-92817b5e393e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data pybiomed \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train.drop([\"Ab_ID\", \"cluster_merged\"], axis=1), y_chen_train, \n",
    "        x_chen_valid.drop([\"Ab_ID\", \"Y\"], axis=1), x_chen_valid[\"Y\"], \n",
    "        x_chen_train[\"cluster_merged\"], \"pybiomed\", EVAL_DIR, preprocessing=\"over-sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "70f1926e-51a4-4f47-b9e2-ca3759a51d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19750</th>\n",
       "      <th>19751</th>\n",
       "      <th>19752</th>\n",
       "      <th>19753</th>\n",
       "      <th>19754</th>\n",
       "      <th>19755</th>\n",
       "      <th>19756</th>\n",
       "      <th>19757</th>\n",
       "      <th>19758</th>\n",
       "      <th>19759</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.084</td>\n",
       "      <td>3.361</td>\n",
       "      <td>2.521</td>\n",
       "      <td>3.361</td>\n",
       "      <td>1.681</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.882</td>\n",
       "      <td>11.765</td>\n",
       "      <td>0.840</td>\n",
       "      <td>1.681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.627</td>\n",
       "      <td>4.237</td>\n",
       "      <td>1.695</td>\n",
       "      <td>3.390</td>\n",
       "      <td>1.695</td>\n",
       "      <td>5.085</td>\n",
       "      <td>5.932</td>\n",
       "      <td>10.169</td>\n",
       "      <td>0.847</td>\n",
       "      <td>2.542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.932</td>\n",
       "      <td>1.695</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.932</td>\n",
       "      <td>1.695</td>\n",
       "      <td>5.085</td>\n",
       "      <td>6.780</td>\n",
       "      <td>10.169</td>\n",
       "      <td>0.847</td>\n",
       "      <td>1.695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.738</td>\n",
       "      <td>6.557</td>\n",
       "      <td>4.098</td>\n",
       "      <td>5.738</td>\n",
       "      <td>1.639</td>\n",
       "      <td>3.279</td>\n",
       "      <td>4.918</td>\n",
       "      <td>11.475</td>\n",
       "      <td>0.820</td>\n",
       "      <td>3.279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.091</td>\n",
       "      <td>4.959</td>\n",
       "      <td>3.306</td>\n",
       "      <td>5.785</td>\n",
       "      <td>1.653</td>\n",
       "      <td>4.132</td>\n",
       "      <td>4.132</td>\n",
       "      <td>9.091</td>\n",
       "      <td>1.653</td>\n",
       "      <td>2.479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19760 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5      6       7      8      9  \\\n",
       "0  10.084  3.361  2.521  3.361  1.681  3.361  5.882  11.765  0.840  1.681   \n",
       "1   7.627  4.237  1.695  3.390  1.695  5.085  5.932  10.169  0.847  2.542   \n",
       "2   5.932  1.695  0.000  5.932  1.695  5.085  6.780  10.169  0.847  1.695   \n",
       "3   5.738  6.557  4.098  5.738  1.639  3.279  4.918  11.475  0.820  3.279   \n",
       "4   9.091  4.959  3.306  5.785  1.653  4.132  4.132   9.091  1.653  2.479   \n",
       "\n",
       "   ...  19750  19751  19752  19753  19754  19755  19756  19757  19758  19759  \n",
       "0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 19760 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tap = pd.read_feather(path.join(DATA_DIR, \"tap/pybiomed/X_TAP_data.ftr\"))\n",
    "x_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f655a5d7-44b3-4668-9212-14274181202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all(x_tap, tap_data[\"Y\"], \"pybiomed\", EVAL_DIR, preprocessing=\"over-sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dad6f8-29bd-4423-975c-04719ef58538",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c88b13-a053-42e8-864c-c88338da101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SMOTE(random_state=42)\n",
    "\n",
    "x_chen_train, y_chen_train = sampler.fit_resample(x_chen_train.drop([\"Ab_ID\", \"name\", \"Y\"], axis=1), x_chen_train[\"Y\"]) \n",
    "print('Resampled dataset shape %s' % Counter(y_chen_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce08c1-4932-4804-ae34-7e94e6e1539e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "try_all(x_chen_train.drop([\"cluster_merged\"], axis=1), y_chen_train, \n",
    "        x_chen_valid.drop([\"Ab_ID\", \"Y\"], axis=1), x_chen_valid[\"Y\"], \n",
    "        x_chen_train[\"cluster_merged\"], \"pybiomed\", EVAL_DIR, preprocessing=\"smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684a6c85-9eeb-4c6c-bef6-f8b96eea3a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all(x_tap, tap_data[\"Y\"], \"pybiomed\", EVAL_DIR, preprocessing=\"smote\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77646694-01c8-4a7f-af38-15c2afc8f59a",
   "metadata": {},
   "source": [
    "# Protparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42310c2b-2bbf-4f1a-8507-174b3bf6173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_chen = pd.read_csv(path.join(DATA_DIR, \"chen/protparam/protparam_features.csv\"))\n",
    "x_chen.rename({\"Unnamed: 0\": \"Ab_ID\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d71d7b91-6673-41ff-b57f-05fc13742812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>aa_percent0_x</th>\n",
       "      <th>aa_percent1_x</th>\n",
       "      <th>aa_percent2_x</th>\n",
       "      <th>aa_percent3_x</th>\n",
       "      <th>aa_percent4_x</th>\n",
       "      <th>aa_percent5_x</th>\n",
       "      <th>aa_percent6_x</th>\n",
       "      <th>aa_percent7_x</th>\n",
       "      <th>aa_percent8_x</th>\n",
       "      <th>...</th>\n",
       "      <th>mol_extinct1_y</th>\n",
       "      <th>mol_extinct2_y</th>\n",
       "      <th>mw_y</th>\n",
       "      <th>gravy_y</th>\n",
       "      <th>ss_faction1_y</th>\n",
       "      <th>ss_faction2_y</th>\n",
       "      <th>ss_faction3_y</th>\n",
       "      <th>name</th>\n",
       "      <th>Y</th>\n",
       "      <th>cluster_merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3okd</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.106557</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>...</td>\n",
       "      <td>19940</td>\n",
       "      <td>20065</td>\n",
       "      <td>12297.7329</td>\n",
       "      <td>-0.427679</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.294643</td>\n",
       "      <td>0.205357</td>\n",
       "      <td>3okd</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5fb8</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.041322</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>0.033058</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>...</td>\n",
       "      <td>15930</td>\n",
       "      <td>16055</td>\n",
       "      <td>12046.3419</td>\n",
       "      <td>-0.344144</td>\n",
       "      <td>0.279279</td>\n",
       "      <td>0.306306</td>\n",
       "      <td>0.225225</td>\n",
       "      <td>5fb8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4olz</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>...</td>\n",
       "      <td>21430</td>\n",
       "      <td>21555</td>\n",
       "      <td>11093.1436</td>\n",
       "      <td>-0.370297</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.158416</td>\n",
       "      <td>4olz</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5i19</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.134454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>...</td>\n",
       "      <td>14440</td>\n",
       "      <td>14565</td>\n",
       "      <td>11531.7166</td>\n",
       "      <td>-0.316822</td>\n",
       "      <td>0.271028</td>\n",
       "      <td>0.327103</td>\n",
       "      <td>0.158879</td>\n",
       "      <td>5i19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2xqb</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>...</td>\n",
       "      <td>26930</td>\n",
       "      <td>27055</td>\n",
       "      <td>11672.8413</td>\n",
       "      <td>-0.599057</td>\n",
       "      <td>0.273585</td>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.179245</td>\n",
       "      <td>2xqb</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ab_ID  aa_percent0_x  aa_percent1_x  aa_percent2_x  aa_percent3_x  \\\n",
       "0  3okd       0.081967       0.016393       0.040984       0.049180   \n",
       "1  5fb8       0.049587       0.016529       0.049587       0.041322   \n",
       "2  4olz       0.056000       0.032000       0.048000       0.040000   \n",
       "3  5i19       0.075630       0.016807       0.042017       0.042017   \n",
       "4  2xqb       0.096000       0.016000       0.048000       0.024000   \n",
       "\n",
       "   aa_percent4_x  aa_percent5_x  aa_percent6_x  aa_percent7_x  aa_percent8_x  \\\n",
       "0       0.040984       0.106557       0.008197       0.016393       0.040984   \n",
       "1       0.024793       0.074380       0.016529       0.033058       0.074380   \n",
       "2       0.032000       0.088000       0.008000       0.032000       0.040000   \n",
       "3       0.033613       0.134454       0.000000       0.025210       0.033613   \n",
       "4       0.040000       0.080000       0.000000       0.016000       0.048000   \n",
       "\n",
       "   ...  mol_extinct1_y  mol_extinct2_y        mw_y   gravy_y  ss_faction1_y  \\\n",
       "0  ...           19940           20065  12297.7329 -0.427679       0.276786   \n",
       "1  ...           15930           16055  12046.3419 -0.344144       0.279279   \n",
       "2  ...           21430           21555  11093.1436 -0.370297       0.306931   \n",
       "3  ...           14440           14565  11531.7166 -0.316822       0.271028   \n",
       "4  ...           26930           27055  11672.8413 -0.599057       0.273585   \n",
       "\n",
       "   ss_faction2_y  ss_faction3_y  name  Y  cluster_merged  \n",
       "0       0.294643       0.205357  3okd  1               1  \n",
       "1       0.306306       0.225225  5fb8  1               0  \n",
       "2       0.316832       0.158416  4olz  0               1  \n",
       "3       0.327103       0.158879  5i19  1               0  \n",
       "4       0.330189       0.179245  2xqb  0               7  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_valid = x_chen.merge(chen_valid[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4e31a9f-f557-48c5-9600-d3b42ba258a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 1057, 0: 1057})\n"
     ]
    }
   ],
   "source": [
    "sampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "x_chen_train, y_chen_train = sampler.fit_resample(x_chen_train.drop(\"Y\", axis=1), x_chen_train[\"Y\"]) \n",
    "print('Resampled dataset shape %s' % Counter(y_chen_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e410269-91b8-42dd-913c-0bfad522c35d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data protparam \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/pbs.31824.lich-compute.vscht.cz/ipykernel_46599/3977992157.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m try_all(x_chen_train.drop([\"Ab_ID\", \"name\", \"cluster_merged\"], axis=1), y_chen_train, \n\u001b[1;32m      2\u001b[0m         \u001b[0mx_chen_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Ab_ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_chen_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         x_chen_train[\"cluster_merged\"], \"protparam\", EVAL_DIR, preprocessing=\"over-sampling\")\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.31824.lich-compute.vscht.cz/ipykernel_46599/2726944695.py\u001b[0m in \u001b[0;36mtry_all\u001b[0;34m(X_train, y_train, X_valid, y_valid, groups, data_name, outpath, preprocessing)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training model {model_label} on data {data_name} \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         train_and_eval(model_label, classifier, params, X_train, y_train, X_valid, y_valid, groups,\n\u001b[0;32m----> 8\u001b[0;31m                    data_name, outpath, preprocessing=preprocessing)\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.31824.lich-compute.vscht.cz/ipykernel_46599/133815900.py\u001b[0m in \u001b[0;36mtrain_and_eval\u001b[0;34m(model_name, classifier, parameters, X_train, y_train, X_valid, y_valid, groups, data_name, outpath, preprocessing)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m         evaluate_candidates(\n\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m-> 1768\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m             )\n\u001b[1;32m   1770\u001b[0m         )\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1612\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             )\n\u001b[0;32m-> 1614\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m         )\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    876\u001b[0m                 \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m                 \u001b[0mwarm_start_sag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m                 \u001b[0mis_saga\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"saga\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m             )\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mintercept_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mis_saga\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     )\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train.drop([\"Ab_ID\", \"name\", \"cluster_merged\"], axis=1), y_chen_train, \n",
    "        x_chen_valid.drop([\"Ab_ID\", \"name\", \"Y\"], axis=1), x_chen_valid[\"Y\"], \n",
    "        x_chen_train[\"cluster_merged\"], \"protparam\", EVAL_DIR, preprocessing=\"over-sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0902a2a-461d-4ab5-a1c9-dbf10a713781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>aa_percent0_x</th>\n",
       "      <th>aa_percent1_x</th>\n",
       "      <th>aa_percent2_x</th>\n",
       "      <th>aa_percent3_x</th>\n",
       "      <th>aa_percent4_x</th>\n",
       "      <th>aa_percent5_x</th>\n",
       "      <th>aa_percent6_x</th>\n",
       "      <th>aa_percent7_x</th>\n",
       "      <th>aa_percent8_x</th>\n",
       "      <th>...</th>\n",
       "      <th>instability_y</th>\n",
       "      <th>flexibility_y</th>\n",
       "      <th>isoelectric_y</th>\n",
       "      <th>mol_extinct1_y</th>\n",
       "      <th>mol_extinct2_y</th>\n",
       "      <th>mw_y</th>\n",
       "      <th>gravy_y</th>\n",
       "      <th>ss_faction1_y</th>\n",
       "      <th>ss_faction2_y</th>\n",
       "      <th>ss_faction3_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abagovomab</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>...</td>\n",
       "      <td>53.693458</td>\n",
       "      <td>0.999564</td>\n",
       "      <td>7.973724</td>\n",
       "      <td>14440</td>\n",
       "      <td>14565</td>\n",
       "      <td>11556.8384</td>\n",
       "      <td>-0.257009</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>0.196262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abituzumab</td>\n",
       "      <td>0.076271</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>...</td>\n",
       "      <td>42.514019</td>\n",
       "      <td>1.001379</td>\n",
       "      <td>8.586625</td>\n",
       "      <td>17420</td>\n",
       "      <td>17545</td>\n",
       "      <td>11762.9686</td>\n",
       "      <td>-0.452336</td>\n",
       "      <td>0.280374</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>0.121495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrilumab</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>...</td>\n",
       "      <td>40.151402</td>\n",
       "      <td>1.002818</td>\n",
       "      <td>7.970307</td>\n",
       "      <td>22460</td>\n",
       "      <td>22585</td>\n",
       "      <td>11548.7104</td>\n",
       "      <td>-0.335514</td>\n",
       "      <td>0.271028</td>\n",
       "      <td>0.336449</td>\n",
       "      <td>0.158879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actoxumab</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.024590</td>\n",
       "      <td>...</td>\n",
       "      <td>51.517757</td>\n",
       "      <td>1.000328</td>\n",
       "      <td>8.682102</td>\n",
       "      <td>22460</td>\n",
       "      <td>22585</td>\n",
       "      <td>11530.7383</td>\n",
       "      <td>-0.260748</td>\n",
       "      <td>0.271028</td>\n",
       "      <td>0.317757</td>\n",
       "      <td>0.158879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adalimumab</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>0.057851</td>\n",
       "      <td>0.041322</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>...</td>\n",
       "      <td>46.585047</td>\n",
       "      <td>1.000522</td>\n",
       "      <td>9.428646</td>\n",
       "      <td>15930</td>\n",
       "      <td>16055</td>\n",
       "      <td>11664.9632</td>\n",
       "      <td>-0.402804</td>\n",
       "      <td>0.271028</td>\n",
       "      <td>0.289720</td>\n",
       "      <td>0.168224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ab_ID  aa_percent0_x  aa_percent1_x  aa_percent2_x  aa_percent3_x  \\\n",
       "0  Abagovomab       0.100840       0.016807       0.033613       0.033613   \n",
       "1  Abituzumab       0.076271       0.016949       0.033898       0.050847   \n",
       "2   Abrilumab       0.059322       0.016949       0.059322       0.050847   \n",
       "3   Actoxumab       0.057377       0.016393       0.057377       0.032787   \n",
       "4  Adalimumab       0.090909       0.016529       0.057851       0.041322   \n",
       "\n",
       "   aa_percent4_x  aa_percent5_x  aa_percent6_x  aa_percent7_x  aa_percent8_x  \\\n",
       "0       0.025210       0.117647       0.008403       0.016807       0.067227   \n",
       "1       0.033898       0.101695       0.008475       0.025424       0.033898   \n",
       "2       0.025424       0.101695       0.008475       0.016949       0.059322   \n",
       "3       0.032787       0.114754       0.008197       0.032787       0.024590   \n",
       "4       0.024793       0.090909       0.016529       0.024793       0.024793   \n",
       "\n",
       "   ...  instability_y  flexibility_y  isoelectric_y  mol_extinct1_y  \\\n",
       "0  ...      53.693458       0.999564       7.973724           14440   \n",
       "1  ...      42.514019       1.001379       8.586625           17420   \n",
       "2  ...      40.151402       1.002818       7.970307           22460   \n",
       "3  ...      51.517757       1.000328       8.682102           22460   \n",
       "4  ...      46.585047       1.000522       9.428646           15930   \n",
       "\n",
       "   mol_extinct2_y        mw_y   gravy_y  ss_faction1_y  ss_faction2_y  \\\n",
       "0           14565  11556.8384 -0.257009       0.299065       0.299065   \n",
       "1           17545  11762.9686 -0.452336       0.280374       0.299065   \n",
       "2           22585  11548.7104 -0.335514       0.271028       0.336449   \n",
       "3           22585  11530.7383 -0.260748       0.271028       0.317757   \n",
       "4           16055  11664.9632 -0.402804       0.271028       0.289720   \n",
       "\n",
       "   ss_faction3_y  \n",
       "0       0.196262  \n",
       "1       0.121495  \n",
       "2       0.158879  \n",
       "3       0.158879  \n",
       "4       0.168224  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tap = pd.read_csv(path.join(DATA_DIR, \"tap/protparam/protparam_features_tap.csv\"))\n",
    "x_tap.rename({\"Unnamed: 0\": \"Ab_ID\"}, axis=1, inplace=True)\n",
    "x_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e92f207-70c2-4db4-ae35-33644248d8a4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on protparam...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/evaluations/2021-12-03/models/logistic_regression_protparam_over-sampling.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/pbs.31824.lich-compute.vscht.cz/ipykernel_46599/843675489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ab_ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtap_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"protparam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVAL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"over-sampling\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.31824.lich-compute.vscht.cz/ipykernel_46599/202172768.py\u001b[0m in \u001b[0;36mtest_all\u001b[0;34m(x_test, y_test, data_name, outpath, preprocessing)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"logistic_regression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"random_forest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gradient_boosting\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SVM\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilayer_perceptron\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Testing model {model} on {data_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtest_on_tap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.31824.lich-compute.vscht.cz/ipykernel_46599/2610498457.py\u001b[0m in \u001b[0;36mtest_on_tap\u001b[0;34m(model_name, x_test, y_test, data_name, outpath, preprocessing)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprepro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreprocessing\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"evaluations\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"models\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{model_name}_{data_name}{prepro}.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/evaluations/2021-12-03/models/logistic_regression_protparam_over-sampling.pkl'"
     ]
    }
   ],
   "source": [
    "test_all(x_tap.drop(\"Ab_ID\", axis=1), tap_data[\"Y\"], \"protparam\", EVAL_DIR, preprocessing=\"over-sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5ed385d4-70e0-485d-ba33-839e4727c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6479fa11-449e-44b9-b14b-5a391609f1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 1057, 0: 1057})\n"
     ]
    }
   ],
   "source": [
    "sampler = SMOTE(random_state=42)\n",
    "\n",
    "x_chen_train, y_chen_train = sampler.fit_resample(x_chen_train.drop([\"Ab_ID\", \"name\", \"Y\"], axis=1), x_chen_train[\"Y\"]) \n",
    "print('Resampled dataset shape %s' % Counter(y_chen_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "69a7dfba-9089-43da-bc17-c2f86fd78858",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data protparam \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/pbs.31824.lich-compute.vscht.cz/ipykernel_46599/4174874532.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m try_all(x_chen_train.drop([\"cluster_merged\"], axis=1), y_chen_train, \n\u001b[1;32m      2\u001b[0m         \u001b[0mx_chen_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Ab_ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_chen_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         x_chen_train[\"cluster_merged\"], \"protparam\", EVAL_DIR, preprocessing=\"over-sampling\")\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.31824.lich-compute.vscht.cz/ipykernel_46599/2726944695.py\u001b[0m in \u001b[0;36mtry_all\u001b[0;34m(X_train, y_train, X_valid, y_valid, groups, data_name, outpath, preprocessing)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training model {model_label} on data {data_name} \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         train_and_eval(model_label, classifier, params, X_train, y_train, X_valid, y_valid, groups,\n\u001b[0;32m----> 8\u001b[0;31m                    data_name, outpath, preprocessing=preprocessing)\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.31824.lich-compute.vscht.cz/ipykernel_46599/133815900.py\u001b[0m in \u001b[0;36mtrain_and_eval\u001b[0;34m(model_name, classifier, parameters, X_train, y_train, X_valid, y_valid, groups, data_name, outpath, preprocessing)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m         evaluate_candidates(\n\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m-> 1768\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m             )\n\u001b[1;32m   1770\u001b[0m         )\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1612\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             )\n\u001b[0;32m-> 1614\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m         )\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    876\u001b[0m                 \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m                 \u001b[0mwarm_start_sag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m                 \u001b[0mis_saga\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"saga\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m             )\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mintercept_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mis_saga\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     )\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train.drop([\"cluster_merged\"], axis=1), y_chen_train, \n",
    "        x_chen_valid.drop([\"Ab_ID\", \"name\", \"Y\"], axis=1), x_chen_valid[\"Y\"], \n",
    "        x_chen_train[\"cluster_merged\"], \"protparam\", EVAL_DIR, preprocessing=\"smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fe3f190-d9ea-4988-94fa-2797177a0a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on protparam...\n",
      "Testing model random_forest on protparam...\n",
      "Testing model gradient_boosting on protparam...\n",
      "Testing model SVM on protparam...\n",
      "Testing model multilayer_perceptron on protparam...\n"
     ]
    }
   ],
   "source": [
    "test_all(x_tap.drop(\"Ab_ID\", axis=1), tap_data[\"Y\"], \"protparam\", EVAL_DIR, preprocessing=\"smote\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca554f3e-5877-44b1-9fc8-f80b1dbcbc44",
   "metadata": {},
   "source": [
    "# BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a16dceef-1516-4b03-b681-194070178a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>Y</th>\n",
       "      <th>cluster_merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1a0q</td>\n",
       "      <td>-0.017142</td>\n",
       "      <td>-0.008645</td>\n",
       "      <td>0.008613</td>\n",
       "      <td>-0.046730</td>\n",
       "      <td>0.061336</td>\n",
       "      <td>-0.017951</td>\n",
       "      <td>0.020446</td>\n",
       "      <td>-0.108641</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037837</td>\n",
       "      <td>-0.009891</td>\n",
       "      <td>-0.018668</td>\n",
       "      <td>0.045293</td>\n",
       "      <td>-0.042225</td>\n",
       "      <td>-0.015849</td>\n",
       "      <td>-0.002904</td>\n",
       "      <td>-0.023377</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1a14</td>\n",
       "      <td>-0.016770</td>\n",
       "      <td>-0.016028</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>-0.022389</td>\n",
       "      <td>0.048435</td>\n",
       "      <td>-0.029777</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>-0.091042</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027305</td>\n",
       "      <td>0.012193</td>\n",
       "      <td>0.013407</td>\n",
       "      <td>0.019745</td>\n",
       "      <td>-0.029758</td>\n",
       "      <td>-0.021011</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>-0.014885</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a2y</td>\n",
       "      <td>0.022052</td>\n",
       "      <td>-0.024678</td>\n",
       "      <td>0.013147</td>\n",
       "      <td>-0.041079</td>\n",
       "      <td>0.054560</td>\n",
       "      <td>-0.009407</td>\n",
       "      <td>-0.007112</td>\n",
       "      <td>-0.076221</td>\n",
       "      <td>0.010534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031617</td>\n",
       "      <td>-0.013962</td>\n",
       "      <td>-0.021564</td>\n",
       "      <td>0.045667</td>\n",
       "      <td>-0.028034</td>\n",
       "      <td>-0.023921</td>\n",
       "      <td>-0.020638</td>\n",
       "      <td>-0.019502</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a3l</td>\n",
       "      <td>-0.004759</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>-0.010184</td>\n",
       "      <td>-0.027024</td>\n",
       "      <td>0.073321</td>\n",
       "      <td>-0.015843</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>-0.090230</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016519</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>0.037635</td>\n",
       "      <td>-0.030517</td>\n",
       "      <td>-0.020022</td>\n",
       "      <td>-0.004965</td>\n",
       "      <td>-0.012199</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a4j</td>\n",
       "      <td>-0.008561</td>\n",
       "      <td>-0.015271</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>-0.026142</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>-0.019657</td>\n",
       "      <td>0.031890</td>\n",
       "      <td>-0.106666</td>\n",
       "      <td>-0.001778</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020049</td>\n",
       "      <td>-0.007701</td>\n",
       "      <td>-0.031986</td>\n",
       "      <td>0.017794</td>\n",
       "      <td>-0.022749</td>\n",
       "      <td>-0.019076</td>\n",
       "      <td>-0.008999</td>\n",
       "      <td>-0.030474</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2051 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ab_ID         0         1         2         3         4         5         6  \\\n",
       "0  1a0q -0.017142 -0.008645  0.008613 -0.046730  0.061336 -0.017951  0.020446   \n",
       "1  1a14 -0.016770 -0.016028  0.005558 -0.022389  0.048435 -0.029777  0.005205   \n",
       "2  1a2y  0.022052 -0.024678  0.013147 -0.041079  0.054560 -0.009407 -0.007112   \n",
       "3  1a3l -0.004759  0.000985 -0.010184 -0.027024  0.073321 -0.015843  0.003232   \n",
       "4  1a4j -0.008561 -0.015271  0.014696 -0.026142  0.075300 -0.019657  0.031890   \n",
       "\n",
       "          7         8  ...      2040      2041      2042      2043      2044  \\\n",
       "0 -0.108641  0.002343  ... -0.037837 -0.009891 -0.018668  0.045293 -0.042225   \n",
       "1 -0.091042  0.002346  ... -0.027305  0.012193  0.013407  0.019745 -0.029758   \n",
       "2 -0.076221  0.010534  ... -0.031617 -0.013962 -0.021564  0.045667 -0.028034   \n",
       "3 -0.090230  0.003318  ... -0.016519  0.000595 -0.000173  0.037635 -0.030517   \n",
       "4 -0.106666 -0.001778  ... -0.020049 -0.007701 -0.031986  0.017794 -0.022749   \n",
       "\n",
       "       2045      2046      2047  Y  cluster_merged  \n",
       "0 -0.015849 -0.002904 -0.023377  1               2  \n",
       "1 -0.021011  0.000632 -0.014885  0               4  \n",
       "2 -0.023921 -0.020638 -0.019502  0               1  \n",
       "3 -0.020022 -0.004965 -0.012199  0               4  \n",
       "4 -0.019076 -0.008999 -0.030474  0               7  \n",
       "\n",
       "[5 rows x 2051 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chen = pd.read_feather(path.join(DATA_DIR, \"chen/embeddings/bert/bert_chen_embeddings.ftr\"))\n",
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_valid = x_chen.merge(chen_valid[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "466a7c53-e44b-49c1-8ee0-1ec2d33d871c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 1057, 0: 1057})\n"
     ]
    }
   ],
   "source": [
    "sampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "x_chen_train, y_chen_train = sampler.fit_resample(x_chen_train.drop(\"Y\", axis=1), x_chen_train[\"Y\"]) \n",
    "print('Resampled dataset shape %s' % Counter(y_chen_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "169edc1a-15ba-48a7-b707-9c8117a795e1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data bert \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/pbs.31824.lich-compute.vscht.cz/ipykernel_46599/570267068.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtry_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_chen_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Ab_ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cluster_merged\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_chen_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_chen_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ab_ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchen_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_chen_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cluster_merged\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bert\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVAL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"over-sampling\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.31824.lich-compute.vscht.cz/ipykernel_46599/2726944695.py\u001b[0m in \u001b[0;36mtry_all\u001b[0;34m(X_train, y_train, X_valid, y_valid, groups, data_name, outpath, preprocessing)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training model {model_label} on data {data_name} \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         train_and_eval(model_label, classifier, params, X_train, y_train, X_valid, y_valid, groups,\n\u001b[0;32m----> 8\u001b[0;31m                    data_name, outpath, preprocessing=preprocessing)\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.31824.lich-compute.vscht.cz/ipykernel_46599/133815900.py\u001b[0m in \u001b[0;36mtrain_and_eval\u001b[0;34m(model_name, classifier, parameters, X_train, y_train, X_valid, y_valid, groups, data_name, outpath, preprocessing)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m         evaluate_candidates(\n\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m-> 1768\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m             )\n\u001b[1;32m   1770\u001b[0m         )\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1612\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             )\n\u001b[0;32m-> 1614\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m         )\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    876\u001b[0m                 \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m                 \u001b[0mwarm_start_sag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m                 \u001b[0mis_saga\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"saga\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m             )\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mintercept_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mis_saga\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     )\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train.drop([\"Ab_ID\", \"name\", \"cluster_merged\"], axis=1), y_chen_train, \n",
    "        x_chen_valid.drop([\"Ab_ID\", \"name\", \"Y\"], axis=1), x_chen_valid[\"Y\"], \n",
    "        x_chen_train[\"cluster_merged\"], \"bert\", EVAL_DIR, preprocessing=\"over-sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6946ac56-5e4f-4565-839b-f738d1fad30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abagovomab</td>\n",
       "      <td>-0.004248</td>\n",
       "      <td>-0.024501</td>\n",
       "      <td>-0.011330</td>\n",
       "      <td>-0.027170</td>\n",
       "      <td>0.062747</td>\n",
       "      <td>-0.024793</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>-0.083316</td>\n",
       "      <td>-0.005339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008674</td>\n",
       "      <td>-0.002387</td>\n",
       "      <td>-0.021563</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>-0.020986</td>\n",
       "      <td>0.047104</td>\n",
       "      <td>-0.038736</td>\n",
       "      <td>-0.021780</td>\n",
       "      <td>-0.022153</td>\n",
       "      <td>-0.024539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abituzumab</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>-0.013591</td>\n",
       "      <td>-0.008454</td>\n",
       "      <td>-0.043601</td>\n",
       "      <td>0.065095</td>\n",
       "      <td>-0.016896</td>\n",
       "      <td>-0.001596</td>\n",
       "      <td>-0.090935</td>\n",
       "      <td>-0.002940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>-0.013063</td>\n",
       "      <td>-0.021852</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>-0.024620</td>\n",
       "      <td>0.027387</td>\n",
       "      <td>-0.041001</td>\n",
       "      <td>-0.025708</td>\n",
       "      <td>-0.016437</td>\n",
       "      <td>-0.034342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrilumab</td>\n",
       "      <td>0.019445</td>\n",
       "      <td>-0.002642</td>\n",
       "      <td>-0.011395</td>\n",
       "      <td>-0.058757</td>\n",
       "      <td>0.060623</td>\n",
       "      <td>-0.015046</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>-0.083772</td>\n",
       "      <td>-0.006775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>-0.017189</td>\n",
       "      <td>-0.014557</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>-0.035368</td>\n",
       "      <td>0.020287</td>\n",
       "      <td>-0.033941</td>\n",
       "      <td>-0.023549</td>\n",
       "      <td>-0.008720</td>\n",
       "      <td>-0.044038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actoxumab</td>\n",
       "      <td>-0.006365</td>\n",
       "      <td>-0.043729</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>-0.025613</td>\n",
       "      <td>0.067748</td>\n",
       "      <td>-0.009542</td>\n",
       "      <td>0.017723</td>\n",
       "      <td>-0.096801</td>\n",
       "      <td>-0.007752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.012986</td>\n",
       "      <td>-0.019753</td>\n",
       "      <td>-0.004326</td>\n",
       "      <td>-0.044124</td>\n",
       "      <td>0.019544</td>\n",
       "      <td>-0.039559</td>\n",
       "      <td>-0.015679</td>\n",
       "      <td>-0.008837</td>\n",
       "      <td>-0.043877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adalimumab</td>\n",
       "      <td>-0.012995</td>\n",
       "      <td>-0.035269</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>-0.042136</td>\n",
       "      <td>0.080592</td>\n",
       "      <td>-0.012831</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>-0.091308</td>\n",
       "      <td>-0.018166</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>-0.022957</td>\n",
       "      <td>-0.021145</td>\n",
       "      <td>-0.002762</td>\n",
       "      <td>-0.058199</td>\n",
       "      <td>0.026781</td>\n",
       "      <td>-0.046815</td>\n",
       "      <td>-0.010110</td>\n",
       "      <td>-0.008785</td>\n",
       "      <td>-0.041761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ab_ID         0         1         2         3         4         5  \\\n",
       "0  Abagovomab -0.004248 -0.024501 -0.011330 -0.027170  0.062747 -0.024793   \n",
       "1  Abituzumab  0.006593 -0.013591 -0.008454 -0.043601  0.065095 -0.016896   \n",
       "2   Abrilumab  0.019445 -0.002642 -0.011395 -0.058757  0.060623 -0.015046   \n",
       "3   Actoxumab -0.006365 -0.043729  0.005978 -0.025613  0.067748 -0.009542   \n",
       "4  Adalimumab -0.012995 -0.035269  0.014127 -0.042136  0.080592 -0.012831   \n",
       "\n",
       "          6         7         8  ...      2038      2039      2040      2041  \\\n",
       "0  0.009313 -0.083316 -0.005339  ... -0.008674 -0.002387 -0.021563  0.001087   \n",
       "1 -0.001596 -0.090935 -0.002940  ...  0.000486 -0.013063 -0.021852 -0.003531   \n",
       "2  0.006317 -0.083772 -0.006775  ...  0.005834 -0.017189 -0.014557  0.003359   \n",
       "3  0.017723 -0.096801 -0.007752  ... -0.000024 -0.012986 -0.019753 -0.004326   \n",
       "4  0.031889 -0.091308 -0.018166  ... -0.002067 -0.022957 -0.021145 -0.002762   \n",
       "\n",
       "       2042      2043      2044      2045      2046      2047  \n",
       "0 -0.020986  0.047104 -0.038736 -0.021780 -0.022153 -0.024539  \n",
       "1 -0.024620  0.027387 -0.041001 -0.025708 -0.016437 -0.034342  \n",
       "2 -0.035368  0.020287 -0.033941 -0.023549 -0.008720 -0.044038  \n",
       "3 -0.044124  0.019544 -0.039559 -0.015679 -0.008837 -0.043877  \n",
       "4 -0.058199  0.026781 -0.046815 -0.010110 -0.008785 -0.041761  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tap = pd.read_feather(path.join(DATA_DIR, \"tap/embeddings/bert/bert_tap_embeddings.ftr\"))\n",
    "x_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8244fa99-f130-4aa8-8822-523c5db31375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on bert...\n",
      "Testing model random_forest on bert...\n",
      "Testing model gradient_boosting on bert...\n",
      "Testing model SVM on bert...\n",
      "Testing model multilayer_perceptron on bert...\n"
     ]
    }
   ],
   "source": [
    "test_all(x_tap.drop(\"Ab_ID\", axis=1), tap_data[\"Y\"], \"bert\", EVAL_DIR, preprocessing=\"over-sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c5f4b7f2-5413-4bdd-bee2-c99fd8e549f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 1057, 0: 1057})\n"
     ]
    }
   ],
   "source": [
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "\n",
    "sampler = SMOTE(random_state=42)\n",
    "\n",
    "x_chen_train, y_chen_train = sampler.fit_resample(x_chen_train.drop([\"Ab_ID\", \"Y\"], axis=1), x_chen_train[\"Y\"]) \n",
    "print('Resampled dataset shape %s' % Counter(y_chen_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4503d21-a911-4eb5-8055-18b2387feaed",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data bert \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "logistic_regression, bert\n",
      "F1: 0.32075471698113206\n",
      "MCC: 0.12922774279890484\n",
      "Accuracy: 0.698744769874477\n",
      "Precision: 0.2982456140350877\n",
      "Recall: 0.3469387755102041\n",
      "AUC: 0.5682062298603652\n",
      "-----\n",
      "\n",
      "\n",
      "Training model random_forest on data bert \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "random_forest, bert\n",
      "F1: 0.24390243902439027\n",
      "MCC: 0.09716594376718923\n",
      "Accuracy: 0.7405857740585774\n",
      "Precision: 0.30303030303030304\n",
      "Recall: 0.20408163265306123\n",
      "AUC: 0.541514500537057\n",
      "-----\n",
      "\n",
      "\n",
      "Training model gradient_boosting on data bert \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_boosting, bert\n",
      "F1: 0.23076923076923075\n",
      "MCC: 0.09694811588700399\n",
      "Accuracy: 0.7489539748953975\n",
      "Precision: 0.3103448275862069\n",
      "Recall: 0.1836734693877551\n",
      "AUC: 0.5392051557465091\n",
      "-----\n",
      "\n",
      "\n",
      "Training model SVM on data bert \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, bert\n",
      "F1: 0.41818181818181815\n",
      "MCC: 0.2494467057999306\n",
      "Accuracy: 0.7322175732217573\n",
      "Precision: 0.3770491803278688\n",
      "Recall: 0.46938775510204084\n",
      "AUC: 0.6346938775510205\n",
      "-----\n",
      "\n",
      "\n",
      "Training model multilayer_perceptron on data bert \n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron, bert\n",
      "F1: 0.2727272727272727\n",
      "MCC: 0.11230259609339714\n",
      "Accuracy: 0.7322175732217573\n",
      "Precision: 0.3076923076923077\n",
      "Recall: 0.24489795918367346\n",
      "AUC: 0.5513963480128894\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train.drop([\"cluster_merged\"], axis=1), y_chen_train, \n",
    "        x_chen_valid.drop([\"Ab_ID\", \"Y\"], axis=1), x_chen_valid[\"Y\"], \n",
    "        x_chen_train[\"cluster_merged\"], \"bert\", EVAL_DIR, preprocessing=\"smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fabed1d4-bc8f-4022-b2a0-ddab732ece42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on bert...\n",
      "Testing model random_forest on bert...\n",
      "Testing model gradient_boosting on bert...\n",
      "Testing model SVM on bert...\n",
      "Testing model multilayer_perceptron on bert...\n"
     ]
    }
   ],
   "source": [
    "test_all(x_tap.drop(\"Ab_ID\", axis=1), tap_data[\"Y\"], \"bert\", EVAL_DIR, preprocessing=\"smote\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b72f0-8d1e-49b2-af8c-5f8e40d79114",
   "metadata": {},
   "source": [
    "# SeqVec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "242800ab-9c9f-40bc-8833-2d43e2cfe302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>Y</th>\n",
       "      <th>cluster_merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1a0q</td>\n",
       "      <td>0.073347</td>\n",
       "      <td>-0.186018</td>\n",
       "      <td>-0.233184</td>\n",
       "      <td>-0.165189</td>\n",
       "      <td>0.064193</td>\n",
       "      <td>-0.030149</td>\n",
       "      <td>0.043134</td>\n",
       "      <td>0.111651</td>\n",
       "      <td>-0.120727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138852</td>\n",
       "      <td>0.049886</td>\n",
       "      <td>-0.044254</td>\n",
       "      <td>-0.012993</td>\n",
       "      <td>-0.032100</td>\n",
       "      <td>-0.005154</td>\n",
       "      <td>-0.035896</td>\n",
       "      <td>-0.053616</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1a14</td>\n",
       "      <td>0.066646</td>\n",
       "      <td>-0.216164</td>\n",
       "      <td>-0.275053</td>\n",
       "      <td>-0.124785</td>\n",
       "      <td>0.051032</td>\n",
       "      <td>-0.010701</td>\n",
       "      <td>0.042427</td>\n",
       "      <td>0.123428</td>\n",
       "      <td>-0.098271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141865</td>\n",
       "      <td>-0.114347</td>\n",
       "      <td>0.011103</td>\n",
       "      <td>-0.044319</td>\n",
       "      <td>-0.028007</td>\n",
       "      <td>0.020282</td>\n",
       "      <td>-0.050135</td>\n",
       "      <td>-0.095745</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a2y</td>\n",
       "      <td>0.089280</td>\n",
       "      <td>-0.191509</td>\n",
       "      <td>-0.165287</td>\n",
       "      <td>-0.087335</td>\n",
       "      <td>0.067743</td>\n",
       "      <td>-0.043121</td>\n",
       "      <td>0.027767</td>\n",
       "      <td>0.232575</td>\n",
       "      <td>-0.080467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216815</td>\n",
       "      <td>0.082564</td>\n",
       "      <td>0.016979</td>\n",
       "      <td>-0.003557</td>\n",
       "      <td>-0.081891</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>-0.041633</td>\n",
       "      <td>-0.220336</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a3l</td>\n",
       "      <td>0.007294</td>\n",
       "      <td>-0.190514</td>\n",
       "      <td>-0.289291</td>\n",
       "      <td>-0.150268</td>\n",
       "      <td>0.056585</td>\n",
       "      <td>0.023869</td>\n",
       "      <td>-0.016217</td>\n",
       "      <td>0.094631</td>\n",
       "      <td>-0.208477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179691</td>\n",
       "      <td>-0.022877</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>-0.055541</td>\n",
       "      <td>-0.035867</td>\n",
       "      <td>-0.030935</td>\n",
       "      <td>-0.006666</td>\n",
       "      <td>0.009036</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a4j</td>\n",
       "      <td>-0.016434</td>\n",
       "      <td>-0.144044</td>\n",
       "      <td>-0.292733</td>\n",
       "      <td>-0.124054</td>\n",
       "      <td>0.080313</td>\n",
       "      <td>-0.051480</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.087235</td>\n",
       "      <td>-0.182320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267914</td>\n",
       "      <td>0.044216</td>\n",
       "      <td>0.020647</td>\n",
       "      <td>0.060805</td>\n",
       "      <td>-0.116175</td>\n",
       "      <td>0.111569</td>\n",
       "      <td>0.045578</td>\n",
       "      <td>-0.108075</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2051 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ab_ID         0         1         2         3         4         5         6  \\\n",
       "0  1a0q  0.073347 -0.186018 -0.233184 -0.165189  0.064193 -0.030149  0.043134   \n",
       "1  1a14  0.066646 -0.216164 -0.275053 -0.124785  0.051032 -0.010701  0.042427   \n",
       "2  1a2y  0.089280 -0.191509 -0.165287 -0.087335  0.067743 -0.043121  0.027767   \n",
       "3  1a3l  0.007294 -0.190514 -0.289291 -0.150268  0.056585  0.023869 -0.016217   \n",
       "4  1a4j -0.016434 -0.144044 -0.292733 -0.124054  0.080313 -0.051480  0.000747   \n",
       "\n",
       "          7         8  ...      2040      2041      2042      2043      2044  \\\n",
       "0  0.111651 -0.120727  ...  0.138852  0.049886 -0.044254 -0.012993 -0.032100   \n",
       "1  0.123428 -0.098271  ...  0.141865 -0.114347  0.011103 -0.044319 -0.028007   \n",
       "2  0.232575 -0.080467  ...  0.216815  0.082564  0.016979 -0.003557 -0.081891   \n",
       "3  0.094631 -0.208477  ...  0.179691 -0.022877  0.003620 -0.055541 -0.035867   \n",
       "4  0.087235 -0.182320  ...  0.267914  0.044216  0.020647  0.060805 -0.116175   \n",
       "\n",
       "       2045      2046      2047  Y  cluster_merged  \n",
       "0 -0.005154 -0.035896 -0.053616  1               2  \n",
       "1  0.020282 -0.050135 -0.095745  0               4  \n",
       "2  0.005624 -0.041633 -0.220336  0               1  \n",
       "3 -0.030935 -0.006666  0.009036  0               4  \n",
       "4  0.111569  0.045578 -0.108075  0               7  \n",
       "\n",
       "[5 rows x 2051 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chen = pd.read_feather(path.join(DATA_DIR, \"chen/embeddings/seqvec/seqvec_chen_embeddings.ftr\"))\n",
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_valid = x_chen.merge(chen_valid[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1545dd54-c9f8-4c22-b091-3bf444a650cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 1057, 0: 1057})\n"
     ]
    }
   ],
   "source": [
    "sampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "x_chen_train, y_chen_train = sampler.fit_resample(x_chen_train.drop(\"Y\", axis=1), x_chen_train[\"Y\"]) \n",
    "print('Resampled dataset shape %s' % Counter(y_chen_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40df67f1-1c9a-419b-816f-87d21b10882c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression, seqvec\n",
      "F1: 0.32989690721649484\n",
      "MCC: 0.15932930700455064\n",
      "Accuracy: 0.7280334728033473\n",
      "Precision: 0.3333333333333333\n",
      "Recall: 0.32653061224489793\n",
      "AUC: 0.5790547798066595\n",
      "-----\n",
      "\n",
      "\n",
      "Training model random_forest on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest, seqvec\n",
      "F1: 0.3\n",
      "MCC: 0.17411035250043286\n",
      "Accuracy: 0.7656903765690377\n",
      "Precision: 0.3870967741935484\n",
      "Recall: 0.24489795918367346\n",
      "AUC: 0.5724489795918368\n",
      "-----\n",
      "\n",
      "\n",
      "Training model gradient_boosting on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_boosting, seqvec\n",
      "F1: 0.18666666666666665\n",
      "MCC: 0.05556759229181543\n",
      "Accuracy: 0.7447698744769874\n",
      "Precision: 0.2692307692307692\n",
      "Recall: 0.14285714285714285\n",
      "AUC: 0.5214285714285714\n",
      "-----\n",
      "\n",
      "\n",
      "Training model SVM on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, seqvec\n",
      "F1: 0.31683168316831684\n",
      "MCC: 0.13410759024069596\n",
      "Accuracy: 0.7112970711297071\n",
      "Precision: 0.3076923076923077\n",
      "Recall: 0.32653061224489793\n",
      "AUC: 0.5685284640171857\n",
      "-----\n",
      "\n",
      "\n",
      "Training model multilayer_perceptron on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron, seqvec\n",
      "F1: 0.4036697247706422\n",
      "MCC: 0.23181228637677556\n",
      "Accuracy: 0.7280334728033473\n",
      "Precision: 0.36666666666666664\n",
      "Recall: 0.4489795918367347\n",
      "AUC: 0.6244897959183674\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train.drop([\"Ab_ID\", \"cluster_merged\"], axis=1), y_chen_train, \n",
    "        x_chen_valid.drop(\"Ab_ID\", \"Y\", axis=1), x_chen_valid[\"Y\"], x_chen_train[\"cluster_merged\"], \n",
    "        \"seqvec\", EVAL_DIR, preprocessing=\"over-sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50dd5635-2548-4aa9-ba29-2c84aaa34c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abagovomab</td>\n",
       "      <td>-0.004248</td>\n",
       "      <td>-0.024501</td>\n",
       "      <td>-0.011330</td>\n",
       "      <td>-0.027170</td>\n",
       "      <td>0.062747</td>\n",
       "      <td>-0.024793</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>-0.083316</td>\n",
       "      <td>-0.005339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008674</td>\n",
       "      <td>-0.002387</td>\n",
       "      <td>-0.021563</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>-0.020986</td>\n",
       "      <td>0.047104</td>\n",
       "      <td>-0.038736</td>\n",
       "      <td>-0.021780</td>\n",
       "      <td>-0.022153</td>\n",
       "      <td>-0.024539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abituzumab</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>-0.013591</td>\n",
       "      <td>-0.008454</td>\n",
       "      <td>-0.043601</td>\n",
       "      <td>0.065095</td>\n",
       "      <td>-0.016896</td>\n",
       "      <td>-0.001596</td>\n",
       "      <td>-0.090935</td>\n",
       "      <td>-0.002940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>-0.013063</td>\n",
       "      <td>-0.021852</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>-0.024620</td>\n",
       "      <td>0.027387</td>\n",
       "      <td>-0.041001</td>\n",
       "      <td>-0.025708</td>\n",
       "      <td>-0.016437</td>\n",
       "      <td>-0.034342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrilumab</td>\n",
       "      <td>0.019445</td>\n",
       "      <td>-0.002642</td>\n",
       "      <td>-0.011395</td>\n",
       "      <td>-0.058757</td>\n",
       "      <td>0.060623</td>\n",
       "      <td>-0.015046</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>-0.083772</td>\n",
       "      <td>-0.006775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>-0.017189</td>\n",
       "      <td>-0.014557</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>-0.035368</td>\n",
       "      <td>0.020287</td>\n",
       "      <td>-0.033941</td>\n",
       "      <td>-0.023549</td>\n",
       "      <td>-0.008720</td>\n",
       "      <td>-0.044038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actoxumab</td>\n",
       "      <td>-0.006365</td>\n",
       "      <td>-0.043729</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>-0.025613</td>\n",
       "      <td>0.067748</td>\n",
       "      <td>-0.009542</td>\n",
       "      <td>0.017723</td>\n",
       "      <td>-0.096801</td>\n",
       "      <td>-0.007752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.012986</td>\n",
       "      <td>-0.019753</td>\n",
       "      <td>-0.004326</td>\n",
       "      <td>-0.044124</td>\n",
       "      <td>0.019544</td>\n",
       "      <td>-0.039559</td>\n",
       "      <td>-0.015679</td>\n",
       "      <td>-0.008837</td>\n",
       "      <td>-0.043877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adalimumab</td>\n",
       "      <td>-0.012995</td>\n",
       "      <td>-0.035269</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>-0.042136</td>\n",
       "      <td>0.080592</td>\n",
       "      <td>-0.012831</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>-0.091308</td>\n",
       "      <td>-0.018166</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>-0.022957</td>\n",
       "      <td>-0.021145</td>\n",
       "      <td>-0.002762</td>\n",
       "      <td>-0.058199</td>\n",
       "      <td>0.026781</td>\n",
       "      <td>-0.046815</td>\n",
       "      <td>-0.010110</td>\n",
       "      <td>-0.008785</td>\n",
       "      <td>-0.041761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ab_ID         0         1         2         3         4         5  \\\n",
       "0  Abagovomab -0.004248 -0.024501 -0.011330 -0.027170  0.062747 -0.024793   \n",
       "1  Abituzumab  0.006593 -0.013591 -0.008454 -0.043601  0.065095 -0.016896   \n",
       "2   Abrilumab  0.019445 -0.002642 -0.011395 -0.058757  0.060623 -0.015046   \n",
       "3   Actoxumab -0.006365 -0.043729  0.005978 -0.025613  0.067748 -0.009542   \n",
       "4  Adalimumab -0.012995 -0.035269  0.014127 -0.042136  0.080592 -0.012831   \n",
       "\n",
       "          6         7         8  ...      2038      2039      2040      2041  \\\n",
       "0  0.009313 -0.083316 -0.005339  ... -0.008674 -0.002387 -0.021563  0.001087   \n",
       "1 -0.001596 -0.090935 -0.002940  ...  0.000486 -0.013063 -0.021852 -0.003531   \n",
       "2  0.006317 -0.083772 -0.006775  ...  0.005834 -0.017189 -0.014557  0.003359   \n",
       "3  0.017723 -0.096801 -0.007752  ... -0.000024 -0.012986 -0.019753 -0.004326   \n",
       "4  0.031889 -0.091308 -0.018166  ... -0.002067 -0.022957 -0.021145 -0.002762   \n",
       "\n",
       "       2042      2043      2044      2045      2046      2047  \n",
       "0 -0.020986  0.047104 -0.038736 -0.021780 -0.022153 -0.024539  \n",
       "1 -0.024620  0.027387 -0.041001 -0.025708 -0.016437 -0.034342  \n",
       "2 -0.035368  0.020287 -0.033941 -0.023549 -0.008720 -0.044038  \n",
       "3 -0.044124  0.019544 -0.039559 -0.015679 -0.008837 -0.043877  \n",
       "4 -0.058199  0.026781 -0.046815 -0.010110 -0.008785 -0.041761  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tap = pd.read_feather(path.join(DATA_DIR, \"tap/embeddings/seqvec/seqvec_tap_embeddings.ftr\"))\n",
    "x_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7be0003-dc87-4e08-99d5-a5f2220dc25a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on seqvec...\n",
      "Testing model random_forest on seqvec...\n",
      "Testing model gradient_boosting on seqvec...\n",
      "Testing model SVM on seqvec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model multilayer_perceptron on seqvec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_all(x_tap.drop(\"Ab_ID\", axis=1), tap_data[\"Y\"], \"seqvec\", EVAL_DIR, preprocessing=\"over-sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2af7b167-9932-4433-9014-4e590101ec64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 1057, 0: 1057})\n"
     ]
    }
   ],
   "source": [
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "\n",
    "sampler = SMOTE(random_state=42)\n",
    "\n",
    "x_chen_train, y_chen_train = sampler.fit_resample(x_chen_train.drop([\"Ab_ID\", \"Y\"], axis=1), x_chen_train[\"Y\"]) \n",
    "print('Resampled dataset shape %s' % Counter(y_chen_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9dc2fcf-e226-4391-95f6-481ca8956862",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression, seqvec\n",
      "F1: 0.32653061224489793\n",
      "MCC: 0.15284640171858216\n",
      "Accuracy: 0.7238493723849372\n",
      "Precision: 0.32653061224489793\n",
      "Recall: 0.32653061224489793\n",
      "AUC: 0.5764232008592911\n",
      "-----\n",
      "\n",
      "\n",
      "Training model random_forest on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest, seqvec\n",
      "F1: 0.3146067415730337\n",
      "MCC: 0.16100221685529514\n",
      "Accuracy: 0.7447698744769874\n",
      "Precision: 0.35\n",
      "Recall: 0.2857142857142857\n",
      "AUC: 0.5744360902255639\n",
      "-----\n",
      "\n",
      "\n",
      "Training model gradient_boosting on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_boosting, seqvec\n",
      "F1: 0.2988505747126437\n",
      "MCC: 0.14764022008576264\n",
      "Accuracy: 0.7447698744769874\n",
      "Precision: 0.34210526315789475\n",
      "Recall: 0.2653061224489796\n",
      "AUC: 0.5668635875402793\n",
      "-----\n",
      "\n",
      "\n",
      "Training model SVM on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "SVM, seqvec\n",
      "F1: 0.36697247706422015\n",
      "MCC: 0.18400975277535248\n",
      "Accuracy: 0.7112970711297071\n",
      "Precision: 0.3333333333333333\n",
      "Recall: 0.40816326530612246\n",
      "AUC: 0.5988184747583244\n",
      "-----\n",
      "\n",
      "\n",
      "Training model multilayer_perceptron on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron, seqvec\n",
      "F1: 0.34615384615384615\n",
      "MCC: 0.16555823204102568\n",
      "Accuracy: 0.7154811715481172\n",
      "Precision: 0.32727272727272727\n",
      "Recall: 0.3673469387755102\n",
      "AUC: 0.5863050483351236\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train.drop([\"Ab_ID\", \"cluster_merged\"], axis=1), y_chen_train, \n",
    "        x_chen_valid.drop([\"Ab_ID\", \"Y\"], axis=1), x_chen_valid[\"Y\"], \n",
    "        x_chen_train[\"cluster_merged\"], \"seqvec\", EVAL_DIR, preprocessing=\"smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d84c859-1e35-4387-bff7-1d35e628f6a4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on seqvec...\n",
      "Testing model random_forest on seqvec...\n",
      "Testing model gradient_boosting on seqvec...\n",
      "Testing model SVM on seqvec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model multilayer_perceptron on seqvec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_all(x_tap.drop(\"Ab_ID\", axis=1), tap_data[\"Y\"], \"seqvec\", EVAL_DIR, preprocessing=\"smote\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a88ec5-093c-4a1f-bc19-f63f28f37ee5",
   "metadata": {},
   "source": [
    "# One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a260bac9-7217-43b7-bbee-434846b30cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_heavy = pd.read_feather(path.join(DATA_DIR, \"chen/abnumber/chen_heavy_one_hot.ftr\")).set_index(\"index\")\n",
    "# rows 1921 and 2097 could not be encoded\n",
    "x_light = pd.read_feather(path.join(DATA_DIR, \"chen/abnumber/chen_light_one_hot.ftr\")).set_index(\"Id\")\n",
    "x_chen = x_heavy.merge(x_light, left_index=True, right_index=True, suffixes=[\"_h\", \"_l\"])\n",
    "x_chen.index = x_heavy.index\n",
    "train_idx = list(chen_train.index)\n",
    "train_idx.remove(1921)\n",
    "train_idx.remove(2097)\n",
    "x_chen_train = x_chen.loc[train_idx]\n",
    "x_chen_valid = x_chen.loc[chen_valid.index]\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288a9a58-bca2-4213-83db-33886a8d233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = chen_train.loc[train_idx][\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f72b5-16a0-437f-b1dc-f749f7608f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "x_chen_train, y_chen_train = sampler.fit_resample(x_chen_train, train_labels) \n",
    "print('Resampled dataset shape %s' % Counter(y_chen_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8faa811-94e5-4755-9994-f11dcfb260fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add groups!!\n",
    "try_all(x_chen_train.drop([\"Ab_ID_h\", \"Ab_ID_l\"], axis=1), y_chen_train, x_chen_valid.drop([\"Ab_ID_h\", \"Ab_ID_l\"], axis=1), chen_valid[\"Y\"], \"onehot\", EVAL_DIR, preprocessing=\"over-sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74352835-bf47-4d2b-9949-c73e73d6a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tap_heavy = pd.read_feather(path.join(DATA_DIR, \"tap/abnumber/tap_heavy_one_hot.ftr\"))\n",
    "x_tap_light = pd.read_feather(path.join(DATA_DIR, \"tap/abnumber/tap_light_one_hot.ftr\"))\n",
    "x_tap = x_heavy.merge(x_light, left_index=True, right_index=True, suffixes=[\"_h\", \"_l\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f860b4-7310-4de4-ae13-36d89cb3cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all(x_tap, tap_data[\"Y\"], \"onehot\", EVAL_DIR, preprocessing=\"over-sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0813617b-bf38-46a0-b2a0-c64ac4e967f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_chen_train = x_chen.loc[chen_train.index]\n",
    "\n",
    "sampler = SMOTE(random_state=42)\n",
    "\n",
    "x_chen_train, y_chen_train = sampler.fit_resample(x_chen_train, chen_train[\"Y\"]) \n",
    "print('Resampled dataset shape %s' % Counter(y_chen_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf1655f-1e16-4437-b3c5-c844d33f8a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_all(x_chen_train.drop(\"Ab_ID\", axis=1), y_chen_train, x_chen_valid.drop(\"Ab_ID\", axis=1), chen_valid[\"Y\"], \"onehot\", EVAL_DIR, preprocessing=\"smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7679225-5519-4e17-85a7-2ba622445073",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all(x_tap, tap_data[\"Y\"], \"onehot\", EVAL_DIR, preprocessing=\"smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913de6b5-4762-4f6d-ab06-8047e277a055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
