{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aaac5ca7-e11d-4cef-8594-dc61e039f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.fixes import loguniform    \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e4ae71e-a22d-4cb6-919a-2d8e8cfad1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e1b5173-daf6-4afc-8f3d-0a1b1a4a7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_DIR = \"2021-12-03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "604e7e5b-1fac-49b4-b2a5-764ed1d46e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...</td>\n",
       "      <td>DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...</td>\n",
       "      <td>DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Antibody_ID                                              heavy  \\\n",
       "2073        6aod  EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...   \n",
       "1517        4yny  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2025        5xcv  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2070        6and  EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...   \n",
       "666         2xqy  QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...   \n",
       "\n",
       "                                                  light  Y  \n",
       "2073  DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...  0  \n",
       "1517  EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2025  QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2070  DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...  1  \n",
       "666   DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...  0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_train = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_train_data.csv\"), index_col=0)\n",
    "chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afda5620-8cda-4a38-b06e-1a3b0659e0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>Y</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>6ct7</td>\n",
       "      <td>EVQLVESGGGLVEPGGSLRLSCAVSGFDFEKAWMSWVRQAPGQGLQ...</td>\n",
       "      <td>SYELTQPPSVSVSPGQTARITCSGEALPMQFAHWYQQRPGKAPVIV...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>4nzu</td>\n",
       "      <td>AVSLVESGGGTVEPGSTLRLSCAASGFTFGSYAFHWVRQAPGDGLE...</td>\n",
       "      <td>DIEMTQSPSSLSASTGDKVTITCQASQDIAKFLDWYQQRPGKTPKL...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>5i8c</td>\n",
       "      <td>QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...</td>\n",
       "      <td>DIQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNL...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>5i8e</td>\n",
       "      <td>QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...</td>\n",
       "      <td>IQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNLL...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>6bb4</td>\n",
       "      <td>QVQLQQSDAELVKPGASVKISCKASGYTFTDRTIHWVKQRPEQGLE...</td>\n",
       "      <td>DVQMIQSPSSLSASLGDIVTMTCQASQDTSINLNWFQQKPGKAPKL...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Antibody_ID                                              heavy  \\\n",
       "2169        6ct7  EVQLVESGGGLVEPGGSLRLSCAVSGFDFEKAWMSWVRQAPGQGLQ...   \n",
       "1342        4nzu  AVSLVESGGGTVEPGSTLRLSCAASGFTFGSYAFHWVRQAPGDGLE...   \n",
       "1728        5i8c  QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...   \n",
       "1729        5i8e  QEVLVQSGAEVKKPGASVKVSCRAFGYTFTGNALHWVRQAPGQGLE...   \n",
       "2114        6bb4  QVQLQQSDAELVKPGASVKISCKASGYTFTDRTIHWVKQRPEQGLE...   \n",
       "\n",
       "                                                  light  Y  Unnamed: 0  \n",
       "2169  SYELTQPPSVSVSPGQTARITCSGEALPMQFAHWYQQRPGKAPVIV...  0         NaN  \n",
       "1342  DIEMTQSPSSLSASTGDKVTITCQASQDIAKFLDWYQQRPGKTPKL...  0         NaN  \n",
       "1728  DIQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNL...  1         NaN  \n",
       "1729  IQLTQSPSFLSASVGDKVTITCRASQGVRNELAWYQQKPGKAPNLL...  0         NaN  \n",
       "2114  DVQMIQSPSSLSASLGDIVTMTCQASQDTSINLNWFQQKPGKAPKL...  0         NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_valid = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_valid_data.csv\"), index_col=0)\n",
    "chen_test = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_test_data.csv\"))\n",
    "chen_valid = pd.concat([chen_valid, chen_test])\n",
    "chen_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19c89493-eacc-42e6-af45-d5bb12a31036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1338 239\n"
     ]
    }
   ],
   "source": [
    "print(len(chen_train), len(chen_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "083e69c0-1ebf-41c8-a4d3-782f364696d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>CDR_length</th>\n",
       "      <th>PSH</th>\n",
       "      <th>PPC</th>\n",
       "      <th>PNC</th>\n",
       "      <th>SFvCSP</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abagovomab</td>\n",
       "      <td>QVKLQESGAELARPGASVKLSCKASGYTFTNYWMQWVKQRPGQGLD...</td>\n",
       "      <td>DIELTQSPASLSASVGETVTITCQASENIYSYLAWHQQKQGKSPQL...</td>\n",
       "      <td>46</td>\n",
       "      <td>129.7603</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abituzumab</td>\n",
       "      <td>QVQLQQSGGELAKPGASVKVSCKASGYTFSSFWMHWVRQAPGQGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQDISNYLAWYQQKPGKAPKL...</td>\n",
       "      <td>45</td>\n",
       "      <td>115.9106</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>-3.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrilumab</td>\n",
       "      <td>QVQLVQSGAEVKKPGASVKVSCKVSGYTLSDLSIHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQQKPGKAPKL...</td>\n",
       "      <td>45</td>\n",
       "      <td>109.6995</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actoxumab</td>\n",
       "      <td>QVQLVESGGGVVQPGRSLRLSCAASGFSFSNYGMHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQHKPGKAPKL...</td>\n",
       "      <td>49</td>\n",
       "      <td>112.6290</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.1247</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adalimumab</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLRLSCAASGFTFDDYAMHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQGIRNYLAWYQQKPGKAPKL...</td>\n",
       "      <td>48</td>\n",
       "      <td>111.2512</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>1.1364</td>\n",
       "      <td>-19.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Antibody_ID                                              heavy  \\\n",
       "0  Abagovomab  QVKLQESGAELARPGASVKLSCKASGYTFTNYWMQWVKQRPGQGLD...   \n",
       "1  Abituzumab  QVQLQQSGGELAKPGASVKVSCKASGYTFSSFWMHWVRQAPGQGLE...   \n",
       "2   Abrilumab  QVQLVQSGAEVKKPGASVKVSCKVSGYTLSDLSIHWVRQAPGKGLE...   \n",
       "3   Actoxumab  QVQLVESGGGVVQPGRSLRLSCAASGFSFSNYGMHWVRQAPGKGLE...   \n",
       "4  Adalimumab  EVQLVESGGGLVQPGRSLRLSCAASGFTFDDYAMHWVRQAPGKGLE...   \n",
       "\n",
       "                                               light  CDR_length       PSH  \\\n",
       "0  DIELTQSPASLSASVGETVTITCQASENIYSYLAWHQQKQGKSPQL...          46  129.7603   \n",
       "1  DIQMTQSPSSLSASVGDRVTITCRASQDISNYLAWYQQKPGKAPKL...          45  115.9106   \n",
       "2  DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQQKPGKAPKL...          45  109.6995   \n",
       "3  DIQMTQSPSSVSASVGDRVTITCRASQGISSWLAWYQHKPGKAPKL...          49  112.6290   \n",
       "4  DIQMTQSPSSLSASVGDRVTITCRASQGIRNYLAWYQQKPGKAPKL...          48  111.2512   \n",
       "\n",
       "      PPC     PNC  SFvCSP  Y  \n",
       "0  0.0000  0.0000   16.32  1  \n",
       "1  0.0954  0.0421   -3.10  1  \n",
       "2  0.0000  0.8965   -4.00  1  \n",
       "3  0.0000  1.1247    3.10  1  \n",
       "4  0.0485  1.1364  -19.50  1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tap_data = pd.read_csv(path.join(DATA_DIR, \"tap/TAP_data.csv\"))\n",
    "tap_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78bcad1b-5d12-4db8-b944-a7ef47b0051e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>2398</th>\n",
       "      <th>2400</th>\n",
       "      <th>2401</th>\n",
       "      <th>2402</th>\n",
       "      <th>2403</th>\n",
       "      <th>2404</th>\n",
       "      <th>2405</th>\n",
       "      <th>2406</th>\n",
       "      <th>2407</th>\n",
       "      <th>2408</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.77700</td>\n",
       "      <td>0.70350</td>\n",
       "      <td>0.69995</td>\n",
       "      <td>0.65085</td>\n",
       "      <td>0.67350</td>\n",
       "      <td>0.66915</td>\n",
       "      <td>0.66915</td>\n",
       "      <td>0.76100</td>\n",
       "      <td>0.71800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59250</td>\n",
       "      <td>0.63185</td>\n",
       "      <td>0.65150</td>\n",
       "      <td>0.61850</td>\n",
       "      <td>0.70070</td>\n",
       "      <td>0.60550</td>\n",
       "      <td>0.54015</td>\n",
       "      <td>0.70460</td>\n",
       "      <td>0.61020</td>\n",
       "      <td>0.62840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.77700</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>0.69315</td>\n",
       "      <td>0.70240</td>\n",
       "      <td>0.65570</td>\n",
       "      <td>0.65570</td>\n",
       "      <td>0.74785</td>\n",
       "      <td>0.79775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59600</td>\n",
       "      <td>0.65265</td>\n",
       "      <td>0.67200</td>\n",
       "      <td>0.63085</td>\n",
       "      <td>0.69350</td>\n",
       "      <td>0.60750</td>\n",
       "      <td>0.55310</td>\n",
       "      <td>0.71665</td>\n",
       "      <td>0.63920</td>\n",
       "      <td>0.63185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.70350</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.76100</td>\n",
       "      <td>0.69315</td>\n",
       "      <td>0.68970</td>\n",
       "      <td>0.64550</td>\n",
       "      <td>0.64550</td>\n",
       "      <td>0.70850</td>\n",
       "      <td>0.72070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.55975</td>\n",
       "      <td>0.60500</td>\n",
       "      <td>0.65050</td>\n",
       "      <td>0.62120</td>\n",
       "      <td>0.69350</td>\n",
       "      <td>0.58815</td>\n",
       "      <td>0.55555</td>\n",
       "      <td>0.69965</td>\n",
       "      <td>0.57580</td>\n",
       "      <td>0.60875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.69995</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>0.76100</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.66160</td>\n",
       "      <td>0.68700</td>\n",
       "      <td>0.65500</td>\n",
       "      <td>0.65500</td>\n",
       "      <td>0.68315</td>\n",
       "      <td>0.71335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57800</td>\n",
       "      <td>0.63665</td>\n",
       "      <td>0.65900</td>\n",
       "      <td>0.61900</td>\n",
       "      <td>0.70700</td>\n",
       "      <td>0.59300</td>\n",
       "      <td>0.54950</td>\n",
       "      <td>0.67185</td>\n",
       "      <td>0.58200</td>\n",
       "      <td>0.61370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.65085</td>\n",
       "      <td>0.69315</td>\n",
       "      <td>0.69315</td>\n",
       "      <td>0.66160</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.63025</td>\n",
       "      <td>0.64000</td>\n",
       "      <td>0.64000</td>\n",
       "      <td>0.64965</td>\n",
       "      <td>0.68375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62485</td>\n",
       "      <td>0.64180</td>\n",
       "      <td>0.60255</td>\n",
       "      <td>0.60010</td>\n",
       "      <td>0.67985</td>\n",
       "      <td>0.61990</td>\n",
       "      <td>0.54340</td>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.62135</td>\n",
       "      <td>0.63570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1577 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2        3        4        5        7        8  \\\n",
       "0  1.00000  0.77700  0.70350  0.69995  0.65085  0.67350  0.66915  0.66915   \n",
       "1  0.77700  1.00000  0.75000  0.73500  0.69315  0.70240  0.65570  0.65570   \n",
       "2  0.70350  0.75000  1.00000  0.76100  0.69315  0.68970  0.64550  0.64550   \n",
       "3  0.69995  0.73500  0.76100  1.00000  0.66160  0.68700  0.65500  0.65500   \n",
       "4  0.65085  0.69315  0.69315  0.66160  1.00000  0.63025  0.64000  0.64000   \n",
       "\n",
       "         9       10  ...     2398     2400     2401     2402     2403  \\\n",
       "0  0.76100  0.71800  ...  0.59250  0.63185  0.65150  0.61850  0.70070   \n",
       "1  0.74785  0.79775  ...  0.59600  0.65265  0.67200  0.63085  0.69350   \n",
       "2  0.70850  0.72070  ...  0.55975  0.60500  0.65050  0.62120  0.69350   \n",
       "3  0.68315  0.71335  ...  0.57800  0.63665  0.65900  0.61900  0.70700   \n",
       "4  0.64965  0.68375  ...  0.62485  0.64180  0.60255  0.60010  0.67985   \n",
       "\n",
       "      2404     2405     2406     2407     2408  \n",
       "0  0.60550  0.54015  0.70460  0.61020  0.62840  \n",
       "1  0.60750  0.55310  0.71665  0.63920  0.63185  \n",
       "2  0.58815  0.55555  0.69965  0.57580  0.60875  \n",
       "3  0.59300  0.54950  0.67185  0.58200  0.61370  \n",
       "4  0.61990  0.54340  0.76250  0.62135  0.63570  \n",
       "\n",
       "[5 rows x 1577 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_similarity = pd.read_csv(path.join(DATA_DIR, \"chen/distances/deduplicated_anarci_similarity.csv\"), index_col=0)\n",
    "chen_similarity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5bcd19-cf8a-47bb-b7f1-adfc2065a30f",
   "metadata": {},
   "source": [
    "## Data clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27561d22-2c39-4eed-bdd9-cb76bd2c22ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  670\n",
       "1  695\n",
       "2   80\n",
       "3  447\n",
       "4   30"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = pd.read_csv(path.join(DATA_DIR, \"chen/clustering.csv\"), index_col=0)\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6cb06db-b815-4031-be6f-9cb43860e4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    939\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique clusters\n",
    "clusters.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee2a436a-84a8-4235-b2d4-d70560eaa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chen_train = chen_train.merge(clusters, left_index=True, right_index=True).rename({\"0\": \"cluster\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2598434-0c40-4dc3-9260-7976498843f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge some cluters to obtain a 10-fold cross-validation\n",
    "chen_train[\"cluster_merged\"] = chen_train[\"cluster\"]\n",
    "chen_train[\"cluster_merged\"][chen_train[\"cluster\"] < 300] = chen_train[\"cluster\"][chen_train[\"cluster\"] < 300] // 30\n",
    "chen_train[\"cluster_merged\"][chen_train[\"cluster\"] >= 300] = chen_train[\"cluster\"][chen_train[\"cluster\"] >= 300] // 100\n",
    "chen_train[\"cluster_merged\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5f91405-cd11-477e-9ee0-6c24e03854ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    276\n",
       "3    189\n",
       "7    147\n",
       "5    137\n",
       "1    132\n",
       "4    129\n",
       "6    120\n",
       "8    106\n",
       "9     59\n",
       "2     43\n",
       "Name: cluster_merged, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_train[\"cluster_merged\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d6a3b02-d76e-45c6-99b3-c3b9bd18efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "chen_train.to_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_train_data_w_clusters.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de8365-c6c4-4b79-837e-e6211b19382f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38f59f95-95e6-4674-91f2-0c0ec62cc977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different usage from the other models\n",
    "def knn(n):\n",
    "    model = NearestNeighbors(metric=\"precomputed\")\n",
    "    parameters = {'n_neighbors': [1,3,5]}\n",
    "    return model, parameters, \"kNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf100a-6da8-4b89-a9be-8259631741db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "abcd2b91-90cc-44cb-bd99-6d7f5ddada56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(n):\n",
    "    lr = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "    parameters = {'C':loguniform(0.001, 1000), 'penalty': [\"l2\"], \"solver\": [\"lbfgs\", \"sag\"]}\n",
    "    return lr, parameters, \"logistic_regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a4026c4-0b4f-4c6e-b1f1-4f72640506d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(n):\n",
    "    rf = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "    parameters = {'n_estimators': np.arange(1, 200, 10), 'max_depth': np.arange(1, min(50,n), 2), \n",
    "                  'max_features': np.arange(0.1, 0.75, 0.05)}\n",
    "    return rf, parameters, \"random_forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee462921-baee-4031-81ab-70a55154c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(n):\n",
    "    mlp = MLPClassifier(random_state=42, max_iter=int(1000))\n",
    "    parameters = {'hidden_layer_sizes': [(100,), (50,), (100, 100)], \"activation\": [\"relu\", \"logistic\"]}\n",
    "    return mlp, parameters, \"multilayer_perceptron\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de36f9d6-9b40-4420-b4eb-27f540feb1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(n):\n",
    "    svc = SVC(max_iter=8000, probability=True, class_weight='balanced')\n",
    "    parameters = {'C': loguniform(0.001, 100), 'kernel':[\"linear\", \"rbf\"], 'gamma': loguniform(1e-3, 1e0)}\n",
    "    return svc, parameters, \"SVM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11c6c12c-77ad-4b1c-96a0-b0190535f978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting(n):\n",
    "    gb = GradientBoostingClassifier(random_state=42, n_iter_no_change=70)\n",
    "    parameters = {'learning_rate': loguniform(0.01, 0.5), \n",
    "                  'n_estimators': np.arange(1, 200, 10), \n",
    "                  'max_depth': np.arange(1, min(20,n), 2), \n",
    "                  'max_features': np.arange(0.1, 0.6, 0.1)}\n",
    "    return gb, parameters, \"gradient_boosting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522bdca9-8b15-41b5-ba27-4043bae9924a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f49eab4-1c92-401f-8aca-ef05d4e52ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_evaluation(model_type, params, best_params, metrics, data, outpath, preprocessing=None):\n",
    "    prepro = \"_\"+preprocessing if preprocessing is not None else \"\"\n",
    "    filename = os.path.join(DATA_DIR, \"evaluations\", outpath, f\"{model_type}_{data}{prepro}.json\")\n",
    "    out_dict = {\n",
    "        \"model_type\": model_type,\n",
    "        \"data\": data\n",
    "    }\n",
    "    out_dict[\"params\"] = {}\n",
    "    out_dict[\"best_params\"] = {}\n",
    "    for key, value in params.items():\n",
    "        out_dict[\"params\"][key] = str(value)\n",
    "    for key, value in best_params.items():\n",
    "        out_dict[\"best_params\"][key] = str(value)\n",
    "    out_dict[\"metrics\"] = metrics\n",
    "    out_dict[\"preprocessing\"] = \"none\" if preprocessing is None else preprocessing\n",
    "    \n",
    "    json.dump(out_dict, open(filename, \"w\"))\n",
    "    \n",
    "    filename_sum = os.path.join(DATA_DIR, f\"evaluations/{outpath}/all.csv\")\n",
    "    #\"../evaluations/all.csv\"\n",
    "    line = [model_type, data, out_dict[\"preprocessing\"], metrics[\"f1\"], metrics[\"mcc\"], metrics[\"acc\"],metrics[\"precision\"],metrics[\"recall\"],metrics[\"auc\"], filename]\n",
    "    with open(filename_sum, 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter='\\t')\n",
    "        csvwriter.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96bd4c58-b7dd-49f2-bf3d-39b3938f6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(model_name, classifier, parameters, X_train, y_train, X_valid, y_valid, groups,\n",
    "                   data_name, outpath, preprocessing=None):\n",
    "    splitter = LeaveOneGroupOut()\n",
    "    split = splitter.split(X_train, y_train, groups=groups)\n",
    "    grid = RandomizedSearchCV(classifier, parameters, verbose=1, scoring=\"f1\", cv=split)\n",
    "    grid.fit(X_train, y_train)\n",
    "    estimator = grid.best_estimator_\n",
    "    best_params = grid.best_params_\n",
    "    y_pred = estimator.predict(X_valid)\n",
    "    prepro = \"_\"+preprocessing if preprocessing is not None else \"\"\n",
    "    filename = path.join(DATA_DIR, \"evaluations\", outpath, \"models\", f\"{model_name}_{data_name}{prepro}.pkl\")\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(estimator, f)\n",
    "    #pickle.dump(estimator, open(filename, \"w\"))\n",
    "    metric_dict = {\n",
    "        \"f1\": float(metrics.f1_score(y_valid, y_pred)),\n",
    "        \"acc\": float(metrics.accuracy_score(y_valid, y_pred)),\n",
    "        \"mcc\": float(metrics.matthews_corrcoef(y_valid, y_pred)),\n",
    "        \"auc\": float(metrics.roc_auc_score(y_valid, y_pred)),\n",
    "        \"precision\": float(metrics.precision_score(y_valid, y_pred)),\n",
    "        \"recall\": float(metrics.recall_score(y_valid, y_pred))\n",
    "    }\n",
    "    \n",
    "    print(f\"{model_name}, {data_name}\")\n",
    "    print(f\"F1: {metric_dict['f1']}\")\n",
    "    print(f\"MCC: {metric_dict['mcc']}\")\n",
    "    print(f\"Accuracy: {metric_dict['acc']}\")\n",
    "    print(f\"Precision: {metric_dict['precision']}\")\n",
    "    print(f\"Recall: {metric_dict['recall']}\")\n",
    "    print(f\"AUC: {metric_dict['auc']}\")\n",
    "    print(f\"-----\")\n",
    "    \n",
    "    output_evaluation(model_name, parameters, best_params, metric_dict, data_name, outpath, preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e30d50ba-ac70-40e7-9664-72a812e09efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_all(X_train, y_train, X_valid, y_valid, groups, data_name, outpath, preprocessing=None):\n",
    "    n = len(y_train)\n",
    "    for model_creator in [logistic_regression, random_forest, gradient_boosting, svm, multilayer_perceptron]:\n",
    "    #for model_creator in [logistic_regression, random_forest]:\n",
    "\n",
    "        classifier, params, model_label = model_creator(n)\n",
    "        print(\"\\n\")\n",
    "        print(f'Training model {model_label} on data {data_name} \\n')\n",
    "        train_and_eval(model_label, classifier, params, X_train, y_train, X_valid, y_valid, groups,\n",
    "                   data_name, outpath, preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c258711-5e20-4935-9d14-87e78cf57148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c251ae33-a91c-488b-ad0c-86e201870569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_tap(model_name, x_test, y_test,\n",
    "                   data_name, outpath, preprocessing=None):\n",
    "    prepro = \"_\"+preprocessing if preprocessing is not None else \"\"\n",
    "    filename = path.join(DATA_DIR, \"evaluations\", outpath, \"models\", f\"{model_name}_{data_name}{prepro}.pkl\")\n",
    "    with open(filename, 'rb') as f:\n",
    "        estimator = pickle.load(f)\n",
    "    y_pred = estimator.predict(x_test)\n",
    "    metric_dict = {\n",
    "        \"f1\": float(metrics.f1_score(y_test, y_pred)),\n",
    "        \"acc\": float(metrics.accuracy_score(y_test, y_pred)),\n",
    "        \"mcc\": float(metrics.matthews_corrcoef(y_test, y_pred)),\n",
    "        \"auc\": float(metrics.roc_auc_score(y_test, y_pred)),\n",
    "        \"precision\": float(metrics.precision_score(y_test, y_pred)),\n",
    "        \"recall\": float(metrics.recall_score(y_test, y_pred))\n",
    "    }\n",
    "    filename_sum = os.path.join(DATA_DIR, f\"evaluations/{outpath}/tap.csv\")\n",
    "    line = [model_name, data_name, prepro, metric_dict[\"f1\"], metric_dict[\"mcc\"], metric_dict[\"acc\"],metric_dict[\"precision\"],metric_dict[\"recall\"],metric_dict[\"auc\"], filename]\n",
    "    with open(filename_sum, 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter='\\t')\n",
    "        csvwriter.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a645101-12f1-4883-8607-f534340dc383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all(x_test, y_test, data_name, outpath, preprocessing=None):\n",
    "    for model in [\"logistic_regression\", \"random_forest\", \"gradient_boosting\", \"SVM\", \"multilayer_perceptron\"]:\n",
    "        print(f\"Testing model {model} on {data_name}...\")\n",
    "        test_on_tap(model, x_test, y_test, data_name, outpath, preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d383239-122b-4615-b75d-1af5068ad90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "781371cb-dca2-4c76-8f60-8ef19bfc9171",
   "metadata": {},
   "source": [
    "# Numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c9626df9-c79a-4482-a1c9-611270e5916d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ab_ID   0   1   2   3   4   5   6  7  8  ...  271  272  273  274  275  \\\n",
       "2073  6aod   4  18  14  10  18  14  16  6  1  ...    0    0    0    0    0   \n",
       "1517  4yny   4  18  14  10  18   4  16  6  6  ...    0    0    0    0    0   \n",
       "2025  5xcv   4  18  14  10  18   4  16  6  6  ...    0    0    0    0    0   \n",
       "2070  6and   4  18  14  10  18   4  16  6  6  ...    0    0    0    0    0   \n",
       "666   2xqy  14  18  14  10  14  14  13  6  1  ...    0    0    0    0    0   \n",
       "\n",
       "      276  277  278  279  280  \n",
       "2073    0    0    0    0    0  \n",
       "1517    0    0    0    0    0  \n",
       "2025    0    0    0    0    0  \n",
       "2070    0    0    0    0    0  \n",
       "666     0    0    0    0    0  \n",
       "\n",
       "[5 rows x 282 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chen = pd.read_csv(path.join(DATA_DIR, \"chen/integer_encoding/chen_integer_encoded.csv\"), index_col=0)\n",
    "x_chen_train = x_chen.loc[chen_train.index]\n",
    "x_chen_test = x_chen.loc[chen_test.index]\n",
    "x_chen_valid = x_chen.loc[chen_valid.index]\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4266f527-5492-41af-bb0a-fc03869c6ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_chen_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "818fd933-7d16-47c3-a76c-088b80572c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abagovomab</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abituzumab</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrilumab</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actoxumab</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adalimumab</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ab_ID   0   1   2   3   4   5   6  7  8  ...  271  272  273  274  275  \\\n",
       "0  Abagovomab  14  18   9  10  14   4  16  6  1  ...    0    0    0    0    0   \n",
       "1  Abituzumab  14  18  14  10  14  14  16  6  6  ...    0    0    0    0    0   \n",
       "2   Abrilumab  14  18  14  10  18  14  16  6  1  ...    0    0    0    0    0   \n",
       "3   Actoxumab  14  18  14  10  18   4  16  6  6  ...    0    0    0    0    0   \n",
       "4  Adalimumab   4  18  14  10  18   4  16  6  6  ...    0    0    0    0    0   \n",
       "\n",
       "   276  277  278  279  280  \n",
       "0    0    0    0    0    0  \n",
       "1    0    0    0    0    0  \n",
       "2    0    0    0    0    0  \n",
       "3    0    0    0    0    0  \n",
       "4    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 282 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tap = pd.read_csv(path.join(DATA_DIR, \"tap/integer_encoding/tap_integer_encoded.csv\"))\n",
    "x_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e409afe3-d1ec-4c05-acc3-ef2710dba966",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data integer_encoded \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression, integer_encoded\n",
      "F1: 0.40310077519379844\n",
      "MCC: 0.21080214098455255\n",
      "Accuracy: 0.6778242677824268\n",
      "Precision: 0.325\n",
      "Recall: 0.5306122448979592\n",
      "AUC: 0.6232008592910849\n",
      "-----\n",
      "\n",
      "\n",
      "Training model random_forest on data integer_encoded \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "random_forest, integer_encoded\n",
      "F1: 0.1917808219178082\n",
      "MCC: 0.07170619823815144\n",
      "Accuracy: 0.7531380753138075\n",
      "Precision: 0.2916666666666667\n",
      "Recall: 0.14285714285714285\n",
      "AUC: 0.5266917293233082\n",
      "-----\n",
      "\n",
      "\n",
      "Training model gradient_boosting on data integer_encoded \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_boosting, integer_encoded\n",
      "F1: 0.24000000000000002\n",
      "MCC: 0.12213728932311312\n",
      "Accuracy: 0.7615062761506276\n",
      "Precision: 0.34615384615384615\n",
      "Recall: 0.1836734693877551\n",
      "AUC: 0.5470998925886144\n",
      "-----\n",
      "\n",
      "\n",
      "Training model SVM on data integer_encoded \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, integer_encoded\n",
      "F1: 0.36363636363636365\n",
      "MCC: 0.15201279728782768\n",
      "Accuracy: 0.6485355648535565\n",
      "Precision: 0.2891566265060241\n",
      "Recall: 0.4897959183673469\n",
      "AUC: 0.5896348012889365\n",
      "-----\n",
      "\n",
      "\n",
      "Training model multilayer_perceptron on data integer_encoded \n",
      "\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "multilayer_perceptron, integer_encoded\n",
      "F1: 0.3146067415730337\n",
      "MCC: 0.16100221685529514\n",
      "Accuracy: 0.7447698744769874\n",
      "Precision: 0.35\n",
      "Recall: 0.2857142857142857\n",
      "AUC: 0.5744360902255639\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train.drop(\"Ab_ID\", axis=1), chen_train[\"Y\"], x_chen_valid.drop(\"Ab_ID\", axis=1), chen_valid[\"Y\"], chen_train[\"cluster_merged\"], \"integer_encoded\", EVAL_DIR, preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fbac6348-5ffc-48f9-a67d-2328009f2d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on integer_encoded...\n",
      "Testing model random_forest on integer_encoded...\n",
      "Testing model gradient_boosting on integer_encoded...\n",
      "Testing model SVM on integer_encoded...\n",
      "Testing model multilayer_perceptron on integer_encoded...\n"
     ]
    }
   ],
   "source": [
    "test_all(x_tap.drop(\"Ab_ID\", axis=1), tap_data[\"Y\"], \"integer_encoded\", EVAL_DIR, preprocessing=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a14fdc-99e4-4748-822d-88fddfb49f52",
   "metadata": {},
   "source": [
    "# PyBioMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "544a4e36-4667-41e9-9602-f418aa27a636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>19752</th>\n",
       "      <th>19753</th>\n",
       "      <th>19754</th>\n",
       "      <th>19755</th>\n",
       "      <th>19756</th>\n",
       "      <th>19757</th>\n",
       "      <th>19758</th>\n",
       "      <th>19759</th>\n",
       "      <th>Y</th>\n",
       "      <th>cluster_merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1a0q</td>\n",
       "      <td>5.882</td>\n",
       "      <td>1.681</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.042</td>\n",
       "      <td>1.681</td>\n",
       "      <td>5.882</td>\n",
       "      <td>5.042</td>\n",
       "      <td>9.244</td>\n",
       "      <td>1.681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1a14</td>\n",
       "      <td>6.667</td>\n",
       "      <td>2.500</td>\n",
       "      <td>4.167</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.667</td>\n",
       "      <td>2.500</td>\n",
       "      <td>7.500</td>\n",
       "      <td>11.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a2y</td>\n",
       "      <td>3.448</td>\n",
       "      <td>5.172</td>\n",
       "      <td>4.310</td>\n",
       "      <td>6.034</td>\n",
       "      <td>1.724</td>\n",
       "      <td>2.586</td>\n",
       "      <td>6.034</td>\n",
       "      <td>10.345</td>\n",
       "      <td>0.862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a3l</td>\n",
       "      <td>5.882</td>\n",
       "      <td>3.361</td>\n",
       "      <td>2.521</td>\n",
       "      <td>3.361</td>\n",
       "      <td>1.681</td>\n",
       "      <td>5.882</td>\n",
       "      <td>3.361</td>\n",
       "      <td>13.445</td>\n",
       "      <td>0.840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a4j</td>\n",
       "      <td>7.563</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.042</td>\n",
       "      <td>3.361</td>\n",
       "      <td>1.681</td>\n",
       "      <td>5.882</td>\n",
       "      <td>4.202</td>\n",
       "      <td>9.244</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19763 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ab_ID      0      1      2      3      4      5      6       7      8  ...  \\\n",
       "0  1a0q  5.882  1.681  3.361  5.042  1.681  5.882  5.042   9.244  1.681  ...   \n",
       "1  1a14  6.667  2.500  4.167  5.000  1.667  2.500  7.500  11.667  0.000  ...   \n",
       "2  1a2y  3.448  5.172  4.310  6.034  1.724  2.586  6.034  10.345  0.862  ...   \n",
       "3  1a3l  5.882  3.361  2.521  3.361  1.681  5.882  3.361  13.445  0.840  ...   \n",
       "4  1a4j  7.563  3.361  5.042  3.361  1.681  5.882  4.202   9.244  0.000  ...   \n",
       "\n",
       "   19752  19753  19754  19755  19756  19757  19758  19759  Y  cluster_merged  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  1               2  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0               4  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0               1  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0               4  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0               7  \n",
       "\n",
       "[5 rows x 19763 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chen = pd.read_feather(path.join(DATA_DIR, \"chen/pybiomed/X_data.ftr\"))\n",
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_valid = x_chen.merge(chen_valid[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70f1926e-51a4-4f47-b9e2-ca3759a51d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19750</th>\n",
       "      <th>19751</th>\n",
       "      <th>19752</th>\n",
       "      <th>19753</th>\n",
       "      <th>19754</th>\n",
       "      <th>19755</th>\n",
       "      <th>19756</th>\n",
       "      <th>19757</th>\n",
       "      <th>19758</th>\n",
       "      <th>19759</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.084</td>\n",
       "      <td>3.361</td>\n",
       "      <td>2.521</td>\n",
       "      <td>3.361</td>\n",
       "      <td>1.681</td>\n",
       "      <td>3.361</td>\n",
       "      <td>5.882</td>\n",
       "      <td>11.765</td>\n",
       "      <td>0.840</td>\n",
       "      <td>1.681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.627</td>\n",
       "      <td>4.237</td>\n",
       "      <td>1.695</td>\n",
       "      <td>3.390</td>\n",
       "      <td>1.695</td>\n",
       "      <td>5.085</td>\n",
       "      <td>5.932</td>\n",
       "      <td>10.169</td>\n",
       "      <td>0.847</td>\n",
       "      <td>2.542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.932</td>\n",
       "      <td>1.695</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.932</td>\n",
       "      <td>1.695</td>\n",
       "      <td>5.085</td>\n",
       "      <td>6.780</td>\n",
       "      <td>10.169</td>\n",
       "      <td>0.847</td>\n",
       "      <td>1.695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.738</td>\n",
       "      <td>6.557</td>\n",
       "      <td>4.098</td>\n",
       "      <td>5.738</td>\n",
       "      <td>1.639</td>\n",
       "      <td>3.279</td>\n",
       "      <td>4.918</td>\n",
       "      <td>11.475</td>\n",
       "      <td>0.820</td>\n",
       "      <td>3.279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.091</td>\n",
       "      <td>4.959</td>\n",
       "      <td>3.306</td>\n",
       "      <td>5.785</td>\n",
       "      <td>1.653</td>\n",
       "      <td>4.132</td>\n",
       "      <td>4.132</td>\n",
       "      <td>9.091</td>\n",
       "      <td>1.653</td>\n",
       "      <td>2.479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19760 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5      6       7      8      9  \\\n",
       "0  10.084  3.361  2.521  3.361  1.681  3.361  5.882  11.765  0.840  1.681   \n",
       "1   7.627  4.237  1.695  3.390  1.695  5.085  5.932  10.169  0.847  2.542   \n",
       "2   5.932  1.695  0.000  5.932  1.695  5.085  6.780  10.169  0.847  1.695   \n",
       "3   5.738  6.557  4.098  5.738  1.639  3.279  4.918  11.475  0.820  3.279   \n",
       "4   9.091  4.959  3.306  5.785  1.653  4.132  4.132   9.091  1.653  2.479   \n",
       "\n",
       "   ...  19750  19751  19752  19753  19754  19755  19756  19757  19758  19759  \n",
       "0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 19760 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tap = pd.read_feather(path.join(DATA_DIR, \"tap/pybiomed/X_TAP_data.ftr\"))\n",
    "x_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e1f4a96-fb3a-4daf-bb81-92817b5e393e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data pybiomed \n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/pbs.31824.lich-compute.vscht.cz/ipykernel_46175/2265526379.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtry_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_chen_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ab_ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchen_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_chen_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ab_ID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchen_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchen_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cluster_merged\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pybiomed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVAL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.31824.lich-compute.vscht.cz/ipykernel_46175/3930899140.py\u001b[0m in \u001b[0;36mtry_all\u001b[0;34m(X_train, y_train, X_valid, y_valid, groups, data_name, outpath, preprocessing)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training model {model_label} on data {data_name} \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         train_and_eval(model_label, classifier, params, X_train, y_train, X_valid, y_valid, groups,\n\u001b[0;32m---> 10\u001b[0;31m                    data_name, outpath, preprocessing)\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.31824.lich-compute.vscht.cz/ipykernel_46175/1048747879.py\u001b[0m in \u001b[0;36mtrain_and_eval\u001b[0;34m(model_name, classifier, parameters, X_train, y_train, X_valid, y_valid, groups, data_name, outpath, preprocessing)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m         evaluate_candidates(\n\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m-> 1768\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m             )\n\u001b[1;32m   1770\u001b[0m         )\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1612\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             )\n\u001b[0;32m-> 1614\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m         )\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    810\u001b[0m                 \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iprint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m             )\n\u001b[1;32m    814\u001b[0m             n_iter_i = _check_optimize_result(\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 618\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    619\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;31m# Logistic loss is the negative of the log of the logistic function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_logistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train.drop([\"Ab_ID\", \"Y\", \"cluster_merged\"], axis=1), x_chen_train[\"Y\"], \n",
    "        x_chen_valid.drop([\"Ab_ID\", \"Y\"], axis=1),  x_chen_valid[\"Y\"], \n",
    "        x_chen_train[\"cluster_merged\"], \"pybiomed\", EVAL_DIR, preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4decb380-03ea-45af-8cf1-a0cbff43e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all(x_tap, tap_data[\"Y\"], \"pybiomed\", EVAL_DIR, preprocessing=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77646694-01c8-4a7f-af38-15c2afc8f59a",
   "metadata": {},
   "source": [
    "# Protparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42310c2b-2bbf-4f1a-8507-174b3bf6173d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>aa_percent0_x</th>\n",
       "      <th>aa_percent1_x</th>\n",
       "      <th>aa_percent2_x</th>\n",
       "      <th>aa_percent3_x</th>\n",
       "      <th>aa_percent4_x</th>\n",
       "      <th>aa_percent5_x</th>\n",
       "      <th>aa_percent6_x</th>\n",
       "      <th>aa_percent7_x</th>\n",
       "      <th>aa_percent8_x</th>\n",
       "      <th>...</th>\n",
       "      <th>mol_extinct1_y</th>\n",
       "      <th>mol_extinct2_y</th>\n",
       "      <th>mw_y</th>\n",
       "      <th>gravy_y</th>\n",
       "      <th>ss_faction1_y</th>\n",
       "      <th>ss_faction2_y</th>\n",
       "      <th>ss_faction3_y</th>\n",
       "      <th>name</th>\n",
       "      <th>Y</th>\n",
       "      <th>cluster_merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3okd</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.106557</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>...</td>\n",
       "      <td>19940</td>\n",
       "      <td>20065</td>\n",
       "      <td>12297.7329</td>\n",
       "      <td>-0.427679</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.294643</td>\n",
       "      <td>0.205357</td>\n",
       "      <td>3okd</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5fb8</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.041322</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>0.033058</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>...</td>\n",
       "      <td>15930</td>\n",
       "      <td>16055</td>\n",
       "      <td>12046.3419</td>\n",
       "      <td>-0.344144</td>\n",
       "      <td>0.279279</td>\n",
       "      <td>0.306306</td>\n",
       "      <td>0.225225</td>\n",
       "      <td>5fb8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4olz</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>...</td>\n",
       "      <td>21430</td>\n",
       "      <td>21555</td>\n",
       "      <td>11093.1436</td>\n",
       "      <td>-0.370297</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.158416</td>\n",
       "      <td>4olz</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5i19</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.134454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>...</td>\n",
       "      <td>14440</td>\n",
       "      <td>14565</td>\n",
       "      <td>11531.7166</td>\n",
       "      <td>-0.316822</td>\n",
       "      <td>0.271028</td>\n",
       "      <td>0.327103</td>\n",
       "      <td>0.158879</td>\n",
       "      <td>5i19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2xqb</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>...</td>\n",
       "      <td>26930</td>\n",
       "      <td>27055</td>\n",
       "      <td>11672.8413</td>\n",
       "      <td>-0.599057</td>\n",
       "      <td>0.273585</td>\n",
       "      <td>0.330189</td>\n",
       "      <td>0.179245</td>\n",
       "      <td>2xqb</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ab_ID  aa_percent0_x  aa_percent1_x  aa_percent2_x  aa_percent3_x  \\\n",
       "0  3okd       0.081967       0.016393       0.040984       0.049180   \n",
       "1  5fb8       0.049587       0.016529       0.049587       0.041322   \n",
       "2  4olz       0.056000       0.032000       0.048000       0.040000   \n",
       "3  5i19       0.075630       0.016807       0.042017       0.042017   \n",
       "4  2xqb       0.096000       0.016000       0.048000       0.024000   \n",
       "\n",
       "   aa_percent4_x  aa_percent5_x  aa_percent6_x  aa_percent7_x  aa_percent8_x  \\\n",
       "0       0.040984       0.106557       0.008197       0.016393       0.040984   \n",
       "1       0.024793       0.074380       0.016529       0.033058       0.074380   \n",
       "2       0.032000       0.088000       0.008000       0.032000       0.040000   \n",
       "3       0.033613       0.134454       0.000000       0.025210       0.033613   \n",
       "4       0.040000       0.080000       0.000000       0.016000       0.048000   \n",
       "\n",
       "   ...  mol_extinct1_y  mol_extinct2_y        mw_y   gravy_y  ss_faction1_y  \\\n",
       "0  ...           19940           20065  12297.7329 -0.427679       0.276786   \n",
       "1  ...           15930           16055  12046.3419 -0.344144       0.279279   \n",
       "2  ...           21430           21555  11093.1436 -0.370297       0.306931   \n",
       "3  ...           14440           14565  11531.7166 -0.316822       0.271028   \n",
       "4  ...           26930           27055  11672.8413 -0.599057       0.273585   \n",
       "\n",
       "   ss_faction2_y  ss_faction3_y  name  Y  cluster_merged  \n",
       "0       0.294643       0.205357  3okd  1               1  \n",
       "1       0.306306       0.225225  5fb8  1               0  \n",
       "2       0.316832       0.158416  4olz  0               1  \n",
       "3       0.327103       0.158879  5i19  1               0  \n",
       "4       0.330189       0.179245  2xqb  0               7  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chen = pd.read_csv(path.join(DATA_DIR, \"chen/protparam/protparam_features.csv\"))\n",
    "x_chen.rename({\"Unnamed: 0\": \"Ab_ID\"}, axis=1, inplace=True)\n",
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_valid = x_chen.merge(chen_valid[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ad9974e-c757-4f91-800f-b2bb9daed827",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data protparam \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression, protparam\n",
      "F1: 0.23529411764705882\n",
      "MCC: -0.06944837816027288\n",
      "Accuracy: 0.5104602510460251\n",
      "Precision: 0.17307692307692307\n",
      "Recall: 0.3673469387755102\n",
      "AUC: 0.45735767991407084\n",
      "-----\n",
      "\n",
      "\n",
      "Training model random_forest on data protparam \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest, protparam\n",
      "F1: 0.16822429906542055\n",
      "MCC: -0.06989561373566464\n",
      "Accuracy: 0.6276150627615062\n",
      "Precision: 0.15517241379310345\n",
      "Recall: 0.1836734693877551\n",
      "AUC: 0.4628893662728249\n",
      "-----\n",
      "\n",
      "\n",
      "Training model gradient_boosting on data protparam \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_boosting, protparam\n",
      "F1: 0.061538461538461535\n",
      "MCC: -0.0530926207120254\n",
      "Accuracy: 0.7447698744769874\n",
      "Precision: 0.125\n",
      "Recall: 0.04081632653061224\n",
      "AUC: 0.48356605800214825\n",
      "-----\n",
      "\n",
      "\n",
      "Training model SVM on data protparam \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, protparam\n",
      "F1: 0.30414746543778803\n",
      "MCC: -0.03273862529959418\n",
      "Accuracy: 0.3682008368200837\n",
      "Precision: 0.19642857142857142\n",
      "Recall: 0.673469387755102\n",
      "AUC: 0.48147153598281417\n",
      "-----\n",
      "\n",
      "\n",
      "Training model multilayer_perceptron on data protparam \n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "multilayer_perceptron, protparam\n",
      "F1: 0.14285714285714285\n",
      "MCC: 0.02542701348578424\n",
      "Accuracy: 0.7489539748953975\n",
      "Precision: 0.23809523809523808\n",
      "Recall: 0.10204081632653061\n",
      "AUC: 0.5089151450053705\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train.drop([\"Ab_ID\", \"name\", \"Y\", \"cluster_merged\"], axis=1), x_chen_train[\"Y\"], x_chen_valid.drop([\"Ab_ID\", \"name\", \"Y\", \"cluster_merged\"], axis=1), x_chen_valid[\"Y\"], x_chen_train[\"cluster_merged\"], \"protparam\", EVAL_DIR, preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4c59fe1-7803-4d34-af4e-ad50f2153c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>aa_percent0_x</th>\n",
       "      <th>aa_percent1_x</th>\n",
       "      <th>aa_percent2_x</th>\n",
       "      <th>aa_percent3_x</th>\n",
       "      <th>aa_percent4_x</th>\n",
       "      <th>aa_percent5_x</th>\n",
       "      <th>aa_percent6_x</th>\n",
       "      <th>aa_percent7_x</th>\n",
       "      <th>aa_percent8_x</th>\n",
       "      <th>...</th>\n",
       "      <th>instability_y</th>\n",
       "      <th>flexibility_y</th>\n",
       "      <th>isoelectric_y</th>\n",
       "      <th>mol_extinct1_y</th>\n",
       "      <th>mol_extinct2_y</th>\n",
       "      <th>mw_y</th>\n",
       "      <th>gravy_y</th>\n",
       "      <th>ss_faction1_y</th>\n",
       "      <th>ss_faction2_y</th>\n",
       "      <th>ss_faction3_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abagovomab</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>...</td>\n",
       "      <td>53.693458</td>\n",
       "      <td>0.999564</td>\n",
       "      <td>7.973724</td>\n",
       "      <td>14440</td>\n",
       "      <td>14565</td>\n",
       "      <td>11556.8384</td>\n",
       "      <td>-0.257009</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>0.196262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abituzumab</td>\n",
       "      <td>0.076271</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.033898</td>\n",
       "      <td>...</td>\n",
       "      <td>42.514019</td>\n",
       "      <td>1.001379</td>\n",
       "      <td>8.586625</td>\n",
       "      <td>17420</td>\n",
       "      <td>17545</td>\n",
       "      <td>11762.9686</td>\n",
       "      <td>-0.452336</td>\n",
       "      <td>0.280374</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>0.121495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrilumab</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>...</td>\n",
       "      <td>40.151402</td>\n",
       "      <td>1.002818</td>\n",
       "      <td>7.970307</td>\n",
       "      <td>22460</td>\n",
       "      <td>22585</td>\n",
       "      <td>11548.7104</td>\n",
       "      <td>-0.335514</td>\n",
       "      <td>0.271028</td>\n",
       "      <td>0.336449</td>\n",
       "      <td>0.158879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actoxumab</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.024590</td>\n",
       "      <td>...</td>\n",
       "      <td>51.517757</td>\n",
       "      <td>1.000328</td>\n",
       "      <td>8.682102</td>\n",
       "      <td>22460</td>\n",
       "      <td>22585</td>\n",
       "      <td>11530.7383</td>\n",
       "      <td>-0.260748</td>\n",
       "      <td>0.271028</td>\n",
       "      <td>0.317757</td>\n",
       "      <td>0.158879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adalimumab</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>0.057851</td>\n",
       "      <td>0.041322</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>0.024793</td>\n",
       "      <td>...</td>\n",
       "      <td>46.585047</td>\n",
       "      <td>1.000522</td>\n",
       "      <td>9.428646</td>\n",
       "      <td>15930</td>\n",
       "      <td>16055</td>\n",
       "      <td>11664.9632</td>\n",
       "      <td>-0.402804</td>\n",
       "      <td>0.271028</td>\n",
       "      <td>0.289720</td>\n",
       "      <td>0.168224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ab_ID  aa_percent0_x  aa_percent1_x  aa_percent2_x  aa_percent3_x  \\\n",
       "0  Abagovomab       0.100840       0.016807       0.033613       0.033613   \n",
       "1  Abituzumab       0.076271       0.016949       0.033898       0.050847   \n",
       "2   Abrilumab       0.059322       0.016949       0.059322       0.050847   \n",
       "3   Actoxumab       0.057377       0.016393       0.057377       0.032787   \n",
       "4  Adalimumab       0.090909       0.016529       0.057851       0.041322   \n",
       "\n",
       "   aa_percent4_x  aa_percent5_x  aa_percent6_x  aa_percent7_x  aa_percent8_x  \\\n",
       "0       0.025210       0.117647       0.008403       0.016807       0.067227   \n",
       "1       0.033898       0.101695       0.008475       0.025424       0.033898   \n",
       "2       0.025424       0.101695       0.008475       0.016949       0.059322   \n",
       "3       0.032787       0.114754       0.008197       0.032787       0.024590   \n",
       "4       0.024793       0.090909       0.016529       0.024793       0.024793   \n",
       "\n",
       "   ...  instability_y  flexibility_y  isoelectric_y  mol_extinct1_y  \\\n",
       "0  ...      53.693458       0.999564       7.973724           14440   \n",
       "1  ...      42.514019       1.001379       8.586625           17420   \n",
       "2  ...      40.151402       1.002818       7.970307           22460   \n",
       "3  ...      51.517757       1.000328       8.682102           22460   \n",
       "4  ...      46.585047       1.000522       9.428646           15930   \n",
       "\n",
       "   mol_extinct2_y        mw_y   gravy_y  ss_faction1_y  ss_faction2_y  \\\n",
       "0           14565  11556.8384 -0.257009       0.299065       0.299065   \n",
       "1           17545  11762.9686 -0.452336       0.280374       0.299065   \n",
       "2           22585  11548.7104 -0.335514       0.271028       0.336449   \n",
       "3           22585  11530.7383 -0.260748       0.271028       0.317757   \n",
       "4           16055  11664.9632 -0.402804       0.271028       0.289720   \n",
       "\n",
       "   ss_faction3_y  \n",
       "0       0.196262  \n",
       "1       0.121495  \n",
       "2       0.158879  \n",
       "3       0.158879  \n",
       "4       0.168224  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tap = pd.read_csv(path.join(DATA_DIR, \"tap/protparam/protparam_features_tap.csv\"))\n",
    "x_tap.rename({\"Unnamed: 0\": \"Ab_ID\"}, axis=1, inplace=True)\n",
    "x_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2f015dd7-2d97-447e-b6c9-f1ad31807865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on protparam...\n",
      "Testing model random_forest on protparam...\n",
      "Testing model gradient_boosting on protparam...\n",
      "Testing model SVM on protparam...\n",
      "Testing model multilayer_perceptron on protparam...\n"
     ]
    }
   ],
   "source": [
    "test_all(x_tap.drop(\"Ab_ID\", axis=1), tap_data[\"Y\"], \"protparam\", EVAL_DIR, preprocessing=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca554f3e-5877-44b1-9fc8-f80b1dbcbc44",
   "metadata": {},
   "source": [
    "# BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a16dceef-1516-4b03-b681-194070178a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>0.020196</td>\n",
       "      <td>-0.020793</td>\n",
       "      <td>-0.010549</td>\n",
       "      <td>-0.038375</td>\n",
       "      <td>0.066936</td>\n",
       "      <td>-0.022921</td>\n",
       "      <td>0.017874</td>\n",
       "      <td>-0.088493</td>\n",
       "      <td>-0.018926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>-0.003466</td>\n",
       "      <td>-0.014579</td>\n",
       "      <td>0.007682</td>\n",
       "      <td>-0.027888</td>\n",
       "      <td>0.026192</td>\n",
       "      <td>-0.040531</td>\n",
       "      <td>-0.010679</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>-0.027332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>-0.007447</td>\n",
       "      <td>-0.058638</td>\n",
       "      <td>0.013139</td>\n",
       "      <td>-0.029136</td>\n",
       "      <td>0.074901</td>\n",
       "      <td>-0.025573</td>\n",
       "      <td>0.035983</td>\n",
       "      <td>-0.105274</td>\n",
       "      <td>-0.014490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008387</td>\n",
       "      <td>0.007312</td>\n",
       "      <td>-0.013750</td>\n",
       "      <td>-0.003369</td>\n",
       "      <td>0.007132</td>\n",
       "      <td>0.042410</td>\n",
       "      <td>-0.044542</td>\n",
       "      <td>-0.034221</td>\n",
       "      <td>-0.023036</td>\n",
       "      <td>-0.013044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>-0.005372</td>\n",
       "      <td>-0.056795</td>\n",
       "      <td>0.012577</td>\n",
       "      <td>-0.031566</td>\n",
       "      <td>0.071131</td>\n",
       "      <td>-0.023377</td>\n",
       "      <td>0.037339</td>\n",
       "      <td>-0.102565</td>\n",
       "      <td>-0.009340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>0.003619</td>\n",
       "      <td>-0.015327</td>\n",
       "      <td>-0.003542</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.043285</td>\n",
       "      <td>-0.046977</td>\n",
       "      <td>-0.033989</td>\n",
       "      <td>-0.025775</td>\n",
       "      <td>-0.012205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>-0.004229</td>\n",
       "      <td>-0.043975</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>-0.031739</td>\n",
       "      <td>0.070902</td>\n",
       "      <td>-0.022174</td>\n",
       "      <td>0.038274</td>\n",
       "      <td>-0.111665</td>\n",
       "      <td>-0.030382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>-0.016125</td>\n",
       "      <td>-0.021334</td>\n",
       "      <td>-0.005837</td>\n",
       "      <td>-0.025217</td>\n",
       "      <td>0.024086</td>\n",
       "      <td>-0.032259</td>\n",
       "      <td>-0.023480</td>\n",
       "      <td>-0.013043</td>\n",
       "      <td>-0.035664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>-0.018278</td>\n",
       "      <td>-0.001506</td>\n",
       "      <td>-0.037899</td>\n",
       "      <td>0.050809</td>\n",
       "      <td>-0.026173</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>-0.090757</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003720</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>-0.036547</td>\n",
       "      <td>-0.009119</td>\n",
       "      <td>-0.038372</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>-0.030063</td>\n",
       "      <td>-0.003554</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>-0.041985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ab_ID         0         1         2         3         4         5  \\\n",
       "2073  6aod  0.020196 -0.020793 -0.010549 -0.038375  0.066936 -0.022921   \n",
       "1517  4yny -0.007447 -0.058638  0.013139 -0.029136  0.074901 -0.025573   \n",
       "2025  5xcv -0.005372 -0.056795  0.012577 -0.031566  0.071131 -0.023377   \n",
       "2070  6and -0.004229 -0.043975  0.003673 -0.031739  0.070902 -0.022174   \n",
       "666   2xqy  0.003754 -0.018278 -0.001506 -0.037899  0.050809 -0.026173   \n",
       "\n",
       "             6         7         8  ...      2038      2039      2040  \\\n",
       "2073  0.017874 -0.088493 -0.018926  ...  0.001973 -0.003466 -0.014579   \n",
       "1517  0.035983 -0.105274 -0.014490  ...  0.008387  0.007312 -0.013750   \n",
       "2025  0.037339 -0.102565 -0.009340  ...  0.008306  0.003619 -0.015327   \n",
       "2070  0.038274 -0.111665 -0.030382  ...  0.006203 -0.016125 -0.021334   \n",
       "666   0.003026 -0.090757  0.005515  ... -0.003720  0.004341 -0.036547   \n",
       "\n",
       "          2041      2042      2043      2044      2045      2046      2047  \n",
       "2073  0.007682 -0.027888  0.026192 -0.040531 -0.010679  0.007133 -0.027332  \n",
       "1517 -0.003369  0.007132  0.042410 -0.044542 -0.034221 -0.023036 -0.013044  \n",
       "2025 -0.003542  0.003720  0.043285 -0.046977 -0.033989 -0.025775 -0.012205  \n",
       "2070 -0.005837 -0.025217  0.024086 -0.032259 -0.023480 -0.013043 -0.035664  \n",
       "666  -0.009119 -0.038372  0.023391 -0.030063 -0.003554  0.000142 -0.041985  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chen = pd.read_feather(path.join(DATA_DIR, \"chen/embeddings/bert/bert_chen_embeddings.ftr\"))\n",
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_valid = x_chen.merge(chen_valid[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90b0e22e-3342-4a63-8d0f-4247f103ef11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abagovomab</td>\n",
       "      <td>-0.004248</td>\n",
       "      <td>-0.024501</td>\n",
       "      <td>-0.011330</td>\n",
       "      <td>-0.027170</td>\n",
       "      <td>0.062747</td>\n",
       "      <td>-0.024793</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>-0.083316</td>\n",
       "      <td>-0.005339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008674</td>\n",
       "      <td>-0.002387</td>\n",
       "      <td>-0.021563</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>-0.020986</td>\n",
       "      <td>0.047104</td>\n",
       "      <td>-0.038736</td>\n",
       "      <td>-0.021780</td>\n",
       "      <td>-0.022153</td>\n",
       "      <td>-0.024539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abituzumab</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>-0.013591</td>\n",
       "      <td>-0.008454</td>\n",
       "      <td>-0.043601</td>\n",
       "      <td>0.065095</td>\n",
       "      <td>-0.016896</td>\n",
       "      <td>-0.001596</td>\n",
       "      <td>-0.090935</td>\n",
       "      <td>-0.002940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>-0.013063</td>\n",
       "      <td>-0.021852</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>-0.024620</td>\n",
       "      <td>0.027387</td>\n",
       "      <td>-0.041001</td>\n",
       "      <td>-0.025708</td>\n",
       "      <td>-0.016437</td>\n",
       "      <td>-0.034342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrilumab</td>\n",
       "      <td>0.019445</td>\n",
       "      <td>-0.002642</td>\n",
       "      <td>-0.011395</td>\n",
       "      <td>-0.058757</td>\n",
       "      <td>0.060623</td>\n",
       "      <td>-0.015046</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>-0.083772</td>\n",
       "      <td>-0.006775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>-0.017189</td>\n",
       "      <td>-0.014557</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>-0.035368</td>\n",
       "      <td>0.020287</td>\n",
       "      <td>-0.033941</td>\n",
       "      <td>-0.023549</td>\n",
       "      <td>-0.008720</td>\n",
       "      <td>-0.044038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actoxumab</td>\n",
       "      <td>-0.006365</td>\n",
       "      <td>-0.043729</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>-0.025613</td>\n",
       "      <td>0.067748</td>\n",
       "      <td>-0.009542</td>\n",
       "      <td>0.017723</td>\n",
       "      <td>-0.096801</td>\n",
       "      <td>-0.007752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.012986</td>\n",
       "      <td>-0.019753</td>\n",
       "      <td>-0.004326</td>\n",
       "      <td>-0.044124</td>\n",
       "      <td>0.019544</td>\n",
       "      <td>-0.039559</td>\n",
       "      <td>-0.015679</td>\n",
       "      <td>-0.008837</td>\n",
       "      <td>-0.043877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adalimumab</td>\n",
       "      <td>-0.012995</td>\n",
       "      <td>-0.035269</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>-0.042136</td>\n",
       "      <td>0.080592</td>\n",
       "      <td>-0.012831</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>-0.091308</td>\n",
       "      <td>-0.018166</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>-0.022957</td>\n",
       "      <td>-0.021145</td>\n",
       "      <td>-0.002762</td>\n",
       "      <td>-0.058199</td>\n",
       "      <td>0.026781</td>\n",
       "      <td>-0.046815</td>\n",
       "      <td>-0.010110</td>\n",
       "      <td>-0.008785</td>\n",
       "      <td>-0.041761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ab_ID         0         1         2         3         4         5  \\\n",
       "0  Abagovomab -0.004248 -0.024501 -0.011330 -0.027170  0.062747 -0.024793   \n",
       "1  Abituzumab  0.006593 -0.013591 -0.008454 -0.043601  0.065095 -0.016896   \n",
       "2   Abrilumab  0.019445 -0.002642 -0.011395 -0.058757  0.060623 -0.015046   \n",
       "3   Actoxumab -0.006365 -0.043729  0.005978 -0.025613  0.067748 -0.009542   \n",
       "4  Adalimumab -0.012995 -0.035269  0.014127 -0.042136  0.080592 -0.012831   \n",
       "\n",
       "          6         7         8  ...      2038      2039      2040      2041  \\\n",
       "0  0.009313 -0.083316 -0.005339  ... -0.008674 -0.002387 -0.021563  0.001087   \n",
       "1 -0.001596 -0.090935 -0.002940  ...  0.000486 -0.013063 -0.021852 -0.003531   \n",
       "2  0.006317 -0.083772 -0.006775  ...  0.005834 -0.017189 -0.014557  0.003359   \n",
       "3  0.017723 -0.096801 -0.007752  ... -0.000024 -0.012986 -0.019753 -0.004326   \n",
       "4  0.031889 -0.091308 -0.018166  ... -0.002067 -0.022957 -0.021145 -0.002762   \n",
       "\n",
       "       2042      2043      2044      2045      2046      2047  \n",
       "0 -0.020986  0.047104 -0.038736 -0.021780 -0.022153 -0.024539  \n",
       "1 -0.024620  0.027387 -0.041001 -0.025708 -0.016437 -0.034342  \n",
       "2 -0.035368  0.020287 -0.033941 -0.023549 -0.008720 -0.044038  \n",
       "3 -0.044124  0.019544 -0.039559 -0.015679 -0.008837 -0.043877  \n",
       "4 -0.058199  0.026781 -0.046815 -0.010110 -0.008785 -0.041761  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tap = pd.read_feather(path.join(DATA_DIR, \"tap/embeddings/bert/bert_tap_embeddings.ftr\"))\n",
    "x_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "169edc1a-15ba-48a7-b707-9c8117a795e1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data bert \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "logistic_regression, bert\n",
      "F1: 0.3787878787878788\n",
      "MCC: 0.1737809569953117\n",
      "Accuracy: 0.6569037656903766\n",
      "Precision: 0.30120481927710846\n",
      "Recall: 0.5102040816326531\n",
      "AUC: 0.602470461868958\n",
      "-----\n",
      "\n",
      "\n",
      "Training model random_forest on data bert \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "random_forest, bert\n",
      "F1: 0.34615384615384615\n",
      "MCC: 0.16555823204102568\n",
      "Accuracy: 0.7154811715481172\n",
      "Precision: 0.32727272727272727\n",
      "Recall: 0.3673469387755102\n",
      "AUC: 0.5863050483351236\n",
      "-----\n",
      "\n",
      "\n",
      "Training model gradient_boosting on data bert \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_boosting, bert\n",
      "F1: 0.16216216216216214\n",
      "MCC: 0.02961382833938806\n",
      "Accuracy: 0.7405857740585774\n",
      "Precision: 0.24\n",
      "Recall: 0.12244897959183673\n",
      "AUC: 0.5112244897959183\n",
      "-----\n",
      "\n",
      "\n",
      "Training model SVM on data bert \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, bert\n",
      "F1: 0.44755244755244755\n",
      "MCC: 0.2700451870177944\n",
      "Accuracy: 0.6694560669456067\n",
      "Precision: 0.3404255319148936\n",
      "Recall: 0.6530612244897959\n",
      "AUC: 0.6633727175080557\n",
      "-----\n",
      "\n",
      "\n",
      "Training model multilayer_perceptron on data bert \n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron, bert\n",
      "F1: 0.2716049382716049\n",
      "MCC: 0.13510778731572384\n",
      "Accuracy: 0.7531380753138075\n",
      "Precision: 0.34375\n",
      "Recall: 0.22448979591836735\n",
      "AUC: 0.5569817400644468\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train.drop([\"Ab_ID\", \"Y\", \"cluster_merged\"], axis=1), x_chen_train[\"Y\"], \n",
    "        x_chen_valid.drop([\"Ab_ID\", \"Y\"], axis=1),  x_chen_valid[\"Y\"], \n",
    "        x_chen_train[\"cluster_merged\"], \"bert\", EVAL_DIR, preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8469c75-b42f-4ff6-a7c3-028ed4e75c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on bert...\n",
      "Testing model random_forest on bert...\n",
      "Testing model gradient_boosting on bert...\n",
      "Testing model SVM on bert...\n",
      "Testing model multilayer_perceptron on bert...\n"
     ]
    }
   ],
   "source": [
    "test_all(x_tap.drop(\"Ab_ID\", axis=1), tap_data[\"Y\"], \"bert\", EVAL_DIR, preprocessing=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b72f0-8d1e-49b2-af8c-5f8e40d79114",
   "metadata": {},
   "source": [
    "# SeqVec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "242800ab-9c9f-40bc-8833-2d43e2cfe302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>0.031640</td>\n",
       "      <td>-0.191203</td>\n",
       "      <td>-0.268825</td>\n",
       "      <td>-0.134525</td>\n",
       "      <td>0.097435</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.019496</td>\n",
       "      <td>0.118835</td>\n",
       "      <td>-0.136518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>-0.013639</td>\n",
       "      <td>0.135580</td>\n",
       "      <td>0.059035</td>\n",
       "      <td>-0.006357</td>\n",
       "      <td>-0.085073</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>-0.000886</td>\n",
       "      <td>-0.016590</td>\n",
       "      <td>-0.071586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>0.063575</td>\n",
       "      <td>-0.219689</td>\n",
       "      <td>-0.285444</td>\n",
       "      <td>-0.134554</td>\n",
       "      <td>0.089054</td>\n",
       "      <td>-0.023122</td>\n",
       "      <td>0.004502</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>-0.047376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005196</td>\n",
       "      <td>-0.113235</td>\n",
       "      <td>0.048879</td>\n",
       "      <td>0.061190</td>\n",
       "      <td>-0.005911</td>\n",
       "      <td>-0.104957</td>\n",
       "      <td>0.026941</td>\n",
       "      <td>0.016444</td>\n",
       "      <td>-0.065021</td>\n",
       "      <td>-0.105957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>0.060840</td>\n",
       "      <td>-0.227532</td>\n",
       "      <td>-0.280555</td>\n",
       "      <td>-0.136953</td>\n",
       "      <td>0.091411</td>\n",
       "      <td>-0.028528</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.166315</td>\n",
       "      <td>-0.045701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005788</td>\n",
       "      <td>-0.112651</td>\n",
       "      <td>0.049541</td>\n",
       "      <td>0.063261</td>\n",
       "      <td>-0.005133</td>\n",
       "      <td>-0.104734</td>\n",
       "      <td>0.027340</td>\n",
       "      <td>0.017490</td>\n",
       "      <td>-0.064584</td>\n",
       "      <td>-0.105592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>0.062686</td>\n",
       "      <td>-0.220758</td>\n",
       "      <td>-0.278071</td>\n",
       "      <td>-0.137741</td>\n",
       "      <td>0.086655</td>\n",
       "      <td>-0.016114</td>\n",
       "      <td>-0.027874</td>\n",
       "      <td>0.158912</td>\n",
       "      <td>-0.119345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041290</td>\n",
       "      <td>-0.032623</td>\n",
       "      <td>0.144864</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>-0.014455</td>\n",
       "      <td>-0.080329</td>\n",
       "      <td>-0.049089</td>\n",
       "      <td>0.033029</td>\n",
       "      <td>-0.017042</td>\n",
       "      <td>-0.044416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>-0.000458</td>\n",
       "      <td>-0.200469</td>\n",
       "      <td>-0.269982</td>\n",
       "      <td>-0.138054</td>\n",
       "      <td>0.112663</td>\n",
       "      <td>-0.007346</td>\n",
       "      <td>0.037440</td>\n",
       "      <td>0.075526</td>\n",
       "      <td>-0.178788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020374</td>\n",
       "      <td>-0.059074</td>\n",
       "      <td>0.133179</td>\n",
       "      <td>0.018044</td>\n",
       "      <td>0.066013</td>\n",
       "      <td>-0.061189</td>\n",
       "      <td>-0.029644</td>\n",
       "      <td>-0.050942</td>\n",
       "      <td>-0.035482</td>\n",
       "      <td>-0.058019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ab_ID         0         1         2         3         4         5  \\\n",
       "2073  6aod  0.031640 -0.191203 -0.268825 -0.134525  0.097435  0.001770   \n",
       "1517  4yny  0.063575 -0.219689 -0.285444 -0.134554  0.089054 -0.023122   \n",
       "2025  5xcv  0.060840 -0.227532 -0.280555 -0.136953  0.091411 -0.028528   \n",
       "2070  6and  0.062686 -0.220758 -0.278071 -0.137741  0.086655 -0.016114   \n",
       "666   2xqy -0.000458 -0.200469 -0.269982 -0.138054  0.112663 -0.007346   \n",
       "\n",
       "             6         7         8  ...      2038      2039      2040  \\\n",
       "2073  0.019496  0.118835 -0.136518  ...  0.104400 -0.013639  0.135580   \n",
       "1517  0.004502  0.162193 -0.047376  ... -0.005196 -0.113235  0.048879   \n",
       "2025  0.001440  0.166315 -0.045701  ... -0.005788 -0.112651  0.049541   \n",
       "2070 -0.027874  0.158912 -0.119345  ...  0.041290 -0.032623  0.144864   \n",
       "666   0.037440  0.075526 -0.178788  ... -0.020374 -0.059074  0.133179   \n",
       "\n",
       "          2041      2042      2043      2044      2045      2046      2047  \n",
       "2073  0.059035 -0.006357 -0.085073  0.009538 -0.000886 -0.016590 -0.071586  \n",
       "1517  0.061190 -0.005911 -0.104957  0.026941  0.016444 -0.065021 -0.105957  \n",
       "2025  0.063261 -0.005133 -0.104734  0.027340  0.017490 -0.064584 -0.105592  \n",
       "2070  0.008824 -0.014455 -0.080329 -0.049089  0.033029 -0.017042 -0.044416  \n",
       "666   0.018044  0.066013 -0.061189 -0.029644 -0.050942 -0.035482 -0.058019  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chen = pd.read_feather(path.join(DATA_DIR, \"chen/embeddings/seqvec/seqvec_chen_embeddings.ftr\"))\n",
    "x_chen_train = x_chen.merge(chen_train[[\"Antibody_ID\", \"Y\", \"cluster_merged\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_valid = x_chen.merge(chen_valid[[\"Antibody_ID\", \"Y\"]], left_on=\"Ab_ID\", right_on=\"Antibody_ID\").drop(\"Antibody_ID\", axis=1)\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0bfe959c-adc2-4402-b7a6-e3d7ee825a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abagovomab</td>\n",
       "      <td>-0.004248</td>\n",
       "      <td>-0.024501</td>\n",
       "      <td>-0.011330</td>\n",
       "      <td>-0.027170</td>\n",
       "      <td>0.062747</td>\n",
       "      <td>-0.024793</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>-0.083316</td>\n",
       "      <td>-0.005339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008674</td>\n",
       "      <td>-0.002387</td>\n",
       "      <td>-0.021563</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>-0.020986</td>\n",
       "      <td>0.047104</td>\n",
       "      <td>-0.038736</td>\n",
       "      <td>-0.021780</td>\n",
       "      <td>-0.022153</td>\n",
       "      <td>-0.024539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abituzumab</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>-0.013591</td>\n",
       "      <td>-0.008454</td>\n",
       "      <td>-0.043601</td>\n",
       "      <td>0.065095</td>\n",
       "      <td>-0.016896</td>\n",
       "      <td>-0.001596</td>\n",
       "      <td>-0.090935</td>\n",
       "      <td>-0.002940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>-0.013063</td>\n",
       "      <td>-0.021852</td>\n",
       "      <td>-0.003531</td>\n",
       "      <td>-0.024620</td>\n",
       "      <td>0.027387</td>\n",
       "      <td>-0.041001</td>\n",
       "      <td>-0.025708</td>\n",
       "      <td>-0.016437</td>\n",
       "      <td>-0.034342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrilumab</td>\n",
       "      <td>0.019445</td>\n",
       "      <td>-0.002642</td>\n",
       "      <td>-0.011395</td>\n",
       "      <td>-0.058757</td>\n",
       "      <td>0.060623</td>\n",
       "      <td>-0.015046</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>-0.083772</td>\n",
       "      <td>-0.006775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>-0.017189</td>\n",
       "      <td>-0.014557</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>-0.035368</td>\n",
       "      <td>0.020287</td>\n",
       "      <td>-0.033941</td>\n",
       "      <td>-0.023549</td>\n",
       "      <td>-0.008720</td>\n",
       "      <td>-0.044038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actoxumab</td>\n",
       "      <td>-0.006365</td>\n",
       "      <td>-0.043729</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>-0.025613</td>\n",
       "      <td>0.067748</td>\n",
       "      <td>-0.009542</td>\n",
       "      <td>0.017723</td>\n",
       "      <td>-0.096801</td>\n",
       "      <td>-0.007752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.012986</td>\n",
       "      <td>-0.019753</td>\n",
       "      <td>-0.004326</td>\n",
       "      <td>-0.044124</td>\n",
       "      <td>0.019544</td>\n",
       "      <td>-0.039559</td>\n",
       "      <td>-0.015679</td>\n",
       "      <td>-0.008837</td>\n",
       "      <td>-0.043877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adalimumab</td>\n",
       "      <td>-0.012995</td>\n",
       "      <td>-0.035269</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>-0.042136</td>\n",
       "      <td>0.080592</td>\n",
       "      <td>-0.012831</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>-0.091308</td>\n",
       "      <td>-0.018166</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>-0.022957</td>\n",
       "      <td>-0.021145</td>\n",
       "      <td>-0.002762</td>\n",
       "      <td>-0.058199</td>\n",
       "      <td>0.026781</td>\n",
       "      <td>-0.046815</td>\n",
       "      <td>-0.010110</td>\n",
       "      <td>-0.008785</td>\n",
       "      <td>-0.041761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ab_ID         0         1         2         3         4         5  \\\n",
       "0  Abagovomab -0.004248 -0.024501 -0.011330 -0.027170  0.062747 -0.024793   \n",
       "1  Abituzumab  0.006593 -0.013591 -0.008454 -0.043601  0.065095 -0.016896   \n",
       "2   Abrilumab  0.019445 -0.002642 -0.011395 -0.058757  0.060623 -0.015046   \n",
       "3   Actoxumab -0.006365 -0.043729  0.005978 -0.025613  0.067748 -0.009542   \n",
       "4  Adalimumab -0.012995 -0.035269  0.014127 -0.042136  0.080592 -0.012831   \n",
       "\n",
       "          6         7         8  ...      2038      2039      2040      2041  \\\n",
       "0  0.009313 -0.083316 -0.005339  ... -0.008674 -0.002387 -0.021563  0.001087   \n",
       "1 -0.001596 -0.090935 -0.002940  ...  0.000486 -0.013063 -0.021852 -0.003531   \n",
       "2  0.006317 -0.083772 -0.006775  ...  0.005834 -0.017189 -0.014557  0.003359   \n",
       "3  0.017723 -0.096801 -0.007752  ... -0.000024 -0.012986 -0.019753 -0.004326   \n",
       "4  0.031889 -0.091308 -0.018166  ... -0.002067 -0.022957 -0.021145 -0.002762   \n",
       "\n",
       "       2042      2043      2044      2045      2046      2047  \n",
       "0 -0.020986  0.047104 -0.038736 -0.021780 -0.022153 -0.024539  \n",
       "1 -0.024620  0.027387 -0.041001 -0.025708 -0.016437 -0.034342  \n",
       "2 -0.035368  0.020287 -0.033941 -0.023549 -0.008720 -0.044038  \n",
       "3 -0.044124  0.019544 -0.039559 -0.015679 -0.008837 -0.043877  \n",
       "4 -0.058199  0.026781 -0.046815 -0.010110 -0.008785 -0.041761  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tap = pd.read_feather(path.join(DATA_DIR, \"tap/embeddings/seqvec/seqvec_tap_embeddings.ftr\"))\n",
    "x_tap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40df67f1-1c9a-419b-816f-87d21b10882c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression, seqvec\n",
      "F1: 0.375\n",
      "MCC: 0.17192160569556778\n",
      "Accuracy: 0.6652719665271967\n",
      "Precision: 0.3037974683544304\n",
      "Recall: 0.4897959183673469\n",
      "AUC: 0.6001611170784104\n",
      "-----\n",
      "\n",
      "\n",
      "Training model random_forest on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "random_forest, seqvec\n",
      "F1: 0.4133333333333333\n",
      "MCC: 0.21595339527185456\n",
      "Accuracy: 0.6317991631799164\n",
      "Precision: 0.3069306930693069\n",
      "Recall: 0.6326530612244898\n",
      "AUC: 0.6321160042964554\n",
      "-----\n",
      "\n",
      "\n",
      "Training model gradient_boosting on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_boosting, seqvec\n",
      "F1: 0.21686746987951805\n",
      "MCC: 0.06020748817732093\n",
      "Accuracy: 0.7280334728033473\n",
      "Precision: 0.2647058823529412\n",
      "Recall: 0.1836734693877551\n",
      "AUC: 0.526047261009667\n",
      "-----\n",
      "\n",
      "\n",
      "Training model SVM on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, seqvec\n",
      "F1: 0.3851851851851852\n",
      "MCC: 0.18070085777906472\n",
      "Accuracy: 0.6527196652719666\n",
      "Precision: 0.3023255813953488\n",
      "Recall: 0.5306122448979592\n",
      "AUC: 0.6074113856068744\n",
      "-----\n",
      "\n",
      "\n",
      "Training model multilayer_perceptron on data seqvec \n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron, seqvec\n",
      "F1: 0.22784810126582278\n",
      "MCC: 0.08913299526754152\n",
      "Accuracy: 0.7447698744769874\n",
      "Precision: 0.3\n",
      "Recall: 0.1836734693877551\n",
      "AUC: 0.5365735767991406\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "try_all(x_chen_train.drop([\"Ab_ID\", \"Y\", \"cluster_merged\"], axis=1), x_chen_train[\"Y\"], \n",
    "        x_chen_valid.drop([\"Ab_ID\", \"Y\"], axis=1),  x_chen_valid[\"Y\"], \n",
    "        x_chen_train[\"cluster_merged\"], \"seqvec\", EVAL_DIR, preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50dd5635-2548-4aa9-ba29-2c84aaa34c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on seqvec...\n",
      "Testing model random_forest on seqvec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model gradient_boosting on seqvec...\n",
      "Testing model SVM on seqvec...\n",
      "Testing model multilayer_perceptron on seqvec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_all(x_tap.drop(\"Ab_ID\", axis=1), tap_data[\"Y\"], \"seqvec\", EVAL_DIR, preprocessing=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514468c1-5d01-4679-a873-448a9e75cfa1",
   "metadata": {},
   "source": [
    "# One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c29ea9f-0574-4903-a00a-e079b67434de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID_h</th>\n",
       "      <th>A_1_h</th>\n",
       "      <th>C_1_h</th>\n",
       "      <th>D_1_h</th>\n",
       "      <th>E_1_h</th>\n",
       "      <th>F_1_h</th>\n",
       "      <th>G_1_h</th>\n",
       "      <th>H_1_h</th>\n",
       "      <th>I_1_h</th>\n",
       "      <th>K_1_h</th>\n",
       "      <th>...</th>\n",
       "      <th>O_138_l</th>\n",
       "      <th>P_138_l</th>\n",
       "      <th>Q_138_l</th>\n",
       "      <th>R_138_l</th>\n",
       "      <th>S_138_l</th>\n",
       "      <th>T_138_l</th>\n",
       "      <th>U_138_l</th>\n",
       "      <th>V_138_l</th>\n",
       "      <th>W_138_l</th>\n",
       "      <th>Y_138_l</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7526 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ab_ID_h  A_1_h  C_1_h  D_1_h  E_1_h  F_1_h  G_1_h  H_1_h  I_1_h  K_1_h  \\\n",
       "index                                                                          \n",
       "2073     6aod      0      0      0      1      0      0      0      0      0   \n",
       "1517     4yny      0      0      0      1      0      0      0      0      0   \n",
       "2025     5xcv      0      0      0      1      0      0      0      0      0   \n",
       "2070     6and      0      0      0      1      0      0      0      0      0   \n",
       "666      2xqy      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "       ...  O_138_l  P_138_l  Q_138_l  R_138_l  S_138_l  T_138_l  U_138_l  \\\n",
       "index  ...                                                                  \n",
       "2073   ...        0        0        0        0        0        0        0   \n",
       "1517   ...        0        0        0        0        0        0        0   \n",
       "2025   ...        0        0        0        0        0        0        0   \n",
       "2070   ...        0        0        0        0        0        0        0   \n",
       "666    ...        0        0        0        0        0        0        0   \n",
       "\n",
       "       V_138_l  W_138_l  Y_138_l  \n",
       "index                             \n",
       "2073         0        0        0  \n",
       "1517         0        0        0  \n",
       "2025         0        0        0  \n",
       "2070         0        0        0  \n",
       "666          0        0        0  \n",
       "\n",
       "[5 rows x 7526 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_heavy = pd.read_feather(path.join(DATA_DIR, \"chen/abnumber/chen_heavy_one_hot.ftr\")).set_index(\"index\")\n",
    "# rows 1921 and 2097 could not be encoded\n",
    "x_light = pd.read_feather(path.join(DATA_DIR, \"chen/abnumber/chen_light_one_hot.ftr\")).set_index(\"Id\")\n",
    "x_chen = x_heavy.merge(x_light, left_index=True, right_index=True, suffixes=[\"_h\", \"_l\"])\n",
    "x_chen.index = x_heavy.index\n",
    "train_idx = list(chen_train.index)\n",
    "train_idx.remove(1921)\n",
    "train_idx.remove(2097)\n",
    "x_chen_train = x_chen.loc[train_idx]\n",
    "x_chen_valid = x_chen.loc[chen_valid.index]\n",
    "x_chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "91873511-e395-4ce1-9225-026d3a241b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = chen_train.loc[train_idx][\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "401ccb70-678f-4787-a563-69985cc6407d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model logistic_regression on data onehot \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression, onehot\n",
      "F1: 0.3676470588235294\n",
      "MCC: 0.15429345341033412\n",
      "Accuracy: 0.6401673640167364\n",
      "Precision: 0.28735632183908044\n",
      "Recall: 0.5102040816326531\n",
      "AUC: 0.5919441460794843\n",
      "-----\n",
      "\n",
      "\n",
      "Training model random_forest on data onehot \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "random_forest, onehot\n",
      "F1: 0.27499999999999997\n",
      "MCC: 0.14326352207226128\n",
      "Accuracy: 0.7573221757322176\n",
      "Precision: 0.3548387096774194\n",
      "Recall: 0.22448979591836735\n",
      "AUC: 0.5596133190118153\n",
      "-----\n",
      "\n",
      "\n",
      "Training model gradient_boosting on data onehot \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_boosting, onehot\n",
      "F1: 0.18666666666666665\n",
      "MCC: 0.05556759229181543\n",
      "Accuracy: 0.7447698744769874\n",
      "Precision: 0.2692307692307692\n",
      "Recall: 0.14285714285714285\n",
      "AUC: 0.5214285714285714\n",
      "-----\n",
      "\n",
      "\n",
      "Training model SVM on data onehot \n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "SVM, onehot\n",
      "F1: 0.3597122302158273\n",
      "MCC: 0.14006354446702016\n",
      "Accuracy: 0.6276150627615062\n",
      "Precision: 0.2777777777777778\n",
      "Recall: 0.5102040816326531\n",
      "AUC: 0.5840494092373791\n",
      "-----\n",
      "\n",
      "\n",
      "Training model multilayer_perceptron on data onehot \n",
      "\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multilayer_perceptron, onehot\n",
      "F1: 0.3157894736842105\n",
      "MCC: 0.1464015398458587\n",
      "Accuracy: 0.7280334728033473\n",
      "Precision: 0.32608695652173914\n",
      "Recall: 0.30612244897959184\n",
      "AUC: 0.5714822771213749\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# add groups for data split\n",
    "try_all(x_chen_train.drop([\"Ab_ID_h\", \"Ab_ID_l\"], axis=1), train_labels, x_chen_valid.drop([\"Ab_ID_h\", \"Ab_ID_l\"], axis=1), chen_valid[\"Y\"], \"onehot\", EVAL_DIR, preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ab52adf3-0969-4487-9df4-ba41e4cbd7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tap_heavy = pd.read_feather(path.join(DATA_DIR, \"tap/abnumber/tap_heavy_one_hot.ftr\")).drop([\"index\"], axis=1)\n",
    "x_tap_light = pd.read_feather(path.join(DATA_DIR, \"tap/abnumber/tap_light_one_hot.ftr\")).drop([\"index\"], axis=1)\n",
    "x_tap = x_tap_heavy.merge(x_tap_light, left_index=True, right_index=True, suffixes=[\"_h\", \"_l\"]).drop(\"Ab_ID_l\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d589ad47-2811-4aef-8c28-8d5d89f046ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ab_ID_h</th>\n",
       "      <th>A_1_h</th>\n",
       "      <th>C_1_h</th>\n",
       "      <th>D_1_h</th>\n",
       "      <th>E_1_h</th>\n",
       "      <th>F_1_h</th>\n",
       "      <th>G_1_h</th>\n",
       "      <th>H_1_h</th>\n",
       "      <th>I_1_h</th>\n",
       "      <th>K_1_h</th>\n",
       "      <th>...</th>\n",
       "      <th>O_120_l</th>\n",
       "      <th>P_120_l</th>\n",
       "      <th>Q_120_l</th>\n",
       "      <th>R_120_l</th>\n",
       "      <th>S_120_l</th>\n",
       "      <th>T_120_l</th>\n",
       "      <th>U_120_l</th>\n",
       "      <th>V_120_l</th>\n",
       "      <th>W_120_l</th>\n",
       "      <th>Y_120_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abagovomab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abituzumab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abrilumab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actoxumab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adalimumab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Visilizumab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Vonlerolizumab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Zalutumumab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Zanolimumab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Zolbetuximab (Claudiximab)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 5633 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Ab_ID_h  A_1_h  C_1_h  D_1_h  E_1_h  F_1_h  G_1_h  \\\n",
       "0                    Abagovomab      0      0      0      0      0      0   \n",
       "1                    Abituzumab      0      0      0      0      0      0   \n",
       "2                     Abrilumab      0      0      0      0      0      0   \n",
       "3                     Actoxumab      0      0      0      0      0      0   \n",
       "4                    Adalimumab      0      0      0      1      0      0   \n",
       "..                          ...    ...    ...    ...    ...    ...    ...   \n",
       "236                 Visilizumab      0      0      0      0      0      0   \n",
       "237              Vonlerolizumab      0      0      0      1      0      0   \n",
       "238                 Zalutumumab      0      0      0      0      0      0   \n",
       "239                 Zanolimumab      0      0      0      0      0      0   \n",
       "240  Zolbetuximab (Claudiximab)      0      0      0      0      0      0   \n",
       "\n",
       "     H_1_h  I_1_h  K_1_h  ...  O_120_l  P_120_l  Q_120_l  R_120_l  S_120_l  \\\n",
       "0        0      0      0  ...        0        0        0        0        0   \n",
       "1        0      0      0  ...        0        0        0        0        0   \n",
       "2        0      0      0  ...        0        0        0        0        0   \n",
       "3        0      0      0  ...        0        0        0        0        0   \n",
       "4        0      0      0  ...        0        0        0        0        0   \n",
       "..     ...    ...    ...  ...      ...      ...      ...      ...      ...   \n",
       "236      0      0      0  ...        0        0        0        0        0   \n",
       "237      0      0      0  ...        0        0        0        0        0   \n",
       "238      0      0      0  ...        0        0        0        0        0   \n",
       "239      0      0      0  ...        0        0        0        0        0   \n",
       "240      0      0      0  ...        0        0        0        0        0   \n",
       "\n",
       "     T_120_l  U_120_l  V_120_l  W_120_l  Y_120_l  \n",
       "0          0        0        0        0        0  \n",
       "1          0        0        0        0        0  \n",
       "2          0        0        0        0        0  \n",
       "3          0        0        0        0        0  \n",
       "4          0        0        0        0        0  \n",
       "..       ...      ...      ...      ...      ...  \n",
       "236        0        0        0        0        0  \n",
       "237        0        0        0        0        0  \n",
       "238        0        0        0        0        0  \n",
       "239        0        0        0        0        0  \n",
       "240        0        0        0        0        0  \n",
       "\n",
       "[241 rows x 5633 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1718a7f2-f150-4814-87f2-ceb45cb5fd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model logistic_regression on onehot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- A_121\n",
      "- A_122\n",
      "- A_123\n",
      "- A_124\n",
      "- A_125\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- A_121_h\n",
      "- A_121_l\n",
      "- A_122_h\n",
      "- A_122_l\n",
      "- A_123_h\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 5632 features, but LogisticRegression is expecting 7524 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/pbs.31293.lich-compute.vscht.cz/ipykernel_49113/2316997838.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Ab_ID_h\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtap_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"onehot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEVAL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.31293.lich-compute.vscht.cz/ipykernel_49113/202172768.py\u001b[0m in \u001b[0;36mtest_all\u001b[0;34m(x_test, y_test, data_name, outpath, preprocessing)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"logistic_regression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"random_forest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gradient_boosting\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SVM\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilayer_perceptron\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Testing model {model} on {data_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtest_on_tap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/tmp/pbs.31293.lich-compute.vscht.cz/ipykernel_49113/2610498457.py\u001b[0m in \u001b[0;36mtest_on_tap\u001b[0;34m(model_name, x_test, y_test, data_name, outpath, preprocessing)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     metric_dict = {\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \"\"\"\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ml/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             raise ValueError(\n\u001b[0;32m--> 396\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 5632 features, but LogisticRegression is expecting 7524 features as input."
     ]
    }
   ],
   "source": [
    "test_all(x_tap.drop([\"Ab_ID_h\"], axis=1), tap_data[\"Y\"], \"onehot\", EVAL_DIR, preprocessing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3839ca60-71b3-4234-8d89-2e2eb2357549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9af0b5-4f6a-407d-88ee-1c3e0760b612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
