{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfd1bf8e-8e65-44ca-aa5c-a1a9e997c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from os import path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b10cc0d-3610-4f33-800d-3795852925cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0afa3328-47f7-4467-b797-364d8e1e9d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...</td>\n",
       "      <td>DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...</td>\n",
       "      <td>DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Antibody_ID                                              heavy  \\\n",
       "2073        6aod  EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...   \n",
       "1517        4yny  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2025        5xcv  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2070        6and  EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...   \n",
       "666         2xqy  QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...   \n",
       "\n",
       "                                                  light  Y  \n",
       "2073  DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...  0  \n",
       "1517  EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2025  QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2070  DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...  1  \n",
       "666   DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...  0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_train = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_train_data.csv\"), index_col=0)\n",
    "chen_valid = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_valid_data.csv\"), index_col=0)\n",
    "chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c6f684-ce92-406d-a044-6965a85eb976",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path.join(DATA_DIR, \"fairseq/train.input0\"), \"w\") as dat:\n",
    "    with open(path.join(DATA_DIR, \"fairseq/train.label\"), \"w\") as lab:\n",
    "        for i, row in chen_train.iterrows():\n",
    "            dat.write(row[\"heavy\"] + row[\"light\"] + '\\n')\n",
    "            lab.write(str(row[\"Y\"]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5830e8a3-5f29-4f55-8372-20c61ccf84be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs = [row[\"heavy\"] + row[\"light\"] for i, row in chen_train.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04d2af0-a0e4-4fb9-94d7-a2a83fbb5bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path.join(DATA_DIR, \"fairseq/dev.input0\"), \"w\") as dat:\n",
    "    with open(path.join(DATA_DIR, \"fairseq/dev.label\"), \"w\") as lab:\n",
    "        for i, row in chen_valid.iterrows():\n",
    "            dat.write(row[\"heavy\"] + row[\"light\"] + '\\n')\n",
    "            lab.write(str(row[\"Y\"]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3963bc8a-ec96-44b5-940e-713a20429311",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_seqs = [row[\"heavy\"] + row[\"light\"] for i, row in chen_valid.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64bab3dc-2c80-47db-988d-eef425e52311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.data import Dictionary\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aac2806-687c-4384-9c70-3a418fda848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counter = Counter()\n",
    "for record in train_seqs:\n",
    "    token_counter.update(record)\n",
    "    \n",
    "dictionary = Dictionary()\n",
    "for token, count in sorted(token_counter.items()):\n",
    "    dictionary.add_symbol(token, count)\n",
    "    \n",
    "with open(path.join(DATA_DIR, \"fairseq/dict.txt\"), \"w\") as f:\n",
    "    dictionary.save(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bfe9a0-fe09-4989-862a-79db4caeab76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30ee4f79-21f1-412a-bf55-547a32937a69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-16 14:58:27 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.999)', adam_eps=1e-08, add_prev_output_tokens=False, all_gather_list_size=16384, arch='roberta_small', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', classification_head_name='sentence_classification_head', clip_norm=0.0, cpu=False, criterion='sentence_prediction', curriculum=0, data='../../data/fairseq/', data_buffer_size=10, dataset_impl='raw', ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=128, encoder_ffn_embed_dim=256, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', init_token=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0001], lr_scheduler='inverse_sqrt', max_epoch=0, max_positions=512, max_tokens=8096, max_tokens_valid=8096, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, no_shuffle=False, nprocs_per_node=1, num_classes=2, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='../../../../BioPhi/biophi/humanization/methods/sapiens/models/v1/checkpoint_vh.pt', save_dir='../../data/models/fairseq', save_interval=1, save_interval_updates=5000, scoring='bleu', seed=1, sentence_avg=False, separator_token=None, shard_id=0, shorten_data_split_list='', shorten_method='none', skip_invalid_size_inputs_valid_test=True, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, stop_time_hours=0, task='sentence_prediction', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', update_freq=[4], use_bmuf=False, use_old_adam=False, user_dir='/Users/brazdilk/Projects/BioPhi/biophi/humanization/methods/sapiens', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=5000, warmup_init_lr=-1, warmup_updates=16000, weight_decay=0.0, zero_sharding='none')\n",
      "2022-01-16 14:58:27 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 25 types\n",
      "2022-01-16 14:58:27 | INFO | fairseq.tasks.sentence_prediction | [label] dictionary: 7 types\n",
      "2022-01-16 14:58:27 | INFO | fairseq.data.data_utils | loaded 120 examples from: ../../data/fairseq/input0/valid\n",
      "2022-01-16 14:58:27 | INFO | fairseq.data.data_utils | loaded 120 examples from: ../../data/fairseq/label/valid\n",
      "2022-01-16 14:58:27 | INFO | fairseq.tasks.sentence_prediction | Loaded valid with #samples: 120\n",
      "2022-01-16 14:58:28 | INFO | fairseq_cli.train | RobertaModel(\n",
      "  (encoder): RobertaEncoder(\n",
      "    (sentence_encoder): TransformerSentenceEncoder(\n",
      "      (dropout_module): FairseqDropout()\n",
      "      (embed_tokens): Embedding(25, 128, padding_idx=1)\n",
      "      (embed_positions): LearnedPositionalEmbedding(514, 128, padding_idx=1)\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (emb_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (lm_head): RobertaLMHead(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (classification_heads): ModuleDict(\n",
      "    (sentence_classification_head): RobertaClassificationHead(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (out_proj): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2022-01-16 14:58:28 | INFO | fairseq_cli.train | task: sentence_prediction (SentencePredictionTask)\n",
      "2022-01-16 14:58:28 | INFO | fairseq_cli.train | model: roberta_small (RobertaModel)\n",
      "2022-01-16 14:58:28 | INFO | fairseq_cli.train | criterion: sentence_prediction (SentencePredictionCriterion)\n",
      "2022-01-16 14:58:28 | INFO | fairseq_cli.train | num. model params: 632731 (num. trained: 632731)\n",
      "2022-01-16 14:58:28 | INFO | fairseq.trainer | detected shared parameter: encoder.sentence_encoder.embed_tokens.weight <- encoder.lm_head.weight\n",
      "2022-01-16 14:58:28 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
      "2022-01-16 14:58:28 | INFO | fairseq_cli.train | max tokens per GPU = 8096 and max sentences per GPU = None\n",
      "2022-01-16 14:58:28 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.dense.weight\n",
      "2022-01-16 14:58:28 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.dense.bias\n",
      "2022-01-16 14:58:28 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.out_proj.weight\n",
      "2022-01-16 14:58:28 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.out_proj.bias\n",
      "odict_keys(['encoder.sentence_encoder.embed_tokens.weight', 'encoder.sentence_encoder.embed_positions.weight', 'encoder.sentence_encoder.layers.0.self_attn.k_proj.weight', 'encoder.sentence_encoder.layers.0.self_attn.k_proj.bias', 'encoder.sentence_encoder.layers.0.self_attn.v_proj.weight', 'encoder.sentence_encoder.layers.0.self_attn.v_proj.bias', 'encoder.sentence_encoder.layers.0.self_attn.q_proj.weight', 'encoder.sentence_encoder.layers.0.self_attn.q_proj.bias', 'encoder.sentence_encoder.layers.0.self_attn.out_proj.weight', 'encoder.sentence_encoder.layers.0.self_attn.out_proj.bias', 'encoder.sentence_encoder.layers.0.self_attn_layer_norm.weight', 'encoder.sentence_encoder.layers.0.self_attn_layer_norm.bias', 'encoder.sentence_encoder.layers.0.fc1.weight', 'encoder.sentence_encoder.layers.0.fc1.bias', 'encoder.sentence_encoder.layers.0.fc2.weight', 'encoder.sentence_encoder.layers.0.fc2.bias', 'encoder.sentence_encoder.layers.0.final_layer_norm.weight', 'encoder.sentence_encoder.layers.0.final_layer_norm.bias', 'encoder.sentence_encoder.layers.1.self_attn.k_proj.weight', 'encoder.sentence_encoder.layers.1.self_attn.k_proj.bias', 'encoder.sentence_encoder.layers.1.self_attn.v_proj.weight', 'encoder.sentence_encoder.layers.1.self_attn.v_proj.bias', 'encoder.sentence_encoder.layers.1.self_attn.q_proj.weight', 'encoder.sentence_encoder.layers.1.self_attn.q_proj.bias', 'encoder.sentence_encoder.layers.1.self_attn.out_proj.weight', 'encoder.sentence_encoder.layers.1.self_attn.out_proj.bias', 'encoder.sentence_encoder.layers.1.self_attn_layer_norm.weight', 'encoder.sentence_encoder.layers.1.self_attn_layer_norm.bias', 'encoder.sentence_encoder.layers.1.fc1.weight', 'encoder.sentence_encoder.layers.1.fc1.bias', 'encoder.sentence_encoder.layers.1.fc2.weight', 'encoder.sentence_encoder.layers.1.fc2.bias', 'encoder.sentence_encoder.layers.1.final_layer_norm.weight', 'encoder.sentence_encoder.layers.1.final_layer_norm.bias', 'encoder.sentence_encoder.layers.2.self_attn.k_proj.weight', 'encoder.sentence_encoder.layers.2.self_attn.k_proj.bias', 'encoder.sentence_encoder.layers.2.self_attn.v_proj.weight', 'encoder.sentence_encoder.layers.2.self_attn.v_proj.bias', 'encoder.sentence_encoder.layers.2.self_attn.q_proj.weight', 'encoder.sentence_encoder.layers.2.self_attn.q_proj.bias', 'encoder.sentence_encoder.layers.2.self_attn.out_proj.weight', 'encoder.sentence_encoder.layers.2.self_attn.out_proj.bias', 'encoder.sentence_encoder.layers.2.self_attn_layer_norm.weight', 'encoder.sentence_encoder.layers.2.self_attn_layer_norm.bias', 'encoder.sentence_encoder.layers.2.fc1.weight', 'encoder.sentence_encoder.layers.2.fc1.bias', 'encoder.sentence_encoder.layers.2.fc2.weight', 'encoder.sentence_encoder.layers.2.fc2.bias', 'encoder.sentence_encoder.layers.2.final_layer_norm.weight', 'encoder.sentence_encoder.layers.2.final_layer_norm.bias', 'encoder.sentence_encoder.layers.3.self_attn.k_proj.weight', 'encoder.sentence_encoder.layers.3.self_attn.k_proj.bias', 'encoder.sentence_encoder.layers.3.self_attn.v_proj.weight', 'encoder.sentence_encoder.layers.3.self_attn.v_proj.bias', 'encoder.sentence_encoder.layers.3.self_attn.q_proj.weight', 'encoder.sentence_encoder.layers.3.self_attn.q_proj.bias', 'encoder.sentence_encoder.layers.3.self_attn.out_proj.weight', 'encoder.sentence_encoder.layers.3.self_attn.out_proj.bias', 'encoder.sentence_encoder.layers.3.self_attn_layer_norm.weight', 'encoder.sentence_encoder.layers.3.self_attn_layer_norm.bias', 'encoder.sentence_encoder.layers.3.fc1.weight', 'encoder.sentence_encoder.layers.3.fc1.bias', 'encoder.sentence_encoder.layers.3.fc2.weight', 'encoder.sentence_encoder.layers.3.fc2.bias', 'encoder.sentence_encoder.layers.3.final_layer_norm.weight', 'encoder.sentence_encoder.layers.3.final_layer_norm.bias', 'encoder.sentence_encoder.emb_layer_norm.weight', 'encoder.sentence_encoder.emb_layer_norm.bias', 'encoder.lm_head.weight', 'encoder.lm_head.bias', 'encoder.lm_head.dense.weight', 'encoder.lm_head.dense.bias', 'encoder.lm_head.layer_norm.weight', 'encoder.lm_head.layer_norm.bias', 'classification_heads.sentence_classification_head.dense.weight', 'classification_heads.sentence_classification_head.dense.bias', 'classification_heads.sentence_classification_head.out_proj.weight', 'classification_heads.sentence_classification_head.out_proj.bias'])\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi/lib/python3.8/site-packages/fairseq/trainer.py\", line 283, in load_checkpoint\n",
      "    self.get_model().load_state_dict(\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi/lib/python3.8/site-packages/fairseq/models/fairseq_model.py\", line 100, in load_state_dict\n",
      "    return super().load_state_dict(new_state_dict, strict)\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1482, in load_state_dict\n",
      "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
      "RuntimeError: Error(s) in loading state_dict for RobertaModel:\n",
      "\tsize mismatch for encoder.sentence_encoder.embed_positions.weight: copying a param with shape torch.Size([146, 128]) from checkpoint, the shape in current model is torch.Size([514, 128]).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi/bin/fairseq-train\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi/lib/python3.8/site-packages/fairseq_cli/train.py\", line 352, in cli_main\n",
      "    distributed_utils.call_main(args, main)\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi/lib/python3.8/site-packages/fairseq/distributed_utils.py\", line 301, in call_main\n",
      "    main(args, **kwargs)\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi/lib/python3.8/site-packages/fairseq_cli/train.py\", line 110, in main\n",
      "    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi/lib/python3.8/site-packages/fairseq/checkpoint_utils.py\", line 188, in load_checkpoint\n",
      "    extra_state = trainer.load_checkpoint(\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi/lib/python3.8/site-packages/fairseq/trainer.py\", line 291, in load_checkpoint\n",
      "    raise Exception(\n",
      "Exception: Cannot load model parameters from checkpoint ../../../../BioPhi/biophi/humanization/methods/sapiens/models/v1/checkpoint_vh.pt; please ensure that the architectures match.\n"
     ]
    }
   ],
   "source": [
    "!fairseq-train ../../data/fairseq/ \\\n",
    "    --restore-file ../../../../BioPhi/biophi/humanization/methods/sapiens/models/v1/checkpoint_vh.pt \\\n",
    "    --reset-optimizer --reset-dataloader --reset-meters \\\n",
    "    --dataset-impl raw \\\n",
    "    --task sentence_prediction \\\n",
    "    --criterion sentence_prediction \\\n",
    "    --user-dir ../../../../BioPhi/biophi/humanization/methods/sapiens \\\n",
    "    --arch roberta_small \\\n",
    "    --max-tokens 8096 \\\n",
    "    --update-freq 4 \\\n",
    "    --lr 1e-4 \\\n",
    "    --optimizer adam \\\n",
    "    --lr-scheduler inverse_sqrt \\\n",
    "    --warmup-updates 16000 \\\n",
    "    --max-positions 512 \\\n",
    "    --skip-invalid-size-inputs-valid-test \\\n",
    "    --validate-interval-updates 5000 \\\n",
    "    --save-interval-updates 5000 \\\n",
    "    --save-dir ../../data/models/fairseq \\\n",
    "    --num-classes 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1b54918-8a94-4686-88e0-bbb9e2e14dde",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: fairseq-train [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]\n",
      "                     [--log-format {json,none,simple,tqdm}]\n",
      "                     [--tensorboard-logdir TENSORBOARD_LOGDIR] [--seed SEED]\n",
      "                     [--cpu] [--tpu] [--bf16] [--memory-efficient-bf16]\n",
      "                     [--fp16] [--memory-efficient-fp16]\n",
      "                     [--fp16-no-flatten-grads]\n",
      "                     [--fp16-init-scale FP16_INIT_SCALE]\n",
      "                     [--fp16-scale-window FP16_SCALE_WINDOW]\n",
      "                     [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]\n",
      "                     [--min-loss-scale MIN_LOSS_SCALE]\n",
      "                     [--threshold-loss-scale THRESHOLD_LOSS_SCALE]\n",
      "                     [--user-dir USER_DIR]\n",
      "                     [--empty-cache-freq EMPTY_CACHE_FREQ]\n",
      "                     [--all-gather-list-size ALL_GATHER_LIST_SIZE]\n",
      "                     [--model-parallel-size MODEL_PARALLEL_SIZE]\n",
      "                     [--checkpoint-suffix CHECKPOINT_SUFFIX]\n",
      "                     [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]\n",
      "                     [--quantization-config-path QUANTIZATION_CONFIG_PATH]\n",
      "                     [--profile]\n",
      "                     [--criterion {cross_entropy,ctc,adaptive_loss,wav2vec,legacy_masked_lm_loss,nat_loss,label_smoothed_cross_entropy,composite_loss,sentence_prediction,label_smoothed_cross_entropy_with_alignment,masked_lm,sentence_ranking,vocab_parallel_cross_entropy}]\n",
      "                     [--tokenizer {nltk,space,moses}]\n",
      "                     [--bpe {sentencepiece,fastbpe,gpt2,subword_nmt,hf_byte_bpe,bert,byte_bpe,characters,bytes}]\n",
      "                     [--optimizer {nag,adafactor,sgd,adamax,adagrad,adam,lamb,adadelta}]\n",
      "                     [--lr-scheduler {fixed,reduce_lr_on_plateau,polynomial_decay,inverse_sqrt,tri_stage,cosine,triangular}]\n",
      "                     [--scoring {sacrebleu,bleu,wer,chrf}] [--task TASK]\n",
      "                     [--num-workers NUM_WORKERS]\n",
      "                     [--skip-invalid-size-inputs-valid-test]\n",
      "                     [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]\n",
      "                     [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]\n",
      "                     [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]\n",
      "                     [--dataset-impl {raw,lazy,cached,mmap,fasta}]\n",
      "                     [--data-buffer-size DATA_BUFFER_SIZE]\n",
      "                     [--train-subset TRAIN_SUBSET]\n",
      "                     [--valid-subset VALID_SUBSET]\n",
      "                     [--validate-interval VALIDATE_INTERVAL]\n",
      "                     [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]\n",
      "                     [--validate-after-updates VALIDATE_AFTER_UPDATES]\n",
      "                     [--fixed-validation-seed FIXED_VALIDATION_SEED]\n",
      "                     [--disable-validation]\n",
      "                     [--max-tokens-valid MAX_TOKENS_VALID]\n",
      "                     [--batch-size-valid BATCH_SIZE_VALID]\n",
      "                     [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]\n",
      "                     [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]\n",
      "                     [--distributed-world-size DISTRIBUTED_WORLD_SIZE]\n",
      "                     [--distributed-rank DISTRIBUTED_RANK]\n",
      "                     [--distributed-backend DISTRIBUTED_BACKEND]\n",
      "                     [--distributed-init-method DISTRIBUTED_INIT_METHOD]\n",
      "                     [--distributed-port DISTRIBUTED_PORT]\n",
      "                     [--device-id DEVICE_ID] [--distributed-no-spawn]\n",
      "                     [--ddp-backend {c10d,no_c10d}]\n",
      "                     [--bucket-cap-mb BUCKET_CAP_MB] [--fix-batches-to-gpus]\n",
      "                     [--find-unused-parameters] [--fast-stat-sync]\n",
      "                     [--broadcast-buffers]\n",
      "                     [--distributed-wrapper {DDP,SlowMo}]\n",
      "                     [--slowmo-momentum SLOWMO_MOMENTUM]\n",
      "                     [--slowmo-algorithm SLOWMO_ALGORITHM]\n",
      "                     [--localsgd-frequency LOCALSGD_FREQUENCY]\n",
      "                     [--nprocs-per-node NPROCS_PER_NODE]\n",
      "                     [--pipeline-model-parallel]\n",
      "                     [--pipeline-balance PIPELINE_BALANCE]\n",
      "                     [--pipeline-devices PIPELINE_DEVICES]\n",
      "                     [--pipeline-chunks PIPELINE_CHUNKS]\n",
      "                     [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]\n",
      "                     [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]\n",
      "                     [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]\n",
      "                     [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]\n",
      "                     [--pipeline-checkpoint {always,never,except_last}]\n",
      "                     [--zero-sharding {none,os}] [--arch ARCH]\n",
      "                     [--max-epoch MAX_EPOCH] [--max-update MAX_UPDATE]\n",
      "                     [--stop-time-hours STOP_TIME_HOURS]\n",
      "                     [--clip-norm CLIP_NORM] [--sentence-avg]\n",
      "                     [--update-freq UPDATE_FREQ] [--lr LR] [--min-lr MIN_LR]\n",
      "                     [--use-bmuf] [--save-dir SAVE_DIR]\n",
      "                     [--restore-file RESTORE_FILE]\n",
      "                     [--finetune-from-model FINETUNE_FROM_MODEL]\n",
      "                     [--reset-dataloader] [--reset-lr-scheduler]\n",
      "                     [--reset-meters] [--reset-optimizer]\n",
      "                     [--optimizer-overrides OPTIMIZER_OVERRIDES]\n",
      "                     [--save-interval SAVE_INTERVAL]\n",
      "                     [--save-interval-updates SAVE_INTERVAL_UPDATES]\n",
      "                     [--keep-interval-updates KEEP_INTERVAL_UPDATES]\n",
      "                     [--keep-last-epochs KEEP_LAST_EPOCHS]\n",
      "                     [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS]\n",
      "                     [--no-save] [--no-epoch-checkpoints]\n",
      "                     [--no-last-checkpoints] [--no-save-optimizer-state]\n",
      "                     [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]\n",
      "                     [--maximize-best-checkpoint-metric] [--patience PATIENCE]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --no-progress-bar     disable progress bar\n",
      "  --log-interval LOG_INTERVAL\n",
      "                        log progress every N batches (when progress bar is\n",
      "                        disabled)\n",
      "  --log-format {json,none,simple,tqdm}\n",
      "                        log format to use\n",
      "  --tensorboard-logdir TENSORBOARD_LOGDIR\n",
      "                        path to save logs for tensorboard, should match\n",
      "                        --logdir of running tensorboard (default: no\n",
      "                        tensorboard logging)\n",
      "  --seed SEED           pseudo random number generator seed\n",
      "  --cpu                 use CPU instead of CUDA\n",
      "  --tpu                 use TPU instead of CUDA\n",
      "  --bf16                use bfloat16; implies --tpu\n",
      "  --memory-efficient-bf16\n",
      "                        use a memory-efficient version of BF16 training;\n",
      "                        implies --bf16\n",
      "  --fp16                use FP16\n",
      "  --memory-efficient-fp16\n",
      "                        use a memory-efficient version of FP16 training;\n",
      "                        implies --fp16\n",
      "  --fp16-no-flatten-grads\n",
      "                        don't flatten FP16 grads tensor\n",
      "  --fp16-init-scale FP16_INIT_SCALE\n",
      "                        default FP16 loss scale\n",
      "  --fp16-scale-window FP16_SCALE_WINDOW\n",
      "                        number of updates before increasing loss scale\n",
      "  --fp16-scale-tolerance FP16_SCALE_TOLERANCE\n",
      "                        pct of updates that can overflow before decreasing the\n",
      "                        loss scale\n",
      "  --min-loss-scale MIN_LOSS_SCALE\n",
      "                        minimum FP16 loss scale, after which training is\n",
      "                        stopped\n",
      "  --threshold-loss-scale THRESHOLD_LOSS_SCALE\n",
      "                        threshold FP16 loss scale from below\n",
      "  --user-dir USER_DIR   path to a python module containing custom extensions\n",
      "                        (tasks and/or architectures)\n",
      "  --empty-cache-freq EMPTY_CACHE_FREQ\n",
      "                        how often to clear the PyTorch CUDA cache (0 to\n",
      "                        disable)\n",
      "  --all-gather-list-size ALL_GATHER_LIST_SIZE\n",
      "                        number of bytes reserved for gathering stats from\n",
      "                        workers\n",
      "  --model-parallel-size MODEL_PARALLEL_SIZE\n",
      "                        total number of GPUs to parallelize model over\n",
      "  --checkpoint-suffix CHECKPOINT_SUFFIX\n",
      "                        suffix to add to the checkpoint file name\n",
      "  --checkpoint-shard-count CHECKPOINT_SHARD_COUNT\n",
      "                        Number of shards containing the checkpoint - if the\n",
      "                        checkpoint is over 300GB, it is preferable to split it\n",
      "                        into shards to prevent OOM on CPU while loading the\n",
      "                        checkpoint\n",
      "  --quantization-config-path QUANTIZATION_CONFIG_PATH\n",
      "                        path to quantization config file\n",
      "  --profile             enable autograd profiler emit_nvtx\n",
      "  --criterion {cross_entropy,ctc,adaptive_loss,wav2vec,legacy_masked_lm_loss,nat_loss,label_smoothed_cross_entropy,composite_loss,sentence_prediction,label_smoothed_cross_entropy_with_alignment,masked_lm,sentence_ranking,vocab_parallel_cross_entropy}\n",
      "  --tokenizer {nltk,space,moses}\n",
      "  --bpe {sentencepiece,fastbpe,gpt2,subword_nmt,hf_byte_bpe,bert,byte_bpe,characters,bytes}\n",
      "  --optimizer {nag,adafactor,sgd,adamax,adagrad,adam,lamb,adadelta}\n",
      "  --lr-scheduler {fixed,reduce_lr_on_plateau,polynomial_decay,inverse_sqrt,tri_stage,cosine,triangular}\n",
      "  --scoring {sacrebleu,bleu,wer,chrf}\n",
      "  --task TASK           task\n",
      "\n",
      "dataset_data_loading:\n",
      "  --num-workers NUM_WORKERS\n",
      "                        how many subprocesses to use for data loading\n",
      "  --skip-invalid-size-inputs-valid-test\n",
      "                        ignore too long or too short lines in valid and test\n",
      "                        set\n",
      "  --max-tokens MAX_TOKENS\n",
      "                        maximum number of tokens in a batch\n",
      "  --batch-size BATCH_SIZE\n",
      "                        number of examples in a batch\n",
      "  --required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE\n",
      "                        batch size will be a multiplier of this value\n",
      "  --required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE\n",
      "                        maximum sequence length in batch will be a multiplier\n",
      "                        of this value\n",
      "  --dataset-impl {raw,lazy,cached,mmap,fasta}\n",
      "                        output dataset implementation\n",
      "  --data-buffer-size DATA_BUFFER_SIZE\n",
      "                        Number of batches to preload\n",
      "  --train-subset TRAIN_SUBSET\n",
      "                        data subset to use for training (e.g. train, valid,\n",
      "                        test)\n",
      "  --valid-subset VALID_SUBSET\n",
      "                        comma separated list of data subsets to use for\n",
      "                        validation (e.g. train, valid, test)\n",
      "  --validate-interval VALIDATE_INTERVAL\n",
      "                        validate every N epochs\n",
      "  --validate-interval-updates VALIDATE_INTERVAL_UPDATES\n",
      "                        validate every N updates\n",
      "  --validate-after-updates VALIDATE_AFTER_UPDATES\n",
      "                        dont validate until reaching this many updates\n",
      "  --fixed-validation-seed FIXED_VALIDATION_SEED\n",
      "                        specified random seed for validation\n",
      "  --disable-validation  disable validation\n",
      "  --max-tokens-valid MAX_TOKENS_VALID\n",
      "                        maximum number of tokens in a validation batch\n",
      "                        (defaults to --max-tokens)\n",
      "  --batch-size-valid BATCH_SIZE_VALID\n",
      "                        batch size of the validation batch (defaults to\n",
      "                        --batch-size)\n",
      "  --curriculum CURRICULUM\n",
      "                        don't shuffle batches for first N epochs\n",
      "  --gen-subset GEN_SUBSET\n",
      "                        data subset to generate (train, valid, test)\n",
      "  --num-shards NUM_SHARDS\n",
      "                        shard generation over N shards\n",
      "  --shard-id SHARD_ID   id of the shard to generate (id < num_shards)\n",
      "\n",
      "distributed_training:\n",
      "  --distributed-world-size DISTRIBUTED_WORLD_SIZE\n",
      "                        total number of GPUs across all nodes (default: all\n",
      "                        visible GPUs)\n",
      "  --distributed-rank DISTRIBUTED_RANK\n",
      "                        rank of the current worker\n",
      "  --distributed-backend DISTRIBUTED_BACKEND\n",
      "                        distributed backend\n",
      "  --distributed-init-method DISTRIBUTED_INIT_METHOD\n",
      "                        typically tcp://hostname:port that will be used to\n",
      "                        establish initial connetion\n",
      "  --distributed-port DISTRIBUTED_PORT\n",
      "                        port number (not required if using --distributed-init-\n",
      "                        method)\n",
      "  --device-id DEVICE_ID, --local_rank DEVICE_ID\n",
      "                        which GPU to use (usually configured automatically)\n",
      "  --distributed-no-spawn\n",
      "                        do not spawn multiple processes even if multiple GPUs\n",
      "                        are visible\n",
      "  --ddp-backend {c10d,no_c10d}\n",
      "                        DistributedDataParallel backend\n",
      "  --bucket-cap-mb BUCKET_CAP_MB\n",
      "                        bucket size for reduction\n",
      "  --fix-batches-to-gpus\n",
      "                        don't shuffle batches between GPUs; this reduces\n",
      "                        overall randomness and may affect precision but avoids\n",
      "                        the cost of re-reading the data\n",
      "  --find-unused-parameters\n",
      "                        disable unused parameter detection (not applicable to\n",
      "                        no_c10d ddp-backend\n",
      "  --fast-stat-sync      [deprecated] this is now defined per Criterion\n",
      "  --broadcast-buffers   Copy non-trainable parameters between GPUs, such as\n",
      "                        batchnorm population statistics\n",
      "  --distributed-wrapper {DDP,SlowMo}\n",
      "                        DistributedDataParallel backend\n",
      "  --slowmo-momentum SLOWMO_MOMENTUM\n",
      "                        SlowMo momentum term; by default use 0.0 for 16 GPUs,\n",
      "                        0.2 for 32 GPUs; 0.5 for 64 GPUs, 0.6 for > 64 GPUs\n",
      "  --slowmo-algorithm SLOWMO_ALGORITHM\n",
      "                        whether to use LocalSGD or SGP\n",
      "  --localsgd-frequency LOCALSGD_FREQUENCY\n",
      "                        Local SGD allreduce frequency\n",
      "  --nprocs-per-node NPROCS_PER_NODE\n",
      "                        number of GPUs in each node. An allreduce operation\n",
      "                        across GPUs in a node is very fast. Hence, we do\n",
      "                        allreduce across GPUs in a node, and gossip across\n",
      "                        different nodes\n",
      "  --pipeline-model-parallel\n",
      "                        if set, use pipeline model parallelism across GPUs\n",
      "  --pipeline-balance PIPELINE_BALANCE\n",
      "                        partition the model into N_K pieces, where each piece\n",
      "                        contains N_i layers. The sum(args.pipeline_balance)\n",
      "                        should equal the total number of layers in the model\n",
      "  --pipeline-devices PIPELINE_DEVICES\n",
      "                        a list of device indices indicating which device to\n",
      "                        place each of the N_K partitions. The length of this\n",
      "                        list should equal the length of the --pipeline-balance\n",
      "                        argument\n",
      "  --pipeline-chunks PIPELINE_CHUNKS\n",
      "                        microbatch count for pipeline model parallelism\n",
      "  --pipeline-encoder-balance PIPELINE_ENCODER_BALANCE\n",
      "                        partition the pipeline parallel encoder into N_K\n",
      "                        pieces, where each piece contains N_i layers. The\n",
      "                        sum(args.pipeline_encoder_balance) should equal the\n",
      "                        total number of encoder layers in the model\n",
      "  --pipeline-encoder-devices PIPELINE_ENCODER_DEVICES\n",
      "                        a list of device indices indicating which device to\n",
      "                        place each of the N_K partitions. The length of this\n",
      "                        list should equal the length of the --pipeline-\n",
      "                        encoder-balance argument\n",
      "  --pipeline-decoder-balance PIPELINE_DECODER_BALANCE\n",
      "                        partition the pipeline parallel decoder into N_K\n",
      "                        pieces, where each piece contains N_i layers. The\n",
      "                        sum(args.pipeline_decoder_balance) should equal the\n",
      "                        total number of decoder layers in the model\n",
      "  --pipeline-decoder-devices PIPELINE_DECODER_DEVICES\n",
      "                        a list of device indices indicating which device to\n",
      "                        place each of the N_K partitions. The length of this\n",
      "                        list should equal the length of the --pipeline-\n",
      "                        decoder-balance argument\n",
      "  --pipeline-checkpoint {always,never,except_last}\n",
      "                        checkpointing mode for pipeline model parallelism\n",
      "  --zero-sharding {none,os}\n",
      "                        ZeRO sharding\n",
      "\n",
      "Model configuration:\n",
      "  --arch ARCH, -a ARCH  model architecture\n",
      "\n",
      "optimization:\n",
      "  --max-epoch MAX_EPOCH\n",
      "                        force stop training at specified epoch\n",
      "  --max-update MAX_UPDATE\n",
      "                        force stop training at specified update\n",
      "  --stop-time-hours STOP_TIME_HOURS\n",
      "                        force stop training after specified cumulative time\n",
      "                        (if >0)\n",
      "  --clip-norm CLIP_NORM\n",
      "                        clip threshold of gradients\n",
      "  --sentence-avg        normalize gradients by the number of sentences in a\n",
      "                        batch (default is to normalize by number of tokens)\n",
      "  --update-freq UPDATE_FREQ\n",
      "                        update parameters every N_i batches, when in epoch i\n",
      "  --lr LR               learning rate for the first N epochs; all epochs >N\n",
      "                        using LR_N (note: this may be interpreted differently\n",
      "                        depending on --lr-scheduler)\n",
      "  --min-lr MIN_LR       stop training when the learning rate reaches this\n",
      "                        minimum\n",
      "  --use-bmuf            specify global optimizer for syncing models on\n",
      "                        different GPUs/shards\n",
      "\n",
      "checkpoint:\n",
      "  --save-dir SAVE_DIR   path to save checkpoints\n",
      "  --restore-file RESTORE_FILE\n",
      "                        filename from which to load checkpoint (default:\n",
      "                        <save-dir>/checkpoint_last.pt\n",
      "  --finetune-from-model FINETUNE_FROM_MODEL\n",
      "                        finetune from a pretrained model; note that meters and\n",
      "                        lr scheduler will be reset\n",
      "  --reset-dataloader    if set, does not reload dataloader state from the\n",
      "                        checkpoint\n",
      "  --reset-lr-scheduler  if set, does not load lr scheduler state from the\n",
      "                        checkpoint\n",
      "  --reset-meters        if set, does not load meters from the checkpoint\n",
      "  --reset-optimizer     if set, does not load optimizer state from the\n",
      "                        checkpoint\n",
      "  --optimizer-overrides OPTIMIZER_OVERRIDES\n",
      "                        a dictionary used to override optimizer args when\n",
      "                        loading a checkpoint\n",
      "  --save-interval SAVE_INTERVAL\n",
      "                        save a checkpoint every N epochs\n",
      "  --save-interval-updates SAVE_INTERVAL_UPDATES\n",
      "                        save a checkpoint (and validate) every N updates\n",
      "  --keep-interval-updates KEEP_INTERVAL_UPDATES\n",
      "                        keep the last N checkpoints saved with --save-\n",
      "                        interval-updates\n",
      "  --keep-last-epochs KEEP_LAST_EPOCHS\n",
      "                        keep last N epoch checkpoints\n",
      "  --keep-best-checkpoints KEEP_BEST_CHECKPOINTS\n",
      "                        keep best N checkpoints based on scores\n",
      "  --no-save             don't save models or checkpoints\n",
      "  --no-epoch-checkpoints\n",
      "                        only store last and best checkpoints\n",
      "  --no-last-checkpoints\n",
      "                        don't store last checkpoints\n",
      "  --no-save-optimizer-state\n",
      "                        don't save optimizer-state as part of checkpoint\n",
      "  --best-checkpoint-metric BEST_CHECKPOINT_METRIC\n",
      "                        metric to use for saving \"best\" checkpoints\n",
      "  --maximize-best-checkpoint-metric\n",
      "                        select the largest metric value for saving \"best\"\n",
      "                        checkpoints\n",
      "  --patience PATIENCE   early stop training if valid performance doesn't\n",
      "                        improve for N consecutive validation runs; note that\n",
      "                        this is influenced by --validate-interval\n"
     ]
    }
   ],
   "source": [
    "! fairseq-train --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cffd4d-1f54-4686-a3f0-e03438fb02a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
