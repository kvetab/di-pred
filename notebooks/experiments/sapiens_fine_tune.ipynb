{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfd1bf8e-8e65-44ca-aa5c-a1a9e997c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from os import path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b10cc0d-3610-4f33-800d-3795852925cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0afa3328-47f7-4467-b797-364d8e1e9d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...</td>\n",
       "      <td>DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...</td>\n",
       "      <td>DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Antibody_ID                                              heavy  \\\n",
       "2073        6aod  EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...   \n",
       "1517        4yny  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2025        5xcv  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2070        6and  EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...   \n",
       "666         2xqy  QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...   \n",
       "\n",
       "                                                  light  Y  \n",
       "2073  DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...  0  \n",
       "1517  EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2025  QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2070  DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...  1  \n",
       "666   DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...  0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_train = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_train_data.csv\"), index_col=0)\n",
    "chen_valid = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_valid_data.csv\"), index_col=0)\n",
    "chen_test = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_test_data.csv\"), index_col=0)\n",
    "chen_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66c6f684-ce92-406d-a044-6965a85eb976",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path.join(DATA_DIR, \"fairseq/heavy/input0/train\"), \"w\") as dat:\n",
    "    with open(path.join(DATA_DIR, \"fairseq/heavy/label/train.label\"), \"w\") as lab:\n",
    "        for i, row in chen_train.iterrows():\n",
    "            dat.write(row[\"heavy\"] + '\\n')\n",
    "            lab.write(str(row[\"Y\"]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c148721-0d72-4502-80db-83ad1d253a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path.join(DATA_DIR, \"fairseq/light/input0/train\"), \"w\") as dat:\n",
    "    with open(path.join(DATA_DIR, \"fairseq/light/label/train.label\"), \"w\") as lab:\n",
    "        for i, row in chen_train.iterrows():\n",
    "            dat.write(row[\"light\"] + '\\n')\n",
    "            lab.write(str(row[\"Y\"]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5830e8a3-5f29-4f55-8372-20c61ccf84be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs = [row[\"heavy\"] for i, row in chen_train.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04d2af0-a0e4-4fb9-94d7-a2a83fbb5bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path.join(DATA_DIR, \"fairseq/heavy/input0/valid\"), \"w\") as dat:\n",
    "    with open(path.join(DATA_DIR, \"fairseq/heavy/label/valid\"), \"w\") as lab:\n",
    "        for i, row in chen_valid.iterrows():\n",
    "            dat.write(row[\"heavy\"] + '\\n')\n",
    "            lab.write(str(row[\"Y\"]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba5e1033-8da2-4589-866d-8fe12e6494a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path.join(DATA_DIR, \"fairseq/light/input0/valid\"), \"w\") as dat:\n",
    "    with open(path.join(DATA_DIR, \"fairseq/light/label/valid\"), \"w\") as lab:\n",
    "        for i, row in chen_valid.iterrows():\n",
    "            dat.write(row[\"light\"] + '\\n')\n",
    "            lab.write(str(row[\"Y\"]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3963bc8a-ec96-44b5-940e-713a20429311",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_seqs = [row[\"heavy\"] + row[\"light\"] for i, row in chen_valid.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64bab3dc-2c80-47db-988d-eef425e52311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.data import Dictionary\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9aac2806-687c-4384-9c70-3a418fda848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counter = Counter()\n",
    "for record in train_seqs:\n",
    "    token_counter.update(record)\n",
    "    \n",
    "dictionary = Dictionary()\n",
    "for token, count in sorted(token_counter.items()):\n",
    "    dictionary.add_symbol(token, count)\n",
    "    \n",
    "with open(path.join(DATA_DIR, \"fairseq/heavy/dict.txt\"), \"w\") as f:\n",
    "    dictionary.save(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bfe9a0-fe09-4989-862a-79db4caeab76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30ee4f79-21f1-412a-bf55-547a32937a69",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-02 10:02:29 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.999)', adam_eps=1e-08, add_prev_output_tokens=False, all_gather_list_size=16384, arch='roberta_small', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', classification_head_name='sentence_classification_head', clip_norm=0.0, cpu=False, criterion='sentence_prediction', curriculum=0, data='../../data/fairseq/heavy/', data_buffer_size=10, dataset_impl='raw', ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=128, encoder_ffn_embed_dim=256, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', init_token=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0001], lr_scheduler='inverse_sqrt', max_epoch=0, max_positions=144, max_tokens=8096, max_tokens_valid=8096, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, no_shuffle=False, nprocs_per_node=1, num_classes=2, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='../../../../BioPhi/biophi/humanization/methods/sapiens/models/v1/checkpoint_vh.pt', save_dir='../../data/models/fairseq', save_interval=1, save_interval_updates=5000, scoring='bleu', seed=1, sentence_avg=False, separator_token=None, shard_id=0, shorten_data_split_list='', shorten_method='truncate', skip_invalid_size_inputs_valid_test=True, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, stop_time_hours=0, task='sentence_prediction', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', update_freq=[4], use_bmuf=False, use_old_adam=False, user_dir='../../../../BioPhi/biophi/humanization/methods/sapiens', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=5000, warmup_init_lr=-1, warmup_updates=16000, weight_decay=0.0, zero_sharding='none')\n",
      "2022-02-02 10:02:29 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 25 types\n",
      "2022-02-02 10:02:29 | INFO | fairseq.tasks.sentence_prediction | [label] dictionary: 7 types\n",
      "2022-02-02 10:02:29 | INFO | fairseq.data.data_utils | loaded 120 examples from: ../../data/fairseq/heavy/input0/valid\n",
      "2022-02-02 10:02:29 | INFO | fairseq.data.data_utils | loaded 120 examples from: ../../data/fairseq/heavy/label/valid\n",
      "2022-02-02 10:02:29 | INFO | fairseq.tasks.sentence_prediction | Loaded valid with #samples: 120\n",
      "2022-02-02 10:02:29 | INFO | fairseq_cli.train | RobertaModel(\n",
      "  (encoder): RobertaEncoder(\n",
      "    (sentence_encoder): TransformerSentenceEncoder(\n",
      "      (dropout_module): FairseqDropout()\n",
      "      (embed_tokens): Embedding(25, 128, padding_idx=1)\n",
      "      (embed_positions): LearnedPositionalEmbedding(146, 128, padding_idx=1)\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (emb_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (lm_head): RobertaLMHead(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (classification_heads): ModuleDict(\n",
      "    (sentence_classification_head): RobertaClassificationHead(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (out_proj): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2022-02-02 10:02:29 | INFO | fairseq_cli.train | task: sentence_prediction (SentencePredictionTask)\n",
      "2022-02-02 10:02:29 | INFO | fairseq_cli.train | model: roberta_small (RobertaModel)\n",
      "2022-02-02 10:02:29 | INFO | fairseq_cli.train | criterion: sentence_prediction (SentencePredictionCriterion)\n",
      "2022-02-02 10:02:29 | INFO | fairseq_cli.train | num. model params: 585627 (num. trained: 585627)\n",
      "2022-02-02 10:02:29 | INFO | fairseq.trainer | detected shared parameter: encoder.sentence_encoder.embed_tokens.weight <- encoder.lm_head.weight\n",
      "2022-02-02 10:02:29 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
      "2022-02-02 10:02:29 | INFO | fairseq_cli.train | max tokens per GPU = 8096 and max sentences per GPU = None\n",
      "2022-02-02 10:02:29 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.dense.weight\n",
      "2022-02-02 10:02:29 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.dense.bias\n",
      "2022-02-02 10:02:29 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.out_proj.weight\n",
      "2022-02-02 10:02:29 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.out_proj.bias\n",
      "2022-02-02 10:02:29 | INFO | fairseq.trainer | loaded checkpoint ../../../../BioPhi/biophi/humanization/methods/sapiens/models/v1/checkpoint_vh.pt (epoch 700 @ 0 updates)\n",
      "2022-02-02 10:02:29 | INFO | fairseq.trainer | loading train data for epoch 1\n",
      "2022-02-02 10:02:29 | INFO | fairseq.data.data_utils | loaded 1338 examples from: ../../data/fairseq/heavy/input0/train\n",
      "2022-02-02 10:02:29 | INFO | fairseq.data.data_utils | loaded 1338 examples from: ../../data/fairseq/heavy/label/train\n",
      "2022-02-02 10:02:29 | INFO | fairseq.tasks.sentence_prediction | Loaded train with #samples: 1338\n",
      "epoch 001:   0%|                                          | 0/1 [00:00<?, ?it/s]2022-02-02 10:02:29 | INFO | fairseq.trainer | begin training epoch 1\n",
      "2022-02-02 10:02:32 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:02:34 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 0.964 | nll_loss 0.482 | accuracy 78.3 | wps 0 | wpb 240 | bsz 120 | num_updates 1\n",
      "2022-02-02 10:02:34 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:02:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint1.pt (epoch 1 @ 1 updates, score 0.964) (writing took 0.02896524999999972 seconds)\n",
      "2022-02-02 10:02:34 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
      "2022-02-02 10:02:34 | INFO | train | epoch 001 | loss 0.969 | nll_loss 0.485 | accuracy 63.9 | wps 0 | ups 0 | wpb 2676 | bsz 1338 | num_updates 1 | lr 6.25e-09 | gnorm 3.076 | train_wall 0 | wall 5\n",
      "epoch 002:   0%|                                          | 0/1 [00:00<?, ?it/s]2022-02-02 10:02:34 | INFO | fairseq.trainer | begin training epoch 2\n",
      "2022-02-02 10:02:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 002 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.49s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:02:38 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 0.964 | nll_loss 0.482 | accuracy 78.3 | wps 0 | wpb 240 | bsz 120 | num_updates 2 | best_loss 0.964\n",
      "2022-02-02 10:02:38 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:02:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint2.pt (epoch 2 @ 2 updates, score 0.964) (writing took 0.03728059699999875 seconds)\n",
      "2022-02-02 10:02:38 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
      "2022-02-02 10:02:38 | INFO | train | epoch 002 | loss 0.972 | nll_loss 0.486 | accuracy 63.5 | wps 674.3 | ups 0.25 | wpb 2676 | bsz 1338 | num_updates 2 | lr 1.25e-08 | gnorm 3.068 | train_wall 0 | wall 9\n",
      "epoch 003:   0%|                                          | 0/1 [00:00<?, ?it/s]2022-02-02 10:02:38 | INFO | fairseq.trainer | begin training epoch 3\n",
      "2022-02-02 10:02:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 003 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:02:41 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 0.964 | nll_loss 0.482 | accuracy 78.3 | wps 0 | wpb 240 | bsz 120 | num_updates 3 | best_loss 0.964\n",
      "2022-02-02 10:02:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:02:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint3.pt (epoch 3 @ 3 updates, score 0.964) (writing took 0.024370570000000313 seconds)\n",
      "2022-02-02 10:02:41 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
      "2022-02-02 10:02:41 | INFO | train | epoch 003 | loss 0.966 | nll_loss 0.483 | accuracy 64.7 | wps 687.7 | ups 0.26 | wpb 2676 | bsz 1338 | num_updates 3 | lr 1.875e-08 | gnorm 3.058 | train_wall 0 | wall 13\n",
      "epoch 004:   0%|                                          | 0/1 [00:00<?, ?it/s]2022-02-02 10:02:42 | INFO | fairseq.trainer | begin training epoch 4\n",
      "2022-02-02 10:02:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 004 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.47s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:02:45 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 0.964 | nll_loss 0.482 | accuracy 78.3 | wps 0 | wpb 240 | bsz 120 | num_updates 4 | best_loss 0.964\n",
      "2022-02-02 10:02:45 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:02:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint4.pt (epoch 4 @ 4 updates, score 0.964) (writing took 0.04262476400000281 seconds)\n",
      "2022-02-02 10:02:45 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
      "2022-02-02 10:02:45 | INFO | train | epoch 004 | loss 0.965 | nll_loss 0.483 | accuracy 66.1 | wps 699.6 | ups 0.26 | wpb 2676 | bsz 1338 | num_updates 4 | lr 2.5e-08 | gnorm 3.025 | train_wall 0 | wall 17\n",
      "epoch 005:   0%|                                          | 0/1 [00:00<?, ?it/s]2022-02-02 10:02:45 | INFO | fairseq.trainer | begin training epoch 5\n",
      "2022-02-02 10:02:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 005 | valid on 'valid' subset:   0%|                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset: 100%|████████| 1/1 [00:01<00:00,  1.48s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:02:49 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 0.964 | nll_loss 0.482 | accuracy 78.3 | wps 0 | wpb 240 | bsz 120 | num_updates 5 | best_loss 0.964\n",
      "2022-02-02 10:02:49 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:02:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint5.pt (epoch 5 @ 5 updates, score 0.964) (writing took 0.037110687999998504 seconds)\n",
      "2022-02-02 10:02:49 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
      "2022-02-02 10:02:49 | INFO | train | epoch 005 | loss 0.97 | nll_loss 0.485 | accuracy 64.1 | wps 702.5 | ups 0.26 | wpb 2676 | bsz 1338 | num_updates 5 | lr 3.125e-08 | gnorm 3.05 | train_wall 0 | wall 20\n",
      "epoch 006:   0%|                                          | 0/1 [00:00<?, ?it/s]2022-02-02 10:02:49 | INFO | fairseq.trainer | begin training epoch 6\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi_inst/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi_inst/bin/fairseq-train\", line 33, in <module>\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi_inst/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi_inst/lib/python3.8/site-packages/torch-1.10.1-py3.8-macosx-10.9-x86_64.egg/torch/__init__.py\", line 613, in <module>\n",
      "    sys.exit(load_entry_point('fairseq==0.10.2', 'console_scripts', 'fairseq-train')())\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi_inst/lib/python3.8/site-packages/fairseq-0.10.2-py3.8-macosx-10.9-x86_64.egg/fairseq_cli/train.py\", line 352, in cli_main\n",
      "    _C._initExtension(manager_path())\n",
      "  File \"<frozen importlib._bootstrap>\", line 194, in _lock_unlock_module\n",
      "    distributed_utils.call_main(args, main)\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi_inst/lib/python3.8/site-packages/fairseq-0.10.2-py3.8-macosx-10.9-x86_64.egg/fairseq/distributed_utils.py\", line 301, in call_main\n",
      "KeyboardInterrupt\n",
      "    main(args, **kwargs)\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi_inst/lib/python3.8/site-packages/fairseq-0.10.2-py3.8-macosx-10.9-x86_64.egg/fairseq_cli/train.py\", line 125, in main\n",
      "    valid_losses, should_stop = train(args, trainer, task, epoch_itr)\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi_inst/lib/python3.8/contextlib.py\", line 75, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi_inst/lib/python3.8/site-packages/fairseq-0.10.2-py3.8-macosx-10.9-x86_64.egg/fairseq_cli/train.py\", line 204, in train\n",
      "    for i, samples in enumerate(progress):\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi_inst/lib/python3.8/site-packages/tqdm-4.62.3-py3.8.egg/tqdm/std.py\", line 1180, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi_inst/lib/python3.8/site-packages/fairseq-0.10.2-py3.8-macosx-10.9-x86_64.egg/fairseq/data/iterators.py\", line 59, in __iter__\n",
      "    for x in self.iterable:\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi_inst/lib/python3.8/site-packages/fairseq-0.10.2-py3.8-macosx-10.9-x86_64.egg/fairseq/data/iterators.py\", line 469, in _chunk_iterator\n",
      "    for x in itr:\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi_inst/lib/python3.8/site-packages/fairseq-0.10.2-py3.8-macosx-10.9-x86_64.egg/fairseq/data/iterators.py\", line 59, in __iter__\n",
      "    for x in self.iterable:\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi_inst/lib/python3.8/site-packages/fairseq-0.10.2-py3.8-macosx-10.9-x86_64.egg/fairseq/data/iterators.py\", line 589, in __next__\n",
      "    item = self._queue.get(True)\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi_inst/lib/python3.8/queue.py\", line 170, in get\n",
      "    self.not_empty.wait()\n",
      "  File \"/Users/brazdilk/opt/anaconda3/envs/biophi_inst/lib/python3.8/threading.py\", line 302, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!fairseq-train ../../data/fairseq/heavy/ \\\n",
    "    --restore-file ../../../../BioPhi/biophi/humanization/methods/sapiens/models/v1/checkpoint_vh.pt \\\n",
    "    --reset-optimizer --reset-dataloader --reset-meters \\\n",
    "    --dataset-impl raw \\\n",
    "    --task sentence_prediction \\\n",
    "    --criterion sentence_prediction \\\n",
    "    --user-dir ../../../../BioPhi/biophi/humanization/methods/sapiens \\\n",
    "    --arch roberta_small \\\n",
    "    --max-tokens 8096 \\\n",
    "    --update-freq 4 \\\n",
    "    --lr 1e-4 \\\n",
    "    --optimizer adam \\\n",
    "    --lr-scheduler inverse_sqrt \\\n",
    "    --warmup-updates 16000 \\\n",
    "    --max-positions 144 \\\n",
    "    --skip-invalid-size-inputs-valid-test \\\n",
    "    --validate-interval-updates 5000 \\\n",
    "    --save-interval-updates 5000 \\\n",
    "    --save-dir ../../data/models/fairseq \\\n",
    "    --num-classes 2 \\\n",
    "    --shorten-method truncate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6f116178-2204-458d-bd07-b4672d716def",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-02 10:30:08 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.999)', adam_eps=1e-08, add_prev_output_tokens=False, all_gather_list_size=16384, arch='roberta_small', attention_dropout=0.1, batch_size=8, batch_size_valid=8, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', classification_head_name='di-pred', clip_norm=0.0, cpu=False, criterion='sentence_prediction', curriculum=0, data='../../data/fairseq/heavy/', data_buffer_size=10, dataset_impl='raw', ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=128, encoder_ffn_embed_dim=256, encoder_layerdrop=0, encoder_layers=4, encoder_layers_to_keep=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', init_token=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0001], lr_scheduler='inverse_sqrt', max_epoch=500, max_positions=144, max_tokens=8096, max_tokens_valid=8096, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, no_shuffle=False, nprocs_per_node=1, num_classes=2, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='../../../../BioPhi/biophi/humanization/methods/sapiens/models/v1/checkpoint_vh.pt', save_dir='../../data/models/fairseq', save_interval=1, save_interval_updates=5000, scoring='bleu', seed=1, sentence_avg=False, separator_token=None, shard_id=0, shorten_data_split_list='', shorten_method='truncate', skip_invalid_size_inputs_valid_test=True, slowmo_algorithm='LocalSGD', slowmo_momentum=None, spectral_norm_classification_head=False, stop_time_hours=0, task='sentence_prediction', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', update_freq=[4], use_bmuf=False, use_old_adam=False, user_dir='../../../../BioPhi/biophi/humanization/methods/sapiens', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=5000, warmup_init_lr=-1, warmup_updates=1600, weight_decay=0.0, zero_sharding='none')\n",
      "2022-02-02 10:30:08 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 25 types\n",
      "2022-02-02 10:30:08 | INFO | fairseq.tasks.sentence_prediction | [label] dictionary: 7 types\n",
      "2022-02-02 10:30:08 | INFO | fairseq.data.data_utils | loaded 120 examples from: ../../data/fairseq/heavy/input0/valid\n",
      "2022-02-02 10:30:08 | INFO | fairseq.data.data_utils | loaded 120 examples from: ../../data/fairseq/heavy/label/valid\n",
      "2022-02-02 10:30:08 | INFO | fairseq.tasks.sentence_prediction | Loaded valid with #samples: 120\n",
      "2022-02-02 10:30:08 | INFO | fairseq_cli.train | RobertaModel(\n",
      "  (encoder): RobertaEncoder(\n",
      "    (sentence_encoder): TransformerSentenceEncoder(\n",
      "      (dropout_module): FairseqDropout()\n",
      "      (embed_tokens): Embedding(25, 128, padding_idx=1)\n",
      "      (embed_positions): LearnedPositionalEmbedding(146, 128, padding_idx=1)\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerSentenceEncoderLayer(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (final_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (emb_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (lm_head): RobertaLMHead(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (classification_heads): ModuleDict(\n",
      "    (di-pred): RobertaClassificationHead(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (out_proj): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2022-02-02 10:30:08 | INFO | fairseq_cli.train | task: sentence_prediction (SentencePredictionTask)\n",
      "2022-02-02 10:30:08 | INFO | fairseq_cli.train | model: roberta_small (RobertaModel)\n",
      "2022-02-02 10:30:08 | INFO | fairseq_cli.train | criterion: sentence_prediction (SentencePredictionCriterion)\n",
      "2022-02-02 10:30:08 | INFO | fairseq_cli.train | num. model params: 585627 (num. trained: 585627)\n",
      "2022-02-02 10:30:08 | INFO | fairseq.trainer | detected shared parameter: encoder.sentence_encoder.embed_tokens.weight <- encoder.lm_head.weight\n",
      "2022-02-02 10:30:08 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
      "2022-02-02 10:30:08 | INFO | fairseq_cli.train | max tokens per GPU = 8096 and max sentences per GPU = 8\n",
      "2022-02-02 10:30:08 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.di-pred.dense.weight\n",
      "2022-02-02 10:30:08 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.di-pred.dense.bias\n",
      "2022-02-02 10:30:08 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.di-pred.out_proj.weight\n",
      "2022-02-02 10:30:08 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.di-pred.out_proj.bias\n",
      "2022-02-02 10:30:08 | INFO | fairseq.trainer | loaded checkpoint ../../../../BioPhi/biophi/humanization/methods/sapiens/models/v1/checkpoint_vh.pt (epoch 700 @ 0 updates)\n",
      "2022-02-02 10:30:08 | INFO | fairseq.trainer | loading train data for epoch 1\n",
      "2022-02-02 10:30:08 | INFO | fairseq.data.data_utils | loaded 1338 examples from: ../../data/fairseq/heavy/input0/train\n",
      "2022-02-02 10:30:08 | INFO | fairseq.data.data_utils | loaded 1338 examples from: ../../data/fairseq/heavy/label/train\n",
      "2022-02-02 10:30:08 | INFO | fairseq.tasks.sentence_prediction | Loaded train with #samples: 1338\n",
      "epoch 001:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:30:08 | INFO | fairseq.trainer | begin training epoch 1\n",
      "epoch 001:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.83it/s]2022-02-02 10:30:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:30:14 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 0.918 | nll_loss 0.459 | accuracy 78.3 | wps 1138.6 | wpb 16 | bsz 8 | num_updates 42\n",
      "2022-02-02 10:30:14 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:30:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint1.pt (epoch 1 @ 42 updates, score 0.918) (writing took 0.03679307600000037 seconds)\n",
      "2022-02-02 10:30:14 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
      "2022-02-02 10:30:14 | INFO | train | epoch 001 | loss 0.953 | nll_loss 0.477 | accuracy 69.1 | wps 693.4 | ups 10.88 | wpb 63.7 | bsz 31.9 | num_updates 42 | lr 2.625e-06 | gnorm 3.284 | train_wall 2 | wall 6\n",
      "epoch 002:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:30:14 | INFO | fairseq.trainer | begin training epoch 2\n",
      "epoch 002:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.36it/s]2022-02-02 10:30:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 002 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.69s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:30:20 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 0.84 | nll_loss 0.42 | accuracy 78.3 | wps 1160.7 | wpb 16 | bsz 8 | num_updates 84 | best_loss 0.84\n",
      "2022-02-02 10:30:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:30:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint2.pt (epoch 2 @ 84 updates, score 0.84) (writing took 0.037552051000000475 seconds)\n",
      "2022-02-02 10:30:20 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
      "2022-02-02 10:30:20 | INFO | train | epoch 002 | loss 0.888 | nll_loss 0.444 | accuracy 77.7 | wps 464.7 | ups 7.29 | wpb 63.7 | bsz 31.9 | num_updates 84 | lr 5.25e-06 | gnorm 2.555 | train_wall 2 | wall 12\n",
      "epoch 003:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:30:20 | INFO | fairseq.trainer | begin training epoch 3\n",
      "epoch 003:  93%|▉| 39/42 [00:04<00:00, 20.44it/s, loss=0.908, nll_loss=0.454, ac2022-02-02 10:30:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 003 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 003 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:27,  1.95s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:30:26 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 0.779 | nll_loss 0.39 | accuracy 78.3 | wps 856 | wpb 16 | bsz 8 | num_updates 126 | best_loss 0.779\n",
      "2022-02-02 10:30:26 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:30:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint3.pt (epoch 3 @ 126 updates, score 0.779) (writing took 0.04118262300000097 seconds)\n",
      "2022-02-02 10:30:26 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
      "2022-02-02 10:30:26 | INFO | train | epoch 003 | loss 0.816 | nll_loss 0.408 | accuracy 78.9 | wps 411.5 | ups 6.46 | wpb 63.7 | bsz 31.9 | num_updates 126 | lr 7.875e-06 | gnorm 1.853 | train_wall 2 | wall 18\n",
      "epoch 004:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:30:26 | INFO | fairseq.trainer | begin training epoch 4\n",
      "epoch 004:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.54it/s]2022-02-02 10:30:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 004 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.50s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:30:31 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1167.9 | wpb 16 | bsz 8 | num_updates 168 | best_loss 0.755\n",
      "2022-02-02 10:30:31 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:30:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint4.pt (epoch 4 @ 168 updates, score 0.755) (writing took 0.03275316500000258 seconds)\n",
      "2022-02-02 10:30:31 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
      "2022-02-02 10:30:31 | INFO | train | epoch 004 | loss 0.769 | nll_loss 0.385 | accuracy 79 | wps 507.1 | ups 7.96 | wpb 63.7 | bsz 31.9 | num_updates 168 | lr 1.05e-05 | gnorm 1.421 | train_wall 2 | wall 23\n",
      "epoch 005:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:30:31 | INFO | fairseq.trainer | begin training epoch 5\n",
      "epoch 005:  95%|▉| 40/42 [00:03<00:00, 21.04it/s, loss=0.771, nll_loss=0.386, ac2022-02-02 10:30:35 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 005 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 005 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.47s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:30:36 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 0.76 | nll_loss 0.38 | accuracy 78.3 | wps 1199.6 | wpb 16 | bsz 8 | num_updates 210 | best_loss 0.755\n",
      "2022-02-02 10:30:36 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:30:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint5.pt (epoch 5 @ 210 updates, score 0.76) (writing took 0.02906519700000132 seconds)\n",
      "2022-02-02 10:30:37 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
      "2022-02-02 10:30:37 | INFO | train | epoch 005 | loss 0.75 | nll_loss 0.375 | accuracy 79 | wps 517.7 | ups 8.13 | wpb 63.7 | bsz 31.9 | num_updates 210 | lr 1.3125e-05 | gnorm 1.222 | train_wall 2 | wall 29\n",
      "epoch 006:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:30:37 | INFO | fairseq.trainer | begin training epoch 6\n",
      "epoch 006:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.42it/s]2022-02-02 10:30:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 006 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 006 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.48s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:30:42 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 0.768 | nll_loss 0.384 | accuracy 78.3 | wps 1139.3 | wpb 16 | bsz 8 | num_updates 252 | best_loss 0.755\n",
      "2022-02-02 10:30:42 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:30:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint6.pt (epoch 6 @ 252 updates, score 0.768) (writing took 0.02791443099999924 seconds)\n",
      "2022-02-02 10:30:42 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)\n",
      "2022-02-02 10:30:42 | INFO | train | epoch 006 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 512.8 | ups 8.05 | wpb 63.7 | bsz 31.9 | num_updates 252 | lr 1.575e-05 | gnorm 1.158 | train_wall 2 | wall 34\n",
      "epoch 007:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:30:42 | INFO | fairseq.trainer | begin training epoch 7\n",
      "epoch 007:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.51it/s]2022-02-02 10:30:45 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 007 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 007 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:30:47 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 0.762 | nll_loss 0.381 | accuracy 78.3 | wps 1146.6 | wpb 16 | bsz 8 | num_updates 294 | best_loss 0.755\n",
      "2022-02-02 10:30:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:30:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint7.pt (epoch 7 @ 294 updates, score 0.762) (writing took 0.02805829900000134 seconds)\n",
      "2022-02-02 10:30:47 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)\n",
      "2022-02-02 10:30:47 | INFO | train | epoch 007 | loss 0.745 | nll_loss 0.373 | accuracy 79 | wps 510.1 | ups 8.01 | wpb 63.7 | bsz 31.9 | num_updates 294 | lr 1.8375e-05 | gnorm 1.275 | train_wall 2 | wall 39\n",
      "epoch 008:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:30:47 | INFO | fairseq.trainer | begin training epoch 8\n",
      "epoch 008:  95%|▉| 40/42 [00:03<00:00, 22.50it/s, loss=0.743, nll_loss=0.371, ac2022-02-02 10:30:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 008 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 008 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.48s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:30:52 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 0.759 | nll_loss 0.38 | accuracy 78.3 | wps 1198.6 | wpb 16 | bsz 8 | num_updates 336 | best_loss 0.755\n",
      "2022-02-02 10:30:52 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:30:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint8.pt (epoch 8 @ 336 updates, score 0.759) (writing took 0.031194356999996842 seconds)\n",
      "2022-02-02 10:30:52 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)\n",
      "2022-02-02 10:30:52 | INFO | train | epoch 008 | loss 0.745 | nll_loss 0.373 | accuracy 79 | wps 514.4 | ups 8.07 | wpb 63.7 | bsz 31.9 | num_updates 336 | lr 2.1e-05 | gnorm 1.19 | train_wall 2 | wall 44\n",
      "epoch 009:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:30:52 | INFO | fairseq.trainer | begin training epoch 9\n",
      "epoch 009:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.39it/s]2022-02-02 10:30:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 009 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 009 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.48s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:30:57 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1213.4 | wpb 16 | bsz 8 | num_updates 378 | best_loss 0.755\n",
      "2022-02-02 10:30:57 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:30:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint9.pt (epoch 9 @ 378 updates, score 0.756) (writing took 0.0268837499999961 seconds)\n",
      "2022-02-02 10:30:57 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)\n",
      "2022-02-02 10:30:57 | INFO | train | epoch 009 | loss 0.748 | nll_loss 0.374 | accuracy 79 | wps 517 | ups 8.11 | wpb 63.7 | bsz 31.9 | num_updates 378 | lr 2.3625e-05 | gnorm 1.218 | train_wall 2 | wall 49\n",
      "epoch 010:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:30:57 | INFO | fairseq.trainer | begin training epoch 10\n",
      "epoch 010:  95%|▉| 40/42 [00:03<00:00, 21.19it/s, loss=0.752, nll_loss=0.376, ac2022-02-02 10:31:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 010 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 010 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.47s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:31:03 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 0.757 | nll_loss 0.379 | accuracy 78.3 | wps 1180.5 | wpb 16 | bsz 8 | num_updates 420 | best_loss 0.755\n",
      "2022-02-02 10:31:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:31:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint10.pt (epoch 10 @ 420 updates, score 0.757) (writing took 0.03167937400000653 seconds)\n",
      "2022-02-02 10:31:03 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)\n",
      "2022-02-02 10:31:03 | INFO | train | epoch 010 | loss 0.745 | nll_loss 0.373 | accuracy 79 | wps 507.2 | ups 7.96 | wpb 63.7 | bsz 31.9 | num_updates 420 | lr 2.625e-05 | gnorm 1.145 | train_wall 2 | wall 55\n",
      "epoch 011:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:31:03 | INFO | fairseq.trainer | begin training epoch 11\n",
      "epoch 011:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 19.90it/s]2022-02-02 10:31:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 011 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 011 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:31:08 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 0.761 | nll_loss 0.38 | accuracy 78.3 | wps 1193.1 | wpb 16 | bsz 8 | num_updates 462 | best_loss 0.755\n",
      "2022-02-02 10:31:08 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:31:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint11.pt (epoch 11 @ 462 updates, score 0.761) (writing took 0.02874953100000255 seconds)\n",
      "2022-02-02 10:31:08 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)\n",
      "2022-02-02 10:31:08 | INFO | train | epoch 011 | loss 0.746 | nll_loss 0.373 | accuracy 79 | wps 477.7 | ups 7.5 | wpb 63.7 | bsz 31.9 | num_updates 462 | lr 2.8875e-05 | gnorm 1.031 | train_wall 2 | wall 60\n",
      "epoch 012:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:31:08 | INFO | fairseq.trainer | begin training epoch 12\n",
      "epoch 012:  95%|▉| 40/42 [00:03<00:00, 22.39it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 10:31:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 012 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 012 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.49s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:31:13 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 0.759 | nll_loss 0.38 | accuracy 78.3 | wps 1182.3 | wpb 16 | bsz 8 | num_updates 504 | best_loss 0.755\n",
      "2022-02-02 10:31:13 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:31:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint12.pt (epoch 12 @ 504 updates, score 0.759) (writing took 0.03135382399999287 seconds)\n",
      "2022-02-02 10:31:13 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)\n",
      "2022-02-02 10:31:13 | INFO | train | epoch 012 | loss 0.745 | nll_loss 0.372 | accuracy 79 | wps 511.5 | ups 8.03 | wpb 63.7 | bsz 31.9 | num_updates 504 | lr 3.15e-05 | gnorm 1.013 | train_wall 2 | wall 66\n",
      "epoch 013:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:31:13 | INFO | fairseq.trainer | begin training epoch 13\n",
      "epoch 013:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.24it/s]2022-02-02 10:31:17 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 013 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 013 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.47s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:31:19 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 0.757 | nll_loss 0.379 | accuracy 78.3 | wps 1157.8 | wpb 16 | bsz 8 | num_updates 546 | best_loss 0.755\n",
      "2022-02-02 10:31:19 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:31:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint13.pt (epoch 13 @ 546 updates, score 0.757) (writing took 0.02704624800000488 seconds)\n",
      "2022-02-02 10:31:19 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)\n",
      "2022-02-02 10:31:19 | INFO | train | epoch 013 | loss 0.746 | nll_loss 0.373 | accuracy 79 | wps 515.4 | ups 8.09 | wpb 63.7 | bsz 31.9 | num_updates 546 | lr 3.4125e-05 | gnorm 0.963 | train_wall 2 | wall 71\n",
      "epoch 014:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:31:19 | INFO | fairseq.trainer | begin training epoch 14\n",
      "epoch 014:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.45it/s]2022-02-02 10:31:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 014 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 014 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.48s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:31:24 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 0.758 | nll_loss 0.379 | accuracy 78.3 | wps 1195.2 | wpb 16 | bsz 8 | num_updates 588 | best_loss 0.755\n",
      "2022-02-02 10:31:24 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:31:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint14.pt (epoch 14 @ 588 updates, score 0.758) (writing took 0.03236229499999865 seconds)\n",
      "2022-02-02 10:31:24 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)\n",
      "2022-02-02 10:31:24 | INFO | train | epoch 014 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 519.7 | ups 8.16 | wpb 63.7 | bsz 31.9 | num_updates 588 | lr 3.675e-05 | gnorm 0.851 | train_wall 2 | wall 76\n",
      "epoch 015:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:31:24 | INFO | fairseq.trainer | begin training epoch 15\n",
      "epoch 015:  95%|▉| 40/42 [00:03<00:00, 22.59it/s, loss=0.736, nll_loss=0.368, ac2022-02-02 10:31:27 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 015 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 015 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.48s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:31:29 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1341.4 | wpb 16 | bsz 8 | num_updates 630 | best_loss 0.754\n",
      "2022-02-02 10:31:29 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:31:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint15.pt (epoch 15 @ 630 updates, score 0.754) (writing took 0.02316550700000164 seconds)\n",
      "2022-02-02 10:31:29 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)\n",
      "2022-02-02 10:31:29 | INFO | train | epoch 015 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 511.6 | ups 8.03 | wpb 63.7 | bsz 31.9 | num_updates 630 | lr 3.9375e-05 | gnorm 0.886 | train_wall 2 | wall 81\n",
      "epoch 016:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:31:29 | INFO | fairseq.trainer | begin training epoch 16\n",
      "epoch 016:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.66it/s]2022-02-02 10:31:32 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 016 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 016 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.48s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:31:34 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1341.5 | wpb 16 | bsz 8 | num_updates 672 | best_loss 0.754\n",
      "2022-02-02 10:31:34 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:31:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint16.pt (epoch 16 @ 672 updates, score 0.756) (writing took 0.01902290800001083 seconds)\n",
      "2022-02-02 10:31:34 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)\n",
      "2022-02-02 10:31:34 | INFO | train | epoch 016 | loss 0.745 | nll_loss 0.372 | accuracy 79 | wps 521.3 | ups 8.18 | wpb 63.7 | bsz 31.9 | num_updates 672 | lr 4.2e-05 | gnorm 0.814 | train_wall 2 | wall 86\n",
      "epoch 017:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:31:34 | INFO | fairseq.trainer | begin training epoch 17\n",
      "epoch 017:  95%|▉| 40/42 [00:03<00:00, 22.49it/s, loss=0.752, nll_loss=0.376, ac2022-02-02 10:31:38 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 017 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 017 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.50s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:31:39 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1354.2 | wpb 16 | bsz 8 | num_updates 714 | best_loss 0.754\n",
      "2022-02-02 10:31:39 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:31:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint17.pt (epoch 17 @ 714 updates, score 0.755) (writing took 0.018065103000012073 seconds)\n",
      "2022-02-02 10:31:39 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)\n",
      "2022-02-02 10:31:39 | INFO | train | epoch 017 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 513.7 | ups 8.06 | wpb 63.7 | bsz 31.9 | num_updates 714 | lr 4.4625e-05 | gnorm 0.881 | train_wall 2 | wall 91\n",
      "epoch 018:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:31:39 | INFO | fairseq.trainer | begin training epoch 18\n",
      "epoch 018:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.77it/s]2022-02-02 10:31:43 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 018 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 018 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.46s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:31:44 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1381.4 | wpb 16 | bsz 8 | num_updates 756 | best_loss 0.754\n",
      "2022-02-02 10:31:44 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:31:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint18.pt (epoch 18 @ 756 updates, score 0.756) (writing took 0.017585690000004206 seconds)\n",
      "2022-02-02 10:31:44 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)\n",
      "2022-02-02 10:31:44 | INFO | train | epoch 018 | loss 0.749 | nll_loss 0.375 | accuracy 79 | wps 525.3 | ups 8.25 | wpb 63.7 | bsz 31.9 | num_updates 756 | lr 4.725e-05 | gnorm 1.034 | train_wall 2 | wall 97\n",
      "epoch 019:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:31:44 | INFO | fairseq.trainer | begin training epoch 19\n",
      "epoch 019:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.60it/s]2022-02-02 10:31:48 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 019 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 019 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.50s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:31:50 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1201.9 | wpb 16 | bsz 8 | num_updates 798 | best_loss 0.754\n",
      "2022-02-02 10:31:50 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:31:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint19.pt (epoch 19 @ 798 updates, score 0.754) (writing took 0.02539586599999666 seconds)\n",
      "2022-02-02 10:31:50 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)\n",
      "2022-02-02 10:31:50 | INFO | train | epoch 019 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 514.5 | ups 8.08 | wpb 63.7 | bsz 31.9 | num_updates 798 | lr 4.9875e-05 | gnorm 0.872 | train_wall 2 | wall 102\n",
      "epoch 020:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:31:50 | INFO | fairseq.trainer | begin training epoch 20\n",
      "epoch 020:  95%|▉| 40/42 [00:03<00:00, 22.12it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 10:31:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 020 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 020 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:31:55 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1207.2 | wpb 16 | bsz 8 | num_updates 840 | best_loss 0.754\n",
      "2022-02-02 10:31:55 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:31:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint20.pt (epoch 20 @ 840 updates, score 0.756) (writing took 0.02206864400000086 seconds)\n",
      "2022-02-02 10:31:55 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)\n",
      "2022-02-02 10:31:55 | INFO | train | epoch 020 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 505.6 | ups 7.94 | wpb 63.7 | bsz 31.9 | num_updates 840 | lr 5.25e-05 | gnorm 0.875 | train_wall 2 | wall 107\n",
      "epoch 021:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:31:55 | INFO | fairseq.trainer | begin training epoch 21\n",
      "epoch 021:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.54it/s]2022-02-02 10:31:58 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 021 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 021 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.45s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:32:00 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1184.6 | wpb 16 | bsz 8 | num_updates 882 | best_loss 0.754\n",
      "2022-02-02 10:32:00 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:32:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint21.pt (epoch 21 @ 882 updates, score 0.754) (writing took 0.027156210000001124 seconds)\n",
      "2022-02-02 10:32:00 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)\n",
      "2022-02-02 10:32:00 | INFO | train | epoch 021 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 516.7 | ups 8.11 | wpb 63.7 | bsz 31.9 | num_updates 882 | lr 5.5125e-05 | gnorm 0.829 | train_wall 2 | wall 112\n",
      "epoch 022:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:32:00 | INFO | fairseq.trainer | begin training epoch 22\n",
      "epoch 022:  95%|▉| 40/42 [00:03<00:00, 22.42it/s, loss=0.736, nll_loss=0.368, ac2022-02-02 10:32:04 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 022 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 022 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.46s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:32:05 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1193.8 | wpb 16 | bsz 8 | num_updates 924 | best_loss 0.754\n",
      "2022-02-02 10:32:05 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:32:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint22.pt (epoch 22 @ 924 updates, score 0.754) (writing took 0.02895833099999834 seconds)\n",
      "2022-02-02 10:32:05 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)\n",
      "2022-02-02 10:32:05 | INFO | train | epoch 022 | loss 0.747 | nll_loss 0.373 | accuracy 79 | wps 518 | ups 8.13 | wpb 63.7 | bsz 31.9 | num_updates 924 | lr 5.775e-05 | gnorm 0.897 | train_wall 2 | wall 117\n",
      "epoch 023:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:32:05 | INFO | fairseq.trainer | begin training epoch 23\n",
      "epoch 023:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.57it/s]2022-02-02 10:32:09 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 023 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 023 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.47s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:32:10 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1041.2 | wpb 16 | bsz 8 | num_updates 966 | best_loss 0.754\n",
      "2022-02-02 10:32:10 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:32:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint23.pt (epoch 23 @ 966 updates, score 0.755) (writing took 0.024805204999992725 seconds)\n",
      "2022-02-02 10:32:11 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)\n",
      "2022-02-02 10:32:11 | INFO | train | epoch 023 | loss 0.747 | nll_loss 0.374 | accuracy 79 | wps 513.9 | ups 8.07 | wpb 63.7 | bsz 31.9 | num_updates 966 | lr 6.0375e-05 | gnorm 0.73 | train_wall 2 | wall 123\n",
      "epoch 024:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:32:11 | INFO | fairseq.trainer | begin training epoch 24\n",
      "epoch 024:  95%|▉| 40/42 [00:03<00:00, 22.36it/s, loss=0.762, nll_loss=0.381, ac2022-02-02 10:32:14 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 024 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 024 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.46s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:32:16 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1176.6 | wpb 16 | bsz 8 | num_updates 1008 | best_loss 0.754\n",
      "2022-02-02 10:32:16 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:32:16 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint24.pt (epoch 24 @ 1008 updates, score 0.756) (writing took 0.02082380199999534 seconds)\n",
      "2022-02-02 10:32:16 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)\n",
      "2022-02-02 10:32:16 | INFO | train | epoch 024 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 516.4 | ups 8.1 | wpb 63.7 | bsz 31.9 | num_updates 1008 | lr 6.3e-05 | gnorm 0.728 | train_wall 2 | wall 128\n",
      "epoch 025:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:32:16 | INFO | fairseq.trainer | begin training epoch 25\n",
      "epoch 025:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.06it/s]2022-02-02 10:32:19 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 025 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 025 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:32:21 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1173.5 | wpb 16 | bsz 8 | num_updates 1050 | best_loss 0.754\n",
      "2022-02-02 10:32:21 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:32:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint25.pt (epoch 25 @ 1050 updates, score 0.755) (writing took 0.020722957000003817 seconds)\n",
      "2022-02-02 10:32:21 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)\n",
      "2022-02-02 10:32:21 | INFO | train | epoch 025 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 508.6 | ups 7.98 | wpb 63.7 | bsz 31.9 | num_updates 1050 | lr 6.5625e-05 | gnorm 0.876 | train_wall 2 | wall 133\n",
      "epoch 026:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:32:21 | INFO | fairseq.trainer | begin training epoch 26\n",
      "epoch 026:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.53it/s]2022-02-02 10:32:25 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 026 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 026 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.50s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:32:26 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1120.4 | wpb 16 | bsz 8 | num_updates 1092 | best_loss 0.754\n",
      "2022-02-02 10:32:26 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:32:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint26.pt (epoch 26 @ 1092 updates, score 0.756) (writing took 0.02156524599999443 seconds)\n",
      "2022-02-02 10:32:26 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)\n",
      "2022-02-02 10:32:26 | INFO | train | epoch 026 | loss 0.746 | nll_loss 0.373 | accuracy 79 | wps 496.4 | ups 7.79 | wpb 63.7 | bsz 31.9 | num_updates 1092 | lr 6.825e-05 | gnorm 0.724 | train_wall 2 | wall 138\n",
      "epoch 027:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:32:26 | INFO | fairseq.trainer | begin training epoch 27\n",
      "epoch 027:  95%|▉| 40/42 [00:03<00:00, 20.00it/s, loss=0.743, nll_loss=0.371, ac2022-02-02 10:32:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 027 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 027 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.66s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:32:32 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 0.76 | nll_loss 0.38 | accuracy 78.3 | wps 1235.6 | wpb 16 | bsz 8 | num_updates 1134 | best_loss 0.754\n",
      "2022-02-02 10:32:32 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:32:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint27.pt (epoch 27 @ 1134 updates, score 0.76) (writing took 0.026898125000002437 seconds)\n",
      "2022-02-02 10:32:32 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)\n",
      "2022-02-02 10:32:32 | INFO | train | epoch 027 | loss 0.746 | nll_loss 0.373 | accuracy 79 | wps 476.1 | ups 7.47 | wpb 63.7 | bsz 31.9 | num_updates 1134 | lr 7.0875e-05 | gnorm 0.819 | train_wall 2 | wall 144\n",
      "epoch 028:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:32:32 | INFO | fairseq.trainer | begin training epoch 28\n",
      "epoch 028:  98%|███████████████████████████████▏| 41/42 [00:03<00:00, 20.32it/s]2022-02-02 10:32:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 028 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 028 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:32:38 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 0.757 | nll_loss 0.378 | accuracy 78.3 | wps 1212.1 | wpb 16 | bsz 8 | num_updates 1176 | best_loss 0.754\n",
      "2022-02-02 10:32:38 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:32:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint28.pt (epoch 28 @ 1176 updates, score 0.757) (writing took 0.024251616999976022 seconds)\n",
      "2022-02-02 10:32:38 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)\n",
      "2022-02-02 10:32:38 | INFO | train | epoch 028 | loss 0.746 | nll_loss 0.373 | accuracy 79 | wps 470.3 | ups 7.38 | wpb 63.7 | bsz 31.9 | num_updates 1176 | lr 7.35e-05 | gnorm 0.787 | train_wall 2 | wall 150\n",
      "epoch 029:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:32:38 | INFO | fairseq.trainer | begin training epoch 29\n",
      "epoch 029:  95%|▉| 40/42 [00:04<00:00, 20.71it/s, loss=0.746, nll_loss=0.373, ac2022-02-02 10:32:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 029 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 029 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:32:44 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1214.9 | wpb 16 | bsz 8 | num_updates 1218 | best_loss 0.754\n",
      "2022-02-02 10:32:44 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:32:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint29.pt (epoch 29 @ 1218 updates, score 0.754) (writing took 0.03993731299999581 seconds)\n",
      "2022-02-02 10:32:44 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)\n",
      "2022-02-02 10:32:44 | INFO | train | epoch 029 | loss 0.745 | nll_loss 0.373 | accuracy 79 | wps 454 | ups 7.13 | wpb 63.7 | bsz 31.9 | num_updates 1218 | lr 7.6125e-05 | gnorm 0.716 | train_wall 2 | wall 156\n",
      "epoch 030:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:32:44 | INFO | fairseq.trainer | begin training epoch 30\n",
      "epoch 030:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.25it/s]2022-02-02 10:32:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 030 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 030 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:32:49 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 0.758 | nll_loss 0.379 | accuracy 78.3 | wps 1185.8 | wpb 16 | bsz 8 | num_updates 1260 | best_loss 0.754\n",
      "2022-02-02 10:32:49 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:32:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint30.pt (epoch 30 @ 1260 updates, score 0.758) (writing took 0.025675710999990997 seconds)\n",
      "2022-02-02 10:32:49 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)\n",
      "2022-02-02 10:32:49 | INFO | train | epoch 030 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 477 | ups 7.49 | wpb 63.7 | bsz 31.9 | num_updates 1260 | lr 7.875e-05 | gnorm 0.617 | train_wall 2 | wall 161\n",
      "epoch 031:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:32:49 | INFO | fairseq.trainer | begin training epoch 31\n",
      "epoch 031:  95%|▉| 40/42 [00:03<00:00, 19.05it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 10:32:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 031 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 031 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:32:55 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1158.1 | wpb 16 | bsz 8 | num_updates 1302 | best_loss 0.754\n",
      "2022-02-02 10:32:55 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:32:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint31.pt (epoch 31 @ 1302 updates, score 0.754) (writing took 0.03813362299999312 seconds)\n",
      "2022-02-02 10:32:55 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)\n",
      "2022-02-02 10:32:55 | INFO | train | epoch 031 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 488 | ups 7.66 | wpb 63.7 | bsz 31.9 | num_updates 1302 | lr 8.1375e-05 | gnorm 0.619 | train_wall 2 | wall 167\n",
      "epoch 032:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:32:55 | INFO | fairseq.trainer | begin training epoch 32\n",
      "epoch 032:  98%|███████████████████████████████▏| 41/42 [00:03<00:00, 21.38it/s]2022-02-02 10:32:58 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 032 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 032 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:33:00 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1181.4 | wpb 16 | bsz 8 | num_updates 1344 | best_loss 0.754\n",
      "2022-02-02 10:33:00 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:33:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint32.pt (epoch 32 @ 1344 updates, score 0.756) (writing took 0.02777298600000222 seconds)\n",
      "2022-02-02 10:33:00 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)\n",
      "2022-02-02 10:33:00 | INFO | train | epoch 032 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 485.7 | ups 7.62 | wpb 63.7 | bsz 31.9 | num_updates 1344 | lr 8.4e-05 | gnorm 0.736 | train_wall 2 | wall 172\n",
      "epoch 033:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:33:00 | INFO | fairseq.trainer | begin training epoch 33\n",
      "epoch 033:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.46it/s]2022-02-02 10:33:04 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 033 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 033 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.64s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:33:06 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 0.76 | nll_loss 0.38 | accuracy 78.3 | wps 1106.6 | wpb 16 | bsz 8 | num_updates 1386 | best_loss 0.754\n",
      "2022-02-02 10:33:06 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:33:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint33.pt (epoch 33 @ 1386 updates, score 0.76) (writing took 0.0324712869999928 seconds)\n",
      "2022-02-02 10:33:06 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)\n",
      "2022-02-02 10:33:06 | INFO | train | epoch 033 | loss 0.746 | nll_loss 0.373 | accuracy 79 | wps 476.4 | ups 7.48 | wpb 63.7 | bsz 31.9 | num_updates 1386 | lr 8.6625e-05 | gnorm 0.73 | train_wall 2 | wall 178\n",
      "epoch 034:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:33:06 | INFO | fairseq.trainer | begin training epoch 34\n",
      "epoch 034:  95%|▉| 40/42 [00:04<00:00, 21.37it/s, loss=0.744, nll_loss=0.372, ac2022-02-02 10:33:10 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 034 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 034 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:33:12 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1187.3 | wpb 16 | bsz 8 | num_updates 1428 | best_loss 0.754\n",
      "2022-02-02 10:33:12 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:33:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint34.pt (epoch 34 @ 1428 updates, score 0.756) (writing took 0.0238188579999985 seconds)\n",
      "2022-02-02 10:33:12 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)\n",
      "2022-02-02 10:33:12 | INFO | train | epoch 034 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 451.2 | ups 7.08 | wpb 63.7 | bsz 31.9 | num_updates 1428 | lr 8.925e-05 | gnorm 0.76 | train_wall 2 | wall 184\n",
      "epoch 035:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:33:12 | INFO | fairseq.trainer | begin training epoch 35\n",
      "epoch 035:  98%|███████████████████████████████▏| 41/42 [00:03<00:00, 20.54it/s]2022-02-02 10:33:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 035 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 035 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:33:17 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1188.8 | wpb 16 | bsz 8 | num_updates 1470 | best_loss 0.754\n",
      "2022-02-02 10:33:17 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:33:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint35.pt (epoch 35 @ 1470 updates, score 0.756) (writing took 0.025193715999989763 seconds)\n",
      "2022-02-02 10:33:17 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)\n",
      "2022-02-02 10:33:17 | INFO | train | epoch 035 | loss 0.745 | nll_loss 0.373 | accuracy 79 | wps 466.7 | ups 7.33 | wpb 63.7 | bsz 31.9 | num_updates 1470 | lr 9.1875e-05 | gnorm 0.804 | train_wall 2 | wall 189\n",
      "epoch 036:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:33:17 | INFO | fairseq.trainer | begin training epoch 36\n",
      "epoch 036:  93%|▉| 39/42 [00:03<00:00, 21.29it/s, loss=0.75, nll_loss=0.375, acc2022-02-02 10:33:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 036 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 036 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:33:23 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1164.4 | wpb 16 | bsz 8 | num_updates 1512 | best_loss 0.754\n",
      "2022-02-02 10:33:23 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:33:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint36.pt (epoch 36 @ 1512 updates, score 0.754) (writing took 0.04826553699999181 seconds)\n",
      "2022-02-02 10:33:23 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)\n",
      "2022-02-02 10:33:23 | INFO | train | epoch 036 | loss 0.748 | nll_loss 0.374 | accuracy 79 | wps 482.3 | ups 7.57 | wpb 63.7 | bsz 31.9 | num_updates 1512 | lr 9.45e-05 | gnorm 0.761 | train_wall 2 | wall 195\n",
      "epoch 037:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:33:23 | INFO | fairseq.trainer | begin training epoch 37\n",
      "epoch 037:  98%|███████████████████████████████▏| 41/42 [00:03<00:00, 20.87it/s]2022-02-02 10:33:27 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 037 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 037 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.66s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:33:29 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1188.3 | wpb 16 | bsz 8 | num_updates 1554 | best_loss 0.754\n",
      "2022-02-02 10:33:29 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:33:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint37.pt (epoch 37 @ 1554 updates, score 0.754) (writing took 0.03269970399998101 seconds)\n",
      "2022-02-02 10:33:29 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)\n",
      "2022-02-02 10:33:29 | INFO | train | epoch 037 | loss 0.747 | nll_loss 0.374 | accuracy 79 | wps 461.1 | ups 7.24 | wpb 63.7 | bsz 31.9 | num_updates 1554 | lr 9.7125e-05 | gnorm 0.864 | train_wall 2 | wall 201\n",
      "epoch 038:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:33:29 | INFO | fairseq.trainer | begin training epoch 38\n",
      "epoch 038:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.93it/s]2022-02-02 10:33:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 038 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 038 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.64s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:33:35 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 0.76 | nll_loss 0.38 | accuracy 78.3 | wps 1136.1 | wpb 16 | bsz 8 | num_updates 1596 | best_loss 0.754\n",
      "2022-02-02 10:33:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:33:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint38.pt (epoch 38 @ 1596 updates, score 0.76) (writing took 0.022191629999980478 seconds)\n",
      "2022-02-02 10:33:35 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)\n",
      "2022-02-02 10:33:35 | INFO | train | epoch 038 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 466.3 | ups 7.32 | wpb 63.7 | bsz 31.9 | num_updates 1596 | lr 9.975e-05 | gnorm 0.669 | train_wall 2 | wall 207\n",
      "epoch 039:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:33:35 | INFO | fairseq.trainer | begin training epoch 39\n",
      "epoch 039:  95%|▉| 40/42 [00:03<00:00, 21.56it/s, loss=0.74, nll_loss=0.37, accu2022-02-02 10:33:38 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 039 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 039 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:26,  1.87s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:33:41 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 0.759 | nll_loss 0.38 | accuracy 78.3 | wps 1171 | wpb 16 | bsz 8 | num_updates 1638 | best_loss 0.754\n",
      "2022-02-02 10:33:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:33:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint39.pt (epoch 39 @ 1638 updates, score 0.759) (writing took 0.02866592899999887 seconds)\n",
      "2022-02-02 10:33:41 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)\n",
      "2022-02-02 10:33:41 | INFO | train | epoch 039 | loss 0.745 | nll_loss 0.372 | accuracy 79 | wps 446.5 | ups 7.01 | wpb 63.7 | bsz 31.9 | num_updates 1638 | lr 9.88332e-05 | gnorm 0.744 | train_wall 2 | wall 213\n",
      "epoch 040:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:33:41 | INFO | fairseq.trainer | begin training epoch 40\n",
      "epoch 040:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.93it/s]2022-02-02 10:33:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 040 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 040 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.68s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:33:46 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1118.7 | wpb 16 | bsz 8 | num_updates 1680 | best_loss 0.754\n",
      "2022-02-02 10:33:46 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:33:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint40.pt (epoch 40 @ 1680 updates, score 0.754) (writing took 0.040594305000013264 seconds)\n",
      "2022-02-02 10:33:46 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)\n",
      "2022-02-02 10:33:46 | INFO | train | epoch 040 | loss 0.745 | nll_loss 0.373 | accuracy 79 | wps 460.2 | ups 7.22 | wpb 63.7 | bsz 31.9 | num_updates 1680 | lr 9.759e-05 | gnorm 0.721 | train_wall 2 | wall 218\n",
      "epoch 041:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:33:46 | INFO | fairseq.trainer | begin training epoch 41\n",
      "epoch 041:  93%|▉| 39/42 [00:03<00:00, 21.18it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 10:33:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 041 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 041 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:33:52 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1177.4 | wpb 16 | bsz 8 | num_updates 1722 | best_loss 0.754\n",
      "2022-02-02 10:33:52 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:33:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint41.pt (epoch 41 @ 1722 updates, score 0.754) (writing took 0.04219624300000646 seconds)\n",
      "2022-02-02 10:33:52 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)\n",
      "2022-02-02 10:33:52 | INFO | train | epoch 041 | loss 0.745 | nll_loss 0.373 | accuracy 79 | wps 479.2 | ups 7.52 | wpb 63.7 | bsz 31.9 | num_updates 1722 | lr 9.63925e-05 | gnorm 0.78 | train_wall 2 | wall 224\n",
      "epoch 042:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:33:52 | INFO | fairseq.trainer | begin training epoch 42\n",
      "epoch 042:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.16it/s]2022-02-02 10:33:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 042 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 042 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:33:57 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1150 | wpb 16 | bsz 8 | num_updates 1764 | best_loss 0.754\n",
      "2022-02-02 10:33:57 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:33:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint42.pt (epoch 42 @ 1764 updates, score 0.754) (writing took 0.03721806199999378 seconds)\n",
      "2022-02-02 10:33:58 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)\n",
      "2022-02-02 10:33:58 | INFO | train | epoch 042 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 478.6 | ups 7.51 | wpb 63.7 | bsz 31.9 | num_updates 1764 | lr 9.52381e-05 | gnorm 0.703 | train_wall 2 | wall 230\n",
      "epoch 043:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:33:58 | INFO | fairseq.trainer | begin training epoch 43\n",
      "epoch 043:  98%|▉| 41/42 [00:03<00:00, 20.68it/s, loss=0.749, nll_loss=0.374, ac2022-02-02 10:34:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 043 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 043 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:34:03 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 0.758 | nll_loss 0.379 | accuracy 78.3 | wps 1140.6 | wpb 16 | bsz 8 | num_updates 1806 | best_loss 0.754\n",
      "2022-02-02 10:34:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:34:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint43.pt (epoch 43 @ 1806 updates, score 0.758) (writing took 0.027500838999998223 seconds)\n",
      "2022-02-02 10:34:03 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)\n",
      "2022-02-02 10:34:03 | INFO | train | epoch 043 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 470.7 | ups 7.39 | wpb 63.7 | bsz 31.9 | num_updates 1806 | lr 9.41242e-05 | gnorm 0.767 | train_wall 2 | wall 235\n",
      "epoch 044:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:34:03 | INFO | fairseq.trainer | begin training epoch 44\n",
      "epoch 044:  98%|███████████████████████████████▏| 41/42 [00:03<00:00, 20.09it/s]2022-02-02 10:34:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 044 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 044 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:26,  1.92s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:34:09 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1243.8 | wpb 16 | bsz 8 | num_updates 1848 | best_loss 0.754\n",
      "2022-02-02 10:34:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:34:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint44.pt (epoch 44 @ 1848 updates, score 0.754) (writing took 0.04337740900001563 seconds)\n",
      "2022-02-02 10:34:09 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)\n",
      "2022-02-02 10:34:09 | INFO | train | epoch 044 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 445.6 | ups 6.99 | wpb 63.7 | bsz 31.9 | num_updates 1848 | lr 9.30484e-05 | gnorm 0.69 | train_wall 2 | wall 241\n",
      "epoch 045:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:34:09 | INFO | fairseq.trainer | begin training epoch 45\n",
      "epoch 045:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.94it/s]2022-02-02 10:34:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 045 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 045 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.69s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:34:15 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1140 | wpb 16 | bsz 8 | num_updates 1890 | best_loss 0.754\n",
      "2022-02-02 10:34:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:34:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint45.pt (epoch 45 @ 1890 updates, score 0.756) (writing took 0.030473515000011275 seconds)\n",
      "2022-02-02 10:34:15 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)\n",
      "2022-02-02 10:34:15 | INFO | train | epoch 045 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 461.2 | ups 7.24 | wpb 63.7 | bsz 31.9 | num_updates 1890 | lr 9.20087e-05 | gnorm 0.717 | train_wall 2 | wall 247\n",
      "epoch 046:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:34:15 | INFO | fairseq.trainer | begin training epoch 46\n",
      "epoch 046:  95%|▉| 40/42 [00:03<00:00, 21.01it/s, loss=0.738, nll_loss=0.369, ac2022-02-02 10:34:19 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 046 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 046 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.66s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:34:21 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1105.4 | wpb 16 | bsz 8 | num_updates 1932 | best_loss 0.754\n",
      "2022-02-02 10:34:21 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:34:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint46.pt (epoch 46 @ 1932 updates, score 0.754) (writing took 0.03882040199999892 seconds)\n",
      "2022-02-02 10:34:21 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)\n",
      "2022-02-02 10:34:21 | INFO | train | epoch 046 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 458 | ups 7.19 | wpb 63.7 | bsz 31.9 | num_updates 1932 | lr 9.10032e-05 | gnorm 0.7 | train_wall 2 | wall 253\n",
      "epoch 047:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:34:21 | INFO | fairseq.trainer | begin training epoch 47\n",
      "epoch 047:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.01it/s]2022-02-02 10:34:25 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 047 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 047 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:34:27 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 0.757 | nll_loss 0.378 | accuracy 78.3 | wps 1181.2 | wpb 16 | bsz 8 | num_updates 1974 | best_loss 0.754\n",
      "2022-02-02 10:34:27 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:34:27 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint47.pt (epoch 47 @ 1974 updates, score 0.757) (writing took 0.027627160000008644 seconds)\n",
      "2022-02-02 10:34:27 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)\n",
      "2022-02-02 10:34:27 | INFO | train | epoch 047 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 457.3 | ups 7.18 | wpb 63.7 | bsz 31.9 | num_updates 1974 | lr 9.00298e-05 | gnorm 0.73 | train_wall 2 | wall 259\n",
      "epoch 048:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:34:27 | INFO | fairseq.trainer | begin training epoch 48\n",
      "epoch 048:  93%|▉| 39/42 [00:03<00:00, 20.93it/s, loss=0.754, nll_loss=0.377, ac2022-02-02 10:34:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 048 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 048 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:34:32 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1132.3 | wpb 16 | bsz 8 | num_updates 2016 | best_loss 0.754\n",
      "2022-02-02 10:34:32 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:34:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint48.pt (epoch 48 @ 2016 updates, score 0.756) (writing took 0.02660576999994646 seconds)\n",
      "2022-02-02 10:34:32 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)\n",
      "2022-02-02 10:34:32 | INFO | train | epoch 048 | loss 0.747 | nll_loss 0.373 | accuracy 79 | wps 486.4 | ups 7.63 | wpb 63.7 | bsz 31.9 | num_updates 2016 | lr 8.90871e-05 | gnorm 0.752 | train_wall 2 | wall 264\n",
      "epoch 049:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:34:32 | INFO | fairseq.trainer | begin training epoch 49\n",
      "epoch 049:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.06it/s]2022-02-02 10:34:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 049 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 049 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:34:38 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1176.9 | wpb 16 | bsz 8 | num_updates 2058 | best_loss 0.754\n",
      "2022-02-02 10:34:38 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:34:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint49.pt (epoch 49 @ 2058 updates, score 0.754) (writing took 0.040675684000007095 seconds)\n",
      "2022-02-02 10:34:38 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)\n",
      "2022-02-02 10:34:38 | INFO | train | epoch 049 | loss 0.745 | nll_loss 0.372 | accuracy 79 | wps 473.5 | ups 7.43 | wpb 63.7 | bsz 31.9 | num_updates 2058 | lr 8.81733e-05 | gnorm 0.681 | train_wall 2 | wall 270\n",
      "epoch 050:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:34:38 | INFO | fairseq.trainer | begin training epoch 50\n",
      "epoch 050:  98%|███████████████████████████████▏| 41/42 [00:03<00:00, 20.81it/s]2022-02-02 10:34:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 050 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 050 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:34:43 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1175.9 | wpb 16 | bsz 8 | num_updates 2100 | best_loss 0.754\n",
      "2022-02-02 10:34:43 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:34:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint50.pt (epoch 50 @ 2100 updates, score 0.756) (writing took 0.030851905000019997 seconds)\n",
      "2022-02-02 10:34:44 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)\n",
      "2022-02-02 10:34:44 | INFO | train | epoch 050 | loss 0.745 | nll_loss 0.372 | accuracy 79 | wps 473.7 | ups 7.43 | wpb 63.7 | bsz 31.9 | num_updates 2100 | lr 8.72872e-05 | gnorm 0.789 | train_wall 2 | wall 276\n",
      "epoch 051:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:34:44 | INFO | fairseq.trainer | begin training epoch 51\n",
      "epoch 051:  95%|██████████████████████████████▍ | 40/42 [00:04<00:00, 21.28it/s]2022-02-02 10:34:48 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 051 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 051 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.65s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:34:50 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1128.7 | wpb 16 | bsz 8 | num_updates 2142 | best_loss 0.754\n",
      "2022-02-02 10:34:50 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:34:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint51.pt (epoch 51 @ 2142 updates, score 0.754) (writing took 0.03145293000000038 seconds)\n",
      "2022-02-02 10:34:50 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)\n",
      "2022-02-02 10:34:50 | INFO | train | epoch 051 | loss 0.747 | nll_loss 0.374 | accuracy 79 | wps 440.6 | ups 6.92 | wpb 63.7 | bsz 31.9 | num_updates 2142 | lr 8.64272e-05 | gnorm 0.701 | train_wall 2 | wall 282\n",
      "epoch 052:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:34:50 | INFO | fairseq.trainer | begin training epoch 52\n",
      "epoch 052:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.57it/s]2022-02-02 10:34:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 052 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 052 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.63s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:34:55 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1020.3 | wpb 16 | bsz 8 | num_updates 2184 | best_loss 0.754\n",
      "2022-02-02 10:34:55 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:34:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint52.pt (epoch 52 @ 2184 updates, score 0.754) (writing took 0.03408437299998468 seconds)\n",
      "2022-02-02 10:34:55 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)\n",
      "2022-02-02 10:34:55 | INFO | train | epoch 052 | loss 0.745 | nll_loss 0.372 | accuracy 79 | wps 471.1 | ups 7.39 | wpb 63.7 | bsz 31.9 | num_updates 2184 | lr 8.55921e-05 | gnorm 0.658 | train_wall 2 | wall 287\n",
      "epoch 053:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:34:55 | INFO | fairseq.trainer | begin training epoch 53\n",
      "epoch 053:  93%|▉| 39/42 [00:03<00:00, 20.44it/s, loss=0.747, nll_loss=0.374, ac2022-02-02 10:34:59 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 053 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 053 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:35:01 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1126 | wpb 16 | bsz 8 | num_updates 2226 | best_loss 0.754\n",
      "2022-02-02 10:35:01 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:35:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint53.pt (epoch 53 @ 2226 updates, score 0.756) (writing took 0.01976071500001808 seconds)\n",
      "2022-02-02 10:35:01 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)\n",
      "2022-02-02 10:35:01 | INFO | train | epoch 053 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 478.4 | ups 7.51 | wpb 63.7 | bsz 31.9 | num_updates 2226 | lr 8.47808e-05 | gnorm 0.721 | train_wall 2 | wall 293\n",
      "epoch 054:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:35:01 | INFO | fairseq.trainer | begin training epoch 54\n",
      "epoch 054:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.43it/s]2022-02-02 10:35:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 054 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 054 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.66s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:35:07 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 0.76 | nll_loss 0.38 | accuracy 78.3 | wps 1186.9 | wpb 16 | bsz 8 | num_updates 2268 | best_loss 0.754\n",
      "2022-02-02 10:35:07 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:35:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint54.pt (epoch 54 @ 2268 updates, score 0.76) (writing took 0.03619249299998728 seconds)\n",
      "2022-02-02 10:35:07 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)\n",
      "2022-02-02 10:35:07 | INFO | train | epoch 054 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 441.7 | ups 6.93 | wpb 63.7 | bsz 31.9 | num_updates 2268 | lr 8.39921e-05 | gnorm 0.732 | train_wall 2 | wall 299\n",
      "epoch 055:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:35:07 | INFO | fairseq.trainer | begin training epoch 55\n",
      "epoch 055:  98%|▉| 41/42 [00:03<00:00, 20.87it/s, loss=0.744, nll_loss=0.372, ac2022-02-02 10:35:11 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 055 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 055 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:35:13 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1166.3 | wpb 16 | bsz 8 | num_updates 2310 | best_loss 0.754\n",
      "2022-02-02 10:35:13 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:35:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint55.pt (epoch 55 @ 2310 updates, score 0.755) (writing took 0.03527480799999694 seconds)\n",
      "2022-02-02 10:35:13 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)\n",
      "2022-02-02 10:35:13 | INFO | train | epoch 055 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 476.9 | ups 7.49 | wpb 63.7 | bsz 31.9 | num_updates 2310 | lr 8.3225e-05 | gnorm 0.665 | train_wall 2 | wall 305\n",
      "epoch 056:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:35:13 | INFO | fairseq.trainer | begin training epoch 56\n",
      "epoch 056:  98%|███████████████████████████████▏| 41/42 [00:03<00:00, 20.62it/s]2022-02-02 10:35:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 056 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 056 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:35:18 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1114.3 | wpb 16 | bsz 8 | num_updates 2352 | best_loss 0.754\n",
      "2022-02-02 10:35:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:35:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint56.pt (epoch 56 @ 2352 updates, score 0.755) (writing took 0.03248905300000615 seconds)\n",
      "2022-02-02 10:35:18 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)\n",
      "2022-02-02 10:35:18 | INFO | train | epoch 056 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 472.2 | ups 7.41 | wpb 63.7 | bsz 31.9 | num_updates 2352 | lr 8.24786e-05 | gnorm 0.691 | train_wall 2 | wall 310\n",
      "epoch 057:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:35:18 | INFO | fairseq.trainer | begin training epoch 57\n",
      "epoch 057:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.76it/s]2022-02-02 10:35:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 057 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 057 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:35:24 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 0.757 | nll_loss 0.378 | accuracy 78.3 | wps 1155.9 | wpb 16 | bsz 8 | num_updates 2394 | best_loss 0.754\n",
      "2022-02-02 10:35:24 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:35:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint57.pt (epoch 57 @ 2394 updates, score 0.757) (writing took 0.029572033000022202 seconds)\n",
      "2022-02-02 10:35:24 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)\n",
      "2022-02-02 10:35:24 | INFO | train | epoch 057 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 488.5 | ups 7.67 | wpb 63.7 | bsz 31.9 | num_updates 2394 | lr 8.17519e-05 | gnorm 0.702 | train_wall 2 | wall 316\n",
      "epoch 058:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:35:24 | INFO | fairseq.trainer | begin training epoch 58\n",
      "epoch 058:  98%|▉| 41/42 [00:03<00:00, 20.79it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 10:35:27 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 058 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 058 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:35:29 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1142.4 | wpb 16 | bsz 8 | num_updates 2436 | best_loss 0.754\n",
      "2022-02-02 10:35:29 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:35:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint58.pt (epoch 58 @ 2436 updates, score 0.755) (writing took 0.030413489000011396 seconds)\n",
      "2022-02-02 10:35:29 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)\n",
      "2022-02-02 10:35:29 | INFO | train | epoch 058 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 484.3 | ups 7.6 | wpb 63.7 | bsz 31.9 | num_updates 2436 | lr 8.10441e-05 | gnorm 0.637 | train_wall 2 | wall 321\n",
      "epoch 059:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:35:29 | INFO | fairseq.trainer | begin training epoch 59\n",
      "epoch 059:  98%|███████████████████████████████▏| 41/42 [00:03<00:00, 20.85it/s]2022-02-02 10:35:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 059 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 059 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:35:35 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1150.9 | wpb 16 | bsz 8 | num_updates 2478 | best_loss 0.754\n",
      "2022-02-02 10:35:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:35:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint59.pt (epoch 59 @ 2478 updates, score 0.754) (writing took 0.043003730000009455 seconds)\n",
      "2022-02-02 10:35:35 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)\n",
      "2022-02-02 10:35:35 | INFO | train | epoch 059 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 479.1 | ups 7.52 | wpb 63.7 | bsz 31.9 | num_updates 2478 | lr 8.03543e-05 | gnorm 0.655 | train_wall 2 | wall 327\n",
      "epoch 060:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:35:35 | INFO | fairseq.trainer | begin training epoch 60\n",
      "epoch 060:  93%|▉| 39/42 [00:03<00:00, 20.98it/s, loss=0.749, nll_loss=0.374, ac2022-02-02 10:35:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 060 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 060 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:35:40 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1114.4 | wpb 16 | bsz 8 | num_updates 2520 | best_loss 0.754\n",
      "2022-02-02 10:35:40 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:35:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint60.pt (epoch 60 @ 2520 updates, score 0.756) (writing took 0.02617708700000776 seconds)\n",
      "2022-02-02 10:35:40 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)\n",
      "2022-02-02 10:35:40 | INFO | train | epoch 060 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 481 | ups 7.55 | wpb 63.7 | bsz 31.9 | num_updates 2520 | lr 7.96819e-05 | gnorm 0.608 | train_wall 2 | wall 332\n",
      "epoch 061:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:35:40 | INFO | fairseq.trainer | begin training epoch 61\n",
      "epoch 061:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.53it/s]2022-02-02 10:35:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 061 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 061 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:35:46 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 0.762 | nll_loss 0.381 | accuracy 78.3 | wps 1218 | wpb 16 | bsz 8 | num_updates 2562 | best_loss 0.754\n",
      "2022-02-02 10:35:46 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:35:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint61.pt (epoch 61 @ 2562 updates, score 0.762) (writing took 0.025221620000024814 seconds)\n",
      "2022-02-02 10:35:46 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)\n",
      "2022-02-02 10:35:46 | INFO | train | epoch 061 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 470.3 | ups 7.38 | wpb 63.7 | bsz 31.9 | num_updates 2562 | lr 7.90261e-05 | gnorm 0.678 | train_wall 2 | wall 338\n",
      "epoch 062:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:35:46 | INFO | fairseq.trainer | begin training epoch 62\n",
      "epoch 062:  95%|▉| 40/42 [00:04<00:00, 20.73it/s, loss=0.737, nll_loss=0.368, ac2022-02-02 10:35:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 062 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 062 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.67s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:35:52 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1129.2 | wpb 16 | bsz 8 | num_updates 2604 | best_loss 0.754\n",
      "2022-02-02 10:35:52 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:35:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint62.pt (epoch 62 @ 2604 updates, score 0.755) (writing took 0.031026342000018303 seconds)\n",
      "2022-02-02 10:35:52 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)\n",
      "2022-02-02 10:35:52 | INFO | train | epoch 062 | loss 0.745 | nll_loss 0.373 | accuracy 79 | wps 442.2 | ups 6.94 | wpb 63.7 | bsz 31.9 | num_updates 2604 | lr 7.83862e-05 | gnorm 0.722 | train_wall 2 | wall 344\n",
      "epoch 063:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:35:52 | INFO | fairseq.trainer | begin training epoch 63\n",
      "epoch 063:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.19it/s]2022-02-02 10:35:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 063 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 063 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:35:58 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1117.5 | wpb 16 | bsz 8 | num_updates 2646 | best_loss 0.754\n",
      "2022-02-02 10:35:58 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:35:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint63.pt (epoch 63 @ 2646 updates, score 0.755) (writing took 0.02352277199997843 seconds)\n",
      "2022-02-02 10:35:58 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)\n",
      "2022-02-02 10:35:58 | INFO | train | epoch 063 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 476.5 | ups 7.48 | wpb 63.7 | bsz 31.9 | num_updates 2646 | lr 7.77616e-05 | gnorm 0.781 | train_wall 2 | wall 350\n",
      "epoch 064:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:35:58 | INFO | fairseq.trainer | begin training epoch 64\n",
      "epoch 064:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.83it/s]2022-02-02 10:36:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 064 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 064 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:36:03 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 0.758 | nll_loss 0.379 | accuracy 78.3 | wps 1145.6 | wpb 16 | bsz 8 | num_updates 2688 | best_loss 0.754\n",
      "2022-02-02 10:36:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:36:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint64.pt (epoch 64 @ 2688 updates, score 0.758) (writing took 0.033471457000018745 seconds)\n",
      "2022-02-02 10:36:03 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)\n",
      "2022-02-02 10:36:03 | INFO | train | epoch 064 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 473.1 | ups 7.43 | wpb 63.7 | bsz 31.9 | num_updates 2688 | lr 7.71517e-05 | gnorm 0.646 | train_wall 2 | wall 355\n",
      "epoch 065:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:36:03 | INFO | fairseq.trainer | begin training epoch 65\n",
      "epoch 065:  93%|▉| 39/42 [00:03<00:00, 21.07it/s, loss=0.755, nll_loss=0.377, ac2022-02-02 10:36:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 065 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 065 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:36:09 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1126.7 | wpb 16 | bsz 8 | num_updates 2730 | best_loss 0.754\n",
      "2022-02-02 10:36:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:36:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint65.pt (epoch 65 @ 2730 updates, score 0.756) (writing took 0.03057412900000145 seconds)\n",
      "2022-02-02 10:36:09 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)\n",
      "2022-02-02 10:36:09 | INFO | train | epoch 065 | loss 0.745 | nll_loss 0.372 | accuracy 79 | wps 480.6 | ups 7.54 | wpb 63.7 | bsz 31.9 | num_updates 2730 | lr 7.65559e-05 | gnorm 0.67 | train_wall 2 | wall 361\n",
      "epoch 066:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:36:09 | INFO | fairseq.trainer | begin training epoch 66\n",
      "epoch 066:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.92it/s]2022-02-02 10:36:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 066 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 066 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:36:15 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 0.758 | nll_loss 0.379 | accuracy 78.3 | wps 1181.5 | wpb 16 | bsz 8 | num_updates 2772 | best_loss 0.754\n",
      "2022-02-02 10:36:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:36:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint66.pt (epoch 66 @ 2772 updates, score 0.758) (writing took 0.025906244999987393 seconds)\n",
      "2022-02-02 10:36:15 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)\n",
      "2022-02-02 10:36:15 | INFO | train | epoch 066 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 475.3 | ups 7.46 | wpb 63.7 | bsz 31.9 | num_updates 2772 | lr 7.59737e-05 | gnorm 0.665 | train_wall 2 | wall 367\n",
      "epoch 067:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:36:15 | INFO | fairseq.trainer | begin training epoch 67\n",
      "epoch 067:  95%|▉| 40/42 [00:03<00:00, 20.46it/s, loss=0.739, nll_loss=0.37, acc2022-02-02 10:36:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 067 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 067 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:36:20 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1213.8 | wpb 16 | bsz 8 | num_updates 2814 | best_loss 0.754\n",
      "2022-02-02 10:36:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:36:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint67.pt (epoch 67 @ 2814 updates, score 0.754) (writing took 0.04277246600003082 seconds)\n",
      "2022-02-02 10:36:20 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)\n",
      "2022-02-02 10:36:20 | INFO | train | epoch 067 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 472.1 | ups 7.41 | wpb 63.7 | bsz 31.9 | num_updates 2814 | lr 7.54046e-05 | gnorm 0.612 | train_wall 2 | wall 372\n",
      "epoch 068:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:36:20 | INFO | fairseq.trainer | begin training epoch 68\n",
      "epoch 068:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 19.85it/s]2022-02-02 10:36:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 068 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 068 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.65s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:36:26 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1214 | wpb 16 | bsz 8 | num_updates 2856 | best_loss 0.754\n",
      "2022-02-02 10:36:26 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:36:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint68.pt (epoch 68 @ 2856 updates, score 0.754) (writing took 0.03919630799998686 seconds)\n",
      "2022-02-02 10:36:26 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)\n",
      "2022-02-02 10:36:26 | INFO | train | epoch 068 | loss 0.745 | nll_loss 0.373 | accuracy 79 | wps 470.7 | ups 7.39 | wpb 63.7 | bsz 31.9 | num_updates 2856 | lr 7.48481e-05 | gnorm 0.616 | train_wall 2 | wall 378\n",
      "epoch 069:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:36:26 | INFO | fairseq.trainer | begin training epoch 69\n",
      "epoch 069:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 22.02it/s]2022-02-02 10:36:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 069 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 069 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:36:32 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1105 | wpb 16 | bsz 8 | num_updates 2898 | best_loss 0.754\n",
      "2022-02-02 10:36:32 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:36:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint69.pt (epoch 69 @ 2898 updates, score 0.755) (writing took 0.02820060999999896 seconds)\n",
      "2022-02-02 10:36:32 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)\n",
      "2022-02-02 10:36:32 | INFO | train | epoch 069 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 452 | ups 7.09 | wpb 63.7 | bsz 31.9 | num_updates 2898 | lr 7.43038e-05 | gnorm 0.605 | train_wall 2 | wall 384\n",
      "epoch 070:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:36:32 | INFO | fairseq.trainer | begin training epoch 70\n",
      "epoch 070:  95%|▉| 40/42 [00:03<00:00, 22.24it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 10:36:35 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 070 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 070 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:36:37 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 0.757 | nll_loss 0.379 | accuracy 78.3 | wps 1172.4 | wpb 16 | bsz 8 | num_updates 2940 | best_loss 0.754\n",
      "2022-02-02 10:36:37 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:36:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint70.pt (epoch 70 @ 2940 updates, score 0.757) (writing took 0.0283902420000004 seconds)\n",
      "2022-02-02 10:36:37 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)\n",
      "2022-02-02 10:36:37 | INFO | train | epoch 070 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 495.5 | ups 7.78 | wpb 63.7 | bsz 31.9 | num_updates 2940 | lr 7.37711e-05 | gnorm 0.642 | train_wall 2 | wall 389\n",
      "epoch 071:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:36:37 | INFO | fairseq.trainer | begin training epoch 71\n",
      "epoch 071:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.93it/s]2022-02-02 10:36:41 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 071 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 071 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.50s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:36:42 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1196.4 | wpb 16 | bsz 8 | num_updates 2982 | best_loss 0.754\n",
      "2022-02-02 10:36:42 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:36:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint71.pt (epoch 71 @ 2982 updates, score 0.755) (writing took 0.029365785000038613 seconds)\n",
      "2022-02-02 10:36:43 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)\n",
      "2022-02-02 10:36:43 | INFO | train | epoch 071 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 507.1 | ups 7.96 | wpb 63.7 | bsz 31.9 | num_updates 2982 | lr 7.32498e-05 | gnorm 0.646 | train_wall 2 | wall 395\n",
      "epoch 072:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:36:43 | INFO | fairseq.trainer | begin training epoch 72\n",
      "epoch 072:  95%|▉| 40/42 [00:03<00:00, 22.02it/s, loss=0.736, nll_loss=0.368, ac2022-02-02 10:36:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 072 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 072 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:36:48 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1219.5 | wpb 16 | bsz 8 | num_updates 3024 | best_loss 0.754\n",
      "2022-02-02 10:36:48 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:36:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint72.pt (epoch 72 @ 3024 updates, score 0.754) (writing took 0.03458962099995233 seconds)\n",
      "2022-02-02 10:36:48 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)\n",
      "2022-02-02 10:36:48 | INFO | train | epoch 072 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 505.4 | ups 7.93 | wpb 63.7 | bsz 31.9 | num_updates 3024 | lr 7.27393e-05 | gnorm 0.718 | train_wall 2 | wall 400\n",
      "epoch 073:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:36:48 | INFO | fairseq.trainer | begin training epoch 73\n",
      "epoch 073:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 19.42it/s]2022-02-02 10:36:52 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 073 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 073 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:36:53 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1242 | wpb 16 | bsz 8 | num_updates 3066 | best_loss 0.754\n",
      "2022-02-02 10:36:53 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:36:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint73.pt (epoch 73 @ 3066 updates, score 0.755) (writing took 0.031175611999969988 seconds)\n",
      "2022-02-02 10:36:53 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)\n",
      "2022-02-02 10:36:53 | INFO | train | epoch 073 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 493.6 | ups 7.75 | wpb 63.7 | bsz 31.9 | num_updates 3066 | lr 7.22394e-05 | gnorm 0.663 | train_wall 2 | wall 405\n",
      "epoch 074:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:36:53 | INFO | fairseq.trainer | begin training epoch 74\n",
      "epoch 074:  95%|▉| 40/42 [00:03<00:00, 20.97it/s, loss=0.748, nll_loss=0.374, ac2022-02-02 10:36:57 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 074 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 074 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:36:59 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 0.757 | nll_loss 0.379 | accuracy 78.3 | wps 1171.2 | wpb 16 | bsz 8 | num_updates 3108 | best_loss 0.754\n",
      "2022-02-02 10:36:59 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:36:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint74.pt (epoch 74 @ 3108 updates, score 0.757) (writing took 0.029111284999999043 seconds)\n",
      "2022-02-02 10:36:59 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)\n",
      "2022-02-02 10:36:59 | INFO | train | epoch 074 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 503.6 | ups 7.9 | wpb 63.7 | bsz 31.9 | num_updates 3108 | lr 7.17496e-05 | gnorm 0.653 | train_wall 2 | wall 411\n",
      "epoch 075:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:36:59 | INFO | fairseq.trainer | begin training epoch 75\n",
      "epoch 075:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.15it/s]2022-02-02 10:37:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 075 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 075 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:37:04 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1190.9 | wpb 16 | bsz 8 | num_updates 3150 | best_loss 0.754\n",
      "2022-02-02 10:37:04 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:37:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint75.pt (epoch 75 @ 3150 updates, score 0.755) (writing took 0.02710828300001822 seconds)\n",
      "2022-02-02 10:37:04 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)\n",
      "2022-02-02 10:37:04 | INFO | train | epoch 075 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 496.7 | ups 7.8 | wpb 63.7 | bsz 31.9 | num_updates 3150 | lr 7.12697e-05 | gnorm 0.615 | train_wall 2 | wall 416\n",
      "epoch 076:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:37:04 | INFO | fairseq.trainer | begin training epoch 76\n",
      "epoch 076:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 19.46it/s]2022-02-02 10:37:08 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 076 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 076 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:37:09 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1196.9 | wpb 16 | bsz 8 | num_updates 3192 | best_loss 0.754\n",
      "2022-02-02 10:37:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:37:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint76.pt (epoch 76 @ 3192 updates, score 0.754) (writing took 0.04936246500000152 seconds)\n",
      "2022-02-02 10:37:09 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)\n",
      "2022-02-02 10:37:09 | INFO | train | epoch 076 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 482.4 | ups 7.57 | wpb 63.7 | bsz 31.9 | num_updates 3192 | lr 7.07992e-05 | gnorm 0.684 | train_wall 2 | wall 422\n",
      "epoch 077:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:37:09 | INFO | fairseq.trainer | begin training epoch 77\n",
      "epoch 077:  93%|▉| 39/42 [00:03<00:00, 22.18it/s, loss=0.746, nll_loss=0.373, ac2022-02-02 10:37:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 077 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 077 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.50s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:37:15 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1182.2 | wpb 16 | bsz 8 | num_updates 3234 | best_loss 0.754\n",
      "2022-02-02 10:37:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:37:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint77.pt (epoch 77 @ 3234 updates, score 0.755) (writing took 0.03325940900003843 seconds)\n",
      "2022-02-02 10:37:15 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)\n",
      "2022-02-02 10:37:15 | INFO | train | epoch 077 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 490.4 | ups 7.7 | wpb 63.7 | bsz 31.9 | num_updates 3234 | lr 7.0338e-05 | gnorm 0.752 | train_wall 2 | wall 427\n",
      "epoch 078:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:37:15 | INFO | fairseq.trainer | begin training epoch 78\n",
      "epoch 078:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.27it/s]2022-02-02 10:37:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 078 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 078 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:37:20 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1194.2 | wpb 16 | bsz 8 | num_updates 3276 | best_loss 0.754\n",
      "2022-02-02 10:37:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:37:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint78.pt (epoch 78 @ 3276 updates, score 0.754) (writing took 0.04161819699999114 seconds)\n",
      "2022-02-02 10:37:20 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)\n",
      "2022-02-02 10:37:20 | INFO | train | epoch 078 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 506.4 | ups 7.95 | wpb 63.7 | bsz 31.9 | num_updates 3276 | lr 6.98857e-05 | gnorm 0.668 | train_wall 2 | wall 432\n",
      "epoch 079:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:37:20 | INFO | fairseq.trainer | begin training epoch 79\n",
      "epoch 079:  95%|▉| 40/42 [00:03<00:00, 21.84it/s, loss=0.734, nll_loss=0.367, ac2022-02-02 10:37:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 079 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 079 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.48s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:37:26 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1213.7 | wpb 16 | bsz 8 | num_updates 3318 | best_loss 0.754\n",
      "2022-02-02 10:37:26 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:37:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint79.pt (epoch 79 @ 3318 updates, score 0.754) (writing took 0.034280859999967106 seconds)\n",
      "2022-02-02 10:37:26 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)\n",
      "2022-02-02 10:37:26 | INFO | train | epoch 079 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 504.8 | ups 7.92 | wpb 63.7 | bsz 31.9 | num_updates 3318 | lr 6.94419e-05 | gnorm 0.72 | train_wall 2 | wall 438\n",
      "epoch 080:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:37:26 | INFO | fairseq.trainer | begin training epoch 80\n",
      "epoch 080:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.62it/s]2022-02-02 10:37:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 080 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 080 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.49s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:37:31 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1184.3 | wpb 16 | bsz 8 | num_updates 3360 | best_loss 0.754\n",
      "2022-02-02 10:37:31 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:37:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint80.pt (epoch 80 @ 3360 updates, score 0.754) (writing took 0.0420913489999748 seconds)\n",
      "2022-02-02 10:37:31 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)\n",
      "2022-02-02 10:37:31 | INFO | train | epoch 080 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 498.3 | ups 7.82 | wpb 63.7 | bsz 31.9 | num_updates 3360 | lr 6.90066e-05 | gnorm 0.603 | train_wall 2 | wall 443\n",
      "epoch 081:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:37:31 | INFO | fairseq.trainer | begin training epoch 81\n",
      "epoch 081:  95%|▉| 40/42 [00:03<00:00, 21.75it/s, loss=0.748, nll_loss=0.374, ac2022-02-02 10:37:35 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 081 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 081 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:37:37 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1150.7 | wpb 16 | bsz 8 | num_updates 3402 | best_loss 0.754\n",
      "2022-02-02 10:37:37 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:37:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint81.pt (epoch 81 @ 3402 updates, score 0.755) (writing took 0.029555893999997807 seconds)\n",
      "2022-02-02 10:37:37 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)\n",
      "2022-02-02 10:37:37 | INFO | train | epoch 081 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 474.9 | ups 7.45 | wpb 63.7 | bsz 31.9 | num_updates 3402 | lr 6.85793e-05 | gnorm 0.529 | train_wall 2 | wall 449\n",
      "epoch 082:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:37:37 | INFO | fairseq.trainer | begin training epoch 82\n",
      "epoch 082:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.87it/s]2022-02-02 10:37:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 082 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 082 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.48s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:37:42 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1199.9 | wpb 16 | bsz 8 | num_updates 3444 | best_loss 0.754\n",
      "2022-02-02 10:37:42 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:37:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint82.pt (epoch 82 @ 3444 updates, score 0.754) (writing took 0.03448027999996839 seconds)\n",
      "2022-02-02 10:37:42 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)\n",
      "2022-02-02 10:37:42 | INFO | train | epoch 082 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 506.9 | ups 7.96 | wpb 63.7 | bsz 31.9 | num_updates 3444 | lr 6.81598e-05 | gnorm 0.633 | train_wall 2 | wall 454\n",
      "epoch 083:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:37:42 | INFO | fairseq.trainer | begin training epoch 83\n",
      "epoch 083:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 19.87it/s]2022-02-02 10:37:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 083 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 083 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:37:47 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1243.6 | wpb 16 | bsz 8 | num_updates 3486 | best_loss 0.754\n",
      "2022-02-02 10:37:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:37:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint83.pt (epoch 83 @ 3486 updates, score 0.754) (writing took 0.045447396999975354 seconds)\n",
      "2022-02-02 10:37:47 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)\n",
      "2022-02-02 10:37:47 | INFO | train | epoch 083 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 484.6 | ups 7.61 | wpb 63.7 | bsz 31.9 | num_updates 3486 | lr 6.7748e-05 | gnorm 0.613 | train_wall 2 | wall 459\n",
      "epoch 084:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:37:47 | INFO | fairseq.trainer | begin training epoch 84\n",
      "epoch 084:  95%|▉| 40/42 [00:03<00:00, 21.91it/s, loss=0.74, nll_loss=0.37, accu2022-02-02 10:37:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 084 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 084 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:37:53 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1180.8 | wpb 16 | bsz 8 | num_updates 3528 | best_loss 0.754\n",
      "2022-02-02 10:37:53 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:37:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint84.pt (epoch 84 @ 3528 updates, score 0.755) (writing took 0.028363251999962813 seconds)\n",
      "2022-02-02 10:37:53 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)\n",
      "2022-02-02 10:37:53 | INFO | train | epoch 084 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 458.1 | ups 7.19 | wpb 63.7 | bsz 31.9 | num_updates 3528 | lr 6.73435e-05 | gnorm 0.621 | train_wall 2 | wall 465\n",
      "epoch 085:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:37:53 | INFO | fairseq.trainer | begin training epoch 85\n",
      "epoch 085:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.10it/s]2022-02-02 10:37:57 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 085 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 085 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.50s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:37:59 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1238.6 | wpb 16 | bsz 8 | num_updates 3570 | best_loss 0.754\n",
      "2022-02-02 10:37:59 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:37:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint85.pt (epoch 85 @ 3570 updates, score 0.754) (writing took 0.04430390000004536 seconds)\n",
      "2022-02-02 10:37:59 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)\n",
      "2022-02-02 10:37:59 | INFO | train | epoch 085 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 498.2 | ups 7.82 | wpb 63.7 | bsz 31.9 | num_updates 3570 | lr 6.69462e-05 | gnorm 0.687 | train_wall 2 | wall 471\n",
      "epoch 086:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:37:59 | INFO | fairseq.trainer | begin training epoch 86\n",
      "epoch 086:  95%|▉| 40/42 [00:03<00:00, 22.02it/s, loss=0.746, nll_loss=0.373, ac2022-02-02 10:38:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 086 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 086 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.49s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:38:04 | INFO | valid | epoch 086 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1214.6 | wpb 16 | bsz 8 | num_updates 3612 | best_loss 0.754\n",
      "2022-02-02 10:38:04 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:38:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint86.pt (epoch 86 @ 3612 updates, score 0.756) (writing took 0.031629993999956696 seconds)\n",
      "2022-02-02 10:38:04 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)\n",
      "2022-02-02 10:38:04 | INFO | train | epoch 086 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 509.9 | ups 8 | wpb 63.7 | bsz 31.9 | num_updates 3612 | lr 6.65558e-05 | gnorm 0.709 | train_wall 2 | wall 476\n",
      "epoch 087:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:38:04 | INFO | fairseq.trainer | begin training epoch 87\n",
      "epoch 087:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 22.12it/s]2022-02-02 10:38:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 087 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 087 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:38:09 | INFO | valid | epoch 087 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1198.1 | wpb 16 | bsz 8 | num_updates 3654 | best_loss 0.754\n",
      "2022-02-02 10:38:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:38:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint87.pt (epoch 87 @ 3654 updates, score 0.755) (writing took 0.028155454999989615 seconds)\n",
      "2022-02-02 10:38:09 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)\n",
      "2022-02-02 10:38:09 | INFO | train | epoch 087 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 494.2 | ups 7.76 | wpb 63.7 | bsz 31.9 | num_updates 3654 | lr 6.61722e-05 | gnorm 0.616 | train_wall 2 | wall 481\n",
      "epoch 088:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:38:09 | INFO | fairseq.trainer | begin training epoch 88\n",
      "epoch 088:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.23it/s]2022-02-02 10:38:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 088 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 088 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.50s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:38:14 | INFO | valid | epoch 088 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1216.2 | wpb 16 | bsz 8 | num_updates 3696 | best_loss 0.754\n",
      "2022-02-02 10:38:14 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:38:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint88.pt (epoch 88 @ 3696 updates, score 0.755) (writing took 0.03253775999996833 seconds)\n",
      "2022-02-02 10:38:14 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)\n",
      "2022-02-02 10:38:14 | INFO | train | epoch 088 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 509.8 | ups 8 | wpb 63.7 | bsz 31.9 | num_updates 3696 | lr 6.57952e-05 | gnorm 0.622 | train_wall 2 | wall 487\n",
      "epoch 089:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:38:14 | INFO | fairseq.trainer | begin training epoch 89\n",
      "epoch 089:  93%|▉| 39/42 [00:03<00:00, 22.07it/s, loss=0.744, nll_loss=0.372, ac2022-02-02 10:38:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 089 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 089 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.48s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:38:20 | INFO | valid | epoch 089 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1214.7 | wpb 16 | bsz 8 | num_updates 3738 | best_loss 0.754\n",
      "2022-02-02 10:38:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:38:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint89.pt (epoch 89 @ 3738 updates, score 0.754) (writing took 0.04124691399999847 seconds)\n",
      "2022-02-02 10:38:20 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)\n",
      "2022-02-02 10:38:20 | INFO | train | epoch 089 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 508.1 | ups 7.97 | wpb 63.7 | bsz 31.9 | num_updates 3738 | lr 6.54245e-05 | gnorm 0.531 | train_wall 2 | wall 492\n",
      "epoch 090:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:38:20 | INFO | fairseq.trainer | begin training epoch 90\n",
      "epoch 090:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.11it/s]2022-02-02 10:38:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 090 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 090 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:38:25 | INFO | valid | epoch 090 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1145.9 | wpb 16 | bsz 8 | num_updates 3780 | best_loss 0.754\n",
      "2022-02-02 10:38:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:38:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint90.pt (epoch 90 @ 3780 updates, score 0.754) (writing took 0.04946527200002038 seconds)\n",
      "2022-02-02 10:38:25 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)\n",
      "2022-02-02 10:38:25 | INFO | train | epoch 090 | loss 0.745 | nll_loss 0.372 | accuracy 79 | wps 490.3 | ups 7.7 | wpb 63.7 | bsz 31.9 | num_updates 3780 | lr 6.506e-05 | gnorm 0.668 | train_wall 2 | wall 497\n",
      "epoch 091:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:38:25 | INFO | fairseq.trainer | begin training epoch 91\n",
      "epoch 091:  95%|▉| 40/42 [00:03<00:00, 20.94it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 10:38:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 091 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 091 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:38:31 | INFO | valid | epoch 091 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1229.7 | wpb 16 | bsz 8 | num_updates 3822 | best_loss 0.754\n",
      "2022-02-02 10:38:31 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:38:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint91.pt (epoch 91 @ 3822 updates, score 0.755) (writing took 0.032005113000025176 seconds)\n",
      "2022-02-02 10:38:31 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)\n",
      "2022-02-02 10:38:31 | INFO | train | epoch 091 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 468.7 | ups 7.36 | wpb 63.7 | bsz 31.9 | num_updates 3822 | lr 6.47015e-05 | gnorm 0.581 | train_wall 2 | wall 503\n",
      "epoch 092:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:38:31 | INFO | fairseq.trainer | begin training epoch 92\n",
      "epoch 092:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.84it/s]2022-02-02 10:38:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 092 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 092 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:38:36 | INFO | valid | epoch 092 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1248.4 | wpb 16 | bsz 8 | num_updates 3864 | best_loss 0.754\n",
      "2022-02-02 10:38:36 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:38:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint92.pt (epoch 92 @ 3864 updates, score 0.754) (writing took 0.04378639699996256 seconds)\n",
      "2022-02-02 10:38:36 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)\n",
      "2022-02-02 10:38:36 | INFO | train | epoch 092 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 509.1 | ups 7.99 | wpb 63.7 | bsz 31.9 | num_updates 3864 | lr 6.43489e-05 | gnorm 0.617 | train_wall 2 | wall 508\n",
      "epoch 093:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:38:36 | INFO | fairseq.trainer | begin training epoch 93\n",
      "epoch 093:  95%|▉| 40/42 [00:03<00:00, 22.16it/s, loss=0.745, nll_loss=0.372, ac2022-02-02 10:38:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 093 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 093 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:38:41 | INFO | valid | epoch 093 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1217.7 | wpb 16 | bsz 8 | num_updates 3906 | best_loss 0.754\n",
      "2022-02-02 10:38:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:38:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint93.pt (epoch 93 @ 3906 updates, score 0.755) (writing took 0.030362898000021232 seconds)\n",
      "2022-02-02 10:38:41 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)\n",
      "2022-02-02 10:38:41 | INFO | train | epoch 093 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 507.1 | ups 7.96 | wpb 63.7 | bsz 31.9 | num_updates 3906 | lr 6.4002e-05 | gnorm 0.69 | train_wall 2 | wall 513\n",
      "epoch 094:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:38:41 | INFO | fairseq.trainer | begin training epoch 94\n",
      "epoch 094:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.32it/s]2022-02-02 10:38:45 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 094 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 094 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:38:47 | INFO | valid | epoch 094 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1209.7 | wpb 16 | bsz 8 | num_updates 3948 | best_loss 0.754\n",
      "2022-02-02 10:38:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:38:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint94.pt (epoch 94 @ 3948 updates, score 0.754) (writing took 0.030318668000063553 seconds)\n",
      "2022-02-02 10:38:47 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)\n",
      "2022-02-02 10:38:47 | INFO | train | epoch 094 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 505.9 | ups 7.94 | wpb 63.7 | bsz 31.9 | num_updates 3948 | lr 6.36607e-05 | gnorm 0.514 | train_wall 2 | wall 519\n",
      "epoch 095:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:38:47 | INFO | fairseq.trainer | begin training epoch 95\n",
      "epoch 095:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.21it/s]2022-02-02 10:38:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 095 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 095 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:38:52 | INFO | valid | epoch 095 | valid on 'valid' subset | loss 0.758 | nll_loss 0.379 | accuracy 78.3 | wps 1233.5 | wpb 16 | bsz 8 | num_updates 3990 | best_loss 0.754\n",
      "2022-02-02 10:38:52 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:38:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint95.pt (epoch 95 @ 3990 updates, score 0.758) (writing took 0.030744605000109004 seconds)\n",
      "2022-02-02 10:38:52 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)\n",
      "2022-02-02 10:38:52 | INFO | train | epoch 095 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 498.7 | ups 7.83 | wpb 63.7 | bsz 31.9 | num_updates 3990 | lr 6.33248e-05 | gnorm 0.577 | train_wall 2 | wall 524\n",
      "epoch 096:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:38:52 | INFO | fairseq.trainer | begin training epoch 96\n",
      "epoch 096:  95%|▉| 40/42 [00:03<00:00, 21.84it/s, loss=0.746, nll_loss=0.373, ac2022-02-02 10:38:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 096 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 096 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:38:57 | INFO | valid | epoch 096 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1214.5 | wpb 16 | bsz 8 | num_updates 4032 | best_loss 0.754\n",
      "2022-02-02 10:38:57 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:38:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint96.pt (epoch 96 @ 4032 updates, score 0.754) (writing took 0.037306575999991765 seconds)\n",
      "2022-02-02 10:38:57 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)\n",
      "2022-02-02 10:38:57 | INFO | train | epoch 096 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 504 | ups 7.91 | wpb 63.7 | bsz 31.9 | num_updates 4032 | lr 6.29941e-05 | gnorm 0.689 | train_wall 2 | wall 529\n",
      "epoch 097:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:38:57 | INFO | fairseq.trainer | begin training epoch 97\n",
      "epoch 097:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.96it/s]2022-02-02 10:39:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 097 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 097 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:39:03 | INFO | valid | epoch 097 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1170.9 | wpb 16 | bsz 8 | num_updates 4074 | best_loss 0.754\n",
      "2022-02-02 10:39:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:39:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint97.pt (epoch 97 @ 4074 updates, score 0.755) (writing took 0.029068198000004486 seconds)\n",
      "2022-02-02 10:39:03 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)\n",
      "2022-02-02 10:39:03 | INFO | train | epoch 097 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 504.7 | ups 7.92 | wpb 63.7 | bsz 31.9 | num_updates 4074 | lr 6.26685e-05 | gnorm 0.56 | train_wall 2 | wall 535\n",
      "epoch 098:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:39:03 | INFO | fairseq.trainer | begin training epoch 98\n",
      "epoch 098:  95%|▉| 40/42 [00:03<00:00, 22.08it/s, loss=0.735, nll_loss=0.368, ac2022-02-02 10:39:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 098 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 098 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:39:08 | INFO | valid | epoch 098 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1106.3 | wpb 16 | bsz 8 | num_updates 4116 | best_loss 0.754\n",
      "2022-02-02 10:39:08 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:39:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint98.pt (epoch 98 @ 4116 updates, score 0.754) (writing took 0.044358741999985796 seconds)\n",
      "2022-02-02 10:39:08 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)\n",
      "2022-02-02 10:39:08 | INFO | train | epoch 098 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 490.7 | ups 7.7 | wpb 63.7 | bsz 31.9 | num_updates 4116 | lr 6.2348e-05 | gnorm 0.717 | train_wall 2 | wall 540\n",
      "epoch 099:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:39:08 | INFO | fairseq.trainer | begin training epoch 99\n",
      "epoch 099:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.99it/s]2022-02-02 10:39:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 099 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 099 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.49s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:39:14 | INFO | valid | epoch 099 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1189 | wpb 16 | bsz 8 | num_updates 4158 | best_loss 0.754\n",
      "2022-02-02 10:39:14 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:39:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint99.pt (epoch 99 @ 4158 updates, score 0.756) (writing took 0.030524665000029927 seconds)\n",
      "2022-02-02 10:39:14 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)\n",
      "2022-02-02 10:39:14 | INFO | train | epoch 099 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 461.9 | ups 7.25 | wpb 63.7 | bsz 31.9 | num_updates 4158 | lr 6.20323e-05 | gnorm 0.617 | train_wall 2 | wall 546\n",
      "epoch 100:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:39:14 | INFO | fairseq.trainer | begin training epoch 100\n",
      "epoch 100:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.89it/s]2022-02-02 10:39:17 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 100 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 100 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.46s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:39:19 | INFO | valid | epoch 100 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1224.7 | wpb 16 | bsz 8 | num_updates 4200 | best_loss 0.754\n",
      "2022-02-02 10:39:19 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:39:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint100.pt (epoch 100 @ 4200 updates, score 0.755) (writing took 0.0309771649999675 seconds)\n",
      "2022-02-02 10:39:19 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)\n",
      "2022-02-02 10:39:19 | INFO | train | epoch 100 | loss 0.745 | nll_loss 0.372 | accuracy 79 | wps 512.3 | ups 8.04 | wpb 63.7 | bsz 31.9 | num_updates 4200 | lr 6.17213e-05 | gnorm 0.667 | train_wall 2 | wall 551\n",
      "epoch 101:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:39:19 | INFO | fairseq.trainer | begin training epoch 101\n",
      "epoch 101:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.01it/s]2022-02-02 10:39:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 101 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 101 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.49s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:39:24 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1146.3 | wpb 16 | bsz 8 | num_updates 4242 | best_loss 0.754\n",
      "2022-02-02 10:39:24 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:39:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint101.pt (epoch 101 @ 4242 updates, score 0.755) (writing took 0.03891429899999821 seconds)\n",
      "2022-02-02 10:39:24 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)\n",
      "2022-02-02 10:39:24 | INFO | train | epoch 101 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 508.5 | ups 7.98 | wpb 63.7 | bsz 31.9 | num_updates 4242 | lr 6.1415e-05 | gnorm 0.596 | train_wall 2 | wall 556\n",
      "epoch 102:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:39:24 | INFO | fairseq.trainer | begin training epoch 102\n",
      "epoch 102:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.51it/s]2022-02-02 10:39:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 102 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 102 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.47s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:39:30 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1230 | wpb 16 | bsz 8 | num_updates 4284 | best_loss 0.754\n",
      "2022-02-02 10:39:30 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:39:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint102.pt (epoch 102 @ 4284 updates, score 0.755) (writing took 0.02962628800003131 seconds)\n",
      "2022-02-02 10:39:30 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)\n",
      "2022-02-02 10:39:30 | INFO | train | epoch 102 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 512.4 | ups 8.04 | wpb 63.7 | bsz 31.9 | num_updates 4284 | lr 6.11132e-05 | gnorm 0.554 | train_wall 2 | wall 562\n",
      "epoch 103:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:39:30 | INFO | fairseq.trainer | begin training epoch 103\n",
      "epoch 103:  95%|▉| 40/42 [00:03<00:00, 22.18it/s, loss=0.737, nll_loss=0.369, ac2022-02-02 10:39:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 103 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 103 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.48s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:39:35 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1044.7 | wpb 16 | bsz 8 | num_updates 4326 | best_loss 0.754\n",
      "2022-02-02 10:39:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:39:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint103.pt (epoch 103 @ 4326 updates, score 0.754) (writing took 0.04376832100001593 seconds)\n",
      "2022-02-02 10:39:35 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)\n",
      "2022-02-02 10:39:35 | INFO | train | epoch 103 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 506 | ups 7.94 | wpb 63.7 | bsz 31.9 | num_updates 4326 | lr 6.08158e-05 | gnorm 0.69 | train_wall 2 | wall 567\n",
      "epoch 104:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:39:35 | INFO | fairseq.trainer | begin training epoch 104\n",
      "epoch 104:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.07it/s]2022-02-02 10:39:38 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 104 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 104 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.45s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:39:40 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1259.5 | wpb 16 | bsz 8 | num_updates 4368 | best_loss 0.754\n",
      "2022-02-02 10:39:40 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:39:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint104.pt (epoch 104 @ 4368 updates, score 0.754) (writing took 0.03371612799992363 seconds)\n",
      "2022-02-02 10:39:40 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)\n",
      "2022-02-02 10:39:40 | INFO | train | epoch 104 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 515 | ups 8.08 | wpb 63.7 | bsz 31.9 | num_updates 4368 | lr 6.05228e-05 | gnorm 0.59 | train_wall 2 | wall 572\n",
      "epoch 105:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:39:40 | INFO | fairseq.trainer | begin training epoch 105\n",
      "epoch 105:  95%|▉| 40/42 [00:03<00:00, 21.96it/s, loss=0.743, nll_loss=0.371, ac2022-02-02 10:39:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 105 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 105 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:39:45 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1218.9 | wpb 16 | bsz 8 | num_updates 4410 | best_loss 0.754\n",
      "2022-02-02 10:39:45 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:39:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint105.pt (epoch 105 @ 4410 updates, score 0.754) (writing took 0.04117176700003711 seconds)\n",
      "2022-02-02 10:39:45 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)\n",
      "2022-02-02 10:39:45 | INFO | train | epoch 105 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 508 | ups 7.97 | wpb 63.7 | bsz 31.9 | num_updates 4410 | lr 6.02339e-05 | gnorm 0.741 | train_wall 2 | wall 577\n",
      "epoch 106:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:39:45 | INFO | fairseq.trainer | begin training epoch 106\n",
      "epoch 106:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.95it/s]2022-02-02 10:39:49 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 106 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 106 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:39:51 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1250.8 | wpb 16 | bsz 8 | num_updates 4452 | best_loss 0.754\n",
      "2022-02-02 10:39:51 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:39:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint106.pt (epoch 106 @ 4452 updates, score 0.754) (writing took 0.038101297000025625 seconds)\n",
      "2022-02-02 10:39:51 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)\n",
      "2022-02-02 10:39:51 | INFO | train | epoch 106 | loss 0.745 | nll_loss 0.373 | accuracy 79 | wps 499.8 | ups 7.84 | wpb 63.7 | bsz 31.9 | num_updates 4452 | lr 5.99491e-05 | gnorm 0.635 | train_wall 2 | wall 583\n",
      "epoch 107:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:39:51 | INFO | fairseq.trainer | begin training epoch 107\n",
      "epoch 107:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.03it/s]2022-02-02 10:39:54 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 107 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 107 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:39:56 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1207.5 | wpb 16 | bsz 8 | num_updates 4494 | best_loss 0.754\n",
      "2022-02-02 10:39:56 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:39:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint107.pt (epoch 107 @ 4494 updates, score 0.755) (writing took 0.030668670000068232 seconds)\n",
      "2022-02-02 10:39:56 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)\n",
      "2022-02-02 10:39:56 | INFO | train | epoch 107 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 507.4 | ups 7.96 | wpb 63.7 | bsz 31.9 | num_updates 4494 | lr 5.96683e-05 | gnorm 0.599 | train_wall 2 | wall 588\n",
      "epoch 108:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:39:56 | INFO | fairseq.trainer | begin training epoch 108\n",
      "epoch 108:  95%|▉| 40/42 [00:03<00:00, 20.95it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 10:40:00 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 108 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 108 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:40:01 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1249.2 | wpb 16 | bsz 8 | num_updates 4536 | best_loss 0.754\n",
      "2022-02-02 10:40:01 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:40:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint108.pt (epoch 108 @ 4536 updates, score 0.754) (writing took 0.039718817999983 seconds)\n",
      "2022-02-02 10:40:01 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)\n",
      "2022-02-02 10:40:01 | INFO | train | epoch 108 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 494.1 | ups 7.75 | wpb 63.7 | bsz 31.9 | num_updates 4536 | lr 5.93914e-05 | gnorm 0.662 | train_wall 2 | wall 594\n",
      "epoch 109:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:40:01 | INFO | fairseq.trainer | begin training epoch 109\n",
      "epoch 109:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.93it/s]2022-02-02 10:40:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 109 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 109 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:40:07 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1234.9 | wpb 16 | bsz 8 | num_updates 4578 | best_loss 0.754\n",
      "2022-02-02 10:40:07 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:40:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint109.pt (epoch 109 @ 4578 updates, score 0.754) (writing took 0.026545887999986917 seconds)\n",
      "2022-02-02 10:40:07 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)\n",
      "2022-02-02 10:40:07 | INFO | train | epoch 109 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 506.7 | ups 7.95 | wpb 63.7 | bsz 31.9 | num_updates 4578 | lr 5.91183e-05 | gnorm 0.629 | train_wall 2 | wall 599\n",
      "epoch 110:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:40:07 | INFO | fairseq.trainer | begin training epoch 110\n",
      "epoch 110:  95%|▉| 40/42 [00:03<00:00, 21.27it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 10:40:10 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 110 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 110 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.46s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:40:12 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1255.7 | wpb 16 | bsz 8 | num_updates 4620 | best_loss 0.754\n",
      "2022-02-02 10:40:12 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:40:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint110.pt (epoch 110 @ 4620 updates, score 0.754) (writing took 0.03922688900001958 seconds)\n",
      "2022-02-02 10:40:12 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)\n",
      "2022-02-02 10:40:12 | INFO | train | epoch 110 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 507.1 | ups 7.96 | wpb 63.7 | bsz 31.9 | num_updates 4620 | lr 5.8849e-05 | gnorm 0.633 | train_wall 2 | wall 604\n",
      "epoch 111:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:40:12 | INFO | fairseq.trainer | begin training epoch 111\n",
      "epoch 111:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.05it/s]2022-02-02 10:40:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 111 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 111 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:40:17 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1157.2 | wpb 16 | bsz 8 | num_updates 4662 | best_loss 0.754\n",
      "2022-02-02 10:40:17 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:40:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint111.pt (epoch 111 @ 4662 updates, score 0.755) (writing took 0.03066057700004876 seconds)\n",
      "2022-02-02 10:40:17 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)\n",
      "2022-02-02 10:40:17 | INFO | train | epoch 111 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 502.1 | ups 7.88 | wpb 63.7 | bsz 31.9 | num_updates 4662 | lr 5.85833e-05 | gnorm 0.57 | train_wall 2 | wall 609\n",
      "epoch 112:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:40:17 | INFO | fairseq.trainer | begin training epoch 112\n",
      "epoch 112:  95%|▉| 40/42 [00:03<00:00, 21.32it/s, loss=0.751, nll_loss=0.376, ac2022-02-02 10:40:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 112 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 112 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.50s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:40:23 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1155.8 | wpb 16 | bsz 8 | num_updates 4704 | best_loss 0.754\n",
      "2022-02-02 10:40:23 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:40:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint112.pt (epoch 112 @ 4704 updates, score 0.755) (writing took 0.03827487400008067 seconds)\n",
      "2022-02-02 10:40:23 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)\n",
      "2022-02-02 10:40:23 | INFO | train | epoch 112 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 502.7 | ups 7.89 | wpb 63.7 | bsz 31.9 | num_updates 4704 | lr 5.83212e-05 | gnorm 0.588 | train_wall 2 | wall 615\n",
      "epoch 113:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:40:23 | INFO | fairseq.trainer | begin training epoch 113\n",
      "epoch 113:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.89it/s]2022-02-02 10:40:26 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 113 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 113 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:40:28 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1229.5 | wpb 16 | bsz 8 | num_updates 4746 | best_loss 0.754\n",
      "2022-02-02 10:40:28 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:40:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint113.pt (epoch 113 @ 4746 updates, score 0.755) (writing took 0.029215827000030004 seconds)\n",
      "2022-02-02 10:40:28 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)\n",
      "2022-02-02 10:40:28 | INFO | train | epoch 113 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 504.8 | ups 7.92 | wpb 63.7 | bsz 31.9 | num_updates 4746 | lr 5.80626e-05 | gnorm 0.564 | train_wall 2 | wall 620\n",
      "epoch 114:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:40:28 | INFO | fairseq.trainer | begin training epoch 114\n",
      "epoch 114:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.71it/s]2022-02-02 10:40:32 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 114 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 114 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:40:33 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1200.4 | wpb 16 | bsz 8 | num_updates 4788 | best_loss 0.754\n",
      "2022-02-02 10:40:33 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:40:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint114.pt (epoch 114 @ 4788 updates, score 0.755) (writing took 0.031052755000018806 seconds)\n",
      "2022-02-02 10:40:33 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)\n",
      "2022-02-02 10:40:33 | INFO | train | epoch 114 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 502 | ups 7.88 | wpb 63.7 | bsz 31.9 | num_updates 4788 | lr 5.78073e-05 | gnorm 0.604 | train_wall 2 | wall 625\n",
      "epoch 115:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:40:33 | INFO | fairseq.trainer | begin training epoch 115\n",
      "epoch 115:  93%|▉| 39/42 [00:03<00:00, 21.12it/s, loss=0.741, nll_loss=0.371, ac2022-02-02 10:40:37 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 115 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 115 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.46s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:40:38 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1270.1 | wpb 16 | bsz 8 | num_updates 4830 | best_loss 0.754\n",
      "2022-02-02 10:40:38 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:40:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint115.pt (epoch 115 @ 4830 updates, score 0.755) (writing took 0.03169384400007402 seconds)\n",
      "2022-02-02 10:40:39 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)\n",
      "2022-02-02 10:40:39 | INFO | train | epoch 115 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 515.1 | ups 8.08 | wpb 63.7 | bsz 31.9 | num_updates 4830 | lr 5.75554e-05 | gnorm 0.603 | train_wall 2 | wall 631\n",
      "epoch 116:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:40:39 | INFO | fairseq.trainer | begin training epoch 116\n",
      "epoch 116:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.11it/s]2022-02-02 10:40:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 116 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 116 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.49s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:40:44 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1270.7 | wpb 16 | bsz 8 | num_updates 4872 | best_loss 0.754\n",
      "2022-02-02 10:40:44 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:40:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint116.pt (epoch 116 @ 4872 updates, score 0.756) (writing took 0.02873639599999933 seconds)\n",
      "2022-02-02 10:40:44 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)\n",
      "2022-02-02 10:40:44 | INFO | train | epoch 116 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 513.7 | ups 8.06 | wpb 63.7 | bsz 31.9 | num_updates 4872 | lr 5.73068e-05 | gnorm 0.542 | train_wall 2 | wall 636\n",
      "epoch 117:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:40:44 | INFO | fairseq.trainer | begin training epoch 117\n",
      "epoch 117:  95%|▉| 40/42 [00:03<00:00, 21.09it/s, loss=0.739, nll_loss=0.37, acc2022-02-02 10:40:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 117 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 117 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.50s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:40:49 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1215.2 | wpb 16 | bsz 8 | num_updates 4914 | best_loss 0.754\n",
      "2022-02-02 10:40:49 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:40:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint117.pt (epoch 117 @ 4914 updates, score 0.755) (writing took 0.027353948000040873 seconds)\n",
      "2022-02-02 10:40:49 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)\n",
      "2022-02-02 10:40:49 | INFO | train | epoch 117 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 501.2 | ups 7.87 | wpb 63.7 | bsz 31.9 | num_updates 4914 | lr 5.70614e-05 | gnorm 0.668 | train_wall 2 | wall 641\n",
      "epoch 118:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:40:49 | INFO | fairseq.trainer | begin training epoch 118\n",
      "epoch 118:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.86it/s]2022-02-02 10:40:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 118 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 118 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:40:54 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1115.1 | wpb 16 | bsz 8 | num_updates 4956 | best_loss 0.754\n",
      "2022-02-02 10:40:54 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:40:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint118.pt (epoch 118 @ 4956 updates, score 0.755) (writing took 0.024420616000043083 seconds)\n",
      "2022-02-02 10:40:54 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)\n",
      "2022-02-02 10:40:54 | INFO | train | epoch 118 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 506.6 | ups 7.95 | wpb 63.7 | bsz 31.9 | num_updates 4956 | lr 5.68191e-05 | gnorm 0.644 | train_wall 2 | wall 646\n",
      "epoch 119:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:40:54 | INFO | fairseq.trainer | begin training epoch 119\n",
      "epoch 119:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.68it/s]2022-02-02 10:40:58 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 119 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 119 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.47s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:41:00 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1241.9 | wpb 16 | bsz 8 | num_updates 4998 | best_loss 0.754\n",
      "2022-02-02 10:41:00 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:41:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint119.pt (epoch 119 @ 4998 updates, score 0.755) (writing took 0.026146503000063603 seconds)\n",
      "2022-02-02 10:41:00 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)\n",
      "2022-02-02 10:41:00 | INFO | train | epoch 119 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 511.8 | ups 8.03 | wpb 63.7 | bsz 31.9 | num_updates 4998 | lr 5.65799e-05 | gnorm 0.621 | train_wall 2 | wall 652\n",
      "epoch 120:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:41:00 | INFO | fairseq.trainer | begin training epoch 120\n",
      "epoch 120:   2%|▊                                | 1/42 [00:01<01:10,  1.72s/it]2022-02-02 10:41:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 120 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 120 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:25,  1.86s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:41:03 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 870.7 | wpb 16 | bsz 8 | num_updates 5000 | best_loss 0.754\n",
      "2022-02-02 10:41:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:41:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint_120_5000.pt (epoch 120 @ 5000 updates, score 0.756) (writing took 0.02939265499992416 seconds)\n",
      "epoch 120:  98%|▉| 41/42 [00:05<00:00, 21.21it/s, loss=0.745, nll_loss=0.373, ac2022-02-02 10:41:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 120 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 120 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.66s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:41:07 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1148.5 | wpb 16 | bsz 8 | num_updates 5040 | best_loss 0.754\n",
      "2022-02-02 10:41:07 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:41:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint120.pt (epoch 120 @ 5040 updates, score 0.755) (writing took 0.023559768000041004 seconds)\n",
      "2022-02-02 10:41:07 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)\n",
      "2022-02-02 10:41:07 | INFO | train | epoch 120 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 348.5 | ups 5.47 | wpb 63.7 | bsz 31.9 | num_updates 5040 | lr 5.63436e-05 | gnorm 0.649 | train_wall 2 | wall 659\n",
      "epoch 121:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:41:07 | INFO | fairseq.trainer | begin training epoch 121\n",
      "epoch 121:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.05it/s]2022-02-02 10:41:11 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 121 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 121 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:41:13 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1146.5 | wpb 16 | bsz 8 | num_updates 5082 | best_loss 0.754\n",
      "2022-02-02 10:41:13 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:41:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint121.pt (epoch 121 @ 5082 updates, score 0.754) (writing took 0.0413883960000021 seconds)\n",
      "2022-02-02 10:41:13 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)\n",
      "2022-02-02 10:41:13 | INFO | train | epoch 121 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 497.7 | ups 7.81 | wpb 63.7 | bsz 31.9 | num_updates 5082 | lr 5.61103e-05 | gnorm 0.651 | train_wall 2 | wall 665\n",
      "epoch 122:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:41:13 | INFO | fairseq.trainer | begin training epoch 122\n",
      "epoch 122:  95%|▉| 40/42 [00:03<00:00, 21.10it/s, loss=0.737, nll_loss=0.368, ac2022-02-02 10:41:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 122 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 122 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.66s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:41:18 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1204.8 | wpb 16 | bsz 8 | num_updates 5124 | best_loss 0.754\n",
      "2022-02-02 10:41:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:41:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint122.pt (epoch 122 @ 5124 updates, score 0.754) (writing took 0.04034241400006522 seconds)\n",
      "2022-02-02 10:41:18 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)\n",
      "2022-02-02 10:41:18 | INFO | train | epoch 122 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 485.1 | ups 7.61 | wpb 63.7 | bsz 31.9 | num_updates 5124 | lr 5.58799e-05 | gnorm 0.557 | train_wall 2 | wall 670\n",
      "epoch 123:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:41:18 | INFO | fairseq.trainer | begin training epoch 123\n",
      "epoch 123:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.56it/s]2022-02-02 10:41:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 123 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 123 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:41:24 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1133.7 | wpb 16 | bsz 8 | num_updates 5166 | best_loss 0.754\n",
      "2022-02-02 10:41:24 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:41:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint123.pt (epoch 123 @ 5166 updates, score 0.754) (writing took 0.039763953000033325 seconds)\n",
      "2022-02-02 10:41:24 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)\n",
      "2022-02-02 10:41:24 | INFO | train | epoch 123 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 461 | ups 7.24 | wpb 63.7 | bsz 31.9 | num_updates 5166 | lr 5.56523e-05 | gnorm 0.654 | train_wall 2 | wall 676\n",
      "epoch 124:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:41:24 | INFO | fairseq.trainer | begin training epoch 124\n",
      "epoch 124:  98%|▉| 41/42 [00:04<00:00, 16.52it/s, loss=0.749, nll_loss=0.374, ac2022-02-02 10:41:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 124 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 124 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:41:30 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1051.2 | wpb 16 | bsz 8 | num_updates 5208 | best_loss 0.754\n",
      "2022-02-02 10:41:30 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:41:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint124.pt (epoch 124 @ 5208 updates, score 0.754) (writing took 0.04717210100000102 seconds)\n",
      "2022-02-02 10:41:30 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)\n",
      "2022-02-02 10:41:30 | INFO | train | epoch 124 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 434.8 | ups 6.82 | wpb 63.7 | bsz 31.9 | num_updates 5208 | lr 5.54274e-05 | gnorm 0.672 | train_wall 2 | wall 682\n",
      "epoch 125:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:41:30 | INFO | fairseq.trainer | begin training epoch 125\n",
      "epoch 125:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.45it/s]2022-02-02 10:41:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 125 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 125 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.66s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:41:36 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1153.3 | wpb 16 | bsz 8 | num_updates 5250 | best_loss 0.754\n",
      "2022-02-02 10:41:36 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:41:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint125.pt (epoch 125 @ 5250 updates, score 0.755) (writing took 0.03411086300002353 seconds)\n",
      "2022-02-02 10:41:36 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)\n",
      "2022-02-02 10:41:36 | INFO | train | epoch 125 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 454 | ups 7.13 | wpb 63.7 | bsz 31.9 | num_updates 5250 | lr 5.52052e-05 | gnorm 0.606 | train_wall 2 | wall 688\n",
      "epoch 126:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:41:36 | INFO | fairseq.trainer | begin training epoch 126\n",
      "epoch 126:  98%|███████████████████████████████▏| 41/42 [00:04<00:00, 18.31it/s]2022-02-02 10:41:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 126 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 126 | valid on 'valid' subset:   7%|▍      | 1/15 [00:02<00:32,  2.30s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:41:43 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1016.9 | wpb 16 | bsz 8 | num_updates 5292 | best_loss 0.754\n",
      "2022-02-02 10:41:43 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:41:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint126.pt (epoch 126 @ 5292 updates, score 0.755) (writing took 0.02258149100009632 seconds)\n",
      "2022-02-02 10:41:43 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)\n",
      "2022-02-02 10:41:43 | INFO | train | epoch 126 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 393.8 | ups 6.18 | wpb 63.7 | bsz 31.9 | num_updates 5292 | lr 5.49857e-05 | gnorm 0.541 | train_wall 2 | wall 695\n",
      "epoch 127:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:41:43 | INFO | fairseq.trainer | begin training epoch 127\n",
      "epoch 127:  95%|▉| 40/42 [00:04<00:00, 19.45it/s, loss=0.74, nll_loss=0.37, accu2022-02-02 10:41:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 127 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 127 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:24,  1.76s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:41:49 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 881.9 | wpb 16 | bsz 8 | num_updates 5334 | best_loss 0.754\n",
      "2022-02-02 10:41:49 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:41:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint127.pt (epoch 127 @ 5334 updates, score 0.755) (writing took 0.024655810000012934 seconds)\n",
      "2022-02-02 10:41:49 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)\n",
      "2022-02-02 10:41:49 | INFO | train | epoch 127 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 427.1 | ups 6.7 | wpb 63.7 | bsz 31.9 | num_updates 5334 | lr 5.47688e-05 | gnorm 0.673 | train_wall 2 | wall 701\n",
      "epoch 128:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:41:49 | INFO | fairseq.trainer | begin training epoch 128\n",
      "epoch 128:  93%|█████████████████████████████▋  | 39/42 [00:04<00:00, 20.73it/s]2022-02-02 10:41:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 128 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 128 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:41:55 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1031.9 | wpb 16 | bsz 8 | num_updates 5376 | best_loss 0.754\n",
      "2022-02-02 10:41:55 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:41:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint128.pt (epoch 128 @ 5376 updates, score 0.755) (writing took 0.02055695100000321 seconds)\n",
      "2022-02-02 10:41:55 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)\n",
      "2022-02-02 10:41:55 | INFO | train | epoch 128 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 439.6 | ups 6.9 | wpb 63.7 | bsz 31.9 | num_updates 5376 | lr 5.45545e-05 | gnorm 0.581 | train_wall 2 | wall 707\n",
      "epoch 129:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:41:55 | INFO | fairseq.trainer | begin training epoch 129\n",
      "epoch 129:  95%|▉| 40/42 [00:03<00:00, 21.06it/s, loss=0.743, nll_loss=0.372, ac2022-02-02 10:41:59 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 129 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 129 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:42:01 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1024 | wpb 16 | bsz 8 | num_updates 5418 | best_loss 0.754\n",
      "2022-02-02 10:42:01 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:42:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint129.pt (epoch 129 @ 5418 updates, score 0.754) (writing took 0.04015708999997969 seconds)\n",
      "2022-02-02 10:42:01 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)\n",
      "2022-02-02 10:42:01 | INFO | train | epoch 129 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 483.3 | ups 7.59 | wpb 63.7 | bsz 31.9 | num_updates 5418 | lr 5.43426e-05 | gnorm 0.52 | train_wall 2 | wall 713\n",
      "epoch 130:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:42:01 | INFO | fairseq.trainer | begin training epoch 130\n",
      "epoch 130:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 19.45it/s]2022-02-02 10:42:04 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 130 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 130 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:42:06 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1090.5 | wpb 16 | bsz 8 | num_updates 5460 | best_loss 0.754\n",
      "2022-02-02 10:42:06 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:42:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint130.pt (epoch 130 @ 5460 updates, score 0.754) (writing took 0.04032327400000213 seconds)\n",
      "2022-02-02 10:42:06 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)\n",
      "2022-02-02 10:42:06 | INFO | train | epoch 130 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 480.1 | ups 7.53 | wpb 63.7 | bsz 31.9 | num_updates 5460 | lr 5.41332e-05 | gnorm 0.582 | train_wall 2 | wall 718\n",
      "epoch 131:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:42:06 | INFO | fairseq.trainer | begin training epoch 131\n",
      "epoch 131:  98%|▉| 41/42 [00:03<00:00, 19.82it/s, loss=0.748, nll_loss=0.374, ac2022-02-02 10:42:10 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 131 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 131 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:42:12 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1158.8 | wpb 16 | bsz 8 | num_updates 5502 | best_loss 0.754\n",
      "2022-02-02 10:42:12 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:42:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint131.pt (epoch 131 @ 5502 updates, score 0.754) (writing took 0.03997380600003453 seconds)\n",
      "2022-02-02 10:42:12 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)\n",
      "2022-02-02 10:42:12 | INFO | train | epoch 131 | loss 0.745 | nll_loss 0.372 | accuracy 79 | wps 471.4 | ups 7.4 | wpb 63.7 | bsz 31.9 | num_updates 5502 | lr 5.39262e-05 | gnorm 0.729 | train_wall 2 | wall 724\n",
      "epoch 132:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:42:12 | INFO | fairseq.trainer | begin training epoch 132\n",
      "epoch 132:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.38it/s]2022-02-02 10:42:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 132 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 132 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:42:18 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1164.6 | wpb 16 | bsz 8 | num_updates 5544 | best_loss 0.754\n",
      "2022-02-02 10:42:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:42:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint132.pt (epoch 132 @ 5544 updates, score 0.754) (writing took 0.040562945000033324 seconds)\n",
      "2022-02-02 10:42:18 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)\n",
      "2022-02-02 10:42:18 | INFO | train | epoch 132 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 474 | ups 7.44 | wpb 63.7 | bsz 31.9 | num_updates 5544 | lr 5.37215e-05 | gnorm 0.591 | train_wall 2 | wall 730\n",
      "epoch 133:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:42:18 | INFO | fairseq.trainer | begin training epoch 133\n",
      "epoch 133:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 18.89it/s]2022-02-02 10:42:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 133 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 133 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:42:23 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1199.5 | wpb 16 | bsz 8 | num_updates 5586 | best_loss 0.754\n",
      "2022-02-02 10:42:23 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:42:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint133.pt (epoch 133 @ 5586 updates, score 0.755) (writing took 0.02713233399992987 seconds)\n",
      "2022-02-02 10:42:23 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)\n",
      "2022-02-02 10:42:23 | INFO | train | epoch 133 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 476 | ups 7.47 | wpb 63.7 | bsz 31.9 | num_updates 5586 | lr 5.35192e-05 | gnorm 0.665 | train_wall 2 | wall 735\n",
      "epoch 134:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:42:23 | INFO | fairseq.trainer | begin training epoch 134\n",
      "epoch 134:  93%|▉| 39/42 [00:03<00:00, 21.34it/s, loss=0.733, nll_loss=0.367, ac2022-02-02 10:42:27 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 134 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 134 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:42:29 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1162.8 | wpb 16 | bsz 8 | num_updates 5628 | best_loss 0.754\n",
      "2022-02-02 10:42:29 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:42:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint134.pt (epoch 134 @ 5628 updates, score 0.754) (writing took 0.042632535000052485 seconds)\n",
      "2022-02-02 10:42:29 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)\n",
      "2022-02-02 10:42:29 | INFO | train | epoch 134 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 493.9 | ups 7.75 | wpb 63.7 | bsz 31.9 | num_updates 5628 | lr 5.33191e-05 | gnorm 0.685 | train_wall 2 | wall 741\n",
      "epoch 135:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:42:29 | INFO | fairseq.trainer | begin training epoch 135\n",
      "epoch 135:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.63it/s]2022-02-02 10:42:32 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 135 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 135 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.50s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:42:34 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1122.9 | wpb 16 | bsz 8 | num_updates 5670 | best_loss 0.754\n",
      "2022-02-02 10:42:34 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:42:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint135.pt (epoch 135 @ 5670 updates, score 0.755) (writing took 0.03398186200001874 seconds)\n",
      "2022-02-02 10:42:34 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)\n",
      "2022-02-02 10:42:34 | INFO | train | epoch 135 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 507.1 | ups 7.96 | wpb 63.7 | bsz 31.9 | num_updates 5670 | lr 5.31213e-05 | gnorm 0.653 | train_wall 2 | wall 746\n",
      "epoch 136:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:42:34 | INFO | fairseq.trainer | begin training epoch 136\n",
      "epoch 136:  95%|▉| 40/42 [00:03<00:00, 21.23it/s, loss=0.747, nll_loss=0.374, ac2022-02-02 10:42:38 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 136 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 136 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.49s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:42:39 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1236 | wpb 16 | bsz 8 | num_updates 5712 | best_loss 0.754\n",
      "2022-02-02 10:42:39 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:42:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint136.pt (epoch 136 @ 5712 updates, score 0.754) (writing took 0.03650647400002072 seconds)\n",
      "2022-02-02 10:42:39 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)\n",
      "2022-02-02 10:42:39 | INFO | train | epoch 136 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 500.1 | ups 7.85 | wpb 63.7 | bsz 31.9 | num_updates 5712 | lr 5.29256e-05 | gnorm 0.559 | train_wall 2 | wall 751\n",
      "epoch 137:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:42:39 | INFO | fairseq.trainer | begin training epoch 137\n",
      "epoch 137:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.39it/s]2022-02-02 10:42:43 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 137 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 137 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.50s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:42:45 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1091.9 | wpb 16 | bsz 8 | num_updates 5754 | best_loss 0.754\n",
      "2022-02-02 10:42:45 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:42:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint137.pt (epoch 137 @ 5754 updates, score 0.754) (writing took 0.04096166900001208 seconds)\n",
      "2022-02-02 10:42:45 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)\n",
      "2022-02-02 10:42:45 | INFO | train | epoch 137 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 501 | ups 7.86 | wpb 63.7 | bsz 31.9 | num_updates 5754 | lr 5.27321e-05 | gnorm 0.664 | train_wall 2 | wall 757\n",
      "epoch 138:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:42:45 | INFO | fairseq.trainer | begin training epoch 138\n",
      "epoch 138:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.42it/s]2022-02-02 10:42:48 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 138 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 138 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:42:50 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1178.3 | wpb 16 | bsz 8 | num_updates 5796 | best_loss 0.754\n",
      "2022-02-02 10:42:50 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:42:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint138.pt (epoch 138 @ 5796 updates, score 0.754) (writing took 0.04111556500004099 seconds)\n",
      "2022-02-02 10:42:50 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)\n",
      "2022-02-02 10:42:50 | INFO | train | epoch 138 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 487.9 | ups 7.66 | wpb 63.7 | bsz 31.9 | num_updates 5796 | lr 5.25407e-05 | gnorm 0.592 | train_wall 2 | wall 762\n",
      "epoch 139:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:42:50 | INFO | fairseq.trainer | begin training epoch 139\n",
      "epoch 139:  95%|▉| 40/42 [00:03<00:00, 21.02it/s, loss=0.75, nll_loss=0.375, acc2022-02-02 10:42:54 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 139 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 139 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:42:56 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1224.7 | wpb 16 | bsz 8 | num_updates 5838 | best_loss 0.754\n",
      "2022-02-02 10:42:56 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:42:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint139.pt (epoch 139 @ 5838 updates, score 0.755) (writing took 0.030884588000049007 seconds)\n",
      "2022-02-02 10:42:56 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)\n",
      "2022-02-02 10:42:56 | INFO | train | epoch 139 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 489.4 | ups 7.68 | wpb 63.7 | bsz 31.9 | num_updates 5838 | lr 5.23514e-05 | gnorm 0.794 | train_wall 2 | wall 768\n",
      "epoch 140:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:42:56 | INFO | fairseq.trainer | begin training epoch 140\n",
      "epoch 140:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.14it/s]2022-02-02 10:42:59 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 140 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 140 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:43:01 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1197.9 | wpb 16 | bsz 8 | num_updates 5880 | best_loss 0.754\n",
      "2022-02-02 10:43:01 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:43:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint140.pt (epoch 140 @ 5880 updates, score 0.755) (writing took 0.02808725800002776 seconds)\n",
      "2022-02-02 10:43:01 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)\n",
      "2022-02-02 10:43:01 | INFO | train | epoch 140 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 499.3 | ups 7.84 | wpb 63.7 | bsz 31.9 | num_updates 5880 | lr 5.21641e-05 | gnorm 0.569 | train_wall 2 | wall 773\n",
      "epoch 141:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:43:01 | INFO | fairseq.trainer | begin training epoch 141\n",
      "epoch 141:  95%|▉| 40/42 [00:03<00:00, 19.79it/s, loss=0.747, nll_loss=0.374, ac2022-02-02 10:43:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 141 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 141 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.66s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:43:07 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1084.8 | wpb 16 | bsz 8 | num_updates 5922 | best_loss 0.754\n",
      "2022-02-02 10:43:07 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:43:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint141.pt (epoch 141 @ 5922 updates, score 0.755) (writing took 0.031756306000033874 seconds)\n",
      "2022-02-02 10:43:07 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)\n",
      "2022-02-02 10:43:07 | INFO | train | epoch 141 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 470 | ups 7.38 | wpb 63.7 | bsz 31.9 | num_updates 5922 | lr 5.19787e-05 | gnorm 0.598 | train_wall 2 | wall 779\n",
      "epoch 142:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:43:07 | INFO | fairseq.trainer | begin training epoch 142\n",
      "epoch 142:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.94it/s]2022-02-02 10:43:10 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 142 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 142 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:43:12 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 0.758 | nll_loss 0.379 | accuracy 78.3 | wps 1206.2 | wpb 16 | bsz 8 | num_updates 5964 | best_loss 0.754\n",
      "2022-02-02 10:43:12 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:43:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint142.pt (epoch 142 @ 5964 updates, score 0.758) (writing took 0.030405972000039583 seconds)\n",
      "2022-02-02 10:43:12 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)\n",
      "2022-02-02 10:43:12 | INFO | train | epoch 142 | loss 0.745 | nll_loss 0.372 | accuracy 79 | wps 485.6 | ups 7.62 | wpb 63.7 | bsz 31.9 | num_updates 5964 | lr 5.17954e-05 | gnorm 0.741 | train_wall 2 | wall 784\n",
      "epoch 143:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:43:12 | INFO | fairseq.trainer | begin training epoch 143\n",
      "epoch 143:  93%|▉| 39/42 [00:03<00:00, 19.37it/s, loss=0.735, nll_loss=0.368, ac2022-02-02 10:43:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 143 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 143 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:43:18 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1241.5 | wpb 16 | bsz 8 | num_updates 6006 | best_loss 0.754\n",
      "2022-02-02 10:43:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:43:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint143.pt (epoch 143 @ 6006 updates, score 0.754) (writing took 0.04531496899994636 seconds)\n",
      "2022-02-02 10:43:18 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)\n",
      "2022-02-02 10:43:18 | INFO | train | epoch 143 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 478.2 | ups 7.5 | wpb 63.7 | bsz 31.9 | num_updates 6006 | lr 5.1614e-05 | gnorm 0.624 | train_wall 2 | wall 790\n",
      "epoch 144:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:43:18 | INFO | fairseq.trainer | begin training epoch 144\n",
      "epoch 144:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.92it/s]2022-02-02 10:43:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 144 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 144 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:43:23 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1055 | wpb 16 | bsz 8 | num_updates 6048 | best_loss 0.754\n",
      "2022-02-02 10:43:23 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:43:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint144.pt (epoch 144 @ 6048 updates, score 0.756) (writing took 0.03446521000000757 seconds)\n",
      "2022-02-02 10:43:23 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)\n",
      "2022-02-02 10:43:23 | INFO | train | epoch 144 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 487 | ups 7.64 | wpb 63.7 | bsz 31.9 | num_updates 6048 | lr 5.14344e-05 | gnorm 0.642 | train_wall 2 | wall 795\n",
      "epoch 145:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:43:23 | INFO | fairseq.trainer | begin training epoch 145\n",
      "epoch 145:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.60it/s]2022-02-02 10:43:27 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 145 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 145 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.45s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:43:28 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1238 | wpb 16 | bsz 8 | num_updates 6090 | best_loss 0.754\n",
      "2022-02-02 10:43:28 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:43:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint145.pt (epoch 145 @ 6090 updates, score 0.754) (writing took 0.03887116999999307 seconds)\n",
      "2022-02-02 10:43:28 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)\n",
      "2022-02-02 10:43:28 | INFO | train | epoch 145 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 507.5 | ups 7.97 | wpb 63.7 | bsz 31.9 | num_updates 6090 | lr 5.12568e-05 | gnorm 0.668 | train_wall 2 | wall 801\n",
      "epoch 146:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:43:28 | INFO | fairseq.trainer | begin training epoch 146\n",
      "epoch 146:  95%|▉| 40/42 [00:03<00:00, 20.40it/s, loss=0.74, nll_loss=0.37, accu2022-02-02 10:43:32 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 146 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 146 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.49s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:43:34 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1193.1 | wpb 16 | bsz 8 | num_updates 6132 | best_loss 0.754\n",
      "2022-02-02 10:43:34 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:43:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint146.pt (epoch 146 @ 6132 updates, score 0.754) (writing took 0.035781690000021626 seconds)\n",
      "2022-02-02 10:43:34 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)\n",
      "2022-02-02 10:43:34 | INFO | train | epoch 146 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 497.3 | ups 7.81 | wpb 63.7 | bsz 31.9 | num_updates 6132 | lr 5.10809e-05 | gnorm 0.605 | train_wall 2 | wall 806\n",
      "epoch 147:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:43:34 | INFO | fairseq.trainer | begin training epoch 147\n",
      "epoch 147:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.30it/s]2022-02-02 10:43:38 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 147 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 147 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:43:39 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1285.4 | wpb 16 | bsz 8 | num_updates 6174 | best_loss 0.754\n",
      "2022-02-02 10:43:39 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:43:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint147.pt (epoch 147 @ 6174 updates, score 0.754) (writing took 0.025278787000047487 seconds)\n",
      "2022-02-02 10:43:39 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)\n",
      "2022-02-02 10:43:39 | INFO | train | epoch 147 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 481.4 | ups 7.56 | wpb 63.7 | bsz 31.9 | num_updates 6174 | lr 5.09069e-05 | gnorm 0.652 | train_wall 2 | wall 811\n",
      "epoch 148:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:43:39 | INFO | fairseq.trainer | begin training epoch 148\n",
      "epoch 148:  95%|▉| 40/42 [00:03<00:00, 21.40it/s, loss=0.749, nll_loss=0.375, ac2022-02-02 10:43:43 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 148 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 148 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:43:45 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1161.1 | wpb 16 | bsz 8 | num_updates 6216 | best_loss 0.754\n",
      "2022-02-02 10:43:45 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:43:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint148.pt (epoch 148 @ 6216 updates, score 0.754) (writing took 0.02647774100000788 seconds)\n",
      "2022-02-02 10:43:45 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)\n",
      "2022-02-02 10:43:45 | INFO | train | epoch 148 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 492.4 | ups 7.73 | wpb 63.7 | bsz 31.9 | num_updates 6216 | lr 5.07346e-05 | gnorm 0.6 | train_wall 2 | wall 817\n",
      "epoch 149:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:43:45 | INFO | fairseq.trainer | begin training epoch 149\n",
      "epoch 149:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.56it/s]2022-02-02 10:43:49 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 149 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 149 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:43:50 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 986.9 | wpb 16 | bsz 8 | num_updates 6258 | best_loss 0.754\n",
      "2022-02-02 10:43:50 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:43:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint149.pt (epoch 149 @ 6258 updates, score 0.754) (writing took 0.0545761800000264 seconds)\n",
      "2022-02-02 10:43:50 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)\n",
      "2022-02-02 10:43:50 | INFO | train | epoch 149 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 476.4 | ups 7.48 | wpb 63.7 | bsz 31.9 | num_updates 6258 | lr 5.05641e-05 | gnorm 0.634 | train_wall 2 | wall 822\n",
      "epoch 150:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:43:50 | INFO | fairseq.trainer | begin training epoch 150\n",
      "epoch 150:  93%|█████████████████████████████▋  | 39/42 [00:04<00:00, 20.29it/s]2022-02-02 10:43:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 150 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 150 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:43:57 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1143.3 | wpb 16 | bsz 8 | num_updates 6300 | best_loss 0.754\n",
      "2022-02-02 10:43:57 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:43:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint150.pt (epoch 150 @ 6300 updates, score 0.754) (writing took 0.03374343100006172 seconds)\n",
      "2022-02-02 10:43:57 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)\n",
      "2022-02-02 10:43:57 | INFO | train | epoch 150 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 436.6 | ups 6.85 | wpb 63.7 | bsz 31.9 | num_updates 6300 | lr 5.03953e-05 | gnorm 0.707 | train_wall 2 | wall 829\n",
      "epoch 151:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:43:57 | INFO | fairseq.trainer | begin training epoch 151\n",
      "epoch 151:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.06it/s]2022-02-02 10:44:00 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 151 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 151 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:44:02 | INFO | valid | epoch 151 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1231.9 | wpb 16 | bsz 8 | num_updates 6342 | best_loss 0.754\n",
      "2022-02-02 10:44:02 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:44:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint151.pt (epoch 151 @ 6342 updates, score 0.755) (writing took 0.02072404299997288 seconds)\n",
      "2022-02-02 10:44:02 | INFO | fairseq_cli.train | end of epoch 151 (average epoch stats below)\n",
      "2022-02-02 10:44:02 | INFO | train | epoch 151 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 481.3 | ups 7.55 | wpb 63.7 | bsz 31.9 | num_updates 6342 | lr 5.02281e-05 | gnorm 0.546 | train_wall 2 | wall 834\n",
      "epoch 152:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:44:02 | INFO | fairseq.trainer | begin training epoch 152\n",
      "epoch 152:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.41it/s]2022-02-02 10:44:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 152 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 152 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:44:08 | INFO | valid | epoch 152 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1173.8 | wpb 16 | bsz 8 | num_updates 6384 | best_loss 0.754\n",
      "2022-02-02 10:44:08 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:44:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint152.pt (epoch 152 @ 6384 updates, score 0.755) (writing took 0.03145280299997921 seconds)\n",
      "2022-02-02 10:44:08 | INFO | fairseq_cli.train | end of epoch 152 (average epoch stats below)\n",
      "2022-02-02 10:44:08 | INFO | train | epoch 152 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 493.7 | ups 7.75 | wpb 63.7 | bsz 31.9 | num_updates 6384 | lr 5.00626e-05 | gnorm 0.602 | train_wall 2 | wall 840\n",
      "epoch 153:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:44:08 | INFO | fairseq.trainer | begin training epoch 153\n",
      "epoch 153:  93%|▉| 39/42 [00:03<00:00, 20.46it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 10:44:11 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 153 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 153 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:24,  1.78s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:44:13 | INFO | valid | epoch 153 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1070.1 | wpb 16 | bsz 8 | num_updates 6426 | best_loss 0.754\n",
      "2022-02-02 10:44:13 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:44:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint153.pt (epoch 153 @ 6426 updates, score 0.755) (writing took 0.02464155099994514 seconds)\n",
      "2022-02-02 10:44:13 | INFO | fairseq_cli.train | end of epoch 153 (average epoch stats below)\n",
      "2022-02-02 10:44:13 | INFO | train | epoch 153 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 473.4 | ups 7.43 | wpb 63.7 | bsz 31.9 | num_updates 6426 | lr 4.98987e-05 | gnorm 0.676 | train_wall 2 | wall 845\n",
      "epoch 154:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:44:13 | INFO | fairseq.trainer | begin training epoch 154\n",
      "epoch 154:  98%|███████████████████████████████▏| 41/42 [00:04<00:00, 16.47it/s]2022-02-02 10:44:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 154 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 154 | valid on 'valid' subset:   7%|▍      | 1/15 [00:02<00:29,  2.08s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:44:20 | INFO | valid | epoch 154 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 956.2 | wpb 16 | bsz 8 | num_updates 6468 | best_loss 0.754\n",
      "2022-02-02 10:44:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:44:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint154.pt (epoch 154 @ 6468 updates, score 0.754) (writing took 0.035464407999938885 seconds)\n",
      "2022-02-02 10:44:20 | INFO | fairseq_cli.train | end of epoch 154 (average epoch stats below)\n",
      "2022-02-02 10:44:20 | INFO | train | epoch 154 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 381.8 | ups 5.99 | wpb 63.7 | bsz 31.9 | num_updates 6468 | lr 4.97365e-05 | gnorm 0.588 | train_wall 2 | wall 852\n",
      "epoch 155:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:44:20 | INFO | fairseq.trainer | begin training epoch 155\n",
      "epoch 155:  95%|▉| 40/42 [00:03<00:00, 20.73it/s, loss=0.746, nll_loss=0.373, ac2022-02-02 10:44:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 155 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 155 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.49s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:44:26 | INFO | valid | epoch 155 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1183.2 | wpb 16 | bsz 8 | num_updates 6510 | best_loss 0.754\n",
      "2022-02-02 10:44:26 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:44:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint155.pt (epoch 155 @ 6510 updates, score 0.755) (writing took 0.029872769000007793 seconds)\n",
      "2022-02-02 10:44:26 | INFO | fairseq_cli.train | end of epoch 155 (average epoch stats below)\n",
      "2022-02-02 10:44:26 | INFO | train | epoch 155 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 482.4 | ups 7.57 | wpb 63.7 | bsz 31.9 | num_updates 6510 | lr 4.95758e-05 | gnorm 0.753 | train_wall 2 | wall 858\n",
      "epoch 156:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:44:26 | INFO | fairseq.trainer | begin training epoch 156\n",
      "epoch 156:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.97it/s]2022-02-02 10:44:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 156 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 156 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.48s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:44:31 | INFO | valid | epoch 156 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1171.8 | wpb 16 | bsz 8 | num_updates 6552 | best_loss 0.754\n",
      "2022-02-02 10:44:31 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:44:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint156.pt (epoch 156 @ 6552 updates, score 0.755) (writing took 0.030896015000053012 seconds)\n",
      "2022-02-02 10:44:31 | INFO | fairseq_cli.train | end of epoch 156 (average epoch stats below)\n",
      "2022-02-02 10:44:31 | INFO | train | epoch 156 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 504.5 | ups 7.92 | wpb 63.7 | bsz 31.9 | num_updates 6552 | lr 4.94166e-05 | gnorm 0.561 | train_wall 2 | wall 863\n",
      "epoch 157:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:44:31 | INFO | fairseq.trainer | begin training epoch 157\n",
      "epoch 157:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.57it/s]2022-02-02 10:44:35 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 157 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 157 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:44:36 | INFO | valid | epoch 157 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 963.1 | wpb 16 | bsz 8 | num_updates 6594 | best_loss 0.754\n",
      "2022-02-02 10:44:36 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:44:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint157.pt (epoch 157 @ 6594 updates, score 0.754) (writing took 0.037562157000024854 seconds)\n",
      "2022-02-02 10:44:37 | INFO | fairseq_cli.train | end of epoch 157 (average epoch stats below)\n",
      "2022-02-02 10:44:37 | INFO | train | epoch 157 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 492.2 | ups 7.73 | wpb 63.7 | bsz 31.9 | num_updates 6594 | lr 4.9259e-05 | gnorm 0.697 | train_wall 2 | wall 869\n",
      "epoch 158:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:44:37 | INFO | fairseq.trainer | begin training epoch 158\n",
      "epoch 158:  93%|▉| 39/42 [00:03<00:00, 21.62it/s, loss=0.75, nll_loss=0.375, acc2022-02-02 10:44:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 158 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 158 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:44:42 | INFO | valid | epoch 158 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1083.2 | wpb 16 | bsz 8 | num_updates 6636 | best_loss 0.754\n",
      "2022-02-02 10:44:42 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:44:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint158.pt (epoch 158 @ 6636 updates, score 0.755) (writing took 0.07348278400002073 seconds)\n",
      "2022-02-02 10:44:42 | INFO | fairseq_cli.train | end of epoch 158 (average epoch stats below)\n",
      "2022-02-02 10:44:42 | INFO | train | epoch 158 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 486.5 | ups 7.64 | wpb 63.7 | bsz 31.9 | num_updates 6636 | lr 4.91029e-05 | gnorm 0.573 | train_wall 2 | wall 874\n",
      "epoch 159:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:44:42 | INFO | fairseq.trainer | begin training epoch 159\n",
      "epoch 159:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.64it/s]2022-02-02 10:44:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 159 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 159 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:44:47 | INFO | valid | epoch 159 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1209.2 | wpb 16 | bsz 8 | num_updates 6678 | best_loss 0.754\n",
      "2022-02-02 10:44:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:44:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint159.pt (epoch 159 @ 6678 updates, score 0.755) (writing took 0.0206694560000642 seconds)\n",
      "2022-02-02 10:44:47 | INFO | fairseq_cli.train | end of epoch 159 (average epoch stats below)\n",
      "2022-02-02 10:44:47 | INFO | train | epoch 159 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 506 | ups 7.94 | wpb 63.7 | bsz 31.9 | num_updates 6678 | lr 4.89482e-05 | gnorm 0.58 | train_wall 2 | wall 879\n",
      "epoch 160:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:44:47 | INFO | fairseq.trainer | begin training epoch 160\n",
      "epoch 160:  95%|▉| 40/42 [00:03<00:00, 20.64it/s, loss=0.732, nll_loss=0.366, ac2022-02-02 10:44:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 160 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 160 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:44:53 | INFO | valid | epoch 160 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1226.6 | wpb 16 | bsz 8 | num_updates 6720 | best_loss 0.754\n",
      "2022-02-02 10:44:53 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:44:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint160.pt (epoch 160 @ 6720 updates, score 0.755) (writing took 0.024751466999987315 seconds)\n",
      "2022-02-02 10:44:53 | INFO | fairseq_cli.train | end of epoch 160 (average epoch stats below)\n",
      "2022-02-02 10:44:53 | INFO | train | epoch 160 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 499.9 | ups 7.85 | wpb 63.7 | bsz 31.9 | num_updates 6720 | lr 4.8795e-05 | gnorm 0.581 | train_wall 2 | wall 885\n",
      "epoch 161:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:44:53 | INFO | fairseq.trainer | begin training epoch 161\n",
      "epoch 161:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.45it/s]2022-02-02 10:44:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 161 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 161 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:44:58 | INFO | valid | epoch 161 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1266.3 | wpb 16 | bsz 8 | num_updates 6762 | best_loss 0.754\n",
      "2022-02-02 10:44:58 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:44:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint161.pt (epoch 161 @ 6762 updates, score 0.755) (writing took 0.02465086600000177 seconds)\n",
      "2022-02-02 10:44:58 | INFO | fairseq_cli.train | end of epoch 161 (average epoch stats below)\n",
      "2022-02-02 10:44:58 | INFO | train | epoch 161 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 498.9 | ups 7.83 | wpb 63.7 | bsz 31.9 | num_updates 6762 | lr 4.86432e-05 | gnorm 0.573 | train_wall 2 | wall 890\n",
      "epoch 162:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:44:58 | INFO | fairseq.trainer | begin training epoch 162\n",
      "epoch 162:  93%|▉| 39/42 [00:03<00:00, 20.32it/s, loss=0.748, nll_loss=0.374, ac2022-02-02 10:45:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 162 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 162 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:45:03 | INFO | valid | epoch 162 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1237.1 | wpb 16 | bsz 8 | num_updates 6804 | best_loss 0.754\n",
      "2022-02-02 10:45:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:45:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint162.pt (epoch 162 @ 6804 updates, score 0.755) (writing took 0.02339064500006316 seconds)\n",
      "2022-02-02 10:45:03 | INFO | fairseq_cli.train | end of epoch 162 (average epoch stats below)\n",
      "2022-02-02 10:45:03 | INFO | train | epoch 162 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 495.6 | ups 7.78 | wpb 63.7 | bsz 31.9 | num_updates 6804 | lr 4.84929e-05 | gnorm 0.692 | train_wall 2 | wall 895\n",
      "epoch 163:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:45:03 | INFO | fairseq.trainer | begin training epoch 163\n",
      "epoch 163:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.99it/s]2022-02-02 10:45:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 163 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 163 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:45:09 | INFO | valid | epoch 163 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1211.8 | wpb 16 | bsz 8 | num_updates 6846 | best_loss 0.754\n",
      "2022-02-02 10:45:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:45:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint163.pt (epoch 163 @ 6846 updates, score 0.755) (writing took 0.018563516999961394 seconds)\n",
      "2022-02-02 10:45:09 | INFO | fairseq_cli.train | end of epoch 163 (average epoch stats below)\n",
      "2022-02-02 10:45:09 | INFO | train | epoch 163 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 486.8 | ups 7.64 | wpb 63.7 | bsz 31.9 | num_updates 6846 | lr 4.83439e-05 | gnorm 0.638 | train_wall 2 | wall 901\n",
      "epoch 164:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:45:09 | INFO | fairseq.trainer | begin training epoch 164\n",
      "epoch 164:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.10it/s]2022-02-02 10:45:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 164 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 164 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:45:14 | INFO | valid | epoch 164 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1156.5 | wpb 16 | bsz 8 | num_updates 6888 | best_loss 0.754\n",
      "2022-02-02 10:45:14 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:45:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint164.pt (epoch 164 @ 6888 updates, score 0.755) (writing took 0.028894999000044663 seconds)\n",
      "2022-02-02 10:45:14 | INFO | fairseq_cli.train | end of epoch 164 (average epoch stats below)\n",
      "2022-02-02 10:45:14 | INFO | train | epoch 164 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 491.7 | ups 7.72 | wpb 63.7 | bsz 31.9 | num_updates 6888 | lr 4.81963e-05 | gnorm 0.573 | train_wall 2 | wall 906\n",
      "epoch 165:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:45:14 | INFO | fairseq.trainer | begin training epoch 165\n",
      "epoch 165:  93%|▉| 39/42 [00:03<00:00, 20.89it/s, loss=0.735, nll_loss=0.367, ac2022-02-02 10:45:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 165 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 165 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:45:20 | INFO | valid | epoch 165 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1225.3 | wpb 16 | bsz 8 | num_updates 6930 | best_loss 0.754\n",
      "2022-02-02 10:45:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:45:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint165.pt (epoch 165 @ 6930 updates, score 0.756) (writing took 0.0353817689999687 seconds)\n",
      "2022-02-02 10:45:20 | INFO | fairseq_cli.train | end of epoch 165 (average epoch stats below)\n",
      "2022-02-02 10:45:20 | INFO | train | epoch 165 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 491 | ups 7.71 | wpb 63.7 | bsz 31.9 | num_updates 6930 | lr 4.805e-05 | gnorm 0.639 | train_wall 2 | wall 912\n",
      "epoch 166:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:45:20 | INFO | fairseq.trainer | begin training epoch 166\n",
      "epoch 166:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.22it/s]2022-02-02 10:45:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 166 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 166 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.49s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:45:25 | INFO | valid | epoch 166 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1235.7 | wpb 16 | bsz 8 | num_updates 6972 | best_loss 0.754\n",
      "2022-02-02 10:45:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:45:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint166.pt (epoch 166 @ 6972 updates, score 0.755) (writing took 0.043266528000003746 seconds)\n",
      "2022-02-02 10:45:25 | INFO | fairseq_cli.train | end of epoch 166 (average epoch stats below)\n",
      "2022-02-02 10:45:25 | INFO | train | epoch 166 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 488.3 | ups 7.66 | wpb 63.7 | bsz 31.9 | num_updates 6972 | lr 4.79051e-05 | gnorm 0.634 | train_wall 2 | wall 917\n",
      "epoch 167:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:45:25 | INFO | fairseq.trainer | begin training epoch 167\n",
      "epoch 167:  93%|▉| 39/42 [00:03<00:00, 21.59it/s, loss=0.751, nll_loss=0.375, ac2022-02-02 10:45:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 167 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 167 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:45:31 | INFO | valid | epoch 167 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1081.5 | wpb 16 | bsz 8 | num_updates 7014 | best_loss 0.754\n",
      "2022-02-02 10:45:31 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:45:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint167.pt (epoch 167 @ 7014 updates, score 0.754) (writing took 0.026790717000039876 seconds)\n",
      "2022-02-02 10:45:31 | INFO | fairseq_cli.train | end of epoch 167 (average epoch stats below)\n",
      "2022-02-02 10:45:31 | INFO | train | epoch 167 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 497.3 | ups 7.81 | wpb 63.7 | bsz 31.9 | num_updates 7014 | lr 4.77614e-05 | gnorm 0.499 | train_wall 2 | wall 923\n",
      "epoch 168:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:45:31 | INFO | fairseq.trainer | begin training epoch 168\n",
      "epoch 168:  95%|██████████████████████████████▍ | 40/42 [00:04<00:00, 20.65it/s]2022-02-02 10:45:35 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 168 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 168 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:45:37 | INFO | valid | epoch 168 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1194 | wpb 16 | bsz 8 | num_updates 7056 | best_loss 0.754\n",
      "2022-02-02 10:45:37 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:45:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint168.pt (epoch 168 @ 7056 updates, score 0.755) (writing took 0.0302842270000383 seconds)\n",
      "2022-02-02 10:45:37 | INFO | fairseq_cli.train | end of epoch 168 (average epoch stats below)\n",
      "2022-02-02 10:45:37 | INFO | train | epoch 168 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 448.1 | ups 7.03 | wpb 63.7 | bsz 31.9 | num_updates 7056 | lr 4.7619e-05 | gnorm 0.602 | train_wall 2 | wall 929\n",
      "epoch 169:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:45:37 | INFO | fairseq.trainer | begin training epoch 169\n",
      "epoch 169:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.75it/s]2022-02-02 10:45:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 169 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 169 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:45:42 | INFO | valid | epoch 169 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1226.4 | wpb 16 | bsz 8 | num_updates 7098 | best_loss 0.754\n",
      "2022-02-02 10:45:42 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:45:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint169.pt (epoch 169 @ 7098 updates, score 0.755) (writing took 0.018884944999967956 seconds)\n",
      "2022-02-02 10:45:42 | INFO | fairseq_cli.train | end of epoch 169 (average epoch stats below)\n",
      "2022-02-02 10:45:42 | INFO | train | epoch 169 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 507.1 | ups 7.96 | wpb 63.7 | bsz 31.9 | num_updates 7098 | lr 4.7478e-05 | gnorm 0.76 | train_wall 2 | wall 934\n",
      "epoch 170:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:45:42 | INFO | fairseq.trainer | begin training epoch 170\n",
      "epoch 170:  95%|▉| 40/42 [00:03<00:00, 21.65it/s, loss=0.737, nll_loss=0.369, ac2022-02-02 10:45:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 170 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 170 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:45:47 | INFO | valid | epoch 170 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1193.9 | wpb 16 | bsz 8 | num_updates 7140 | best_loss 0.754\n",
      "2022-02-02 10:45:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:45:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint170.pt (epoch 170 @ 7140 updates, score 0.754) (writing took 0.029708308999943256 seconds)\n",
      "2022-02-02 10:45:47 | INFO | fairseq_cli.train | end of epoch 170 (average epoch stats below)\n",
      "2022-02-02 10:45:47 | INFO | train | epoch 170 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 490.7 | ups 7.7 | wpb 63.7 | bsz 31.9 | num_updates 7140 | lr 4.73381e-05 | gnorm 0.678 | train_wall 2 | wall 939\n",
      "epoch 171:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:45:47 | INFO | fairseq.trainer | begin training epoch 171\n",
      "epoch 171:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.37it/s]2022-02-02 10:45:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 171 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 171 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.64s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:45:53 | INFO | valid | epoch 171 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1167.8 | wpb 16 | bsz 8 | num_updates 7182 | best_loss 0.754\n",
      "2022-02-02 10:45:53 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:45:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint171.pt (epoch 171 @ 7182 updates, score 0.755) (writing took 0.021807253000019955 seconds)\n",
      "2022-02-02 10:45:53 | INFO | fairseq_cli.train | end of epoch 171 (average epoch stats below)\n",
      "2022-02-02 10:45:53 | INFO | train | epoch 171 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 466.6 | ups 7.32 | wpb 63.7 | bsz 31.9 | num_updates 7182 | lr 4.71995e-05 | gnorm 0.595 | train_wall 2 | wall 945\n",
      "epoch 172:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:45:53 | INFO | fairseq.trainer | begin training epoch 172\n",
      "epoch 172:  95%|▉| 40/42 [00:03<00:00, 21.59it/s, loss=0.741, nll_loss=0.37, acc2022-02-02 10:45:57 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 172 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 172 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:45:59 | INFO | valid | epoch 172 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1171.4 | wpb 16 | bsz 8 | num_updates 7224 | best_loss 0.754\n",
      "2022-02-02 10:45:59 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:45:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint172.pt (epoch 172 @ 7224 updates, score 0.754) (writing took 0.03184833599993908 seconds)\n",
      "2022-02-02 10:45:59 | INFO | fairseq_cli.train | end of epoch 172 (average epoch stats below)\n",
      "2022-02-02 10:45:59 | INFO | train | epoch 172 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 491.8 | ups 7.72 | wpb 63.7 | bsz 31.9 | num_updates 7224 | lr 4.70621e-05 | gnorm 0.706 | train_wall 2 | wall 951\n",
      "epoch 173:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:45:59 | INFO | fairseq.trainer | begin training epoch 173\n",
      "epoch 173:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.40it/s]2022-02-02 10:46:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 173 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 173 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:46:04 | INFO | valid | epoch 173 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1216.1 | wpb 16 | bsz 8 | num_updates 7266 | best_loss 0.754\n",
      "2022-02-02 10:46:04 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:46:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint173.pt (epoch 173 @ 7266 updates, score 0.756) (writing took 0.03019639100000404 seconds)\n",
      "2022-02-02 10:46:04 | INFO | fairseq_cli.train | end of epoch 173 (average epoch stats below)\n",
      "2022-02-02 10:46:04 | INFO | train | epoch 173 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 498 | ups 7.82 | wpb 63.7 | bsz 31.9 | num_updates 7266 | lr 4.69259e-05 | gnorm 0.538 | train_wall 2 | wall 956\n",
      "epoch 174:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:46:04 | INFO | fairseq.trainer | begin training epoch 174\n",
      "epoch 174:  95%|▉| 40/42 [00:03<00:00, 21.62it/s, loss=0.75, nll_loss=0.375, acc2022-02-02 10:46:08 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 174 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 174 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:46:09 | INFO | valid | epoch 174 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1239.1 | wpb 16 | bsz 8 | num_updates 7308 | best_loss 0.754\n",
      "2022-02-02 10:46:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:46:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint174.pt (epoch 174 @ 7308 updates, score 0.755) (writing took 0.02959392700006447 seconds)\n",
      "2022-02-02 10:46:09 | INFO | fairseq_cli.train | end of epoch 174 (average epoch stats below)\n",
      "2022-02-02 10:46:09 | INFO | train | epoch 174 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 500.5 | ups 7.86 | wpb 63.7 | bsz 31.9 | num_updates 7308 | lr 4.67908e-05 | gnorm 0.667 | train_wall 2 | wall 961\n",
      "epoch 175:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:46:09 | INFO | fairseq.trainer | begin training epoch 175\n",
      "epoch 175:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.57it/s]2022-02-02 10:46:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 175 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 175 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:46:15 | INFO | valid | epoch 175 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1259.2 | wpb 16 | bsz 8 | num_updates 7350 | best_loss 0.754\n",
      "2022-02-02 10:46:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:46:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint175.pt (epoch 175 @ 7350 updates, score 0.754) (writing took 0.04243809299998702 seconds)\n",
      "2022-02-02 10:46:15 | INFO | fairseq_cli.train | end of epoch 175 (average epoch stats below)\n",
      "2022-02-02 10:46:15 | INFO | train | epoch 175 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 503.8 | ups 7.91 | wpb 63.7 | bsz 31.9 | num_updates 7350 | lr 4.66569e-05 | gnorm 0.68 | train_wall 2 | wall 967\n",
      "epoch 176:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:46:15 | INFO | fairseq.trainer | begin training epoch 176\n",
      "epoch 176:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.69it/s]2022-02-02 10:46:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 176 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 176 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:46:20 | INFO | valid | epoch 176 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1244.8 | wpb 16 | bsz 8 | num_updates 7392 | best_loss 0.754\n",
      "2022-02-02 10:46:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:46:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint176.pt (epoch 176 @ 7392 updates, score 0.756) (writing took 0.026337089999969976 seconds)\n",
      "2022-02-02 10:46:20 | INFO | fairseq_cli.train | end of epoch 176 (average epoch stats below)\n",
      "2022-02-02 10:46:20 | INFO | train | epoch 176 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 498.9 | ups 7.83 | wpb 63.7 | bsz 31.9 | num_updates 7392 | lr 4.65242e-05 | gnorm 0.655 | train_wall 2 | wall 972\n",
      "epoch 177:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:46:20 | INFO | fairseq.trainer | begin training epoch 177\n",
      "epoch 177:  93%|▉| 39/42 [00:03<00:00, 21.20it/s, loss=0.745, nll_loss=0.373, ac2022-02-02 10:46:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 177 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 177 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:46:25 | INFO | valid | epoch 177 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1239 | wpb 16 | bsz 8 | num_updates 7434 | best_loss 0.754\n",
      "2022-02-02 10:46:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:46:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint177.pt (epoch 177 @ 7434 updates, score 0.755) (writing took 0.029030785000031756 seconds)\n",
      "2022-02-02 10:46:25 | INFO | fairseq_cli.train | end of epoch 177 (average epoch stats below)\n",
      "2022-02-02 10:46:25 | INFO | train | epoch 177 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 488.9 | ups 7.67 | wpb 63.7 | bsz 31.9 | num_updates 7434 | lr 4.63926e-05 | gnorm 0.615 | train_wall 2 | wall 977\n",
      "epoch 178:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:46:25 | INFO | fairseq.trainer | begin training epoch 178\n",
      "epoch 178:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.48it/s]2022-02-02 10:46:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 178 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 178 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:46:31 | INFO | valid | epoch 178 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1243.1 | wpb 16 | bsz 8 | num_updates 7476 | best_loss 0.754\n",
      "2022-02-02 10:46:31 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:46:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint178.pt (epoch 178 @ 7476 updates, score 0.755) (writing took 0.030546103000006042 seconds)\n",
      "2022-02-02 10:46:31 | INFO | fairseq_cli.train | end of epoch 178 (average epoch stats below)\n",
      "2022-02-02 10:46:31 | INFO | train | epoch 178 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 496.5 | ups 7.79 | wpb 63.7 | bsz 31.9 | num_updates 7476 | lr 4.62621e-05 | gnorm 0.541 | train_wall 2 | wall 983\n",
      "epoch 179:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:46:31 | INFO | fairseq.trainer | begin training epoch 179\n",
      "epoch 179:  93%|▉| 39/42 [00:03<00:00, 20.92it/s, loss=0.728, nll_loss=0.364, ac2022-02-02 10:46:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 179 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 179 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:46:36 | INFO | valid | epoch 179 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1247.9 | wpb 16 | bsz 8 | num_updates 7518 | best_loss 0.754\n",
      "2022-02-02 10:46:36 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:46:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint179.pt (epoch 179 @ 7518 updates, score 0.754) (writing took 0.04166328200005864 seconds)\n",
      "2022-02-02 10:46:36 | INFO | fairseq_cli.train | end of epoch 179 (average epoch stats below)\n",
      "2022-02-02 10:46:36 | INFO | train | epoch 179 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 498.1 | ups 7.82 | wpb 63.7 | bsz 31.9 | num_updates 7518 | lr 4.61327e-05 | gnorm 0.697 | train_wall 2 | wall 988\n",
      "epoch 180:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:46:36 | INFO | fairseq.trainer | begin training epoch 180\n",
      "epoch 180:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.17it/s]2022-02-02 10:46:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 180 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 180 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.50s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:46:41 | INFO | valid | epoch 180 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1233.9 | wpb 16 | bsz 8 | num_updates 7560 | best_loss 0.754\n",
      "2022-02-02 10:46:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:46:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint180.pt (epoch 180 @ 7560 updates, score 0.755) (writing took 0.029670520000081524 seconds)\n",
      "2022-02-02 10:46:41 | INFO | fairseq_cli.train | end of epoch 180 (average epoch stats below)\n",
      "2022-02-02 10:46:41 | INFO | train | epoch 180 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 506.1 | ups 7.94 | wpb 63.7 | bsz 31.9 | num_updates 7560 | lr 4.60044e-05 | gnorm 0.497 | train_wall 2 | wall 994\n",
      "epoch 181:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:46:41 | INFO | fairseq.trainer | begin training epoch 181\n",
      "epoch 181:  95%|▉| 40/42 [00:03<00:00, 20.96it/s, loss=0.752, nll_loss=0.376, ac2022-02-02 10:46:45 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 181 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 181 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:46:47 | INFO | valid | epoch 181 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1251.6 | wpb 16 | bsz 8 | num_updates 7602 | best_loss 0.754\n",
      "2022-02-02 10:46:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:46:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint181.pt (epoch 181 @ 7602 updates, score 0.754) (writing took 0.039068516999918756 seconds)\n",
      "2022-02-02 10:46:47 | INFO | fairseq_cli.train | end of epoch 181 (average epoch stats below)\n",
      "2022-02-02 10:46:47 | INFO | train | epoch 181 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 494.9 | ups 7.77 | wpb 63.7 | bsz 31.9 | num_updates 7602 | lr 4.58771e-05 | gnorm 0.607 | train_wall 2 | wall 999\n",
      "epoch 182:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:46:47 | INFO | fairseq.trainer | begin training epoch 182\n",
      "epoch 182:  98%|███████████████████████████████▏| 41/42 [00:03<00:00, 21.62it/s]2022-02-02 10:46:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 182 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 182 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:46:52 | INFO | valid | epoch 182 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1262.3 | wpb 16 | bsz 8 | num_updates 7644 | best_loss 0.754\n",
      "2022-02-02 10:46:52 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:46:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint182.pt (epoch 182 @ 7644 updates, score 0.754) (writing took 0.0468673759999092 seconds)\n",
      "2022-02-02 10:46:52 | INFO | fairseq_cli.train | end of epoch 182 (average epoch stats below)\n",
      "2022-02-02 10:46:52 | INFO | train | epoch 182 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 485.2 | ups 7.61 | wpb 63.7 | bsz 31.9 | num_updates 7644 | lr 4.57509e-05 | gnorm 0.661 | train_wall 2 | wall 1004\n",
      "epoch 183:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:46:52 | INFO | fairseq.trainer | begin training epoch 183\n",
      "epoch 183:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.22it/s]2022-02-02 10:46:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 183 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 183 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:46:58 | INFO | valid | epoch 183 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1216 | wpb 16 | bsz 8 | num_updates 7686 | best_loss 0.754\n",
      "2022-02-02 10:46:58 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:46:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint183.pt (epoch 183 @ 7686 updates, score 0.755) (writing took 0.020940703000064786 seconds)\n",
      "2022-02-02 10:46:58 | INFO | fairseq_cli.train | end of epoch 183 (average epoch stats below)\n",
      "2022-02-02 10:46:58 | INFO | train | epoch 183 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 494.4 | ups 7.76 | wpb 63.7 | bsz 31.9 | num_updates 7686 | lr 4.56257e-05 | gnorm 0.592 | train_wall 2 | wall 1010\n",
      "epoch 184:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:46:58 | INFO | fairseq.trainer | begin training epoch 184\n",
      "epoch 184:  95%|▉| 40/42 [00:03<00:00, 20.65it/s, loss=0.746, nll_loss=0.373, ac2022-02-02 10:47:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 184 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 184 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:47:03 | INFO | valid | epoch 184 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1255.8 | wpb 16 | bsz 8 | num_updates 7728 | best_loss 0.754\n",
      "2022-02-02 10:47:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:47:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint184.pt (epoch 184 @ 7728 updates, score 0.755) (writing took 0.03214775499998268 seconds)\n",
      "2022-02-02 10:47:03 | INFO | fairseq_cli.train | end of epoch 184 (average epoch stats below)\n",
      "2022-02-02 10:47:03 | INFO | train | epoch 184 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 486.6 | ups 7.64 | wpb 63.7 | bsz 31.9 | num_updates 7728 | lr 4.55016e-05 | gnorm 0.651 | train_wall 2 | wall 1015\n",
      "epoch 185:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:47:03 | INFO | fairseq.trainer | begin training epoch 185\n",
      "epoch 185:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.89it/s]2022-02-02 10:47:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 185 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 185 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:47:09 | INFO | valid | epoch 185 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1131.8 | wpb 16 | bsz 8 | num_updates 7770 | best_loss 0.754\n",
      "2022-02-02 10:47:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:47:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint185.pt (epoch 185 @ 7770 updates, score 0.755) (writing took 0.023960434999935387 seconds)\n",
      "2022-02-02 10:47:09 | INFO | fairseq_cli.train | end of epoch 185 (average epoch stats below)\n",
      "2022-02-02 10:47:09 | INFO | train | epoch 185 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 483.2 | ups 7.58 | wpb 63.7 | bsz 31.9 | num_updates 7770 | lr 4.53784e-05 | gnorm 0.633 | train_wall 2 | wall 1021\n",
      "epoch 186:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:47:09 | INFO | fairseq.trainer | begin training epoch 186\n",
      "epoch 186:  95%|▉| 40/42 [00:04<00:00, 17.79it/s, loss=0.735, nll_loss=0.368, ac2022-02-02 10:47:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 186 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 186 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:24,  1.76s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:47:15 | INFO | valid | epoch 186 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1021.8 | wpb 16 | bsz 8 | num_updates 7812 | best_loss 0.754\n",
      "2022-02-02 10:47:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:47:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint186.pt (epoch 186 @ 7812 updates, score 0.755) (writing took 0.031748147999905996 seconds)\n",
      "2022-02-02 10:47:15 | INFO | fairseq_cli.train | end of epoch 186 (average epoch stats below)\n",
      "2022-02-02 10:47:15 | INFO | train | epoch 186 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 427.1 | ups 6.7 | wpb 63.7 | bsz 31.9 | num_updates 7812 | lr 4.52563e-05 | gnorm 0.675 | train_wall 2 | wall 1027\n",
      "epoch 187:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:47:15 | INFO | fairseq.trainer | begin training epoch 187\n",
      "epoch 187:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 19.66it/s]2022-02-02 10:47:19 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 187 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 187 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:47:21 | INFO | valid | epoch 187 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1250 | wpb 16 | bsz 8 | num_updates 7854 | best_loss 0.754\n",
      "2022-02-02 10:47:21 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:47:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint187.pt (epoch 187 @ 7854 updates, score 0.754) (writing took 0.036539124999990236 seconds)\n",
      "2022-02-02 10:47:21 | INFO | fairseq_cli.train | end of epoch 187 (average epoch stats below)\n",
      "2022-02-02 10:47:21 | INFO | train | epoch 187 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 477.4 | ups 7.49 | wpb 63.7 | bsz 31.9 | num_updates 7854 | lr 4.51351e-05 | gnorm 0.612 | train_wall 2 | wall 1033\n",
      "epoch 188:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:47:21 | INFO | fairseq.trainer | begin training epoch 188\n",
      "epoch 188:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.49it/s]2022-02-02 10:47:25 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 188 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 188 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.63s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:47:26 | INFO | valid | epoch 188 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1240 | wpb 16 | bsz 8 | num_updates 7896 | best_loss 0.754\n",
      "2022-02-02 10:47:26 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:47:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint188.pt (epoch 188 @ 7896 updates, score 0.754) (writing took 0.035913529000026756 seconds)\n",
      "2022-02-02 10:47:26 | INFO | fairseq_cli.train | end of epoch 188 (average epoch stats below)\n",
      "2022-02-02 10:47:26 | INFO | train | epoch 188 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 471.1 | ups 7.39 | wpb 63.7 | bsz 31.9 | num_updates 7896 | lr 4.50149e-05 | gnorm 0.693 | train_wall 2 | wall 1038\n",
      "epoch 189:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:47:26 | INFO | fairseq.trainer | begin training epoch 189\n",
      "epoch 189:  95%|▉| 40/42 [00:03<00:00, 21.56it/s, loss=0.748, nll_loss=0.374, ac2022-02-02 10:47:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 189 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 189 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:47:32 | INFO | valid | epoch 189 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1193.4 | wpb 16 | bsz 8 | num_updates 7938 | best_loss 0.754\n",
      "2022-02-02 10:47:32 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:47:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint189.pt (epoch 189 @ 7938 updates, score 0.754) (writing took 0.04048164400001042 seconds)\n",
      "2022-02-02 10:47:32 | INFO | fairseq_cli.train | end of epoch 189 (average epoch stats below)\n",
      "2022-02-02 10:47:32 | INFO | train | epoch 189 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 491.7 | ups 7.72 | wpb 63.7 | bsz 31.9 | num_updates 7938 | lr 4.48957e-05 | gnorm 0.617 | train_wall 2 | wall 1044\n",
      "epoch 190:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:47:32 | INFO | fairseq.trainer | begin training epoch 190\n",
      "epoch 190:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.96it/s]2022-02-02 10:47:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 190 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 190 | valid on 'valid' subset:   7%|▍      | 1/15 [00:02<00:32,  2.29s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:47:38 | INFO | valid | epoch 190 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1038.5 | wpb 16 | bsz 8 | num_updates 7980 | best_loss 0.754\n",
      "2022-02-02 10:47:38 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:47:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint190.pt (epoch 190 @ 7980 updates, score 0.755) (writing took 0.030459367999810638 seconds)\n",
      "2022-02-02 10:47:38 | INFO | fairseq_cli.train | end of epoch 190 (average epoch stats below)\n",
      "2022-02-02 10:47:38 | INFO | train | epoch 190 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 424.7 | ups 6.67 | wpb 63.7 | bsz 31.9 | num_updates 7980 | lr 4.47774e-05 | gnorm 0.573 | train_wall 2 | wall 1050\n",
      "epoch 191:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:47:38 | INFO | fairseq.trainer | begin training epoch 191\n",
      "epoch 191:  95%|▉| 40/42 [00:03<00:00, 21.23it/s, loss=0.74, nll_loss=0.37, accu2022-02-02 10:47:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 191 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 191 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:47:44 | INFO | valid | epoch 191 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1051.6 | wpb 16 | bsz 8 | num_updates 8022 | best_loss 0.754\n",
      "2022-02-02 10:47:44 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:47:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint191.pt (epoch 191 @ 8022 updates, score 0.755) (writing took 0.02834907800001929 seconds)\n",
      "2022-02-02 10:47:44 | INFO | fairseq_cli.train | end of epoch 191 (average epoch stats below)\n",
      "2022-02-02 10:47:44 | INFO | train | epoch 191 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 480.1 | ups 7.54 | wpb 63.7 | bsz 31.9 | num_updates 8022 | lr 4.466e-05 | gnorm 0.628 | train_wall 2 | wall 1056\n",
      "epoch 192:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:47:44 | INFO | fairseq.trainer | begin training epoch 192\n",
      "epoch 192:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.11it/s]2022-02-02 10:47:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 192 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 192 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:47:49 | INFO | valid | epoch 192 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1171.4 | wpb 16 | bsz 8 | num_updates 8064 | best_loss 0.754\n",
      "2022-02-02 10:47:49 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:47:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint192.pt (epoch 192 @ 8064 updates, score 0.754) (writing took 0.03971016799982863 seconds)\n",
      "2022-02-02 10:47:49 | INFO | fairseq_cli.train | end of epoch 192 (average epoch stats below)\n",
      "2022-02-02 10:47:49 | INFO | train | epoch 192 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 490.5 | ups 7.7 | wpb 63.7 | bsz 31.9 | num_updates 8064 | lr 4.45435e-05 | gnorm 0.612 | train_wall 2 | wall 1061\n",
      "epoch 193:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:47:49 | INFO | fairseq.trainer | begin training epoch 193\n",
      "epoch 193:  95%|▉| 40/42 [00:03<00:00, 20.84it/s, loss=0.743, nll_loss=0.371, ac2022-02-02 10:47:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 193 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 193 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:47:55 | INFO | valid | epoch 193 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1226.1 | wpb 16 | bsz 8 | num_updates 8106 | best_loss 0.754\n",
      "2022-02-02 10:47:55 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:47:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint193.pt (epoch 193 @ 8106 updates, score 0.754) (writing took 0.03253418400004193 seconds)\n",
      "2022-02-02 10:47:55 | INFO | fairseq_cli.train | end of epoch 193 (average epoch stats below)\n",
      "2022-02-02 10:47:55 | INFO | train | epoch 193 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 492.8 | ups 7.73 | wpb 63.7 | bsz 31.9 | num_updates 8106 | lr 4.4428e-05 | gnorm 0.606 | train_wall 2 | wall 1067\n",
      "epoch 194:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:47:55 | INFO | fairseq.trainer | begin training epoch 194\n",
      "epoch 194:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.27it/s]2022-02-02 10:47:58 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 194 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 194 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.49s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:48:00 | INFO | valid | epoch 194 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1247.9 | wpb 16 | bsz 8 | num_updates 8148 | best_loss 0.754\n",
      "2022-02-02 10:48:00 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:48:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint194.pt (epoch 194 @ 8148 updates, score 0.755) (writing took 0.029220392999832256 seconds)\n",
      "2022-02-02 10:48:00 | INFO | fairseq_cli.train | end of epoch 194 (average epoch stats below)\n",
      "2022-02-02 10:48:00 | INFO | train | epoch 194 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 507 | ups 7.96 | wpb 63.7 | bsz 31.9 | num_updates 8148 | lr 4.43133e-05 | gnorm 0.644 | train_wall 2 | wall 1072\n",
      "epoch 195:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:48:00 | INFO | fairseq.trainer | begin training epoch 195\n",
      "epoch 195:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 19.74it/s]2022-02-02 10:48:04 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 195 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 195 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.65s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:48:05 | INFO | valid | epoch 195 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1228.6 | wpb 16 | bsz 8 | num_updates 8190 | best_loss 0.754\n",
      "2022-02-02 10:48:05 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:48:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint195.pt (epoch 195 @ 8190 updates, score 0.755) (writing took 0.017857936999917 seconds)\n",
      "2022-02-02 10:48:05 | INFO | fairseq_cli.train | end of epoch 195 (average epoch stats below)\n",
      "2022-02-02 10:48:05 | INFO | train | epoch 195 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 485.6 | ups 7.62 | wpb 63.7 | bsz 31.9 | num_updates 8190 | lr 4.41996e-05 | gnorm 0.611 | train_wall 2 | wall 1077\n",
      "epoch 196:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:48:05 | INFO | fairseq.trainer | begin training epoch 196\n",
      "epoch 196:  93%|▉| 39/42 [00:03<00:00, 21.64it/s, loss=0.741, nll_loss=0.37, acc2022-02-02 10:48:09 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 196 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 196 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:48:11 | INFO | valid | epoch 196 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1250.9 | wpb 16 | bsz 8 | num_updates 8232 | best_loss 0.754\n",
      "2022-02-02 10:48:11 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:48:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint196.pt (epoch 196 @ 8232 updates, score 0.755) (writing took 0.020414229999914824 seconds)\n",
      "2022-02-02 10:48:11 | INFO | fairseq_cli.train | end of epoch 196 (average epoch stats below)\n",
      "2022-02-02 10:48:11 | INFO | train | epoch 196 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 499.5 | ups 7.84 | wpb 63.7 | bsz 31.9 | num_updates 8232 | lr 4.40867e-05 | gnorm 0.593 | train_wall 2 | wall 1083\n",
      "epoch 197:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:48:11 | INFO | fairseq.trainer | begin training epoch 197\n",
      "epoch 197:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.52it/s]2022-02-02 10:48:14 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 197 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 197 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:48:16 | INFO | valid | epoch 197 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1273.1 | wpb 16 | bsz 8 | num_updates 8274 | best_loss 0.754\n",
      "2022-02-02 10:48:16 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:48:16 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint197.pt (epoch 197 @ 8274 updates, score 0.756) (writing took 0.022944041999835463 seconds)\n",
      "2022-02-02 10:48:16 | INFO | fairseq_cli.train | end of epoch 197 (average epoch stats below)\n",
      "2022-02-02 10:48:16 | INFO | train | epoch 197 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 505.6 | ups 7.94 | wpb 63.7 | bsz 31.9 | num_updates 8274 | lr 4.39746e-05 | gnorm 0.523 | train_wall 2 | wall 1088\n",
      "epoch 198:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:48:16 | INFO | fairseq.trainer | begin training epoch 198\n",
      "epoch 198:  95%|▉| 40/42 [00:03<00:00, 21.77it/s, loss=0.738, nll_loss=0.369, ac2022-02-02 10:48:20 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 198 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 198 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:48:21 | INFO | valid | epoch 198 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1334.2 | wpb 16 | bsz 8 | num_updates 8316 | best_loss 0.754\n",
      "2022-02-02 10:48:21 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:48:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint198.pt (epoch 198 @ 8316 updates, score 0.755) (writing took 0.018952390000094965 seconds)\n",
      "2022-02-02 10:48:21 | INFO | fairseq_cli.train | end of epoch 198 (average epoch stats below)\n",
      "2022-02-02 10:48:21 | INFO | train | epoch 198 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 505.6 | ups 7.94 | wpb 63.7 | bsz 31.9 | num_updates 8316 | lr 4.38634e-05 | gnorm 0.523 | train_wall 2 | wall 1093\n",
      "epoch 199:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:48:21 | INFO | fairseq.trainer | begin training epoch 199\n",
      "epoch 199:  98%|███████████████████████████████▏| 41/42 [00:03<00:00, 20.31it/s]2022-02-02 10:48:25 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 199 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 199 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:48:27 | INFO | valid | epoch 199 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1194.8 | wpb 16 | bsz 8 | num_updates 8358 | best_loss 0.754\n",
      "2022-02-02 10:48:27 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:48:27 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint199.pt (epoch 199 @ 8358 updates, score 0.755) (writing took 0.023862599000040063 seconds)\n",
      "2022-02-02 10:48:27 | INFO | fairseq_cli.train | end of epoch 199 (average epoch stats below)\n",
      "2022-02-02 10:48:27 | INFO | train | epoch 199 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 486.4 | ups 7.63 | wpb 63.7 | bsz 31.9 | num_updates 8358 | lr 4.37531e-05 | gnorm 0.643 | train_wall 2 | wall 1099\n",
      "epoch 200:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:48:27 | INFO | fairseq.trainer | begin training epoch 200\n",
      "epoch 200:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.33it/s]2022-02-02 10:48:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 200 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 200 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.69s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:48:32 | INFO | valid | epoch 200 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1101.5 | wpb 16 | bsz 8 | num_updates 8400 | best_loss 0.754\n",
      "2022-02-02 10:48:32 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:48:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint200.pt (epoch 200 @ 8400 updates, score 0.755) (writing took 0.028884705999871585 seconds)\n",
      "2022-02-02 10:48:33 | INFO | fairseq_cli.train | end of epoch 200 (average epoch stats below)\n",
      "2022-02-02 10:48:33 | INFO | train | epoch 200 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 472.1 | ups 7.41 | wpb 63.7 | bsz 31.9 | num_updates 8400 | lr 4.36436e-05 | gnorm 0.573 | train_wall 2 | wall 1105\n",
      "epoch 201:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:48:33 | INFO | fairseq.trainer | begin training epoch 201\n",
      "epoch 201:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.11it/s]2022-02-02 10:48:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 201 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 201 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.66s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:48:38 | INFO | valid | epoch 201 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1203.8 | wpb 16 | bsz 8 | num_updates 8442 | best_loss 0.754\n",
      "2022-02-02 10:48:38 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:48:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint201.pt (epoch 201 @ 8442 updates, score 0.755) (writing took 0.024453651999920112 seconds)\n",
      "2022-02-02 10:48:38 | INFO | fairseq_cli.train | end of epoch 201 (average epoch stats below)\n",
      "2022-02-02 10:48:38 | INFO | train | epoch 201 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 470.4 | ups 7.38 | wpb 63.7 | bsz 31.9 | num_updates 8442 | lr 4.35349e-05 | gnorm 0.601 | train_wall 2 | wall 1110\n",
      "epoch 202:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:48:38 | INFO | fairseq.trainer | begin training epoch 202\n",
      "epoch 202:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.84it/s]2022-02-02 10:48:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 202 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 202 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:48:44 | INFO | valid | epoch 202 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1225.8 | wpb 16 | bsz 8 | num_updates 8484 | best_loss 0.754\n",
      "2022-02-02 10:48:44 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:48:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint202.pt (epoch 202 @ 8484 updates, score 0.755) (writing took 0.05470821999983855 seconds)\n",
      "2022-02-02 10:48:44 | INFO | fairseq_cli.train | end of epoch 202 (average epoch stats below)\n",
      "2022-02-02 10:48:44 | INFO | train | epoch 202 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 481.3 | ups 7.55 | wpb 63.7 | bsz 31.9 | num_updates 8484 | lr 4.3427e-05 | gnorm 0.577 | train_wall 2 | wall 1116\n",
      "epoch 203:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:48:44 | INFO | fairseq.trainer | begin training epoch 203\n",
      "epoch 203:  95%|▉| 40/42 [00:03<00:00, 20.25it/s, loss=0.739, nll_loss=0.37, acc2022-02-02 10:48:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 203 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 203 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:48:49 | INFO | valid | epoch 203 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1212.1 | wpb 16 | bsz 8 | num_updates 8526 | best_loss 0.754\n",
      "2022-02-02 10:48:49 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:48:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint203.pt (epoch 203 @ 8526 updates, score 0.755) (writing took 0.021422058999860383 seconds)\n",
      "2022-02-02 10:48:49 | INFO | fairseq_cli.train | end of epoch 203 (average epoch stats below)\n",
      "2022-02-02 10:48:49 | INFO | train | epoch 203 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 485.1 | ups 7.61 | wpb 63.7 | bsz 31.9 | num_updates 8526 | lr 4.33199e-05 | gnorm 0.568 | train_wall 2 | wall 1121\n",
      "epoch 204:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:48:49 | INFO | fairseq.trainer | begin training epoch 204\n",
      "epoch 204:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.00it/s]2022-02-02 10:48:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 204 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 204 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:48:55 | INFO | valid | epoch 204 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1148.1 | wpb 16 | bsz 8 | num_updates 8568 | best_loss 0.754\n",
      "2022-02-02 10:48:55 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:48:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint204.pt (epoch 204 @ 8568 updates, score 0.754) (writing took 0.045314535999978034 seconds)\n",
      "2022-02-02 10:48:55 | INFO | fairseq_cli.train | end of epoch 204 (average epoch stats below)\n",
      "2022-02-02 10:48:55 | INFO | train | epoch 204 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 480.7 | ups 7.54 | wpb 63.7 | bsz 31.9 | num_updates 8568 | lr 4.32136e-05 | gnorm 0.63 | train_wall 2 | wall 1127\n",
      "epoch 205:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:48:55 | INFO | fairseq.trainer | begin training epoch 205\n",
      "epoch 205:  98%|▉| 41/42 [00:03<00:00, 19.61it/s, loss=0.74, nll_loss=0.37, accu2022-02-02 10:48:59 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 205 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 205 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:24,  1.72s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:49:01 | INFO | valid | epoch 205 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1206.4 | wpb 16 | bsz 8 | num_updates 8610 | best_loss 0.754\n",
      "2022-02-02 10:49:01 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:49:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint205.pt (epoch 205 @ 8610 updates, score 0.755) (writing took 0.026095230000009906 seconds)\n",
      "2022-02-02 10:49:01 | INFO | fairseq_cli.train | end of epoch 205 (average epoch stats below)\n",
      "2022-02-02 10:49:01 | INFO | train | epoch 205 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 460.6 | ups 7.23 | wpb 63.7 | bsz 31.9 | num_updates 8610 | lr 4.31081e-05 | gnorm 0.626 | train_wall 2 | wall 1133\n",
      "epoch 206:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:49:01 | INFO | fairseq.trainer | begin training epoch 206\n",
      "epoch 206:  98%|███████████████████████████████▏| 41/42 [00:04<00:00, 16.63it/s]2022-02-02 10:49:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 206 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 206 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:27,  1.94s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:49:08 | INFO | valid | epoch 206 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 877.3 | wpb 16 | bsz 8 | num_updates 8652 | best_loss 0.754\n",
      "2022-02-02 10:49:08 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:49:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint206.pt (epoch 206 @ 8652 updates, score 0.754) (writing took 0.028906800999948246 seconds)\n",
      "2022-02-02 10:49:08 | INFO | fairseq_cli.train | end of epoch 206 (average epoch stats below)\n",
      "2022-02-02 10:49:08 | INFO | train | epoch 206 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 377.2 | ups 5.92 | wpb 63.7 | bsz 31.9 | num_updates 8652 | lr 4.30033e-05 | gnorm 0.502 | train_wall 2 | wall 1140\n",
      "epoch 207:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:49:08 | INFO | fairseq.trainer | begin training epoch 207\n",
      "epoch 207:  95%|██████████████████████████████▍ | 40/42 [00:04<00:00, 18.06it/s]2022-02-02 10:49:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 207 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 207 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.66s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:49:14 | INFO | valid | epoch 207 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1010.3 | wpb 16 | bsz 8 | num_updates 8694 | best_loss 0.754\n",
      "2022-02-02 10:49:14 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:49:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint207.pt (epoch 207 @ 8694 updates, score 0.755) (writing took 0.022471027000165122 seconds)\n",
      "2022-02-02 10:49:14 | INFO | fairseq_cli.train | end of epoch 207 (average epoch stats below)\n",
      "2022-02-02 10:49:14 | INFO | train | epoch 207 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 428.2 | ups 6.72 | wpb 63.7 | bsz 31.9 | num_updates 8694 | lr 4.28993e-05 | gnorm 0.637 | train_wall 2 | wall 1146\n",
      "epoch 208:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:49:14 | INFO | fairseq.trainer | begin training epoch 208\n",
      "epoch 208:  93%|▉| 39/42 [00:03<00:00, 20.98it/s, loss=0.746, nll_loss=0.373, ac2022-02-02 10:49:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 208 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 208 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:49:19 | INFO | valid | epoch 208 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1210.4 | wpb 16 | bsz 8 | num_updates 8736 | best_loss 0.754\n",
      "2022-02-02 10:49:19 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:49:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint208.pt (epoch 208 @ 8736 updates, score 0.755) (writing took 0.018510968999862598 seconds)\n",
      "2022-02-02 10:49:19 | INFO | fairseq_cli.train | end of epoch 208 (average epoch stats below)\n",
      "2022-02-02 10:49:19 | INFO | train | epoch 208 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 488.1 | ups 7.66 | wpb 63.7 | bsz 31.9 | num_updates 8736 | lr 4.2796e-05 | gnorm 0.59 | train_wall 2 | wall 1152\n",
      "epoch 209:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:49:19 | INFO | fairseq.trainer | begin training epoch 209\n",
      "epoch 209:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.04it/s]2022-02-02 10:49:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 209 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 209 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:49:25 | INFO | valid | epoch 209 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1215.8 | wpb 16 | bsz 8 | num_updates 8778 | best_loss 0.754\n",
      "2022-02-02 10:49:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:49:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint209.pt (epoch 209 @ 8778 updates, score 0.755) (writing took 0.02378010899997207 seconds)\n",
      "2022-02-02 10:49:25 | INFO | fairseq_cli.train | end of epoch 209 (average epoch stats below)\n",
      "2022-02-02 10:49:25 | INFO | train | epoch 209 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 485.1 | ups 7.61 | wpb 63.7 | bsz 31.9 | num_updates 8778 | lr 4.26935e-05 | gnorm 0.622 | train_wall 2 | wall 1157\n",
      "epoch 210:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:49:25 | INFO | fairseq.trainer | begin training epoch 210\n",
      "epoch 210:  93%|▉| 39/42 [00:03<00:00, 21.11it/s, loss=0.743, nll_loss=0.371, ac2022-02-02 10:49:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 210 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 210 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:49:30 | INFO | valid | epoch 210 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1223.6 | wpb 16 | bsz 8 | num_updates 8820 | best_loss 0.754\n",
      "2022-02-02 10:49:30 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:49:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint210.pt (epoch 210 @ 8820 updates, score 0.755) (writing took 0.028242517000080625 seconds)\n",
      "2022-02-02 10:49:30 | INFO | fairseq_cli.train | end of epoch 210 (average epoch stats below)\n",
      "2022-02-02 10:49:30 | INFO | train | epoch 210 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 490.1 | ups 7.69 | wpb 63.7 | bsz 31.9 | num_updates 8820 | lr 4.25918e-05 | gnorm 0.686 | train_wall 2 | wall 1162\n",
      "epoch 211:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:49:30 | INFO | fairseq.trainer | begin training epoch 211\n",
      "epoch 211:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.54it/s]2022-02-02 10:49:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 211 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 211 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:49:36 | INFO | valid | epoch 211 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1227.5 | wpb 16 | bsz 8 | num_updates 8862 | best_loss 0.754\n",
      "2022-02-02 10:49:36 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:49:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint211.pt (epoch 211 @ 8862 updates, score 0.755) (writing took 0.035355798999944454 seconds)\n",
      "2022-02-02 10:49:36 | INFO | fairseq_cli.train | end of epoch 211 (average epoch stats below)\n",
      "2022-02-02 10:49:36 | INFO | train | epoch 211 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 495.6 | ups 7.78 | wpb 63.7 | bsz 31.9 | num_updates 8862 | lr 4.24907e-05 | gnorm 0.648 | train_wall 2 | wall 1168\n",
      "epoch 212:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:49:36 | INFO | fairseq.trainer | begin training epoch 212\n",
      "epoch 212:  95%|▉| 40/42 [00:03<00:00, 21.03it/s, loss=0.747, nll_loss=0.373, ac2022-02-02 10:49:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 212 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 212 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:26,  1.89s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:49:42 | INFO | valid | epoch 212 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1026.8 | wpb 16 | bsz 8 | num_updates 8904 | best_loss 0.754\n",
      "2022-02-02 10:49:42 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:49:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint212.pt (epoch 212 @ 8904 updates, score 0.755) (writing took 0.03156649699985792 seconds)\n",
      "2022-02-02 10:49:42 | INFO | fairseq_cli.train | end of epoch 212 (average epoch stats below)\n",
      "2022-02-02 10:49:42 | INFO | train | epoch 212 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 442.9 | ups 6.95 | wpb 63.7 | bsz 31.9 | num_updates 8904 | lr 4.23904e-05 | gnorm 0.61 | train_wall 2 | wall 1174\n",
      "epoch 213:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:49:42 | INFO | fairseq.trainer | begin training epoch 213\n",
      "epoch 213:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.49it/s]2022-02-02 10:49:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 213 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 213 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:25,  1.81s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:49:48 | INFO | valid | epoch 213 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1265.6 | wpb 16 | bsz 8 | num_updates 8946 | best_loss 0.754\n",
      "2022-02-02 10:49:48 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:49:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint213.pt (epoch 213 @ 8946 updates, score 0.755) (writing took 0.023079849999930957 seconds)\n",
      "2022-02-02 10:49:48 | INFO | fairseq_cli.train | end of epoch 213 (average epoch stats below)\n",
      "2022-02-02 10:49:48 | INFO | train | epoch 213 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 463.3 | ups 7.27 | wpb 63.7 | bsz 31.9 | num_updates 8946 | lr 4.22908e-05 | gnorm 0.709 | train_wall 2 | wall 1180\n",
      "epoch 214:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:49:48 | INFO | fairseq.trainer | begin training epoch 214\n",
      "epoch 214:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.93it/s]2022-02-02 10:49:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 214 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 214 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:49:53 | INFO | valid | epoch 214 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1227.5 | wpb 16 | bsz 8 | num_updates 8988 | best_loss 0.754\n",
      "2022-02-02 10:49:53 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:49:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint214.pt (epoch 214 @ 8988 updates, score 0.755) (writing took 0.019037617999856593 seconds)\n",
      "2022-02-02 10:49:53 | INFO | fairseq_cli.train | end of epoch 214 (average epoch stats below)\n",
      "2022-02-02 10:49:53 | INFO | train | epoch 214 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 497.1 | ups 7.8 | wpb 63.7 | bsz 31.9 | num_updates 8988 | lr 4.21918e-05 | gnorm 0.705 | train_wall 2 | wall 1185\n",
      "epoch 215:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:49:53 | INFO | fairseq.trainer | begin training epoch 215\n",
      "epoch 215:  95%|▉| 40/42 [00:03<00:00, 21.85it/s, loss=0.741, nll_loss=0.37, acc2022-02-02 10:49:57 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 215 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 215 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:49:58 | INFO | valid | epoch 215 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1214.2 | wpb 16 | bsz 8 | num_updates 9030 | best_loss 0.754\n",
      "2022-02-02 10:49:58 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:49:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint215.pt (epoch 215 @ 9030 updates, score 0.755) (writing took 0.025565385000163587 seconds)\n",
      "2022-02-02 10:49:58 | INFO | fairseq_cli.train | end of epoch 215 (average epoch stats below)\n",
      "2022-02-02 10:49:58 | INFO | train | epoch 215 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 501.7 | ups 7.87 | wpb 63.7 | bsz 31.9 | num_updates 9030 | lr 4.20936e-05 | gnorm 0.577 | train_wall 2 | wall 1190\n",
      "epoch 216:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:49:58 | INFO | fairseq.trainer | begin training epoch 216\n",
      "epoch 216:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.56it/s]2022-02-02 10:50:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 216 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 216 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:50:04 | INFO | valid | epoch 216 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1249.7 | wpb 16 | bsz 8 | num_updates 9072 | best_loss 0.754\n",
      "2022-02-02 10:50:04 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:50:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint216.pt (epoch 216 @ 9072 updates, score 0.755) (writing took 0.022526492999986658 seconds)\n",
      "2022-02-02 10:50:04 | INFO | fairseq_cli.train | end of epoch 216 (average epoch stats below)\n",
      "2022-02-02 10:50:04 | INFO | train | epoch 216 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 496.6 | ups 7.79 | wpb 63.7 | bsz 31.9 | num_updates 9072 | lr 4.19961e-05 | gnorm 0.626 | train_wall 2 | wall 1196\n",
      "epoch 217:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:50:04 | INFO | fairseq.trainer | begin training epoch 217\n",
      "epoch 217:  93%|▉| 39/42 [00:03<00:00, 21.36it/s, loss=0.746, nll_loss=0.373, ac2022-02-02 10:50:08 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 217 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 217 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:50:09 | INFO | valid | epoch 217 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1211.5 | wpb 16 | bsz 8 | num_updates 9114 | best_loss 0.754\n",
      "2022-02-02 10:50:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:50:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint217.pt (epoch 217 @ 9114 updates, score 0.755) (writing took 0.023685003999844412 seconds)\n",
      "2022-02-02 10:50:09 | INFO | fairseq_cli.train | end of epoch 217 (average epoch stats below)\n",
      "2022-02-02 10:50:09 | INFO | train | epoch 217 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 486.2 | ups 7.63 | wpb 63.7 | bsz 31.9 | num_updates 9114 | lr 4.18992e-05 | gnorm 0.548 | train_wall 2 | wall 1201\n",
      "epoch 218:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:50:09 | INFO | fairseq.trainer | begin training epoch 218\n",
      "epoch 218:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.59it/s]2022-02-02 10:50:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 218 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 218 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:50:15 | INFO | valid | epoch 218 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1228.1 | wpb 16 | bsz 8 | num_updates 9156 | best_loss 0.754\n",
      "2022-02-02 10:50:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:50:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint218.pt (epoch 218 @ 9156 updates, score 0.754) (writing took 0.045041053000204556 seconds)\n",
      "2022-02-02 10:50:15 | INFO | fairseq_cli.train | end of epoch 218 (average epoch stats below)\n",
      "2022-02-02 10:50:15 | INFO | train | epoch 218 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 491.1 | ups 7.71 | wpb 63.7 | bsz 31.9 | num_updates 9156 | lr 4.1803e-05 | gnorm 0.558 | train_wall 2 | wall 1207\n",
      "epoch 219:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:50:15 | INFO | fairseq.trainer | begin training epoch 219\n",
      "epoch 219:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.54it/s]2022-02-02 10:50:19 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 219 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 219 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:50:20 | INFO | valid | epoch 219 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1230.1 | wpb 16 | bsz 8 | num_updates 9198 | best_loss 0.754\n",
      "2022-02-02 10:50:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:50:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint219.pt (epoch 219 @ 9198 updates, score 0.755) (writing took 0.027095743000018047 seconds)\n",
      "2022-02-02 10:50:20 | INFO | fairseq_cli.train | end of epoch 219 (average epoch stats below)\n",
      "2022-02-02 10:50:20 | INFO | train | epoch 219 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 476.2 | ups 7.47 | wpb 63.7 | bsz 31.9 | num_updates 9198 | lr 4.17074e-05 | gnorm 0.641 | train_wall 2 | wall 1212\n",
      "epoch 220:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:50:20 | INFO | fairseq.trainer | begin training epoch 220\n",
      "epoch 220:  95%|▉| 40/42 [00:03<00:00, 21.40it/s, loss=0.74, nll_loss=0.37, accu2022-02-02 10:50:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 220 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 220 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:50:26 | INFO | valid | epoch 220 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1200.8 | wpb 16 | bsz 8 | num_updates 9240 | best_loss 0.754\n",
      "2022-02-02 10:50:26 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:50:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint220.pt (epoch 220 @ 9240 updates, score 0.755) (writing took 0.03471986699992158 seconds)\n",
      "2022-02-02 10:50:26 | INFO | fairseq_cli.train | end of epoch 220 (average epoch stats below)\n",
      "2022-02-02 10:50:26 | INFO | train | epoch 220 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 495.1 | ups 7.77 | wpb 63.7 | bsz 31.9 | num_updates 9240 | lr 4.16125e-05 | gnorm 0.605 | train_wall 2 | wall 1218\n",
      "epoch 221:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:50:26 | INFO | fairseq.trainer | begin training epoch 221\n",
      "epoch 221:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.99it/s]2022-02-02 10:50:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 221 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 221 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:50:31 | INFO | valid | epoch 221 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1206 | wpb 16 | bsz 8 | num_updates 9282 | best_loss 0.754\n",
      "2022-02-02 10:50:31 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:50:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint221.pt (epoch 221 @ 9282 updates, score 0.754) (writing took 0.03631564099987372 seconds)\n",
      "2022-02-02 10:50:31 | INFO | fairseq_cli.train | end of epoch 221 (average epoch stats below)\n",
      "2022-02-02 10:50:31 | INFO | train | epoch 221 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 491.9 | ups 7.72 | wpb 63.7 | bsz 31.9 | num_updates 9282 | lr 4.15183e-05 | gnorm 0.561 | train_wall 2 | wall 1223\n",
      "epoch 222:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:50:31 | INFO | fairseq.trainer | begin training epoch 222\n",
      "epoch 222:  95%|▉| 40/42 [00:03<00:00, 21.53it/s, loss=0.741, nll_loss=0.37, acc2022-02-02 10:50:35 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 222 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 222 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:50:37 | INFO | valid | epoch 222 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1230 | wpb 16 | bsz 8 | num_updates 9324 | best_loss 0.754\n",
      "2022-02-02 10:50:37 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:50:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint222.pt (epoch 222 @ 9324 updates, score 0.755) (writing took 0.0274593179999556 seconds)\n",
      "2022-02-02 10:50:37 | INFO | fairseq_cli.train | end of epoch 222 (average epoch stats below)\n",
      "2022-02-02 10:50:37 | INFO | train | epoch 222 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 489.1 | ups 7.68 | wpb 63.7 | bsz 31.9 | num_updates 9324 | lr 4.14247e-05 | gnorm 0.691 | train_wall 2 | wall 1229\n",
      "epoch 223:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:50:37 | INFO | fairseq.trainer | begin training epoch 223\n",
      "epoch 223:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.92it/s]2022-02-02 10:50:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 223 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 223 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:50:42 | INFO | valid | epoch 223 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1248.1 | wpb 16 | bsz 8 | num_updates 9366 | best_loss 0.754\n",
      "2022-02-02 10:50:42 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:50:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint223.pt (epoch 223 @ 9366 updates, score 0.754) (writing took 0.038879151000173806 seconds)\n",
      "2022-02-02 10:50:42 | INFO | fairseq_cli.train | end of epoch 223 (average epoch stats below)\n",
      "2022-02-02 10:50:42 | INFO | train | epoch 223 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 494 | ups 7.75 | wpb 63.7 | bsz 31.9 | num_updates 9366 | lr 4.13317e-05 | gnorm 0.614 | train_wall 2 | wall 1234\n",
      "epoch 224:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:50:42 | INFO | fairseq.trainer | begin training epoch 224\n",
      "epoch 224:  93%|▉| 39/42 [00:04<00:00, 20.88it/s, loss=0.74, nll_loss=0.37, accu2022-02-02 10:50:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 224 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 224 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:50:48 | INFO | valid | epoch 224 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1222.8 | wpb 16 | bsz 8 | num_updates 9408 | best_loss 0.754\n",
      "2022-02-02 10:50:48 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:50:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint224.pt (epoch 224 @ 9408 updates, score 0.755) (writing took 0.02282026800003223 seconds)\n",
      "2022-02-02 10:50:48 | INFO | fairseq_cli.train | end of epoch 224 (average epoch stats below)\n",
      "2022-02-02 10:50:48 | INFO | train | epoch 224 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 444.6 | ups 6.98 | wpb 63.7 | bsz 31.9 | num_updates 9408 | lr 4.12393e-05 | gnorm 0.545 | train_wall 2 | wall 1240\n",
      "epoch 225:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:50:48 | INFO | fairseq.trainer | begin training epoch 225\n",
      "epoch 225:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.15it/s]2022-02-02 10:50:52 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 225 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 225 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:50:54 | INFO | valid | epoch 225 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1224.9 | wpb 16 | bsz 8 | num_updates 9450 | best_loss 0.754\n",
      "2022-02-02 10:50:54 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:50:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint225.pt (epoch 225 @ 9450 updates, score 0.755) (writing took 0.02447414900007061 seconds)\n",
      "2022-02-02 10:50:54 | INFO | fairseq_cli.train | end of epoch 225 (average epoch stats below)\n",
      "2022-02-02 10:50:54 | INFO | train | epoch 225 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 494.8 | ups 7.77 | wpb 63.7 | bsz 31.9 | num_updates 9450 | lr 4.11476e-05 | gnorm 0.558 | train_wall 2 | wall 1246\n",
      "epoch 226:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:50:54 | INFO | fairseq.trainer | begin training epoch 226\n",
      "epoch 226:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.16it/s]2022-02-02 10:50:57 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 226 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 226 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:50:59 | INFO | valid | epoch 226 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1194 | wpb 16 | bsz 8 | num_updates 9492 | best_loss 0.754\n",
      "2022-02-02 10:50:59 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:50:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint226.pt (epoch 226 @ 9492 updates, score 0.755) (writing took 0.021458259999917573 seconds)\n",
      "2022-02-02 10:50:59 | INFO | fairseq_cli.train | end of epoch 226 (average epoch stats below)\n",
      "2022-02-02 10:50:59 | INFO | train | epoch 226 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 491.8 | ups 7.72 | wpb 63.7 | bsz 31.9 | num_updates 9492 | lr 4.10564e-05 | gnorm 0.634 | train_wall 2 | wall 1251\n",
      "epoch 227:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:50:59 | INFO | fairseq.trainer | begin training epoch 227\n",
      "epoch 227:  93%|▉| 39/42 [00:03<00:00, 21.48it/s, loss=0.751, nll_loss=0.375, ac2022-02-02 10:51:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 227 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 227 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.66s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:51:05 | INFO | valid | epoch 227 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1218.1 | wpb 16 | bsz 8 | num_updates 9534 | best_loss 0.754\n",
      "2022-02-02 10:51:05 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:51:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint227.pt (epoch 227 @ 9534 updates, score 0.755) (writing took 0.02415088500015372 seconds)\n",
      "2022-02-02 10:51:05 | INFO | fairseq_cli.train | end of epoch 227 (average epoch stats below)\n",
      "2022-02-02 10:51:05 | INFO | train | epoch 227 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 449.7 | ups 7.06 | wpb 63.7 | bsz 31.9 | num_updates 9534 | lr 4.09659e-05 | gnorm 0.548 | train_wall 2 | wall 1257\n",
      "epoch 228:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:51:05 | INFO | fairseq.trainer | begin training epoch 228\n",
      "epoch 228:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.53it/s]2022-02-02 10:51:09 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 228 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 228 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:51:10 | INFO | valid | epoch 228 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1281.6 | wpb 16 | bsz 8 | num_updates 9576 | best_loss 0.754\n",
      "2022-02-02 10:51:10 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:51:10 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint228.pt (epoch 228 @ 9576 updates, score 0.754) (writing took 0.034658764999903724 seconds)\n",
      "2022-02-02 10:51:10 | INFO | fairseq_cli.train | end of epoch 228 (average epoch stats below)\n",
      "2022-02-02 10:51:10 | INFO | train | epoch 228 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 480.9 | ups 7.55 | wpb 63.7 | bsz 31.9 | num_updates 9576 | lr 4.0876e-05 | gnorm 0.586 | train_wall 2 | wall 1263\n",
      "epoch 229:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:51:10 | INFO | fairseq.trainer | begin training epoch 229\n",
      "epoch 229:  95%|▉| 40/42 [00:03<00:00, 21.68it/s, loss=0.734, nll_loss=0.367, ac2022-02-02 10:51:14 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 229 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 229 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:51:16 | INFO | valid | epoch 229 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1220.9 | wpb 16 | bsz 8 | num_updates 9618 | best_loss 0.754\n",
      "2022-02-02 10:51:16 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:51:16 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint229.pt (epoch 229 @ 9618 updates, score 0.755) (writing took 0.027295496999840907 seconds)\n",
      "2022-02-02 10:51:16 | INFO | fairseq_cli.train | end of epoch 229 (average epoch stats below)\n",
      "2022-02-02 10:51:16 | INFO | train | epoch 229 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 494.7 | ups 7.76 | wpb 63.7 | bsz 31.9 | num_updates 9618 | lr 4.07866e-05 | gnorm 0.573 | train_wall 2 | wall 1268\n",
      "epoch 230:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:51:16 | INFO | fairseq.trainer | begin training epoch 230\n",
      "epoch 230:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.75it/s]2022-02-02 10:51:20 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 230 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 230 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:51:21 | INFO | valid | epoch 230 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1172.8 | wpb 16 | bsz 8 | num_updates 9660 | best_loss 0.754\n",
      "2022-02-02 10:51:21 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:51:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint230.pt (epoch 230 @ 9660 updates, score 0.755) (writing took 0.026309635999950842 seconds)\n",
      "2022-02-02 10:51:21 | INFO | fairseq_cli.train | end of epoch 230 (average epoch stats below)\n",
      "2022-02-02 10:51:21 | INFO | train | epoch 230 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 493.6 | ups 7.75 | wpb 63.7 | bsz 31.9 | num_updates 9660 | lr 4.06978e-05 | gnorm 0.512 | train_wall 2 | wall 1273\n",
      "epoch 231:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:51:21 | INFO | fairseq.trainer | begin training epoch 231\n",
      "epoch 231:  95%|▉| 40/42 [00:03<00:00, 21.63it/s, loss=0.74, nll_loss=0.37, accu2022-02-02 10:51:25 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 231 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 231 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:51:27 | INFO | valid | epoch 231 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1219.7 | wpb 16 | bsz 8 | num_updates 9702 | best_loss 0.754\n",
      "2022-02-02 10:51:27 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:51:27 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint231.pt (epoch 231 @ 9702 updates, score 0.755) (writing took 0.02139610599988373 seconds)\n",
      "2022-02-02 10:51:27 | INFO | fairseq_cli.train | end of epoch 231 (average epoch stats below)\n",
      "2022-02-02 10:51:27 | INFO | train | epoch 231 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 496.7 | ups 7.8 | wpb 63.7 | bsz 31.9 | num_updates 9702 | lr 4.06097e-05 | gnorm 0.657 | train_wall 2 | wall 1279\n",
      "epoch 232:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:51:27 | INFO | fairseq.trainer | begin training epoch 232\n",
      "epoch 232:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.85it/s]2022-02-02 10:51:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 232 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 232 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:51:32 | INFO | valid | epoch 232 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1241.5 | wpb 16 | bsz 8 | num_updates 9744 | best_loss 0.754\n",
      "2022-02-02 10:51:32 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:51:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint232.pt (epoch 232 @ 9744 updates, score 0.754) (writing took 0.025727484000071854 seconds)\n",
      "2022-02-02 10:51:32 | INFO | fairseq_cli.train | end of epoch 232 (average epoch stats below)\n",
      "2022-02-02 10:51:32 | INFO | train | epoch 232 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 498.3 | ups 7.82 | wpb 63.7 | bsz 31.9 | num_updates 9744 | lr 4.0522e-05 | gnorm 0.717 | train_wall 2 | wall 1284\n",
      "epoch 233:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:51:32 | INFO | fairseq.trainer | begin training epoch 233\n",
      "epoch 233:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.31it/s]2022-02-02 10:51:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 233 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 233 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:51:37 | INFO | valid | epoch 233 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1268.8 | wpb 16 | bsz 8 | num_updates 9786 | best_loss 0.754\n",
      "2022-02-02 10:51:37 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:51:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint233.pt (epoch 233 @ 9786 updates, score 0.755) (writing took 0.019010564999916824 seconds)\n",
      "2022-02-02 10:51:37 | INFO | fairseq_cli.train | end of epoch 233 (average epoch stats below)\n",
      "2022-02-02 10:51:37 | INFO | train | epoch 233 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 499.6 | ups 7.84 | wpb 63.7 | bsz 31.9 | num_updates 9786 | lr 4.0435e-05 | gnorm 0.564 | train_wall 2 | wall 1289\n",
      "epoch 234:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:51:37 | INFO | fairseq.trainer | begin training epoch 234\n",
      "epoch 234:  93%|▉| 39/42 [00:03<00:00, 21.76it/s, loss=0.748, nll_loss=0.374, ac2022-02-02 10:51:41 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 234 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 234 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:51:43 | INFO | valid | epoch 234 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1212.3 | wpb 16 | bsz 8 | num_updates 9828 | best_loss 0.754\n",
      "2022-02-02 10:51:43 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:51:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint234.pt (epoch 234 @ 9828 updates, score 0.755) (writing took 0.026188907999994626 seconds)\n",
      "2022-02-02 10:51:43 | INFO | fairseq_cli.train | end of epoch 234 (average epoch stats below)\n",
      "2022-02-02 10:51:43 | INFO | train | epoch 234 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 498.7 | ups 7.83 | wpb 63.7 | bsz 31.9 | num_updates 9828 | lr 4.03485e-05 | gnorm 0.665 | train_wall 2 | wall 1295\n",
      "epoch 235:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:51:43 | INFO | fairseq.trainer | begin training epoch 235\n",
      "epoch 235:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.21it/s]2022-02-02 10:51:46 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 235 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 235 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:51:48 | INFO | valid | epoch 235 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1212.9 | wpb 16 | bsz 8 | num_updates 9870 | best_loss 0.754\n",
      "2022-02-02 10:51:48 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:51:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint235.pt (epoch 235 @ 9870 updates, score 0.755) (writing took 0.02359668399981274 seconds)\n",
      "2022-02-02 10:51:48 | INFO | fairseq_cli.train | end of epoch 235 (average epoch stats below)\n",
      "2022-02-02 10:51:48 | INFO | train | epoch 235 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 495.1 | ups 7.77 | wpb 63.7 | bsz 31.9 | num_updates 9870 | lr 4.02626e-05 | gnorm 0.657 | train_wall 2 | wall 1300\n",
      "epoch 236:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:51:48 | INFO | fairseq.trainer | begin training epoch 236\n",
      "epoch 236:  95%|▉| 40/42 [00:03<00:00, 20.98it/s, loss=0.733, nll_loss=0.367, ac2022-02-02 10:51:52 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 236 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 236 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:51:54 | INFO | valid | epoch 236 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1248.1 | wpb 16 | bsz 8 | num_updates 9912 | best_loss 0.754\n",
      "2022-02-02 10:51:54 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:51:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint236.pt (epoch 236 @ 9912 updates, score 0.755) (writing took 0.026987124000015683 seconds)\n",
      "2022-02-02 10:51:54 | INFO | fairseq_cli.train | end of epoch 236 (average epoch stats below)\n",
      "2022-02-02 10:51:54 | INFO | train | epoch 236 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 493.2 | ups 7.74 | wpb 63.7 | bsz 31.9 | num_updates 9912 | lr 4.01772e-05 | gnorm 0.58 | train_wall 2 | wall 1306\n",
      "epoch 237:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:51:54 | INFO | fairseq.trainer | begin training epoch 237\n",
      "epoch 237:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.42it/s]2022-02-02 10:51:57 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 237 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 237 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:51:59 | INFO | valid | epoch 237 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1214.6 | wpb 16 | bsz 8 | num_updates 9954 | best_loss 0.754\n",
      "2022-02-02 10:51:59 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:51:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint237.pt (epoch 237 @ 9954 updates, score 0.754) (writing took 0.035763141999950676 seconds)\n",
      "2022-02-02 10:51:59 | INFO | fairseq_cli.train | end of epoch 237 (average epoch stats below)\n",
      "2022-02-02 10:51:59 | INFO | train | epoch 237 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 489.4 | ups 7.68 | wpb 63.7 | bsz 31.9 | num_updates 9954 | lr 4.00923e-05 | gnorm 0.597 | train_wall 2 | wall 1311\n",
      "epoch 238:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:51:59 | INFO | fairseq.trainer | begin training epoch 238\n",
      "epoch 238:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.55it/s]2022-02-02 10:52:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 238 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 238 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:52:05 | INFO | valid | epoch 238 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1228.4 | wpb 16 | bsz 8 | num_updates 9996 | best_loss 0.754\n",
      "2022-02-02 10:52:05 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:52:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint238.pt (epoch 238 @ 9996 updates, score 0.755) (writing took 0.026955006999969555 seconds)\n",
      "2022-02-02 10:52:05 | INFO | fairseq_cli.train | end of epoch 238 (average epoch stats below)\n",
      "2022-02-02 10:52:05 | INFO | train | epoch 238 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 488.2 | ups 7.66 | wpb 63.7 | bsz 31.9 | num_updates 9996 | lr 4.0008e-05 | gnorm 0.547 | train_wall 2 | wall 1317\n",
      "epoch 239:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:52:05 | INFO | fairseq.trainer | begin training epoch 239\n",
      "epoch 239:   2%|▊                                | 1/42 [00:02<01:22,  2.02s/it]2022-02-02 10:52:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 239 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 239 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.68s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:52:09 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1181.1 | wpb 16 | bsz 8 | num_updates 10000 | best_loss 0.754\n",
      "2022-02-02 10:52:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:52:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint_239_10000.pt (epoch 239 @ 10000 updates, score 0.755) (writing took 0.026486846000125297 seconds)\n",
      "epoch 239:  95%|▉| 40/42 [00:05<00:00, 20.48it/s, loss=0.748, nll_loss=0.374, ac2022-02-02 10:52:10 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 239 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 239 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:52:12 | INFO | valid | epoch 239 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1226.9 | wpb 16 | bsz 8 | num_updates 10038 | best_loss 0.754\n",
      "2022-02-02 10:52:12 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:52:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint239.pt (epoch 239 @ 10038 updates, score 0.754) (writing took 0.031910119000031045 seconds)\n",
      "2022-02-02 10:52:12 | INFO | fairseq_cli.train | end of epoch 239 (average epoch stats below)\n",
      "2022-02-02 10:52:12 | INFO | train | epoch 239 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 349.6 | ups 5.49 | wpb 63.7 | bsz 31.9 | num_updates 10038 | lr 3.99242e-05 | gnorm 0.597 | train_wall 2 | wall 1324\n",
      "epoch 240:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:52:12 | INFO | fairseq.trainer | begin training epoch 240\n",
      "epoch 240:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.22it/s]2022-02-02 10:52:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 240 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 240 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:52:18 | INFO | valid | epoch 240 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1143.5 | wpb 16 | bsz 8 | num_updates 10080 | best_loss 0.754\n",
      "2022-02-02 10:52:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:52:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint240.pt (epoch 240 @ 10080 updates, score 0.755) (writing took 0.03835251700002118 seconds)\n",
      "2022-02-02 10:52:18 | INFO | fairseq_cli.train | end of epoch 240 (average epoch stats below)\n",
      "2022-02-02 10:52:18 | INFO | train | epoch 240 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 502.3 | ups 7.88 | wpb 63.7 | bsz 31.9 | num_updates 10080 | lr 3.9841e-05 | gnorm 0.584 | train_wall 2 | wall 1330\n",
      "epoch 241:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:52:18 | INFO | fairseq.trainer | begin training epoch 241\n",
      "epoch 241:  95%|▉| 40/42 [00:03<00:00, 21.49it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 10:52:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 241 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 241 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:27,  1.94s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:52:23 | INFO | valid | epoch 241 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1040.4 | wpb 16 | bsz 8 | num_updates 10122 | best_loss 0.754\n",
      "2022-02-02 10:52:23 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:52:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint241.pt (epoch 241 @ 10122 updates, score 0.754) (writing took 0.04036121700005424 seconds)\n",
      "2022-02-02 10:52:23 | INFO | fairseq_cli.train | end of epoch 241 (average epoch stats below)\n",
      "2022-02-02 10:52:23 | INFO | train | epoch 241 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 451.3 | ups 7.08 | wpb 63.7 | bsz 31.9 | num_updates 10122 | lr 3.97582e-05 | gnorm 0.574 | train_wall 2 | wall 1336\n",
      "epoch 242:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:52:24 | INFO | fairseq.trainer | begin training epoch 242\n",
      "epoch 242:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.05it/s]2022-02-02 10:52:27 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 242 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 242 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:52:29 | INFO | valid | epoch 242 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1198.5 | wpb 16 | bsz 8 | num_updates 10164 | best_loss 0.754\n",
      "2022-02-02 10:52:29 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:52:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint242.pt (epoch 242 @ 10164 updates, score 0.755) (writing took 0.02518885900008172 seconds)\n",
      "2022-02-02 10:52:29 | INFO | fairseq_cli.train | end of epoch 242 (average epoch stats below)\n",
      "2022-02-02 10:52:29 | INFO | train | epoch 242 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 482.9 | ups 7.58 | wpb 63.7 | bsz 31.9 | num_updates 10164 | lr 3.9676e-05 | gnorm 0.688 | train_wall 2 | wall 1341\n",
      "epoch 243:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:52:29 | INFO | fairseq.trainer | begin training epoch 243\n",
      "epoch 243:  95%|▉| 40/42 [00:03<00:00, 21.01it/s, loss=0.751, nll_loss=0.376, ac2022-02-02 10:52:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 243 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 243 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:52:35 | INFO | valid | epoch 243 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1195.5 | wpb 16 | bsz 8 | num_updates 10206 | best_loss 0.754\n",
      "2022-02-02 10:52:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:52:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint243.pt (epoch 243 @ 10206 updates, score 0.754) (writing took 0.025908744999924238 seconds)\n",
      "2022-02-02 10:52:35 | INFO | fairseq_cli.train | end of epoch 243 (average epoch stats below)\n",
      "2022-02-02 10:52:35 | INFO | train | epoch 243 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 467.8 | ups 7.34 | wpb 63.7 | bsz 31.9 | num_updates 10206 | lr 3.95943e-05 | gnorm 0.595 | train_wall 2 | wall 1347\n",
      "epoch 244:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:52:35 | INFO | fairseq.trainer | begin training epoch 244\n",
      "epoch 244:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.58it/s]2022-02-02 10:52:38 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 244 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 244 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:52:40 | INFO | valid | epoch 244 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1235.3 | wpb 16 | bsz 8 | num_updates 10248 | best_loss 0.754\n",
      "2022-02-02 10:52:40 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:52:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint244.pt (epoch 244 @ 10248 updates, score 0.755) (writing took 0.019167461000051844 seconds)\n",
      "2022-02-02 10:52:40 | INFO | fairseq_cli.train | end of epoch 244 (average epoch stats below)\n",
      "2022-02-02 10:52:40 | INFO | train | epoch 244 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 490.6 | ups 7.7 | wpb 63.7 | bsz 31.9 | num_updates 10248 | lr 3.9513e-05 | gnorm 0.545 | train_wall 2 | wall 1352\n",
      "epoch 245:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:52:40 | INFO | fairseq.trainer | begin training epoch 245\n",
      "epoch 245:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.30it/s]2022-02-02 10:52:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 245 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 245 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:52:46 | INFO | valid | epoch 245 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1214.8 | wpb 16 | bsz 8 | num_updates 10290 | best_loss 0.754\n",
      "2022-02-02 10:52:46 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:52:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint245.pt (epoch 245 @ 10290 updates, score 0.755) (writing took 0.01841295999997783 seconds)\n",
      "2022-02-02 10:52:46 | INFO | fairseq_cli.train | end of epoch 245 (average epoch stats below)\n",
      "2022-02-02 10:52:46 | INFO | train | epoch 245 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 474.7 | ups 7.45 | wpb 63.7 | bsz 31.9 | num_updates 10290 | lr 3.94323e-05 | gnorm 0.64 | train_wall 2 | wall 1358\n",
      "epoch 246:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:52:46 | INFO | fairseq.trainer | begin training epoch 246\n",
      "epoch 246:  95%|▉| 40/42 [00:03<00:00, 21.32it/s, loss=0.739, nll_loss=0.37, acc2022-02-02 10:52:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 246 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 246 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:52:51 | INFO | valid | epoch 246 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1259.9 | wpb 16 | bsz 8 | num_updates 10332 | best_loss 0.754\n",
      "2022-02-02 10:52:51 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:52:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint246.pt (epoch 246 @ 10332 updates, score 0.755) (writing took 0.02759659899993494 seconds)\n",
      "2022-02-02 10:52:51 | INFO | fairseq_cli.train | end of epoch 246 (average epoch stats below)\n",
      "2022-02-02 10:52:51 | INFO | train | epoch 246 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 490.5 | ups 7.7 | wpb 63.7 | bsz 31.9 | num_updates 10332 | lr 3.93521e-05 | gnorm 0.624 | train_wall 2 | wall 1363\n",
      "epoch 247:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:52:51 | INFO | fairseq.trainer | begin training epoch 247\n",
      "epoch 247:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.43it/s]2022-02-02 10:52:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 247 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 247 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:52:57 | INFO | valid | epoch 247 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1271.5 | wpb 16 | bsz 8 | num_updates 10374 | best_loss 0.754\n",
      "2022-02-02 10:52:57 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:52:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint247.pt (epoch 247 @ 10374 updates, score 0.755) (writing took 0.02135458800012202 seconds)\n",
      "2022-02-02 10:52:57 | INFO | fairseq_cli.train | end of epoch 247 (average epoch stats below)\n",
      "2022-02-02 10:52:57 | INFO | train | epoch 247 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 485.4 | ups 7.62 | wpb 63.7 | bsz 31.9 | num_updates 10374 | lr 3.92723e-05 | gnorm 0.661 | train_wall 2 | wall 1369\n",
      "epoch 248:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:52:57 | INFO | fairseq.trainer | begin training epoch 248\n",
      "epoch 248:  93%|▉| 39/42 [00:03<00:00, 19.41it/s, loss=0.741, nll_loss=0.371, ac2022-02-02 10:53:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 248 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 248 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:27,  1.94s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:53:03 | INFO | valid | epoch 248 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1013.2 | wpb 16 | bsz 8 | num_updates 10416 | best_loss 0.754\n",
      "2022-02-02 10:53:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:53:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint248.pt (epoch 248 @ 10416 updates, score 0.754) (writing took 0.0496250119999786 seconds)\n",
      "2022-02-02 10:53:03 | INFO | fairseq_cli.train | end of epoch 248 (average epoch stats below)\n",
      "2022-02-02 10:53:03 | INFO | train | epoch 248 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 449.9 | ups 7.06 | wpb 63.7 | bsz 31.9 | num_updates 10416 | lr 3.91931e-05 | gnorm 0.595 | train_wall 2 | wall 1375\n",
      "epoch 249:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:53:03 | INFO | fairseq.trainer | begin training epoch 249\n",
      "epoch 249:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.18it/s]2022-02-02 10:53:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 249 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 249 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:53:08 | INFO | valid | epoch 249 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1196.5 | wpb 16 | bsz 8 | num_updates 10458 | best_loss 0.754\n",
      "2022-02-02 10:53:08 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:53:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint249.pt (epoch 249 @ 10458 updates, score 0.754) (writing took 0.036806699999942794 seconds)\n",
      "2022-02-02 10:53:08 | INFO | fairseq_cli.train | end of epoch 249 (average epoch stats below)\n",
      "2022-02-02 10:53:08 | INFO | train | epoch 249 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 487.3 | ups 7.65 | wpb 63.7 | bsz 31.9 | num_updates 10458 | lr 3.91143e-05 | gnorm 0.595 | train_wall 2 | wall 1380\n",
      "epoch 250:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:53:08 | INFO | fairseq.trainer | begin training epoch 250\n",
      "epoch 250:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.42it/s]2022-02-02 10:53:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 250 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 250 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:53:14 | INFO | valid | epoch 250 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1238.7 | wpb 16 | bsz 8 | num_updates 10500 | best_loss 0.754\n",
      "2022-02-02 10:53:14 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:53:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint250.pt (epoch 250 @ 10500 updates, score 0.754) (writing took 0.03587068499996349 seconds)\n",
      "2022-02-02 10:53:14 | INFO | fairseq_cli.train | end of epoch 250 (average epoch stats below)\n",
      "2022-02-02 10:53:14 | INFO | train | epoch 250 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 494 | ups 7.75 | wpb 63.7 | bsz 31.9 | num_updates 10500 | lr 3.9036e-05 | gnorm 0.597 | train_wall 2 | wall 1386\n",
      "epoch 251:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:53:14 | INFO | fairseq.trainer | begin training epoch 251\n",
      "epoch 251:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.11it/s]2022-02-02 10:53:17 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 251 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 251 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:53:19 | INFO | valid | epoch 251 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1234.3 | wpb 16 | bsz 8 | num_updates 10542 | best_loss 0.754\n",
      "2022-02-02 10:53:19 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:53:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint251.pt (epoch 251 @ 10542 updates, score 0.754) (writing took 0.034773437000012564 seconds)\n",
      "2022-02-02 10:53:19 | INFO | fairseq_cli.train | end of epoch 251 (average epoch stats below)\n",
      "2022-02-02 10:53:19 | INFO | train | epoch 251 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 498.8 | ups 7.83 | wpb 63.7 | bsz 31.9 | num_updates 10542 | lr 3.89582e-05 | gnorm 0.619 | train_wall 2 | wall 1391\n",
      "epoch 252:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:53:19 | INFO | fairseq.trainer | begin training epoch 252\n",
      "epoch 252:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.51it/s]2022-02-02 10:53:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 252 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 252 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:53:24 | INFO | valid | epoch 252 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1209.9 | wpb 16 | bsz 8 | num_updates 10584 | best_loss 0.754\n",
      "2022-02-02 10:53:24 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:53:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint252.pt (epoch 252 @ 10584 updates, score 0.755) (writing took 0.026065289999905872 seconds)\n",
      "2022-02-02 10:53:24 | INFO | fairseq_cli.train | end of epoch 252 (average epoch stats below)\n",
      "2022-02-02 10:53:24 | INFO | train | epoch 252 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 497.2 | ups 7.8 | wpb 63.7 | bsz 31.9 | num_updates 10584 | lr 3.88808e-05 | gnorm 0.55 | train_wall 2 | wall 1396\n",
      "epoch 253:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:53:24 | INFO | fairseq.trainer | begin training epoch 253\n",
      "epoch 253:  95%|▉| 40/42 [00:03<00:00, 21.54it/s, loss=0.743, nll_loss=0.372, ac2022-02-02 10:53:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 253 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 253 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:53:30 | INFO | valid | epoch 253 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1225.5 | wpb 16 | bsz 8 | num_updates 10626 | best_loss 0.754\n",
      "2022-02-02 10:53:30 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:53:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint253.pt (epoch 253 @ 10626 updates, score 0.755) (writing took 0.025566267000158405 seconds)\n",
      "2022-02-02 10:53:30 | INFO | fairseq_cli.train | end of epoch 253 (average epoch stats below)\n",
      "2022-02-02 10:53:30 | INFO | train | epoch 253 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 504.2 | ups 7.91 | wpb 63.7 | bsz 31.9 | num_updates 10626 | lr 3.88039e-05 | gnorm 0.675 | train_wall 2 | wall 1402\n",
      "epoch 254:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:53:30 | INFO | fairseq.trainer | begin training epoch 254\n",
      "epoch 254:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.45it/s]2022-02-02 10:53:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 254 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 254 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:53:35 | INFO | valid | epoch 254 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1201.1 | wpb 16 | bsz 8 | num_updates 10668 | best_loss 0.754\n",
      "2022-02-02 10:53:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:53:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint254.pt (epoch 254 @ 10668 updates, score 0.754) (writing took 0.03462742600004276 seconds)\n",
      "2022-02-02 10:53:35 | INFO | fairseq_cli.train | end of epoch 254 (average epoch stats below)\n",
      "2022-02-02 10:53:35 | INFO | train | epoch 254 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 502.4 | ups 7.89 | wpb 63.7 | bsz 31.9 | num_updates 10668 | lr 3.87274e-05 | gnorm 0.628 | train_wall 2 | wall 1407\n",
      "epoch 255:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:53:35 | INFO | fairseq.trainer | begin training epoch 255\n",
      "epoch 255:  95%|▉| 40/42 [00:03<00:00, 21.32it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 10:53:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 255 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 255 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:53:40 | INFO | valid | epoch 255 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1277.8 | wpb 16 | bsz 8 | num_updates 10710 | best_loss 0.754\n",
      "2022-02-02 10:53:40 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:53:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint255.pt (epoch 255 @ 10710 updates, score 0.754) (writing took 0.03932371700011572 seconds)\n",
      "2022-02-02 10:53:40 | INFO | fairseq_cli.train | end of epoch 255 (average epoch stats below)\n",
      "2022-02-02 10:53:40 | INFO | train | epoch 255 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 498.4 | ups 7.82 | wpb 63.7 | bsz 31.9 | num_updates 10710 | lr 3.86514e-05 | gnorm 0.657 | train_wall 2 | wall 1412\n",
      "epoch 256:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:53:40 | INFO | fairseq.trainer | begin training epoch 256\n",
      "epoch 256:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.46it/s]2022-02-02 10:53:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 256 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 256 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.63s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:53:46 | INFO | valid | epoch 256 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1234.3 | wpb 16 | bsz 8 | num_updates 10752 | best_loss 0.754\n",
      "2022-02-02 10:53:46 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:53:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint256.pt (epoch 256 @ 10752 updates, score 0.754) (writing took 0.03988186299989138 seconds)\n",
      "2022-02-02 10:53:46 | INFO | fairseq_cli.train | end of epoch 256 (average epoch stats below)\n",
      "2022-02-02 10:53:46 | INFO | train | epoch 256 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 455.6 | ups 7.15 | wpb 63.7 | bsz 31.9 | num_updates 10752 | lr 3.85758e-05 | gnorm 0.617 | train_wall 2 | wall 1418\n",
      "epoch 257:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:53:46 | INFO | fairseq.trainer | begin training epoch 257\n",
      "epoch 257:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.61it/s]2022-02-02 10:53:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 257 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 257 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.63s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:53:52 | INFO | valid | epoch 257 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1214.7 | wpb 16 | bsz 8 | num_updates 10794 | best_loss 0.754\n",
      "2022-02-02 10:53:52 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:53:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint257.pt (epoch 257 @ 10794 updates, score 0.755) (writing took 0.02572981899993465 seconds)\n",
      "2022-02-02 10:53:52 | INFO | fairseq_cli.train | end of epoch 257 (average epoch stats below)\n",
      "2022-02-02 10:53:52 | INFO | train | epoch 257 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 464.2 | ups 7.29 | wpb 63.7 | bsz 31.9 | num_updates 10794 | lr 3.85007e-05 | gnorm 0.657 | train_wall 2 | wall 1424\n",
      "epoch 258:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:53:52 | INFO | fairseq.trainer | begin training epoch 258\n",
      "epoch 258:  95%|▉| 40/42 [00:03<00:00, 21.56it/s, loss=0.738, nll_loss=0.369, ac2022-02-02 10:53:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 258 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 258 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:53:57 | INFO | valid | epoch 258 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1209.8 | wpb 16 | bsz 8 | num_updates 10836 | best_loss 0.754\n",
      "2022-02-02 10:53:57 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:53:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint258.pt (epoch 258 @ 10836 updates, score 0.754) (writing took 0.03505767799993009 seconds)\n",
      "2022-02-02 10:53:57 | INFO | fairseq_cli.train | end of epoch 258 (average epoch stats below)\n",
      "2022-02-02 10:53:57 | INFO | train | epoch 258 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 496.5 | ups 7.79 | wpb 63.7 | bsz 31.9 | num_updates 10836 | lr 3.8426e-05 | gnorm 0.628 | train_wall 2 | wall 1429\n",
      "epoch 259:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:53:57 | INFO | fairseq.trainer | begin training epoch 259\n",
      "epoch 259:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.41it/s]2022-02-02 10:54:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 259 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 259 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:54:03 | INFO | valid | epoch 259 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1220.8 | wpb 16 | bsz 8 | num_updates 10878 | best_loss 0.754\n",
      "2022-02-02 10:54:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:54:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint259.pt (epoch 259 @ 10878 updates, score 0.754) (writing took 0.02971431500009203 seconds)\n",
      "2022-02-02 10:54:03 | INFO | fairseq_cli.train | end of epoch 259 (average epoch stats below)\n",
      "2022-02-02 10:54:03 | INFO | train | epoch 259 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 500.6 | ups 7.86 | wpb 63.7 | bsz 31.9 | num_updates 10878 | lr 3.83518e-05 | gnorm 0.637 | train_wall 2 | wall 1435\n",
      "epoch 260:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:54:03 | INFO | fairseq.trainer | begin training epoch 260\n",
      "epoch 260:  93%|▉| 39/42 [00:03<00:00, 20.68it/s, loss=0.741, nll_loss=0.371, ac2022-02-02 10:54:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 260 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 260 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.63s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:54:08 | INFO | valid | epoch 260 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1252.7 | wpb 16 | bsz 8 | num_updates 10920 | best_loss 0.754\n",
      "2022-02-02 10:54:08 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:54:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint260.pt (epoch 260 @ 10920 updates, score 0.754) (writing took 0.0479791610000575 seconds)\n",
      "2022-02-02 10:54:08 | INFO | fairseq_cli.train | end of epoch 260 (average epoch stats below)\n",
      "2022-02-02 10:54:08 | INFO | train | epoch 260 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 488.7 | ups 7.67 | wpb 63.7 | bsz 31.9 | num_updates 10920 | lr 3.8278e-05 | gnorm 0.584 | train_wall 2 | wall 1440\n",
      "epoch 261:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:54:08 | INFO | fairseq.trainer | begin training epoch 261\n",
      "epoch 261:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.52it/s]2022-02-02 10:54:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 261 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 261 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:54:14 | INFO | valid | epoch 261 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1195.7 | wpb 16 | bsz 8 | num_updates 10962 | best_loss 0.754\n",
      "2022-02-02 10:54:14 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:54:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint261.pt (epoch 261 @ 10962 updates, score 0.754) (writing took 0.03835103999995226 seconds)\n",
      "2022-02-02 10:54:14 | INFO | fairseq_cli.train | end of epoch 261 (average epoch stats below)\n",
      "2022-02-02 10:54:14 | INFO | train | epoch 261 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 497.8 | ups 7.81 | wpb 63.7 | bsz 31.9 | num_updates 10962 | lr 3.82046e-05 | gnorm 0.659 | train_wall 2 | wall 1446\n",
      "epoch 262:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:54:14 | INFO | fairseq.trainer | begin training epoch 262\n",
      "epoch 262:  95%|▉| 40/42 [00:03<00:00, 21.24it/s, loss=0.745, nll_loss=0.372, ac2022-02-02 10:54:17 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 262 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 262 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:54:19 | INFO | valid | epoch 262 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1195.5 | wpb 16 | bsz 8 | num_updates 11004 | best_loss 0.754\n",
      "2022-02-02 10:54:19 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:54:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint262.pt (epoch 262 @ 11004 updates, score 0.755) (writing took 0.026228958999809038 seconds)\n",
      "2022-02-02 10:54:19 | INFO | fairseq_cli.train | end of epoch 262 (average epoch stats below)\n",
      "2022-02-02 10:54:19 | INFO | train | epoch 262 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 492.2 | ups 7.72 | wpb 63.7 | bsz 31.9 | num_updates 11004 | lr 3.81316e-05 | gnorm 0.564 | train_wall 2 | wall 1451\n",
      "epoch 263:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:54:19 | INFO | fairseq.trainer | begin training epoch 263\n",
      "epoch 263:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.53it/s]2022-02-02 10:54:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 263 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 263 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:54:24 | INFO | valid | epoch 263 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1247.8 | wpb 16 | bsz 8 | num_updates 11046 | best_loss 0.754\n",
      "2022-02-02 10:54:24 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:54:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint263.pt (epoch 263 @ 11046 updates, score 0.755) (writing took 0.028591964999804986 seconds)\n",
      "2022-02-02 10:54:24 | INFO | fairseq_cli.train | end of epoch 263 (average epoch stats below)\n",
      "2022-02-02 10:54:24 | INFO | train | epoch 263 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 499 | ups 7.83 | wpb 63.7 | bsz 31.9 | num_updates 11046 | lr 3.8059e-05 | gnorm 0.579 | train_wall 2 | wall 1456\n",
      "epoch 264:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:54:24 | INFO | fairseq.trainer | begin training epoch 264\n",
      "epoch 264:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.65it/s]2022-02-02 10:54:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 264 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 264 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:54:30 | INFO | valid | epoch 264 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1243.8 | wpb 16 | bsz 8 | num_updates 11088 | best_loss 0.754\n",
      "2022-02-02 10:54:30 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:54:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint264.pt (epoch 264 @ 11088 updates, score 0.755) (writing took 0.019652808000046207 seconds)\n",
      "2022-02-02 10:54:30 | INFO | fairseq_cli.train | end of epoch 264 (average epoch stats below)\n",
      "2022-02-02 10:54:30 | INFO | train | epoch 264 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 502.7 | ups 7.89 | wpb 63.7 | bsz 31.9 | num_updates 11088 | lr 3.79869e-05 | gnorm 0.732 | train_wall 2 | wall 1462\n",
      "epoch 265:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:54:30 | INFO | fairseq.trainer | begin training epoch 265\n",
      "epoch 265:  95%|▉| 40/42 [00:03<00:00, 21.49it/s, loss=0.748, nll_loss=0.374, ac2022-02-02 10:54:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 265 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 265 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:54:35 | INFO | valid | epoch 265 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1190.7 | wpb 16 | bsz 8 | num_updates 11130 | best_loss 0.754\n",
      "2022-02-02 10:54:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:54:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint265.pt (epoch 265 @ 11130 updates, score 0.754) (writing took 0.03564004100007878 seconds)\n",
      "2022-02-02 10:54:35 | INFO | fairseq_cli.train | end of epoch 265 (average epoch stats below)\n",
      "2022-02-02 10:54:35 | INFO | train | epoch 265 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 493.4 | ups 7.74 | wpb 63.7 | bsz 31.9 | num_updates 11130 | lr 3.79151e-05 | gnorm 0.635 | train_wall 2 | wall 1467\n",
      "epoch 266:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:54:35 | INFO | fairseq.trainer | begin training epoch 266\n",
      "epoch 266:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.60it/s]2022-02-02 10:54:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 266 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 266 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.49s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:54:40 | INFO | valid | epoch 266 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1234.4 | wpb 16 | bsz 8 | num_updates 11172 | best_loss 0.754\n",
      "2022-02-02 10:54:40 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:54:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint266.pt (epoch 266 @ 11172 updates, score 0.755) (writing took 0.01796066399992924 seconds)\n",
      "2022-02-02 10:54:41 | INFO | fairseq_cli.train | end of epoch 266 (average epoch stats below)\n",
      "2022-02-02 10:54:41 | INFO | train | epoch 266 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 504.3 | ups 7.92 | wpb 63.7 | bsz 31.9 | num_updates 11172 | lr 3.78438e-05 | gnorm 0.629 | train_wall 2 | wall 1473\n",
      "epoch 267:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:54:41 | INFO | fairseq.trainer | begin training epoch 267\n",
      "epoch 267:  95%|▉| 40/42 [00:03<00:00, 21.71it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 10:54:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 267 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 267 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:54:46 | INFO | valid | epoch 267 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1222 | wpb 16 | bsz 8 | num_updates 11214 | best_loss 0.754\n",
      "2022-02-02 10:54:46 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:54:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint267.pt (epoch 267 @ 11214 updates, score 0.755) (writing took 0.01764403099991796 seconds)\n",
      "2022-02-02 10:54:46 | INFO | fairseq_cli.train | end of epoch 267 (average epoch stats below)\n",
      "2022-02-02 10:54:46 | INFO | train | epoch 267 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 499.4 | ups 7.84 | wpb 63.7 | bsz 31.9 | num_updates 11214 | lr 3.77728e-05 | gnorm 0.59 | train_wall 2 | wall 1478\n",
      "epoch 268:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:54:46 | INFO | fairseq.trainer | begin training epoch 268\n",
      "epoch 268:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.74it/s]2022-02-02 10:54:49 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 268 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 268 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:54:51 | INFO | valid | epoch 268 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1200.4 | wpb 16 | bsz 8 | num_updates 11256 | best_loss 0.754\n",
      "2022-02-02 10:54:51 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:54:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint268.pt (epoch 268 @ 11256 updates, score 0.754) (writing took 0.021053833999985727 seconds)\n",
      "2022-02-02 10:54:51 | INFO | fairseq_cli.train | end of epoch 268 (average epoch stats below)\n",
      "2022-02-02 10:54:51 | INFO | train | epoch 268 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 505.1 | ups 7.93 | wpb 63.7 | bsz 31.9 | num_updates 11256 | lr 3.77023e-05 | gnorm 0.601 | train_wall 2 | wall 1483\n",
      "epoch 269:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:54:51 | INFO | fairseq.trainer | begin training epoch 269\n",
      "epoch 269:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.28it/s]2022-02-02 10:54:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 269 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 269 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:54:56 | INFO | valid | epoch 269 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1270.3 | wpb 16 | bsz 8 | num_updates 11298 | best_loss 0.754\n",
      "2022-02-02 10:54:56 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:54:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint269.pt (epoch 269 @ 11298 updates, score 0.755) (writing took 0.01933652399998209 seconds)\n",
      "2022-02-02 10:54:56 | INFO | fairseq_cli.train | end of epoch 269 (average epoch stats below)\n",
      "2022-02-02 10:54:56 | INFO | train | epoch 269 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 507.4 | ups 7.96 | wpb 63.7 | bsz 31.9 | num_updates 11298 | lr 3.76322e-05 | gnorm 0.55 | train_wall 2 | wall 1488\n",
      "epoch 270:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:54:56 | INFO | fairseq.trainer | begin training epoch 270\n",
      "epoch 270:  95%|▉| 40/42 [00:03<00:00, 21.20it/s, loss=0.739, nll_loss=0.369, ac2022-02-02 10:55:00 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 270 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 270 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.68s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:55:02 | INFO | valid | epoch 270 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1074.7 | wpb 16 | bsz 8 | num_updates 11340 | best_loss 0.754\n",
      "2022-02-02 10:55:02 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:55:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint270.pt (epoch 270 @ 11340 updates, score 0.754) (writing took 0.030232707999857666 seconds)\n",
      "2022-02-02 10:55:02 | INFO | fairseq_cli.train | end of epoch 270 (average epoch stats below)\n",
      "2022-02-02 10:55:02 | INFO | train | epoch 270 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 482.9 | ups 7.58 | wpb 63.7 | bsz 31.9 | num_updates 11340 | lr 3.75624e-05 | gnorm 0.671 | train_wall 2 | wall 1494\n",
      "epoch 271:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:55:02 | INFO | fairseq.trainer | begin training epoch 271\n",
      "epoch 271:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.75it/s]2022-02-02 10:55:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 271 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 271 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.67s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:55:08 | INFO | valid | epoch 271 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1217.9 | wpb 16 | bsz 8 | num_updates 11382 | best_loss 0.754\n",
      "2022-02-02 10:55:08 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:55:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint271.pt (epoch 271 @ 11382 updates, score 0.754) (writing took 0.02893288800009941 seconds)\n",
      "2022-02-02 10:55:08 | INFO | fairseq_cli.train | end of epoch 271 (average epoch stats below)\n",
      "2022-02-02 10:55:08 | INFO | train | epoch 271 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 464.1 | ups 7.28 | wpb 63.7 | bsz 31.9 | num_updates 11382 | lr 3.7493e-05 | gnorm 0.618 | train_wall 2 | wall 1500\n",
      "epoch 272:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:55:08 | INFO | fairseq.trainer | begin training epoch 272\n",
      "epoch 272:  95%|▉| 40/42 [00:03<00:00, 21.67it/s, loss=0.739, nll_loss=0.369, ac2022-02-02 10:55:11 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 272 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 272 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:55:13 | INFO | valid | epoch 272 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1261.9 | wpb 16 | bsz 8 | num_updates 11424 | best_loss 0.754\n",
      "2022-02-02 10:55:13 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:55:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint272.pt (epoch 272 @ 11424 updates, score 0.755) (writing took 0.026316728999972838 seconds)\n",
      "2022-02-02 10:55:13 | INFO | fairseq_cli.train | end of epoch 272 (average epoch stats below)\n",
      "2022-02-02 10:55:13 | INFO | train | epoch 272 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 499.8 | ups 7.84 | wpb 63.7 | bsz 31.9 | num_updates 11424 | lr 3.74241e-05 | gnorm 0.628 | train_wall 2 | wall 1505\n",
      "epoch 273:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:55:13 | INFO | fairseq.trainer | begin training epoch 273\n",
      "epoch 273:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.50it/s]2022-02-02 10:55:17 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 273 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 273 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:20,  1.50s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:55:18 | INFO | valid | epoch 273 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1248.3 | wpb 16 | bsz 8 | num_updates 11466 | best_loss 0.754\n",
      "2022-02-02 10:55:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:55:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint273.pt (epoch 273 @ 11466 updates, score 0.755) (writing took 0.026383713000086573 seconds)\n",
      "2022-02-02 10:55:18 | INFO | fairseq_cli.train | end of epoch 273 (average epoch stats below)\n",
      "2022-02-02 10:55:18 | INFO | train | epoch 273 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 504.2 | ups 7.91 | wpb 63.7 | bsz 31.9 | num_updates 11466 | lr 3.73555e-05 | gnorm 0.598 | train_wall 2 | wall 1510\n",
      "epoch 274:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:55:18 | INFO | fairseq.trainer | begin training epoch 274\n",
      "epoch 274:  95%|▉| 40/42 [00:03<00:00, 21.87it/s, loss=0.749, nll_loss=0.374, ac2022-02-02 10:55:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 274 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 274 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:55:24 | INFO | valid | epoch 274 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1195 | wpb 16 | bsz 8 | num_updates 11508 | best_loss 0.754\n",
      "2022-02-02 10:55:24 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:55:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint274.pt (epoch 274 @ 11508 updates, score 0.754) (writing took 0.04376279999996768 seconds)\n",
      "2022-02-02 10:55:24 | INFO | fairseq_cli.train | end of epoch 274 (average epoch stats below)\n",
      "2022-02-02 10:55:24 | INFO | train | epoch 274 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 505.6 | ups 7.94 | wpb 63.7 | bsz 31.9 | num_updates 11508 | lr 3.72872e-05 | gnorm 0.563 | train_wall 2 | wall 1516\n",
      "epoch 275:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:55:24 | INFO | fairseq.trainer | begin training epoch 275\n",
      "epoch 275:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.42it/s]2022-02-02 10:55:27 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 275 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 275 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:55:29 | INFO | valid | epoch 275 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1221.2 | wpb 16 | bsz 8 | num_updates 11550 | best_loss 0.754\n",
      "2022-02-02 10:55:29 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:55:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint275.pt (epoch 275 @ 11550 updates, score 0.756) (writing took 0.019022625999923548 seconds)\n",
      "2022-02-02 10:55:29 | INFO | fairseq_cli.train | end of epoch 275 (average epoch stats below)\n",
      "2022-02-02 10:55:29 | INFO | train | epoch 275 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 493.2 | ups 7.74 | wpb 63.7 | bsz 31.9 | num_updates 11550 | lr 3.72194e-05 | gnorm 0.647 | train_wall 2 | wall 1521\n",
      "epoch 276:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:55:29 | INFO | fairseq.trainer | begin training epoch 276\n",
      "epoch 276:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.95it/s]2022-02-02 10:55:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 276 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 276 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:55:34 | INFO | valid | epoch 276 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1217.9 | wpb 16 | bsz 8 | num_updates 11592 | best_loss 0.754\n",
      "2022-02-02 10:55:34 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:55:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint276.pt (epoch 276 @ 11592 updates, score 0.755) (writing took 0.025602428999945914 seconds)\n",
      "2022-02-02 10:55:34 | INFO | fairseq_cli.train | end of epoch 276 (average epoch stats below)\n",
      "2022-02-02 10:55:34 | INFO | train | epoch 276 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 500.1 | ups 7.85 | wpb 63.7 | bsz 31.9 | num_updates 11592 | lr 3.71519e-05 | gnorm 0.611 | train_wall 2 | wall 1526\n",
      "epoch 277:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:55:34 | INFO | fairseq.trainer | begin training epoch 277\n",
      "epoch 277:  95%|▉| 40/42 [00:03<00:00, 21.69it/s, loss=0.735, nll_loss=0.368, ac2022-02-02 10:55:38 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 277 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 277 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:55:40 | INFO | valid | epoch 277 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1222.4 | wpb 16 | bsz 8 | num_updates 11634 | best_loss 0.754\n",
      "2022-02-02 10:55:40 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:55:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint277.pt (epoch 277 @ 11634 updates, score 0.754) (writing took 0.03822988299998542 seconds)\n",
      "2022-02-02 10:55:40 | INFO | fairseq_cli.train | end of epoch 277 (average epoch stats below)\n",
      "2022-02-02 10:55:40 | INFO | train | epoch 277 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 494.9 | ups 7.77 | wpb 63.7 | bsz 31.9 | num_updates 11634 | lr 3.70848e-05 | gnorm 0.489 | train_wall 2 | wall 1532\n",
      "epoch 278:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:55:40 | INFO | fairseq.trainer | begin training epoch 278\n",
      "epoch 278:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.95it/s]2022-02-02 10:55:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 278 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 278 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:24,  1.76s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:55:46 | INFO | valid | epoch 278 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1025.1 | wpb 16 | bsz 8 | num_updates 11676 | best_loss 0.754\n",
      "2022-02-02 10:55:46 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:55:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint278.pt (epoch 278 @ 11676 updates, score 0.754) (writing took 0.029894372999933694 seconds)\n",
      "2022-02-02 10:55:46 | INFO | fairseq_cli.train | end of epoch 278 (average epoch stats below)\n",
      "2022-02-02 10:55:46 | INFO | train | epoch 278 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 473.2 | ups 7.43 | wpb 63.7 | bsz 31.9 | num_updates 11676 | lr 3.7018e-05 | gnorm 0.665 | train_wall 2 | wall 1538\n",
      "epoch 279:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:55:46 | INFO | fairseq.trainer | begin training epoch 279\n",
      "epoch 279:  95%|▉| 40/42 [00:03<00:00, 21.30it/s, loss=0.755, nll_loss=0.377, ac2022-02-02 10:55:49 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 279 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 279 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:55:51 | INFO | valid | epoch 279 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1200.5 | wpb 16 | bsz 8 | num_updates 11718 | best_loss 0.754\n",
      "2022-02-02 10:55:51 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:55:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint279.pt (epoch 279 @ 11718 updates, score 0.754) (writing took 0.03019513200001711 seconds)\n",
      "2022-02-02 10:55:51 | INFO | fairseq_cli.train | end of epoch 279 (average epoch stats below)\n",
      "2022-02-02 10:55:51 | INFO | train | epoch 279 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 471.2 | ups 7.4 | wpb 63.7 | bsz 31.9 | num_updates 11718 | lr 3.69516e-05 | gnorm 0.732 | train_wall 2 | wall 1543\n",
      "epoch 280:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:55:51 | INFO | fairseq.trainer | begin training epoch 280\n",
      "epoch 280:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.46it/s]2022-02-02 10:55:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 280 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 280 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:55:57 | INFO | valid | epoch 280 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1216.8 | wpb 16 | bsz 8 | num_updates 11760 | best_loss 0.754\n",
      "2022-02-02 10:55:57 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:55:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint280.pt (epoch 280 @ 11760 updates, score 0.755) (writing took 0.026540094999973007 seconds)\n",
      "2022-02-02 10:55:57 | INFO | fairseq_cli.train | end of epoch 280 (average epoch stats below)\n",
      "2022-02-02 10:55:57 | INFO | train | epoch 280 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 497.2 | ups 7.8 | wpb 63.7 | bsz 31.9 | num_updates 11760 | lr 3.68856e-05 | gnorm 0.576 | train_wall 2 | wall 1549\n",
      "epoch 281:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:55:57 | INFO | fairseq.trainer | begin training epoch 281\n",
      "epoch 281:  95%|▉| 40/42 [00:03<00:00, 21.77it/s, loss=0.736, nll_loss=0.368, ac2022-02-02 10:56:00 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 281 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 281 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:56:02 | INFO | valid | epoch 281 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1164.4 | wpb 16 | bsz 8 | num_updates 11802 | best_loss 0.754\n",
      "2022-02-02 10:56:02 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:56:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint281.pt (epoch 281 @ 11802 updates, score 0.754) (writing took 0.03850260400008665 seconds)\n",
      "2022-02-02 10:56:02 | INFO | fairseq_cli.train | end of epoch 281 (average epoch stats below)\n",
      "2022-02-02 10:56:02 | INFO | train | epoch 281 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 501.4 | ups 7.87 | wpb 63.7 | bsz 31.9 | num_updates 11802 | lr 3.68199e-05 | gnorm 0.724 | train_wall 2 | wall 1554\n",
      "epoch 282:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:56:02 | INFO | fairseq.trainer | begin training epoch 282\n",
      "epoch 282:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.73it/s]2022-02-02 10:56:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 282 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 282 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:24,  1.74s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:56:07 | INFO | valid | epoch 282 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1224.2 | wpb 16 | bsz 8 | num_updates 11844 | best_loss 0.754\n",
      "2022-02-02 10:56:07 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:56:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint282.pt (epoch 282 @ 11844 updates, score 0.755) (writing took 0.019704571999909604 seconds)\n",
      "2022-02-02 10:56:07 | INFO | fairseq_cli.train | end of epoch 282 (average epoch stats below)\n",
      "2022-02-02 10:56:07 | INFO | train | epoch 282 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 484.3 | ups 7.6 | wpb 63.7 | bsz 31.9 | num_updates 11844 | lr 3.67545e-05 | gnorm 0.685 | train_wall 2 | wall 1559\n",
      "epoch 283:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:56:07 | INFO | fairseq.trainer | begin training epoch 283\n",
      "epoch 283:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.78it/s]2022-02-02 10:56:11 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 283 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 283 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:56:13 | INFO | valid | epoch 283 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1262.4 | wpb 16 | bsz 8 | num_updates 11886 | best_loss 0.754\n",
      "2022-02-02 10:56:13 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:56:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint283.pt (epoch 283 @ 11886 updates, score 0.754) (writing took 0.033205092000116565 seconds)\n",
      "2022-02-02 10:56:13 | INFO | fairseq_cli.train | end of epoch 283 (average epoch stats below)\n",
      "2022-02-02 10:56:13 | INFO | train | epoch 283 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 494.8 | ups 7.77 | wpb 63.7 | bsz 31.9 | num_updates 11886 | lr 3.66895e-05 | gnorm 0.544 | train_wall 2 | wall 1565\n",
      "epoch 284:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:56:13 | INFO | fairseq.trainer | begin training epoch 284\n",
      "epoch 284:  95%|▉| 40/42 [00:03<00:00, 21.53it/s, loss=0.732, nll_loss=0.366, ac2022-02-02 10:56:17 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 284 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 284 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:56:18 | INFO | valid | epoch 284 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1237 | wpb 16 | bsz 8 | num_updates 11928 | best_loss 0.754\n",
      "2022-02-02 10:56:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:56:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint284.pt (epoch 284 @ 11928 updates, score 0.754) (writing took 0.03601928500006579 seconds)\n",
      "2022-02-02 10:56:18 | INFO | fairseq_cli.train | end of epoch 284 (average epoch stats below)\n",
      "2022-02-02 10:56:18 | INFO | train | epoch 284 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 493.8 | ups 7.75 | wpb 63.7 | bsz 31.9 | num_updates 11928 | lr 3.66249e-05 | gnorm 0.682 | train_wall 2 | wall 1570\n",
      "epoch 285:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:56:18 | INFO | fairseq.trainer | begin training epoch 285\n",
      "epoch 285:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.27it/s]2022-02-02 10:56:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 285 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 285 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:56:24 | INFO | valid | epoch 285 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1260.2 | wpb 16 | bsz 8 | num_updates 11970 | best_loss 0.754\n",
      "2022-02-02 10:56:24 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:56:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint285.pt (epoch 285 @ 11970 updates, score 0.754) (writing took 0.031181724999896687 seconds)\n",
      "2022-02-02 10:56:24 | INFO | fairseq_cli.train | end of epoch 285 (average epoch stats below)\n",
      "2022-02-02 10:56:24 | INFO | train | epoch 285 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 490.7 | ups 7.7 | wpb 63.7 | bsz 31.9 | num_updates 11970 | lr 3.65606e-05 | gnorm 0.603 | train_wall 2 | wall 1576\n",
      "epoch 286:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:56:24 | INFO | fairseq.trainer | begin training epoch 286\n",
      "epoch 286:  95%|▉| 40/42 [00:03<00:00, 20.57it/s, loss=0.749, nll_loss=0.375, ac2022-02-02 10:56:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 286 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 286 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:56:29 | INFO | valid | epoch 286 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1252.9 | wpb 16 | bsz 8 | num_updates 12012 | best_loss 0.754\n",
      "2022-02-02 10:56:29 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:56:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint286.pt (epoch 286 @ 12012 updates, score 0.756) (writing took 0.018700349000027927 seconds)\n",
      "2022-02-02 10:56:29 | INFO | fairseq_cli.train | end of epoch 286 (average epoch stats below)\n",
      "2022-02-02 10:56:29 | INFO | train | epoch 286 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 474.5 | ups 7.45 | wpb 63.7 | bsz 31.9 | num_updates 12012 | lr 3.64966e-05 | gnorm 0.637 | train_wall 2 | wall 1581\n",
      "epoch 287:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:56:29 | INFO | fairseq.trainer | begin training epoch 287\n",
      "epoch 287:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.68it/s]2022-02-02 10:56:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 287 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 287 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:56:35 | INFO | valid | epoch 287 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1241.3 | wpb 16 | bsz 8 | num_updates 12054 | best_loss 0.754\n",
      "2022-02-02 10:56:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:56:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint287.pt (epoch 287 @ 12054 updates, score 0.755) (writing took 0.02557443599994258 seconds)\n",
      "2022-02-02 10:56:35 | INFO | fairseq_cli.train | end of epoch 287 (average epoch stats below)\n",
      "2022-02-02 10:56:35 | INFO | train | epoch 287 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 482.2 | ups 7.57 | wpb 63.7 | bsz 31.9 | num_updates 12054 | lr 3.6433e-05 | gnorm 0.666 | train_wall 2 | wall 1587\n",
      "epoch 288:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:56:35 | INFO | fairseq.trainer | begin training epoch 288\n",
      "epoch 288:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.73it/s]2022-02-02 10:56:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 288 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 288 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.70s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:56:41 | INFO | valid | epoch 288 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1220.7 | wpb 16 | bsz 8 | num_updates 12096 | best_loss 0.754\n",
      "2022-02-02 10:56:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:56:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint288.pt (epoch 288 @ 12096 updates, score 0.755) (writing took 0.025412861999939196 seconds)\n",
      "2022-02-02 10:56:41 | INFO | fairseq_cli.train | end of epoch 288 (average epoch stats below)\n",
      "2022-02-02 10:56:41 | INFO | train | epoch 288 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 465.6 | ups 7.31 | wpb 63.7 | bsz 31.9 | num_updates 12096 | lr 3.63696e-05 | gnorm 0.592 | train_wall 2 | wall 1593\n",
      "epoch 289:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:56:41 | INFO | fairseq.trainer | begin training epoch 289\n",
      "epoch 289:  95%|▉| 40/42 [00:03<00:00, 21.73it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 10:56:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 289 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 289 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:24,  1.74s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:56:46 | INFO | valid | epoch 289 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1247.8 | wpb 16 | bsz 8 | num_updates 12138 | best_loss 0.754\n",
      "2022-02-02 10:56:46 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:56:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint289.pt (epoch 289 @ 12138 updates, score 0.754) (writing took 0.040680390000034095 seconds)\n",
      "2022-02-02 10:56:46 | INFO | fairseq_cli.train | end of epoch 289 (average epoch stats below)\n",
      "2022-02-02 10:56:46 | INFO | train | epoch 289 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 476 | ups 7.47 | wpb 63.7 | bsz 31.9 | num_updates 12138 | lr 3.63067e-05 | gnorm 0.658 | train_wall 2 | wall 1598\n",
      "epoch 290:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:56:46 | INFO | fairseq.trainer | begin training epoch 290\n",
      "epoch 290:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.48it/s]2022-02-02 10:56:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 290 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 290 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:56:52 | INFO | valid | epoch 290 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1196.3 | wpb 16 | bsz 8 | num_updates 12180 | best_loss 0.754\n",
      "2022-02-02 10:56:52 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:56:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint290.pt (epoch 290 @ 12180 updates, score 0.755) (writing took 0.026789521999944554 seconds)\n",
      "2022-02-02 10:56:52 | INFO | fairseq_cli.train | end of epoch 290 (average epoch stats below)\n",
      "2022-02-02 10:56:52 | INFO | train | epoch 290 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 492.4 | ups 7.73 | wpb 63.7 | bsz 31.9 | num_updates 12180 | lr 3.6244e-05 | gnorm 0.484 | train_wall 2 | wall 1604\n",
      "epoch 291:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:56:52 | INFO | fairseq.trainer | begin training epoch 291\n",
      "epoch 291:  95%|▉| 40/42 [00:03<00:00, 18.80it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 10:56:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 291 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 291 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:25,  1.81s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:56:58 | INFO | valid | epoch 291 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1202.9 | wpb 16 | bsz 8 | num_updates 12222 | best_loss 0.754\n",
      "2022-02-02 10:56:58 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:56:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint291.pt (epoch 291 @ 12222 updates, score 0.754) (writing took 0.039888539999992645 seconds)\n",
      "2022-02-02 10:56:58 | INFO | fairseq_cli.train | end of epoch 291 (average epoch stats below)\n",
      "2022-02-02 10:56:58 | INFO | train | epoch 291 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 438.1 | ups 6.88 | wpb 63.7 | bsz 31.9 | num_updates 12222 | lr 3.61817e-05 | gnorm 0.653 | train_wall 2 | wall 1610\n",
      "epoch 292:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:56:58 | INFO | fairseq.trainer | begin training epoch 292\n",
      "epoch 292:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.68it/s]2022-02-02 10:57:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 292 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 292 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:57:03 | INFO | valid | epoch 292 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1194.8 | wpb 16 | bsz 8 | num_updates 12264 | best_loss 0.754\n",
      "2022-02-02 10:57:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:57:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint292.pt (epoch 292 @ 12264 updates, score 0.754) (writing took 0.021907886999997572 seconds)\n",
      "2022-02-02 10:57:03 | INFO | fairseq_cli.train | end of epoch 292 (average epoch stats below)\n",
      "2022-02-02 10:57:03 | INFO | train | epoch 292 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 486.7 | ups 7.64 | wpb 63.7 | bsz 31.9 | num_updates 12264 | lr 3.61197e-05 | gnorm 0.58 | train_wall 2 | wall 1615\n",
      "epoch 293:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:57:03 | INFO | fairseq.trainer | begin training epoch 293\n",
      "epoch 293:  95%|▉| 40/42 [00:03<00:00, 21.78it/s, loss=0.745, nll_loss=0.373, ac2022-02-02 10:57:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 293 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 293 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:57:09 | INFO | valid | epoch 293 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1253.6 | wpb 16 | bsz 8 | num_updates 12306 | best_loss 0.754\n",
      "2022-02-02 10:57:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:57:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint293.pt (epoch 293 @ 12306 updates, score 0.754) (writing took 0.021149658000013005 seconds)\n",
      "2022-02-02 10:57:09 | INFO | fairseq_cli.train | end of epoch 293 (average epoch stats below)\n",
      "2022-02-02 10:57:09 | INFO | train | epoch 293 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 496.8 | ups 7.8 | wpb 63.7 | bsz 31.9 | num_updates 12306 | lr 3.6058e-05 | gnorm 0.635 | train_wall 2 | wall 1621\n",
      "epoch 294:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:57:09 | INFO | fairseq.trainer | begin training epoch 294\n",
      "epoch 294:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.79it/s]2022-02-02 10:57:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 294 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 294 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.63s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:57:14 | INFO | valid | epoch 294 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1194.3 | wpb 16 | bsz 8 | num_updates 12348 | best_loss 0.754\n",
      "2022-02-02 10:57:14 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:57:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint294.pt (epoch 294 @ 12348 updates, score 0.754) (writing took 0.026801680000062333 seconds)\n",
      "2022-02-02 10:57:14 | INFO | fairseq_cli.train | end of epoch 294 (average epoch stats below)\n",
      "2022-02-02 10:57:14 | INFO | train | epoch 294 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 496.5 | ups 7.79 | wpb 63.7 | bsz 31.9 | num_updates 12348 | lr 3.59966e-05 | gnorm 0.638 | train_wall 2 | wall 1626\n",
      "epoch 295:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:57:14 | INFO | fairseq.trainer | begin training epoch 295\n",
      "epoch 295:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.21it/s]2022-02-02 10:57:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 295 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 295 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.66s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:57:20 | INFO | valid | epoch 295 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1246.6 | wpb 16 | bsz 8 | num_updates 12390 | best_loss 0.754\n",
      "2022-02-02 10:57:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:57:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint295.pt (epoch 295 @ 12390 updates, score 0.755) (writing took 0.019905130999859466 seconds)\n",
      "2022-02-02 10:57:20 | INFO | fairseq_cli.train | end of epoch 295 (average epoch stats below)\n",
      "2022-02-02 10:57:20 | INFO | train | epoch 295 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 476.8 | ups 7.48 | wpb 63.7 | bsz 31.9 | num_updates 12390 | lr 3.59356e-05 | gnorm 0.51 | train_wall 2 | wall 1632\n",
      "epoch 296:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:57:20 | INFO | fairseq.trainer | begin training epoch 296\n",
      "epoch 296:  95%|▉| 40/42 [00:03<00:00, 21.73it/s, loss=0.734, nll_loss=0.367, ac2022-02-02 10:57:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 296 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 296 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:57:25 | INFO | valid | epoch 296 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1175.6 | wpb 16 | bsz 8 | num_updates 12432 | best_loss 0.754\n",
      "2022-02-02 10:57:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:57:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint296.pt (epoch 296 @ 12432 updates, score 0.754) (writing took 0.023803420999911395 seconds)\n",
      "2022-02-02 10:57:25 | INFO | fairseq_cli.train | end of epoch 296 (average epoch stats below)\n",
      "2022-02-02 10:57:25 | INFO | train | epoch 296 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 510.4 | ups 8.01 | wpb 63.7 | bsz 31.9 | num_updates 12432 | lr 3.58748e-05 | gnorm 0.626 | train_wall 2 | wall 1637\n",
      "epoch 297:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:57:25 | INFO | fairseq.trainer | begin training epoch 297\n",
      "epoch 297:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.04it/s]2022-02-02 10:57:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 297 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 297 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:57:30 | INFO | valid | epoch 297 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1243.1 | wpb 16 | bsz 8 | num_updates 12474 | best_loss 0.754\n",
      "2022-02-02 10:57:30 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:57:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint297.pt (epoch 297 @ 12474 updates, score 0.754) (writing took 0.02145613199991203 seconds)\n",
      "2022-02-02 10:57:30 | INFO | fairseq_cli.train | end of epoch 297 (average epoch stats below)\n",
      "2022-02-02 10:57:30 | INFO | train | epoch 297 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 502.3 | ups 7.88 | wpb 63.7 | bsz 31.9 | num_updates 12474 | lr 3.58144e-05 | gnorm 0.589 | train_wall 2 | wall 1642\n",
      "epoch 298:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:57:30 | INFO | fairseq.trainer | begin training epoch 298\n",
      "epoch 298:  95%|▉| 40/42 [00:03<00:00, 21.51it/s, loss=0.744, nll_loss=0.372, ac2022-02-02 10:57:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 298 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 298 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:57:36 | INFO | valid | epoch 298 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1242.3 | wpb 16 | bsz 8 | num_updates 12516 | best_loss 0.754\n",
      "2022-02-02 10:57:36 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:57:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint298.pt (epoch 298 @ 12516 updates, score 0.754) (writing took 0.029353883000112546 seconds)\n",
      "2022-02-02 10:57:36 | INFO | fairseq_cli.train | end of epoch 298 (average epoch stats below)\n",
      "2022-02-02 10:57:36 | INFO | train | epoch 298 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 497 | ups 7.8 | wpb 63.7 | bsz 31.9 | num_updates 12516 | lr 3.57542e-05 | gnorm 0.674 | train_wall 2 | wall 1648\n",
      "epoch 299:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:57:36 | INFO | fairseq.trainer | begin training epoch 299\n",
      "epoch 299:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.82it/s]2022-02-02 10:57:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 299 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 299 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:57:41 | INFO | valid | epoch 299 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1192.6 | wpb 16 | bsz 8 | num_updates 12558 | best_loss 0.754\n",
      "2022-02-02 10:57:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:57:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint299.pt (epoch 299 @ 12558 updates, score 0.754) (writing took 0.030613821999850188 seconds)\n",
      "2022-02-02 10:57:41 | INFO | fairseq_cli.train | end of epoch 299 (average epoch stats below)\n",
      "2022-02-02 10:57:41 | INFO | train | epoch 299 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 495.7 | ups 7.78 | wpb 63.7 | bsz 31.9 | num_updates 12558 | lr 3.56944e-05 | gnorm 0.569 | train_wall 2 | wall 1653\n",
      "epoch 300:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:57:41 | INFO | fairseq.trainer | begin training epoch 300\n",
      "epoch 300:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.91it/s]2022-02-02 10:57:45 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 300 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 300 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:57:47 | INFO | valid | epoch 300 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1101.5 | wpb 16 | bsz 8 | num_updates 12600 | best_loss 0.754\n",
      "2022-02-02 10:57:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:57:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint300.pt (epoch 300 @ 12600 updates, score 0.754) (writing took 0.06245112500005234 seconds)\n",
      "2022-02-02 10:57:47 | INFO | fairseq_cli.train | end of epoch 300 (average epoch stats below)\n",
      "2022-02-02 10:57:47 | INFO | train | epoch 300 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 489.8 | ups 7.69 | wpb 63.7 | bsz 31.9 | num_updates 12600 | lr 3.56348e-05 | gnorm 0.714 | train_wall 2 | wall 1659\n",
      "epoch 301:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:57:47 | INFO | fairseq.trainer | begin training epoch 301\n",
      "epoch 301:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.84it/s]2022-02-02 10:57:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 301 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 301 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:57:52 | INFO | valid | epoch 301 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1201.9 | wpb 16 | bsz 8 | num_updates 12642 | best_loss 0.754\n",
      "2022-02-02 10:57:52 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:57:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint301.pt (epoch 301 @ 12642 updates, score 0.755) (writing took 0.02518741299991234 seconds)\n",
      "2022-02-02 10:57:52 | INFO | fairseq_cli.train | end of epoch 301 (average epoch stats below)\n",
      "2022-02-02 10:57:52 | INFO | train | epoch 301 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 492 | ups 7.72 | wpb 63.7 | bsz 31.9 | num_updates 12642 | lr 3.55756e-05 | gnorm 0.543 | train_wall 2 | wall 1664\n",
      "epoch 302:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:57:52 | INFO | fairseq.trainer | begin training epoch 302\n",
      "epoch 302:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.76it/s]2022-02-02 10:57:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 302 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 302 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:57:57 | INFO | valid | epoch 302 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1176.9 | wpb 16 | bsz 8 | num_updates 12684 | best_loss 0.754\n",
      "2022-02-02 10:57:57 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:57:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint302.pt (epoch 302 @ 12684 updates, score 0.754) (writing took 0.0335223130000486 seconds)\n",
      "2022-02-02 10:57:57 | INFO | fairseq_cli.train | end of epoch 302 (average epoch stats below)\n",
      "2022-02-02 10:57:57 | INFO | train | epoch 302 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 494.8 | ups 7.77 | wpb 63.7 | bsz 31.9 | num_updates 12684 | lr 3.55166e-05 | gnorm 0.577 | train_wall 2 | wall 1669\n",
      "epoch 303:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:57:57 | INFO | fairseq.trainer | begin training epoch 303\n",
      "epoch 303:  95%|▉| 40/42 [00:03<00:00, 21.12it/s, loss=0.746, nll_loss=0.373, ac2022-02-02 10:58:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 303 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 303 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:58:03 | INFO | valid | epoch 303 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1230 | wpb 16 | bsz 8 | num_updates 12726 | best_loss 0.754\n",
      "2022-02-02 10:58:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:58:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint303.pt (epoch 303 @ 12726 updates, score 0.755) (writing took 0.021103928999991695 seconds)\n",
      "2022-02-02 10:58:03 | INFO | fairseq_cli.train | end of epoch 303 (average epoch stats below)\n",
      "2022-02-02 10:58:03 | INFO | train | epoch 303 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 494.5 | ups 7.76 | wpb 63.7 | bsz 31.9 | num_updates 12726 | lr 3.5458e-05 | gnorm 0.547 | train_wall 2 | wall 1675\n",
      "epoch 304:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:58:03 | INFO | fairseq.trainer | begin training epoch 304\n",
      "epoch 304:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.72it/s]2022-02-02 10:58:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 304 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 304 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:58:08 | INFO | valid | epoch 304 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1254.5 | wpb 16 | bsz 8 | num_updates 12768 | best_loss 0.754\n",
      "2022-02-02 10:58:08 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:58:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint304.pt (epoch 304 @ 12768 updates, score 0.754) (writing took 0.02949347799994939 seconds)\n",
      "2022-02-02 10:58:08 | INFO | fairseq_cli.train | end of epoch 304 (average epoch stats below)\n",
      "2022-02-02 10:58:08 | INFO | train | epoch 304 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 494.6 | ups 7.76 | wpb 63.7 | bsz 31.9 | num_updates 12768 | lr 3.53996e-05 | gnorm 0.612 | train_wall 2 | wall 1680\n",
      "epoch 305:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:58:08 | INFO | fairseq.trainer | begin training epoch 305\n",
      "epoch 305:  98%|▉| 41/42 [00:03<00:00, 19.20it/s, loss=0.728, nll_loss=0.364, ac2022-02-02 10:58:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 305 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 305 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.65s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:58:14 | INFO | valid | epoch 305 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1226.4 | wpb 16 | bsz 8 | num_updates 12810 | best_loss 0.754\n",
      "2022-02-02 10:58:14 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:58:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint305.pt (epoch 305 @ 12810 updates, score 0.755) (writing took 0.023737430999972275 seconds)\n",
      "2022-02-02 10:58:14 | INFO | fairseq_cli.train | end of epoch 305 (average epoch stats below)\n",
      "2022-02-02 10:58:14 | INFO | train | epoch 305 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 479 | ups 7.52 | wpb 63.7 | bsz 31.9 | num_updates 12810 | lr 3.53415e-05 | gnorm 0.61 | train_wall 2 | wall 1686\n",
      "epoch 306:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:58:14 | INFO | fairseq.trainer | begin training epoch 306\n",
      "epoch 306:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.74it/s]2022-02-02 10:58:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 306 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 306 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:58:20 | INFO | valid | epoch 306 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1210 | wpb 16 | bsz 8 | num_updates 12852 | best_loss 0.754\n",
      "2022-02-02 10:58:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:58:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint306.pt (epoch 306 @ 12852 updates, score 0.754) (writing took 0.024646043000075224 seconds)\n",
      "2022-02-02 10:58:20 | INFO | fairseq_cli.train | end of epoch 306 (average epoch stats below)\n",
      "2022-02-02 10:58:20 | INFO | train | epoch 306 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 466.5 | ups 7.32 | wpb 63.7 | bsz 31.9 | num_updates 12852 | lr 3.52837e-05 | gnorm 0.626 | train_wall 2 | wall 1692\n",
      "epoch 307:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:58:20 | INFO | fairseq.trainer | begin training epoch 307\n",
      "epoch 307:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.41it/s]2022-02-02 10:58:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 307 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 307 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:58:25 | INFO | valid | epoch 307 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1227.2 | wpb 16 | bsz 8 | num_updates 12894 | best_loss 0.754\n",
      "2022-02-02 10:58:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:58:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint307.pt (epoch 307 @ 12894 updates, score 0.755) (writing took 0.024139394000030734 seconds)\n",
      "2022-02-02 10:58:25 | INFO | fairseq_cli.train | end of epoch 307 (average epoch stats below)\n",
      "2022-02-02 10:58:25 | INFO | train | epoch 307 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 484.1 | ups 7.6 | wpb 63.7 | bsz 31.9 | num_updates 12894 | lr 3.52262e-05 | gnorm 0.476 | train_wall 2 | wall 1697\n",
      "epoch 308:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:58:25 | INFO | fairseq.trainer | begin training epoch 308\n",
      "epoch 308:  95%|▉| 40/42 [00:03<00:00, 21.28it/s, loss=0.754, nll_loss=0.377, ac2022-02-02 10:58:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 308 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 308 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:58:30 | INFO | valid | epoch 308 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1249.8 | wpb 16 | bsz 8 | num_updates 12936 | best_loss 0.754\n",
      "2022-02-02 10:58:30 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:58:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint308.pt (epoch 308 @ 12936 updates, score 0.754) (writing took 0.0408496049999485 seconds)\n",
      "2022-02-02 10:58:30 | INFO | fairseq_cli.train | end of epoch 308 (average epoch stats below)\n",
      "2022-02-02 10:58:30 | INFO | train | epoch 308 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 495.1 | ups 7.77 | wpb 63.7 | bsz 31.9 | num_updates 12936 | lr 3.5169e-05 | gnorm 0.573 | train_wall 2 | wall 1703\n",
      "epoch 309:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:58:30 | INFO | fairseq.trainer | begin training epoch 309\n",
      "epoch 309:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.87it/s]2022-02-02 10:58:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 309 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 309 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:58:36 | INFO | valid | epoch 309 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1216.4 | wpb 16 | bsz 8 | num_updates 12978 | best_loss 0.754\n",
      "2022-02-02 10:58:36 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:58:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint309.pt (epoch 309 @ 12978 updates, score 0.755) (writing took 0.02629969899999196 seconds)\n",
      "2022-02-02 10:58:36 | INFO | fairseq_cli.train | end of epoch 309 (average epoch stats below)\n",
      "2022-02-02 10:58:36 | INFO | train | epoch 309 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 499.9 | ups 7.85 | wpb 63.7 | bsz 31.9 | num_updates 12978 | lr 3.5112e-05 | gnorm 0.61 | train_wall 2 | wall 1708\n",
      "epoch 310:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:58:36 | INFO | fairseq.trainer | begin training epoch 310\n",
      "epoch 310:  95%|▉| 40/42 [00:03<00:00, 21.84it/s, loss=0.73, nll_loss=0.365, acc2022-02-02 10:58:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 310 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 310 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:58:41 | INFO | valid | epoch 310 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1206.5 | wpb 16 | bsz 8 | num_updates 13020 | best_loss 0.754\n",
      "2022-02-02 10:58:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:58:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint310.pt (epoch 310 @ 13020 updates, score 0.754) (writing took 0.0365898779998588 seconds)\n",
      "2022-02-02 10:58:41 | INFO | fairseq_cli.train | end of epoch 310 (average epoch stats below)\n",
      "2022-02-02 10:58:41 | INFO | train | epoch 310 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 502 | ups 7.88 | wpb 63.7 | bsz 31.9 | num_updates 13020 | lr 3.50554e-05 | gnorm 0.627 | train_wall 2 | wall 1713\n",
      "epoch 311:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:58:41 | INFO | fairseq.trainer | begin training epoch 311\n",
      "epoch 311:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.89it/s]2022-02-02 10:58:45 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 311 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 311 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:58:47 | INFO | valid | epoch 311 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1218.2 | wpb 16 | bsz 8 | num_updates 13062 | best_loss 0.754\n",
      "2022-02-02 10:58:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:58:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint311.pt (epoch 311 @ 13062 updates, score 0.754) (writing took 0.03973816899997473 seconds)\n",
      "2022-02-02 10:58:47 | INFO | fairseq_cli.train | end of epoch 311 (average epoch stats below)\n",
      "2022-02-02 10:58:47 | INFO | train | epoch 311 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 495 | ups 7.77 | wpb 63.7 | bsz 31.9 | num_updates 13062 | lr 3.4999e-05 | gnorm 0.631 | train_wall 2 | wall 1719\n",
      "epoch 312:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:58:47 | INFO | fairseq.trainer | begin training epoch 312\n",
      "epoch 312:  95%|▉| 40/42 [00:03<00:00, 21.10it/s, loss=0.748, nll_loss=0.374, ac2022-02-02 10:58:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 312 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 312 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.66s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:58:53 | INFO | valid | epoch 312 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1201.6 | wpb 16 | bsz 8 | num_updates 13104 | best_loss 0.754\n",
      "2022-02-02 10:58:53 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:58:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint312.pt (epoch 312 @ 13104 updates, score 0.755) (writing took 0.024737550000054398 seconds)\n",
      "2022-02-02 10:58:53 | INFO | fairseq_cli.train | end of epoch 312 (average epoch stats below)\n",
      "2022-02-02 10:58:53 | INFO | train | epoch 312 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 448 | ups 7.03 | wpb 63.7 | bsz 31.9 | num_updates 13104 | lr 3.49428e-05 | gnorm 0.661 | train_wall 2 | wall 1725\n",
      "epoch 313:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:58:53 | INFO | fairseq.trainer | begin training epoch 313\n",
      "epoch 313:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.11it/s]2022-02-02 10:58:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 313 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 313 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.67s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:58:58 | INFO | valid | epoch 313 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1194.9 | wpb 16 | bsz 8 | num_updates 13146 | best_loss 0.754\n",
      "2022-02-02 10:58:58 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:58:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint313.pt (epoch 313 @ 13146 updates, score 0.755) (writing took 0.02738698200005274 seconds)\n",
      "2022-02-02 10:58:58 | INFO | fairseq_cli.train | end of epoch 313 (average epoch stats below)\n",
      "2022-02-02 10:58:58 | INFO | train | epoch 313 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 483.3 | ups 7.59 | wpb 63.7 | bsz 31.9 | num_updates 13146 | lr 3.4887e-05 | gnorm 0.65 | train_wall 2 | wall 1730\n",
      "epoch 314:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:58:58 | INFO | fairseq.trainer | begin training epoch 314\n",
      "epoch 314:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.92it/s]2022-02-02 10:59:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 314 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 314 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:24,  1.73s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:59:04 | INFO | valid | epoch 314 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1177.3 | wpb 16 | bsz 8 | num_updates 13188 | best_loss 0.754\n",
      "2022-02-02 10:59:04 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:59:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint314.pt (epoch 314 @ 13188 updates, score 0.755) (writing took 0.027754957999832186 seconds)\n",
      "2022-02-02 10:59:04 | INFO | fairseq_cli.train | end of epoch 314 (average epoch stats below)\n",
      "2022-02-02 10:59:04 | INFO | train | epoch 314 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 473.8 | ups 7.44 | wpb 63.7 | bsz 31.9 | num_updates 13188 | lr 3.48314e-05 | gnorm 0.617 | train_wall 2 | wall 1736\n",
      "epoch 315:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:59:04 | INFO | fairseq.trainer | begin training epoch 315\n",
      "epoch 315:  95%|▉| 40/42 [00:03<00:00, 21.84it/s, loss=0.75, nll_loss=0.375, acc2022-02-02 10:59:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 315 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 315 | valid on 'valid' subset:   7%|▍      | 1/15 [00:02<00:29,  2.08s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:59:10 | INFO | valid | epoch 315 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1211.9 | wpb 16 | bsz 8 | num_updates 13230 | best_loss 0.754\n",
      "2022-02-02 10:59:10 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:59:10 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint315.pt (epoch 315 @ 13230 updates, score 0.755) (writing took 0.018935657999918476 seconds)\n",
      "2022-02-02 10:59:10 | INFO | fairseq_cli.train | end of epoch 315 (average epoch stats below)\n",
      "2022-02-02 10:59:10 | INFO | train | epoch 315 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 451.4 | ups 7.09 | wpb 63.7 | bsz 31.9 | num_updates 13230 | lr 3.4776e-05 | gnorm 0.618 | train_wall 2 | wall 1742\n",
      "epoch 316:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:59:10 | INFO | fairseq.trainer | begin training epoch 316\n",
      "epoch 316:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.94it/s]2022-02-02 10:59:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 316 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 316 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:59:15 | INFO | valid | epoch 316 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1293.7 | wpb 16 | bsz 8 | num_updates 13272 | best_loss 0.754\n",
      "2022-02-02 10:59:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:59:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint316.pt (epoch 316 @ 13272 updates, score 0.755) (writing took 0.02602561899993816 seconds)\n",
      "2022-02-02 10:59:15 | INFO | fairseq_cli.train | end of epoch 316 (average epoch stats below)\n",
      "2022-02-02 10:59:15 | INFO | train | epoch 316 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 499.3 | ups 7.84 | wpb 63.7 | bsz 31.9 | num_updates 13272 | lr 3.4721e-05 | gnorm 0.629 | train_wall 2 | wall 1747\n",
      "epoch 317:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:59:15 | INFO | fairseq.trainer | begin training epoch 317\n",
      "epoch 317:  93%|▉| 39/42 [00:03<00:00, 21.73it/s, loss=0.736, nll_loss=0.368, ac2022-02-02 10:59:19 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 317 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 317 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:59:20 | INFO | valid | epoch 317 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1199.3 | wpb 16 | bsz 8 | num_updates 13314 | best_loss 0.754\n",
      "2022-02-02 10:59:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:59:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint317.pt (epoch 317 @ 13314 updates, score 0.754) (writing took 0.03317693799999688 seconds)\n",
      "2022-02-02 10:59:20 | INFO | fairseq_cli.train | end of epoch 317 (average epoch stats below)\n",
      "2022-02-02 10:59:20 | INFO | train | epoch 317 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 502 | ups 7.88 | wpb 63.7 | bsz 31.9 | num_updates 13314 | lr 3.46662e-05 | gnorm 0.518 | train_wall 2 | wall 1752\n",
      "epoch 318:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:59:20 | INFO | fairseq.trainer | begin training epoch 318\n",
      "epoch 318:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.39it/s]2022-02-02 10:59:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 318 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 318 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:59:26 | INFO | valid | epoch 318 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1203.9 | wpb 16 | bsz 8 | num_updates 13356 | best_loss 0.754\n",
      "2022-02-02 10:59:26 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:59:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint318.pt (epoch 318 @ 13356 updates, score 0.755) (writing took 0.02573113900007229 seconds)\n",
      "2022-02-02 10:59:26 | INFO | fairseq_cli.train | end of epoch 318 (average epoch stats below)\n",
      "2022-02-02 10:59:26 | INFO | train | epoch 318 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 498.4 | ups 7.82 | wpb 63.7 | bsz 31.9 | num_updates 13356 | lr 3.46116e-05 | gnorm 0.62 | train_wall 2 | wall 1758\n",
      "epoch 319:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:59:26 | INFO | fairseq.trainer | begin training epoch 319\n",
      "epoch 319:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.79it/s]2022-02-02 10:59:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 319 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 319 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:59:31 | INFO | valid | epoch 319 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1205.9 | wpb 16 | bsz 8 | num_updates 13398 | best_loss 0.754\n",
      "2022-02-02 10:59:31 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:59:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint319.pt (epoch 319 @ 13398 updates, score 0.754) (writing took 0.03525009800000589 seconds)\n",
      "2022-02-02 10:59:31 | INFO | fairseq_cli.train | end of epoch 319 (average epoch stats below)\n",
      "2022-02-02 10:59:31 | INFO | train | epoch 319 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 500 | ups 7.85 | wpb 63.7 | bsz 31.9 | num_updates 13398 | lr 3.45573e-05 | gnorm 0.628 | train_wall 2 | wall 1763\n",
      "epoch 320:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:59:31 | INFO | fairseq.trainer | begin training epoch 320\n",
      "epoch 320:  95%|▉| 40/42 [00:03<00:00, 21.72it/s, loss=0.744, nll_loss=0.372, ac2022-02-02 10:59:35 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 320 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 320 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:59:36 | INFO | valid | epoch 320 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1227.3 | wpb 16 | bsz 8 | num_updates 13440 | best_loss 0.754\n",
      "2022-02-02 10:59:36 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:59:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint320.pt (epoch 320 @ 13440 updates, score 0.755) (writing took 0.026444837999861193 seconds)\n",
      "2022-02-02 10:59:36 | INFO | fairseq_cli.train | end of epoch 320 (average epoch stats below)\n",
      "2022-02-02 10:59:36 | INFO | train | epoch 320 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 506.3 | ups 7.95 | wpb 63.7 | bsz 31.9 | num_updates 13440 | lr 3.45033e-05 | gnorm 0.574 | train_wall 2 | wall 1768\n",
      "epoch 321:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:59:36 | INFO | fairseq.trainer | begin training epoch 321\n",
      "epoch 321:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.03it/s]2022-02-02 10:59:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 321 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 321 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:59:42 | INFO | valid | epoch 321 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1190.5 | wpb 16 | bsz 8 | num_updates 13482 | best_loss 0.754\n",
      "2022-02-02 10:59:42 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:59:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint321.pt (epoch 321 @ 13482 updates, score 0.755) (writing took 0.025086841000074855 seconds)\n",
      "2022-02-02 10:59:42 | INFO | fairseq_cli.train | end of epoch 321 (average epoch stats below)\n",
      "2022-02-02 10:59:42 | INFO | train | epoch 321 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 499.7 | ups 7.84 | wpb 63.7 | bsz 31.9 | num_updates 13482 | lr 3.44495e-05 | gnorm 0.557 | train_wall 2 | wall 1774\n",
      "epoch 322:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:59:42 | INFO | fairseq.trainer | begin training epoch 322\n",
      "epoch 322:  95%|▉| 40/42 [00:03<00:00, 20.22it/s, loss=0.743, nll_loss=0.371, ac2022-02-02 10:59:45 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 322 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 322 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.63s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:59:47 | INFO | valid | epoch 322 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1213.7 | wpb 16 | bsz 8 | num_updates 13524 | best_loss 0.754\n",
      "2022-02-02 10:59:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:59:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint322.pt (epoch 322 @ 13524 updates, score 0.754) (writing took 0.03526702200019827 seconds)\n",
      "2022-02-02 10:59:47 | INFO | fairseq_cli.train | end of epoch 322 (average epoch stats below)\n",
      "2022-02-02 10:59:47 | INFO | train | epoch 322 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 485.4 | ups 7.62 | wpb 63.7 | bsz 31.9 | num_updates 13524 | lr 3.4396e-05 | gnorm 0.62 | train_wall 2 | wall 1779\n",
      "epoch 323:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:59:47 | INFO | fairseq.trainer | begin training epoch 323\n",
      "epoch 323:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.91it/s]2022-02-02 10:59:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 323 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 323 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:59:53 | INFO | valid | epoch 323 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1211.8 | wpb 16 | bsz 8 | num_updates 13566 | best_loss 0.754\n",
      "2022-02-02 10:59:53 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:59:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint323.pt (epoch 323 @ 13566 updates, score 0.754) (writing took 0.03745789300000979 seconds)\n",
      "2022-02-02 10:59:53 | INFO | fairseq_cli.train | end of epoch 323 (average epoch stats below)\n",
      "2022-02-02 10:59:53 | INFO | train | epoch 323 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 497.2 | ups 7.8 | wpb 63.7 | bsz 31.9 | num_updates 13566 | lr 3.43427e-05 | gnorm 0.543 | train_wall 2 | wall 1785\n",
      "epoch 324:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:59:53 | INFO | fairseq.trainer | begin training epoch 324\n",
      "epoch 324:  95%|▉| 40/42 [00:03<00:00, 21.53it/s, loss=0.734, nll_loss=0.367, ac2022-02-02 10:59:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 324 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 324 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 10:59:58 | INFO | valid | epoch 324 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1213.1 | wpb 16 | bsz 8 | num_updates 13608 | best_loss 0.754\n",
      "2022-02-02 10:59:58 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 10:59:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint324.pt (epoch 324 @ 13608 updates, score 0.755) (writing took 0.027357105999954 seconds)\n",
      "2022-02-02 10:59:58 | INFO | fairseq_cli.train | end of epoch 324 (average epoch stats below)\n",
      "2022-02-02 10:59:58 | INFO | train | epoch 324 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 482.6 | ups 7.57 | wpb 63.7 | bsz 31.9 | num_updates 13608 | lr 3.42896e-05 | gnorm 0.57 | train_wall 2 | wall 1790\n",
      "epoch 325:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 10:59:58 | INFO | fairseq.trainer | begin training epoch 325\n",
      "epoch 325:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.56it/s]2022-02-02 11:00:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 325 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 325 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:00:04 | INFO | valid | epoch 325 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1296.8 | wpb 16 | bsz 8 | num_updates 13650 | best_loss 0.754\n",
      "2022-02-02 11:00:04 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:00:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint325.pt (epoch 325 @ 13650 updates, score 0.754) (writing took 0.03842848799990861 seconds)\n",
      "2022-02-02 11:00:04 | INFO | fairseq_cli.train | end of epoch 325 (average epoch stats below)\n",
      "2022-02-02 11:00:04 | INFO | train | epoch 325 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 493.2 | ups 7.74 | wpb 63.7 | bsz 31.9 | num_updates 13650 | lr 3.42368e-05 | gnorm 0.564 | train_wall 2 | wall 1796\n",
      "epoch 326:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:00:04 | INFO | fairseq.trainer | begin training epoch 326\n",
      "epoch 326:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.16it/s]2022-02-02 11:00:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 326 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 326 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:00:09 | INFO | valid | epoch 326 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1200.1 | wpb 16 | bsz 8 | num_updates 13692 | best_loss 0.754\n",
      "2022-02-02 11:00:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:00:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint326.pt (epoch 326 @ 13692 updates, score 0.754) (writing took 0.03790789799995764 seconds)\n",
      "2022-02-02 11:00:09 | INFO | fairseq_cli.train | end of epoch 326 (average epoch stats below)\n",
      "2022-02-02 11:00:09 | INFO | train | epoch 326 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 497.2 | ups 7.8 | wpb 63.7 | bsz 31.9 | num_updates 13692 | lr 3.41843e-05 | gnorm 0.606 | train_wall 2 | wall 1801\n",
      "epoch 327:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:00:09 | INFO | fairseq.trainer | begin training epoch 327\n",
      "epoch 327:  95%|▉| 40/42 [00:03<00:00, 21.69it/s, loss=0.75, nll_loss=0.375, acc2022-02-02 11:00:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 327 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 327 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:00:14 | INFO | valid | epoch 327 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1216.4 | wpb 16 | bsz 8 | num_updates 13734 | best_loss 0.754\n",
      "2022-02-02 11:00:14 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:00:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint327.pt (epoch 327 @ 13734 updates, score 0.755) (writing took 0.026069645999996283 seconds)\n",
      "2022-02-02 11:00:14 | INFO | fairseq_cli.train | end of epoch 327 (average epoch stats below)\n",
      "2022-02-02 11:00:14 | INFO | train | epoch 327 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 497 | ups 7.8 | wpb 63.7 | bsz 31.9 | num_updates 13734 | lr 3.4132e-05 | gnorm 0.621 | train_wall 2 | wall 1806\n",
      "epoch 328:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:00:14 | INFO | fairseq.trainer | begin training epoch 328\n",
      "epoch 328:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.02it/s]2022-02-02 11:00:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 328 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 328 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:00:20 | INFO | valid | epoch 328 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1206.4 | wpb 16 | bsz 8 | num_updates 13776 | best_loss 0.754\n",
      "2022-02-02 11:00:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:00:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint328.pt (epoch 328 @ 13776 updates, score 0.755) (writing took 0.025559091000104672 seconds)\n",
      "2022-02-02 11:00:20 | INFO | fairseq_cli.train | end of epoch 328 (average epoch stats below)\n",
      "2022-02-02 11:00:20 | INFO | train | epoch 328 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 506.4 | ups 7.95 | wpb 63.7 | bsz 31.9 | num_updates 13776 | lr 3.40799e-05 | gnorm 0.636 | train_wall 2 | wall 1812\n",
      "epoch 329:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:00:20 | INFO | fairseq.trainer | begin training epoch 329\n",
      "epoch 329:  95%|▉| 40/42 [00:03<00:00, 21.79it/s, loss=0.739, nll_loss=0.369, ac2022-02-02 11:00:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 329 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 329 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:00:25 | INFO | valid | epoch 329 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1217.9 | wpb 16 | bsz 8 | num_updates 13818 | best_loss 0.754\n",
      "2022-02-02 11:00:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:00:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint329.pt (epoch 329 @ 13818 updates, score 0.755) (writing took 0.018223391999981686 seconds)\n",
      "2022-02-02 11:00:25 | INFO | fairseq_cli.train | end of epoch 329 (average epoch stats below)\n",
      "2022-02-02 11:00:25 | INFO | train | epoch 329 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 507.4 | ups 7.96 | wpb 63.7 | bsz 31.9 | num_updates 13818 | lr 3.40281e-05 | gnorm 0.685 | train_wall 2 | wall 1817\n",
      "epoch 330:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:00:25 | INFO | fairseq.trainer | begin training epoch 330\n",
      "epoch 330:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.07it/s]2022-02-02 11:00:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 330 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 330 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.50s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:00:30 | INFO | valid | epoch 330 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1211.6 | wpb 16 | bsz 8 | num_updates 13860 | best_loss 0.754\n",
      "2022-02-02 11:00:30 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:00:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint330.pt (epoch 330 @ 13860 updates, score 0.754) (writing took 0.03178511000010076 seconds)\n",
      "2022-02-02 11:00:30 | INFO | fairseq_cli.train | end of epoch 330 (average epoch stats below)\n",
      "2022-02-02 11:00:30 | INFO | train | epoch 330 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 506.8 | ups 7.95 | wpb 63.7 | bsz 31.9 | num_updates 13860 | lr 3.39765e-05 | gnorm 0.544 | train_wall 2 | wall 1822\n",
      "epoch 331:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:00:30 | INFO | fairseq.trainer | begin training epoch 331\n",
      "epoch 331:  95%|▉| 40/42 [00:03<00:00, 21.52it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 11:00:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 331 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 331 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:00:36 | INFO | valid | epoch 331 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1240.6 | wpb 16 | bsz 8 | num_updates 13902 | best_loss 0.754\n",
      "2022-02-02 11:00:36 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:00:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint331.pt (epoch 331 @ 13902 updates, score 0.755) (writing took 0.01873820499986323 seconds)\n",
      "2022-02-02 11:00:36 | INFO | fairseq_cli.train | end of epoch 331 (average epoch stats below)\n",
      "2022-02-02 11:00:36 | INFO | train | epoch 331 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 501.3 | ups 7.87 | wpb 63.7 | bsz 31.9 | num_updates 13902 | lr 3.39251e-05 | gnorm 0.611 | train_wall 2 | wall 1828\n",
      "epoch 332:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:00:36 | INFO | fairseq.trainer | begin training epoch 332\n",
      "epoch 332:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.77it/s]2022-02-02 11:00:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 332 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 332 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:00:41 | INFO | valid | epoch 332 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1220.8 | wpb 16 | bsz 8 | num_updates 13944 | best_loss 0.754\n",
      "2022-02-02 11:00:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:00:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint332.pt (epoch 332 @ 13944 updates, score 0.755) (writing took 0.018847820000019055 seconds)\n",
      "2022-02-02 11:00:41 | INFO | fairseq_cli.train | end of epoch 332 (average epoch stats below)\n",
      "2022-02-02 11:00:41 | INFO | train | epoch 332 | loss 0.744 | nll_loss 0.372 | accuracy 79 | wps 502.2 | ups 7.88 | wpb 63.7 | bsz 31.9 | num_updates 13944 | lr 3.3874e-05 | gnorm 0.61 | train_wall 2 | wall 1833\n",
      "epoch 333:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:00:41 | INFO | fairseq.trainer | begin training epoch 333\n",
      "epoch 333:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.98it/s]2022-02-02 11:00:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 333 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 333 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.50s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:00:46 | INFO | valid | epoch 333 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1211.7 | wpb 16 | bsz 8 | num_updates 13986 | best_loss 0.754\n",
      "2022-02-02 11:00:46 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:00:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint333.pt (epoch 333 @ 13986 updates, score 0.755) (writing took 0.023851562000118065 seconds)\n",
      "2022-02-02 11:00:46 | INFO | fairseq_cli.train | end of epoch 333 (average epoch stats below)\n",
      "2022-02-02 11:00:46 | INFO | train | epoch 333 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 507.1 | ups 7.96 | wpb 63.7 | bsz 31.9 | num_updates 13986 | lr 3.38231e-05 | gnorm 0.575 | train_wall 2 | wall 1838\n",
      "epoch 334:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:00:46 | INFO | fairseq.trainer | begin training epoch 334\n",
      "epoch 334:  95%|▉| 40/42 [00:03<00:00, 21.67it/s, loss=0.745, nll_loss=0.372, ac2022-02-02 11:00:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 334 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 334 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:00:51 | INFO | valid | epoch 334 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1203.3 | wpb 16 | bsz 8 | num_updates 14028 | best_loss 0.754\n",
      "2022-02-02 11:00:51 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:00:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint334.pt (epoch 334 @ 14028 updates, score 0.755) (writing took 0.01857580300020345 seconds)\n",
      "2022-02-02 11:00:51 | INFO | fairseq_cli.train | end of epoch 334 (average epoch stats below)\n",
      "2022-02-02 11:00:51 | INFO | train | epoch 334 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 505 | ups 7.93 | wpb 63.7 | bsz 31.9 | num_updates 14028 | lr 3.37724e-05 | gnorm 0.662 | train_wall 2 | wall 1843\n",
      "epoch 335:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:00:51 | INFO | fairseq.trainer | begin training epoch 335\n",
      "epoch 335:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.64it/s]2022-02-02 11:00:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 335 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 335 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:00:57 | INFO | valid | epoch 335 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1167.9 | wpb 16 | bsz 8 | num_updates 14070 | best_loss 0.754\n",
      "2022-02-02 11:00:57 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:00:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint335.pt (epoch 335 @ 14070 updates, score 0.754) (writing took 0.024046941000051447 seconds)\n",
      "2022-02-02 11:00:57 | INFO | fairseq_cli.train | end of epoch 335 (average epoch stats below)\n",
      "2022-02-02 11:00:57 | INFO | train | epoch 335 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 498 | ups 7.82 | wpb 63.7 | bsz 31.9 | num_updates 14070 | lr 3.3722e-05 | gnorm 0.533 | train_wall 2 | wall 1849\n",
      "epoch 336:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:00:57 | INFO | fairseq.trainer | begin training epoch 336\n",
      "epoch 336:  98%|▉| 41/42 [00:03<00:00, 19.57it/s, loss=0.748, nll_loss=0.374, ac2022-02-02 11:01:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 336 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 336 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:24,  1.77s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:01:03 | INFO | valid | epoch 336 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1116.5 | wpb 16 | bsz 8 | num_updates 14112 | best_loss 0.754\n",
      "2022-02-02 11:01:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:01:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint336.pt (epoch 336 @ 14112 updates, score 0.755) (writing took 0.027677420999907554 seconds)\n",
      "2022-02-02 11:01:03 | INFO | fairseq_cli.train | end of epoch 336 (average epoch stats below)\n",
      "2022-02-02 11:01:03 | INFO | train | epoch 336 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 454.6 | ups 7.13 | wpb 63.7 | bsz 31.9 | num_updates 14112 | lr 3.36718e-05 | gnorm 0.56 | train_wall 2 | wall 1855\n",
      "epoch 337:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:01:03 | INFO | fairseq.trainer | begin training epoch 337\n",
      "epoch 337:  98%|███████████████████████████████▏| 41/42 [00:04<00:00, 19.32it/s]2022-02-02 11:01:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 337 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 337 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:24,  1.78s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:01:09 | INFO | valid | epoch 337 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1017.8 | wpb 16 | bsz 8 | num_updates 14154 | best_loss 0.754\n",
      "2022-02-02 11:01:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:01:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint337.pt (epoch 337 @ 14154 updates, score 0.754) (writing took 0.03135879599994951 seconds)\n",
      "2022-02-02 11:01:09 | INFO | fairseq_cli.train | end of epoch 337 (average epoch stats below)\n",
      "2022-02-02 11:01:09 | INFO | train | epoch 337 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 419.4 | ups 6.58 | wpb 63.7 | bsz 31.9 | num_updates 14154 | lr 3.36218e-05 | gnorm 0.561 | train_wall 2 | wall 1861\n",
      "epoch 338:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:01:09 | INFO | fairseq.trainer | begin training epoch 338\n",
      "epoch 338:  98%|███████████████████████████████▏| 41/42 [00:03<00:00, 21.19it/s]2022-02-02 11:01:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 338 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 338 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:01:15 | INFO | valid | epoch 338 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1212.1 | wpb 16 | bsz 8 | num_updates 14196 | best_loss 0.754\n",
      "2022-02-02 11:01:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:01:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint338.pt (epoch 338 @ 14196 updates, score 0.754) (writing took 0.03935235799986003 seconds)\n",
      "2022-02-02 11:01:15 | INFO | fairseq_cli.train | end of epoch 338 (average epoch stats below)\n",
      "2022-02-02 11:01:15 | INFO | train | epoch 338 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 470.8 | ups 7.39 | wpb 63.7 | bsz 31.9 | num_updates 14196 | lr 3.3572e-05 | gnorm 0.529 | train_wall 2 | wall 1867\n",
      "epoch 339:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:01:15 | INFO | fairseq.trainer | begin training epoch 339\n",
      "epoch 339:  95%|▉| 40/42 [00:03<00:00, 19.25it/s, loss=0.738, nll_loss=0.369, ac2022-02-02 11:01:19 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 339 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 339 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:01:20 | INFO | valid | epoch 339 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1075 | wpb 16 | bsz 8 | num_updates 14238 | best_loss 0.754\n",
      "2022-02-02 11:01:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:01:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint339.pt (epoch 339 @ 14238 updates, score 0.755) (writing took 0.026527611000119578 seconds)\n",
      "2022-02-02 11:01:20 | INFO | fairseq_cli.train | end of epoch 339 (average epoch stats below)\n",
      "2022-02-02 11:01:20 | INFO | train | epoch 339 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 471.5 | ups 7.4 | wpb 63.7 | bsz 31.9 | num_updates 14238 | lr 3.35224e-05 | gnorm 0.652 | train_wall 2 | wall 1872\n",
      "epoch 340:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:01:20 | INFO | fairseq.trainer | begin training epoch 340\n",
      "epoch 340:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 19.76it/s]2022-02-02 11:01:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 340 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 340 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.63s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:01:26 | INFO | valid | epoch 340 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1121.8 | wpb 16 | bsz 8 | num_updates 14280 | best_loss 0.754\n",
      "2022-02-02 11:01:26 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:01:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint340.pt (epoch 340 @ 14280 updates, score 0.754) (writing took 0.04048766100004286 seconds)\n",
      "2022-02-02 11:01:26 | INFO | fairseq_cli.train | end of epoch 340 (average epoch stats below)\n",
      "2022-02-02 11:01:26 | INFO | train | epoch 340 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 471.4 | ups 7.4 | wpb 63.7 | bsz 31.9 | num_updates 14280 | lr 3.34731e-05 | gnorm 0.569 | train_wall 2 | wall 1878\n",
      "epoch 341:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:01:26 | INFO | fairseq.trainer | begin training epoch 341\n",
      "epoch 341:  95%|▉| 40/42 [00:03<00:00, 21.07it/s, loss=0.746, nll_loss=0.373, ac2022-02-02 11:01:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 341 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 341 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.63s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:01:32 | INFO | valid | epoch 341 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1206.3 | wpb 16 | bsz 8 | num_updates 14322 | best_loss 0.754\n",
      "2022-02-02 11:01:32 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:01:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint341.pt (epoch 341 @ 14322 updates, score 0.755) (writing took 0.02787465100004738 seconds)\n",
      "2022-02-02 11:01:32 | INFO | fairseq_cli.train | end of epoch 341 (average epoch stats below)\n",
      "2022-02-02 11:01:32 | INFO | train | epoch 341 | loss 0.741 | nll_loss 0.37 | accuracy 79 | wps 478 | ups 7.5 | wpb 63.7 | bsz 31.9 | num_updates 14322 | lr 3.3424e-05 | gnorm 0.587 | train_wall 2 | wall 1884\n",
      "epoch 342:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:01:32 | INFO | fairseq.trainer | begin training epoch 342\n",
      "epoch 342:  98%|███████████████████████████████▏| 41/42 [00:03<00:00, 20.79it/s]2022-02-02 11:01:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 342 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 342 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:25,  1.79s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:01:38 | INFO | valid | epoch 342 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1023.9 | wpb 16 | bsz 8 | num_updates 14364 | best_loss 0.754\n",
      "2022-02-02 11:01:38 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:01:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint342.pt (epoch 342 @ 14364 updates, score 0.755) (writing took 0.027741741999989245 seconds)\n",
      "2022-02-02 11:01:38 | INFO | fairseq_cli.train | end of epoch 342 (average epoch stats below)\n",
      "2022-02-02 11:01:38 | INFO | train | epoch 342 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 455.2 | ups 7.14 | wpb 63.7 | bsz 31.9 | num_updates 14364 | lr 3.33751e-05 | gnorm 0.536 | train_wall 2 | wall 1890\n",
      "epoch 343:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:01:38 | INFO | fairseq.trainer | begin training epoch 343\n",
      "epoch 343:  95%|▉| 40/42 [00:03<00:00, 19.27it/s, loss=0.738, nll_loss=0.369, ac2022-02-02 11:01:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 343 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 343 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:26,  1.87s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:01:44 | INFO | valid | epoch 343 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1183.8 | wpb 16 | bsz 8 | num_updates 14406 | best_loss 0.754\n",
      "2022-02-02 11:01:44 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:01:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint343.pt (epoch 343 @ 14406 updates, score 0.755) (writing took 0.024300506999907157 seconds)\n",
      "2022-02-02 11:01:44 | INFO | fairseq_cli.train | end of epoch 343 (average epoch stats below)\n",
      "2022-02-02 11:01:44 | INFO | train | epoch 343 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 437.2 | ups 6.86 | wpb 63.7 | bsz 31.9 | num_updates 14406 | lr 3.33264e-05 | gnorm 0.612 | train_wall 2 | wall 1896\n",
      "epoch 344:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:01:44 | INFO | fairseq.trainer | begin training epoch 344\n",
      "epoch 344:  98%|███████████████████████████████▏| 41/42 [00:03<00:00, 21.75it/s]2022-02-02 11:01:48 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 344 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 344 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:01:49 | INFO | valid | epoch 344 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1162.7 | wpb 16 | bsz 8 | num_updates 14448 | best_loss 0.754\n",
      "2022-02-02 11:01:49 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:01:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint344.pt (epoch 344 @ 14448 updates, score 0.754) (writing took 0.02495947200009141 seconds)\n",
      "2022-02-02 11:01:49 | INFO | fairseq_cli.train | end of epoch 344 (average epoch stats below)\n",
      "2022-02-02 11:01:49 | INFO | train | epoch 344 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 472.2 | ups 7.41 | wpb 63.7 | bsz 31.9 | num_updates 14448 | lr 3.32779e-05 | gnorm 0.625 | train_wall 2 | wall 1901\n",
      "epoch 345:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:01:49 | INFO | fairseq.trainer | begin training epoch 345\n",
      "epoch 345:  98%|███████████████████████████████▏| 41/42 [00:03<00:00, 20.91it/s]2022-02-02 11:01:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 345 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 345 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:01:55 | INFO | valid | epoch 345 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1125.1 | wpb 16 | bsz 8 | num_updates 14490 | best_loss 0.754\n",
      "2022-02-02 11:01:55 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:01:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint345.pt (epoch 345 @ 14490 updates, score 0.754) (writing took 0.039136299000119834 seconds)\n",
      "2022-02-02 11:01:55 | INFO | fairseq_cli.train | end of epoch 345 (average epoch stats below)\n",
      "2022-02-02 11:01:55 | INFO | train | epoch 345 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 474.8 | ups 7.45 | wpb 63.7 | bsz 31.9 | num_updates 14490 | lr 3.32297e-05 | gnorm 0.59 | train_wall 2 | wall 1907\n",
      "epoch 346:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:01:55 | INFO | fairseq.trainer | begin training epoch 346\n",
      "epoch 346:  95%|▉| 40/42 [00:03<00:00, 21.92it/s, loss=0.741, nll_loss=0.37, acc2022-02-02 11:01:59 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 346 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 346 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:02:00 | INFO | valid | epoch 346 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1157.8 | wpb 16 | bsz 8 | num_updates 14532 | best_loss 0.754\n",
      "2022-02-02 11:02:00 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:02:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint346.pt (epoch 346 @ 14532 updates, score 0.754) (writing took 0.04171274700001959 seconds)\n",
      "2022-02-02 11:02:00 | INFO | fairseq_cli.train | end of epoch 346 (average epoch stats below)\n",
      "2022-02-02 11:02:00 | INFO | train | epoch 346 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 492.7 | ups 7.73 | wpb 63.7 | bsz 31.9 | num_updates 14532 | lr 3.31816e-05 | gnorm 0.532 | train_wall 2 | wall 1912\n",
      "epoch 347:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:02:00 | INFO | fairseq.trainer | begin training epoch 347\n",
      "epoch 347:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.43it/s]2022-02-02 11:02:04 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 347 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 347 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.51s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:02:06 | INFO | valid | epoch 347 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1135.2 | wpb 16 | bsz 8 | num_updates 14574 | best_loss 0.754\n",
      "2022-02-02 11:02:06 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:02:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint347.pt (epoch 347 @ 14574 updates, score 0.754) (writing took 0.03443239600005654 seconds)\n",
      "2022-02-02 11:02:06 | INFO | fairseq_cli.train | end of epoch 347 (average epoch stats below)\n",
      "2022-02-02 11:02:06 | INFO | train | epoch 347 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 494.9 | ups 7.77 | wpb 63.7 | bsz 31.9 | num_updates 14574 | lr 3.31338e-05 | gnorm 0.513 | train_wall 2 | wall 1918\n",
      "epoch 348:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:02:06 | INFO | fairseq.trainer | begin training epoch 348\n",
      "epoch 348:  95%|▉| 40/42 [00:03<00:00, 21.57it/s, loss=0.747, nll_loss=0.374, ac2022-02-02 11:02:10 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 348 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 348 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:02:11 | INFO | valid | epoch 348 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1095.5 | wpb 16 | bsz 8 | num_updates 14616 | best_loss 0.754\n",
      "2022-02-02 11:02:11 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:02:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint348.pt (epoch 348 @ 14616 updates, score 0.755) (writing took 0.02785440299999209 seconds)\n",
      "2022-02-02 11:02:11 | INFO | fairseq_cli.train | end of epoch 348 (average epoch stats below)\n",
      "2022-02-02 11:02:11 | INFO | train | epoch 348 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 483.6 | ups 7.59 | wpb 63.7 | bsz 31.9 | num_updates 14616 | lr 3.30861e-05 | gnorm 0.66 | train_wall 2 | wall 1923\n",
      "epoch 349:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:02:11 | INFO | fairseq.trainer | begin training epoch 349\n",
      "epoch 349:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.74it/s]2022-02-02 11:02:15 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 349 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 349 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:02:17 | INFO | valid | epoch 349 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1116 | wpb 16 | bsz 8 | num_updates 14658 | best_loss 0.754\n",
      "2022-02-02 11:02:17 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:02:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint349.pt (epoch 349 @ 14658 updates, score 0.755) (writing took 0.028537294999978258 seconds)\n",
      "2022-02-02 11:02:17 | INFO | fairseq_cli.train | end of epoch 349 (average epoch stats below)\n",
      "2022-02-02 11:02:17 | INFO | train | epoch 349 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 489.1 | ups 7.68 | wpb 63.7 | bsz 31.9 | num_updates 14658 | lr 3.30387e-05 | gnorm 0.585 | train_wall 2 | wall 1929\n",
      "epoch 350:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:02:17 | INFO | fairseq.trainer | begin training epoch 350\n",
      "epoch 350:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.83it/s]2022-02-02 11:02:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 350 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 350 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:02:22 | INFO | valid | epoch 350 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1122.9 | wpb 16 | bsz 8 | num_updates 14700 | best_loss 0.754\n",
      "2022-02-02 11:02:22 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:02:22 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint350.pt (epoch 350 @ 14700 updates, score 0.756) (writing took 0.026888559999861172 seconds)\n",
      "2022-02-02 11:02:22 | INFO | fairseq_cli.train | end of epoch 350 (average epoch stats below)\n",
      "2022-02-02 11:02:22 | INFO | train | epoch 350 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 494.1 | ups 7.75 | wpb 63.7 | bsz 31.9 | num_updates 14700 | lr 3.29914e-05 | gnorm 0.66 | train_wall 2 | wall 1934\n",
      "epoch 351:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:02:22 | INFO | fairseq.trainer | begin training epoch 351\n",
      "epoch 351:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.43it/s]2022-02-02 11:02:26 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 351 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 351 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:02:28 | INFO | valid | epoch 351 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1181.9 | wpb 16 | bsz 8 | num_updates 14742 | best_loss 0.754\n",
      "2022-02-02 11:02:28 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:02:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint351.pt (epoch 351 @ 14742 updates, score 0.755) (writing took 0.01833145599994168 seconds)\n",
      "2022-02-02 11:02:28 | INFO | fairseq_cli.train | end of epoch 351 (average epoch stats below)\n",
      "2022-02-02 11:02:28 | INFO | train | epoch 351 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 500.6 | ups 7.86 | wpb 63.7 | bsz 31.9 | num_updates 14742 | lr 3.29444e-05 | gnorm 0.588 | train_wall 2 | wall 1940\n",
      "epoch 352:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:02:28 | INFO | fairseq.trainer | begin training epoch 352\n",
      "epoch 352:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.51it/s]2022-02-02 11:02:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 352 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 352 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:02:33 | INFO | valid | epoch 352 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1172.7 | wpb 16 | bsz 8 | num_updates 14784 | best_loss 0.754\n",
      "2022-02-02 11:02:33 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:02:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint352.pt (epoch 352 @ 14784 updates, score 0.755) (writing took 0.019392896999988807 seconds)\n",
      "2022-02-02 11:02:33 | INFO | fairseq_cli.train | end of epoch 352 (average epoch stats below)\n",
      "2022-02-02 11:02:33 | INFO | train | epoch 352 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 500.8 | ups 7.86 | wpb 63.7 | bsz 31.9 | num_updates 14784 | lr 3.28976e-05 | gnorm 0.62 | train_wall 2 | wall 1945\n",
      "epoch 353:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:02:33 | INFO | fairseq.trainer | begin training epoch 353\n",
      "epoch 353:  95%|▉| 40/42 [00:03<00:00, 21.86it/s, loss=0.746, nll_loss=0.373, ac2022-02-02 11:02:37 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 353 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 353 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:02:38 | INFO | valid | epoch 353 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1215.6 | wpb 16 | bsz 8 | num_updates 14826 | best_loss 0.754\n",
      "2022-02-02 11:02:38 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:02:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint353.pt (epoch 353 @ 14826 updates, score 0.755) (writing took 0.025233762999960163 seconds)\n",
      "2022-02-02 11:02:38 | INFO | fairseq_cli.train | end of epoch 353 (average epoch stats below)\n",
      "2022-02-02 11:02:38 | INFO | train | epoch 353 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 492.3 | ups 7.73 | wpb 63.7 | bsz 31.9 | num_updates 14826 | lr 3.2851e-05 | gnorm 0.604 | train_wall 2 | wall 1950\n",
      "epoch 354:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:02:38 | INFO | fairseq.trainer | begin training epoch 354\n",
      "epoch 354:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 22.03it/s]2022-02-02 11:02:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 354 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 354 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:02:44 | INFO | valid | epoch 354 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1077 | wpb 16 | bsz 8 | num_updates 14868 | best_loss 0.754\n",
      "2022-02-02 11:02:44 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:02:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint354.pt (epoch 354 @ 14868 updates, score 0.755) (writing took 0.02409319699995649 seconds)\n",
      "2022-02-02 11:02:44 | INFO | fairseq_cli.train | end of epoch 354 (average epoch stats below)\n",
      "2022-02-02 11:02:44 | INFO | train | epoch 354 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 504.6 | ups 7.92 | wpb 63.7 | bsz 31.9 | num_updates 14868 | lr 3.28045e-05 | gnorm 0.602 | train_wall 2 | wall 1956\n",
      "epoch 355:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:02:44 | INFO | fairseq.trainer | begin training epoch 355\n",
      "epoch 355:  95%|▉| 40/42 [00:03<00:00, 21.48it/s, loss=0.73, nll_loss=0.365, acc2022-02-02 11:02:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 355 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 355 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:02:49 | INFO | valid | epoch 355 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1199.7 | wpb 16 | bsz 8 | num_updates 14910 | best_loss 0.754\n",
      "2022-02-02 11:02:49 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:02:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint355.pt (epoch 355 @ 14910 updates, score 0.755) (writing took 0.01803230599989547 seconds)\n",
      "2022-02-02 11:02:49 | INFO | fairseq_cli.train | end of epoch 355 (average epoch stats below)\n",
      "2022-02-02 11:02:49 | INFO | train | epoch 355 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 500.5 | ups 7.86 | wpb 63.7 | bsz 31.9 | num_updates 14910 | lr 3.27583e-05 | gnorm 0.614 | train_wall 2 | wall 1961\n",
      "epoch 356:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:02:49 | INFO | fairseq.trainer | begin training epoch 356\n",
      "epoch 356:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.87it/s]2022-02-02 11:02:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 356 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 356 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:02:54 | INFO | valid | epoch 356 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1194.4 | wpb 16 | bsz 8 | num_updates 14952 | best_loss 0.754\n",
      "2022-02-02 11:02:54 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:02:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint356.pt (epoch 356 @ 14952 updates, score 0.754) (writing took 0.022068922000016755 seconds)\n",
      "2022-02-02 11:02:54 | INFO | fairseq_cli.train | end of epoch 356 (average epoch stats below)\n",
      "2022-02-02 11:02:54 | INFO | train | epoch 356 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 503.7 | ups 7.91 | wpb 63.7 | bsz 31.9 | num_updates 14952 | lr 3.27122e-05 | gnorm 0.599 | train_wall 2 | wall 1966\n",
      "epoch 357:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:02:54 | INFO | fairseq.trainer | begin training epoch 357\n",
      "epoch 357:  98%|███████████████████████████████▏| 41/42 [00:03<00:00, 21.85it/s]2022-02-02 11:02:58 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 357 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 357 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.67s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:03:00 | INFO | valid | epoch 357 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1146.8 | wpb 16 | bsz 8 | num_updates 14994 | best_loss 0.754\n",
      "2022-02-02 11:03:00 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:03:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint357.pt (epoch 357 @ 14994 updates, score 0.755) (writing took 0.024881763999928808 seconds)\n",
      "2022-02-02 11:03:00 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)\n",
      "2022-02-02 11:03:00 | INFO | train | epoch 357 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 480.3 | ups 7.54 | wpb 63.7 | bsz 31.9 | num_updates 14994 | lr 3.26664e-05 | gnorm 0.654 | train_wall 2 | wall 1972\n",
      "epoch 358:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:03:00 | INFO | fairseq.trainer | begin training epoch 358\n",
      "epoch 358:  10%|███▏                             | 4/42 [00:02<00:15,  2.52it/s]2022-02-02 11:03:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 358 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 358 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:25,  1.79s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:03:04 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1063.1 | wpb 16 | bsz 8 | num_updates 15000 | best_loss 0.754\n",
      "2022-02-02 11:03:04 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:03:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint_358_15000.pt (epoch 358 @ 15000 updates, score 0.754) (writing took 0.02867950000018027 seconds)\n",
      "epoch 358:  93%|▉| 39/42 [00:05<00:00, 20.37it/s, loss=0.749, nll_loss=0.375, ac2022-02-02 11:03:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 358 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 358 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:03:08 | INFO | valid | epoch 358 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 907.1 | wpb 16 | bsz 8 | num_updates 15036 | best_loss 0.754\n",
      "2022-02-02 11:03:08 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:03:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint358.pt (epoch 358 @ 15036 updates, score 0.754) (writing took 0.03679523499999959 seconds)\n",
      "2022-02-02 11:03:08 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)\n",
      "2022-02-02 11:03:08 | INFO | train | epoch 358 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 338.3 | ups 5.31 | wpb 63.7 | bsz 31.9 | num_updates 15036 | lr 3.26207e-05 | gnorm 0.645 | train_wall 2 | wall 1980\n",
      "epoch 359:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:03:08 | INFO | fairseq.trainer | begin training epoch 359\n",
      "epoch 359:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.88it/s]2022-02-02 11:03:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 359 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 359 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:03:13 | INFO | valid | epoch 359 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1217.3 | wpb 16 | bsz 8 | num_updates 15078 | best_loss 0.754\n",
      "2022-02-02 11:03:13 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:03:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint359.pt (epoch 359 @ 15078 updates, score 0.754) (writing took 0.034401882999873123 seconds)\n",
      "2022-02-02 11:03:13 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)\n",
      "2022-02-02 11:03:13 | INFO | train | epoch 359 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 474.8 | ups 7.45 | wpb 63.7 | bsz 31.9 | num_updates 15078 | lr 3.25753e-05 | gnorm 0.593 | train_wall 2 | wall 1985\n",
      "epoch 360:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:03:13 | INFO | fairseq.trainer | begin training epoch 360\n",
      "epoch 360:  95%|▉| 40/42 [00:03<00:00, 20.47it/s, loss=0.746, nll_loss=0.373, ac2022-02-02 11:03:17 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 360 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 360 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:03:19 | INFO | valid | epoch 360 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1270.2 | wpb 16 | bsz 8 | num_updates 15120 | best_loss 0.754\n",
      "2022-02-02 11:03:19 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:03:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint360.pt (epoch 360 @ 15120 updates, score 0.754) (writing took 0.038380520999908185 seconds)\n",
      "2022-02-02 11:03:19 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)\n",
      "2022-02-02 11:03:19 | INFO | train | epoch 360 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 498 | ups 7.82 | wpb 63.7 | bsz 31.9 | num_updates 15120 | lr 3.253e-05 | gnorm 0.595 | train_wall 2 | wall 1991\n",
      "epoch 361:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:03:19 | INFO | fairseq.trainer | begin training epoch 361\n",
      "epoch 361:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.37it/s]2022-02-02 11:03:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 361 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 361 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:03:24 | INFO | valid | epoch 361 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1195.6 | wpb 16 | bsz 8 | num_updates 15162 | best_loss 0.754\n",
      "2022-02-02 11:03:24 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:03:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint361.pt (epoch 361 @ 15162 updates, score 0.755) (writing took 0.026536924000083673 seconds)\n",
      "2022-02-02 11:03:24 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)\n",
      "2022-02-02 11:03:24 | INFO | train | epoch 361 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 498.5 | ups 7.82 | wpb 63.7 | bsz 31.9 | num_updates 15162 | lr 3.24849e-05 | gnorm 0.585 | train_wall 2 | wall 1996\n",
      "epoch 362:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:03:24 | INFO | fairseq.trainer | begin training epoch 362\n",
      "epoch 362:  95%|▉| 40/42 [00:03<00:00, 21.76it/s, loss=0.737, nll_loss=0.368, ac2022-02-02 11:03:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 362 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 362 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:03:30 | INFO | valid | epoch 362 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1247.2 | wpb 16 | bsz 8 | num_updates 15204 | best_loss 0.754\n",
      "2022-02-02 11:03:30 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:03:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint362.pt (epoch 362 @ 15204 updates, score 0.755) (writing took 0.024941260000105103 seconds)\n",
      "2022-02-02 11:03:30 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)\n",
      "2022-02-02 11:03:30 | INFO | train | epoch 362 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 498.9 | ups 7.83 | wpb 63.7 | bsz 31.9 | num_updates 15204 | lr 3.244e-05 | gnorm 0.602 | train_wall 2 | wall 2002\n",
      "epoch 363:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:03:30 | INFO | fairseq.trainer | begin training epoch 363\n",
      "epoch 363:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.23it/s]2022-02-02 11:03:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 363 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 363 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:03:35 | INFO | valid | epoch 363 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1167.1 | wpb 16 | bsz 8 | num_updates 15246 | best_loss 0.754\n",
      "2022-02-02 11:03:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:03:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint363.pt (epoch 363 @ 15246 updates, score 0.755) (writing took 0.0309033940000063 seconds)\n",
      "2022-02-02 11:03:35 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)\n",
      "2022-02-02 11:03:35 | INFO | train | epoch 363 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 502.1 | ups 7.88 | wpb 63.7 | bsz 31.9 | num_updates 15246 | lr 3.23953e-05 | gnorm 0.556 | train_wall 2 | wall 2007\n",
      "epoch 364:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:03:35 | INFO | fairseq.trainer | begin training epoch 364\n",
      "epoch 364:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.15it/s]2022-02-02 11:03:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 364 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 364 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:03:40 | INFO | valid | epoch 364 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1328.5 | wpb 16 | bsz 8 | num_updates 15288 | best_loss 0.754\n",
      "2022-02-02 11:03:40 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:03:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint364.pt (epoch 364 @ 15288 updates, score 0.755) (writing took 0.036116539999966335 seconds)\n",
      "2022-02-02 11:03:40 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)\n",
      "2022-02-02 11:03:40 | INFO | train | epoch 364 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 499.6 | ups 7.84 | wpb 63.7 | bsz 31.9 | num_updates 15288 | lr 3.23508e-05 | gnorm 0.703 | train_wall 2 | wall 2012\n",
      "epoch 365:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:03:40 | INFO | fairseq.trainer | begin training epoch 365\n",
      "epoch 365:  95%|▉| 40/42 [00:03<00:00, 21.41it/s, loss=0.751, nll_loss=0.376, ac2022-02-02 11:03:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 365 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 365 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:03:46 | INFO | valid | epoch 365 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1318.1 | wpb 16 | bsz 8 | num_updates 15330 | best_loss 0.754\n",
      "2022-02-02 11:03:46 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:03:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint365.pt (epoch 365 @ 15330 updates, score 0.755) (writing took 0.03662000400004217 seconds)\n",
      "2022-02-02 11:03:46 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)\n",
      "2022-02-02 11:03:46 | INFO | train | epoch 365 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 504.4 | ups 7.92 | wpb 63.7 | bsz 31.9 | num_updates 15330 | lr 3.23064e-05 | gnorm 0.574 | train_wall 2 | wall 2018\n",
      "epoch 366:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:03:46 | INFO | fairseq.trainer | begin training epoch 366\n",
      "epoch 366:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.13it/s]2022-02-02 11:03:49 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 366 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 366 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:03:51 | INFO | valid | epoch 366 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1297 | wpb 16 | bsz 8 | num_updates 15372 | best_loss 0.754\n",
      "2022-02-02 11:03:51 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:03:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint366.pt (epoch 366 @ 15372 updates, score 0.756) (writing took 0.021978459999900224 seconds)\n",
      "2022-02-02 11:03:51 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)\n",
      "2022-02-02 11:03:51 | INFO | train | epoch 366 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 485.8 | ups 7.62 | wpb 63.7 | bsz 31.9 | num_updates 15372 | lr 3.22623e-05 | gnorm 0.596 | train_wall 2 | wall 2023\n",
      "epoch 367:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:03:51 | INFO | fairseq.trainer | begin training epoch 367\n",
      "epoch 367:  93%|▉| 39/42 [00:03<00:00, 21.85it/s, loss=0.732, nll_loss=0.366, ac2022-02-02 11:03:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 367 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 367 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:03:57 | INFO | valid | epoch 367 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1155.2 | wpb 16 | bsz 8 | num_updates 15414 | best_loss 0.754\n",
      "2022-02-02 11:03:57 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:03:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint367.pt (epoch 367 @ 15414 updates, score 0.754) (writing took 0.028452509000089776 seconds)\n",
      "2022-02-02 11:03:57 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)\n",
      "2022-02-02 11:03:57 | INFO | train | epoch 367 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 486.6 | ups 7.64 | wpb 63.7 | bsz 31.9 | num_updates 15414 | lr 3.22183e-05 | gnorm 0.552 | train_wall 2 | wall 2029\n",
      "epoch 368:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:03:57 | INFO | fairseq.trainer | begin training epoch 368\n",
      "epoch 368:  98%|███████████████████████████████▏| 41/42 [00:04<00:00, 21.11it/s]2022-02-02 11:04:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 368 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 368 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:04:02 | INFO | valid | epoch 368 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1092.1 | wpb 16 | bsz 8 | num_updates 15456 | best_loss 0.754\n",
      "2022-02-02 11:04:02 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:04:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint368.pt (epoch 368 @ 15456 updates, score 0.755) (writing took 0.024661509999987175 seconds)\n",
      "2022-02-02 11:04:03 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)\n",
      "2022-02-02 11:04:03 | INFO | train | epoch 368 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 452.7 | ups 7.11 | wpb 63.7 | bsz 31.9 | num_updates 15456 | lr 3.21745e-05 | gnorm 0.623 | train_wall 2 | wall 2035\n",
      "epoch 369:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:04:03 | INFO | fairseq.trainer | begin training epoch 369\n",
      "epoch 369:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.67it/s]2022-02-02 11:04:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 369 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 369 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.66s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:04:08 | INFO | valid | epoch 369 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1153.8 | wpb 16 | bsz 8 | num_updates 15498 | best_loss 0.754\n",
      "2022-02-02 11:04:08 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:04:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint369.pt (epoch 369 @ 15498 updates, score 0.755) (writing took 0.02500438399988525 seconds)\n",
      "2022-02-02 11:04:08 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)\n",
      "2022-02-02 11:04:08 | INFO | train | epoch 369 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 471.5 | ups 7.4 | wpb 63.7 | bsz 31.9 | num_updates 15498 | lr 3.21308e-05 | gnorm 0.55 | train_wall 2 | wall 2040\n",
      "epoch 370:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:04:08 | INFO | fairseq.trainer | begin training epoch 370\n",
      "epoch 370:  98%|▉| 41/42 [00:05<00:00, 15.86it/s, loss=0.745, nll_loss=0.373, ac2022-02-02 11:04:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 370 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 370 | valid on 'valid' subset:   7%|▍      | 1/15 [00:02<00:29,  2.13s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:04:16 | INFO | valid | epoch 370 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 999.4 | wpb 16 | bsz 8 | num_updates 15540 | best_loss 0.754\n",
      "2022-02-02 11:04:16 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:04:16 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint370.pt (epoch 370 @ 15540 updates, score 0.755) (writing took 0.029843683000308374 seconds)\n",
      "2022-02-02 11:04:16 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)\n",
      "2022-02-02 11:04:16 | INFO | train | epoch 370 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 354.2 | ups 5.56 | wpb 63.7 | bsz 31.9 | num_updates 15540 | lr 3.20874e-05 | gnorm 0.626 | train_wall 3 | wall 2048\n",
      "epoch 371:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:04:16 | INFO | fairseq.trainer | begin training epoch 371\n",
      "epoch 371:  98%|███████████████████████████████▏| 41/42 [00:05<00:00, 13.48it/s]2022-02-02 11:04:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 371 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 371 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:27,  1.93s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:04:24 | INFO | valid | epoch 371 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1081.2 | wpb 16 | bsz 8 | num_updates 15582 | best_loss 0.754\n",
      "2022-02-02 11:04:24 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:04:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint371.pt (epoch 371 @ 15582 updates, score 0.755) (writing took 0.02274880300001314 seconds)\n",
      "2022-02-02 11:04:24 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)\n",
      "2022-02-02 11:04:24 | INFO | train | epoch 371 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 332.1 | ups 5.21 | wpb 63.7 | bsz 31.9 | num_updates 15582 | lr 3.20441e-05 | gnorm 0.644 | train_wall 3 | wall 2056\n",
      "epoch 372:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:04:24 | INFO | fairseq.trainer | begin training epoch 372\n",
      "epoch 372:  98%|▉| 41/42 [00:03<00:00, 18.81it/s, loss=0.738, nll_loss=0.369, ac2022-02-02 11:04:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 372 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 372 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:04:29 | INFO | valid | epoch 372 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1229.5 | wpb 16 | bsz 8 | num_updates 15624 | best_loss 0.754\n",
      "2022-02-02 11:04:29 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:04:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint372.pt (epoch 372 @ 15624 updates, score 0.755) (writing took 0.024736860999837518 seconds)\n",
      "2022-02-02 11:04:30 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)\n",
      "2022-02-02 11:04:30 | INFO | train | epoch 372 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 469 | ups 7.36 | wpb 63.7 | bsz 31.9 | num_updates 15624 | lr 3.2001e-05 | gnorm 0.684 | train_wall 2 | wall 2062\n",
      "epoch 373:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:04:30 | INFO | fairseq.trainer | begin training epoch 373\n",
      "epoch 373:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 18.54it/s]2022-02-02 11:04:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 373 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 373 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.69s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:04:35 | INFO | valid | epoch 373 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1112.4 | wpb 16 | bsz 8 | num_updates 15666 | best_loss 0.754\n",
      "2022-02-02 11:04:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:04:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint373.pt (epoch 373 @ 15666 updates, score 0.754) (writing took 0.041476038999917364 seconds)\n",
      "2022-02-02 11:04:35 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)\n",
      "2022-02-02 11:04:35 | INFO | train | epoch 373 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 457.1 | ups 7.17 | wpb 63.7 | bsz 31.9 | num_updates 15666 | lr 3.19581e-05 | gnorm 0.601 | train_wall 2 | wall 2067\n",
      "epoch 374:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:04:35 | INFO | fairseq.trainer | begin training epoch 374\n",
      "epoch 374:  93%|▉| 39/42 [00:03<00:00, 20.92it/s, loss=0.746, nll_loss=0.373, ac2022-02-02 11:04:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 374 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 374 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.67s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:04:41 | INFO | valid | epoch 374 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1249.8 | wpb 16 | bsz 8 | num_updates 15708 | best_loss 0.754\n",
      "2022-02-02 11:04:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:04:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint374.pt (epoch 374 @ 15708 updates, score 0.755) (writing took 0.02957900600040375 seconds)\n",
      "2022-02-02 11:04:41 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)\n",
      "2022-02-02 11:04:41 | INFO | train | epoch 374 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 463.1 | ups 7.27 | wpb 63.7 | bsz 31.9 | num_updates 15708 | lr 3.19153e-05 | gnorm 0.633 | train_wall 2 | wall 2073\n",
      "epoch 375:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:04:41 | INFO | fairseq.trainer | begin training epoch 375\n",
      "epoch 375:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.57it/s]2022-02-02 11:04:45 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 375 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 375 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.68s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:04:47 | INFO | valid | epoch 375 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1014.9 | wpb 16 | bsz 8 | num_updates 15750 | best_loss 0.754\n",
      "2022-02-02 11:04:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:04:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint375.pt (epoch 375 @ 15750 updates, score 0.754) (writing took 0.02726740099978997 seconds)\n",
      "2022-02-02 11:04:47 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)\n",
      "2022-02-02 11:04:47 | INFO | train | epoch 375 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 466.7 | ups 7.32 | wpb 63.7 | bsz 31.9 | num_updates 15750 | lr 3.18728e-05 | gnorm 0.631 | train_wall 2 | wall 2079\n",
      "epoch 376:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:04:47 | INFO | fairseq.trainer | begin training epoch 376\n",
      "epoch 376:  95%|██████████████████████████████▍ | 40/42 [00:04<00:00, 20.79it/s]2022-02-02 11:04:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 376 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 376 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:24,  1.76s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:04:53 | INFO | valid | epoch 376 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1146.3 | wpb 16 | bsz 8 | num_updates 15792 | best_loss 0.754\n",
      "2022-02-02 11:04:53 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:04:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint376.pt (epoch 376 @ 15792 updates, score 0.755) (writing took 0.030101577000095858 seconds)\n",
      "2022-02-02 11:04:53 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)\n",
      "2022-02-02 11:04:53 | INFO | train | epoch 376 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 411.7 | ups 6.46 | wpb 63.7 | bsz 31.9 | num_updates 15792 | lr 3.18304e-05 | gnorm 0.635 | train_wall 2 | wall 2085\n",
      "epoch 377:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:04:53 | INFO | fairseq.trainer | begin training epoch 377\n",
      "epoch 377:  98%|▉| 41/42 [00:03<00:00, 20.90it/s, loss=0.751, nll_loss=0.375, ac2022-02-02 11:04:57 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 377 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 377 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.65s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:04:59 | INFO | valid | epoch 377 | valid on 'valid' subset | loss 0.756 | nll_loss 0.378 | accuracy 78.3 | wps 1200.8 | wpb 16 | bsz 8 | num_updates 15834 | best_loss 0.754\n",
      "2022-02-02 11:04:59 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:04:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint377.pt (epoch 377 @ 15834 updates, score 0.756) (writing took 0.018896202000178164 seconds)\n",
      "2022-02-02 11:04:59 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)\n",
      "2022-02-02 11:04:59 | INFO | train | epoch 377 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 478.4 | ups 7.51 | wpb 63.7 | bsz 31.9 | num_updates 15834 | lr 3.17881e-05 | gnorm 0.616 | train_wall 2 | wall 2091\n",
      "epoch 378:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:04:59 | INFO | fairseq.trainer | begin training epoch 378\n",
      "epoch 378:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 19.22it/s]2022-02-02 11:05:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 378 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 378 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.68s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:05:05 | INFO | valid | epoch 378 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1181.5 | wpb 16 | bsz 8 | num_updates 15876 | best_loss 0.754\n",
      "2022-02-02 11:05:05 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:05:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint378.pt (epoch 378 @ 15876 updates, score 0.755) (writing took 0.029617955000048823 seconds)\n",
      "2022-02-02 11:05:05 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)\n",
      "2022-02-02 11:05:05 | INFO | train | epoch 378 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 456.1 | ups 7.16 | wpb 63.7 | bsz 31.9 | num_updates 15876 | lr 3.1746e-05 | gnorm 0.608 | train_wall 2 | wall 2097\n",
      "epoch 379:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:05:05 | INFO | fairseq.trainer | begin training epoch 379\n",
      "epoch 379:  98%|▉| 41/42 [00:03<00:00, 20.20it/s, loss=0.737, nll_loss=0.368, ac2022-02-02 11:05:09 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 379 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 379 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:24,  1.74s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:05:11 | INFO | valid | epoch 379 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1083.5 | wpb 16 | bsz 8 | num_updates 15918 | best_loss 0.754\n",
      "2022-02-02 11:05:11 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:05:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint379.pt (epoch 379 @ 15918 updates, score 0.754) (writing took 0.038610331999734626 seconds)\n",
      "2022-02-02 11:05:11 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)\n",
      "2022-02-02 11:05:11 | INFO | train | epoch 379 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 454.1 | ups 7.13 | wpb 63.7 | bsz 31.9 | num_updates 15918 | lr 3.17041e-05 | gnorm 0.571 | train_wall 2 | wall 2103\n",
      "epoch 380:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:05:11 | INFO | fairseq.trainer | begin training epoch 380\n",
      "epoch 380:  93%|█████████████████████████████▋  | 39/42 [00:04<00:00, 20.37it/s]2022-02-02 11:05:15 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 380 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 380 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.64s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:05:17 | INFO | valid | epoch 380 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1211.5 | wpb 16 | bsz 8 | num_updates 15960 | best_loss 0.754\n",
      "2022-02-02 11:05:17 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:05:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint380.pt (epoch 380 @ 15960 updates, score 0.755) (writing took 0.033069892000185064 seconds)\n",
      "2022-02-02 11:05:17 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)\n",
      "2022-02-02 11:05:17 | INFO | train | epoch 380 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 435.8 | ups 6.84 | wpb 63.7 | bsz 31.9 | num_updates 15960 | lr 3.16624e-05 | gnorm 0.536 | train_wall 2 | wall 2109\n",
      "epoch 381:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:05:17 | INFO | fairseq.trainer | begin training epoch 381\n",
      "epoch 381:  95%|▉| 40/42 [00:03<00:00, 20.53it/s, loss=0.738, nll_loss=0.369, ac2022-02-02 11:05:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 381 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 381 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.63s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:05:23 | INFO | valid | epoch 381 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1172.5 | wpb 16 | bsz 8 | num_updates 16002 | best_loss 0.754\n",
      "2022-02-02 11:05:23 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:05:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint381.pt (epoch 381 @ 16002 updates, score 0.755) (writing took 0.03142610499980947 seconds)\n",
      "2022-02-02 11:05:23 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)\n",
      "2022-02-02 11:05:23 | INFO | train | epoch 381 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 471.8 | ups 7.41 | wpb 63.7 | bsz 31.9 | num_updates 16002 | lr 3.16208e-05 | gnorm 0.592 | train_wall 2 | wall 2115\n",
      "epoch 382:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:05:23 | INFO | fairseq.trainer | begin training epoch 382\n",
      "epoch 382:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 20.99it/s]2022-02-02 11:05:26 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 382 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 382 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.65s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:05:28 | INFO | valid | epoch 382 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1294.1 | wpb 16 | bsz 8 | num_updates 16044 | best_loss 0.754\n",
      "2022-02-02 11:05:28 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:05:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint382.pt (epoch 382 @ 16044 updates, score 0.754) (writing took 0.04005731100005505 seconds)\n",
      "2022-02-02 11:05:28 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)\n",
      "2022-02-02 11:05:28 | INFO | train | epoch 382 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 477.7 | ups 7.5 | wpb 63.7 | bsz 31.9 | num_updates 16044 | lr 3.15794e-05 | gnorm 0.524 | train_wall 2 | wall 2120\n",
      "epoch 383:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:05:28 | INFO | fairseq.trainer | begin training epoch 383\n",
      "epoch 383:  95%|██████████████████████████████▍ | 40/42 [00:04<00:00, 20.07it/s]2022-02-02 11:05:32 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 383 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 383 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:24,  1.74s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:05:34 | INFO | valid | epoch 383 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1224.2 | wpb 16 | bsz 8 | num_updates 16086 | best_loss 0.754\n",
      "2022-02-02 11:05:34 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:05:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint383.pt (epoch 383 @ 16086 updates, score 0.754) (writing took 0.030503428999963944 seconds)\n",
      "2022-02-02 11:05:34 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)\n",
      "2022-02-02 11:05:34 | INFO | train | epoch 383 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 434.9 | ups 6.83 | wpb 63.7 | bsz 31.9 | num_updates 16086 | lr 3.15381e-05 | gnorm 0.662 | train_wall 2 | wall 2126\n",
      "epoch 384:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:05:34 | INFO | fairseq.trainer | begin training epoch 384\n",
      "epoch 384:  93%|▉| 39/42 [00:04<00:00, 20.55it/s, loss=0.737, nll_loss=0.369, ac2022-02-02 11:05:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 384 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 384 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.64s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:05:40 | INFO | valid | epoch 384 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1126.5 | wpb 16 | bsz 8 | num_updates 16128 | best_loss 0.754\n",
      "2022-02-02 11:05:40 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:05:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint384.pt (epoch 384 @ 16128 updates, score 0.754) (writing took 0.038485862000015914 seconds)\n",
      "2022-02-02 11:05:40 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)\n",
      "2022-02-02 11:05:40 | INFO | train | epoch 384 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 436.8 | ups 6.86 | wpb 63.7 | bsz 31.9 | num_updates 16128 | lr 3.1497e-05 | gnorm 0.665 | train_wall 2 | wall 2132\n",
      "epoch 385:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:05:40 | INFO | fairseq.trainer | begin training epoch 385\n",
      "epoch 385:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 19.36it/s]2022-02-02 11:05:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 385 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 385 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:05:46 | INFO | valid | epoch 385 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1246 | wpb 16 | bsz 8 | num_updates 16170 | best_loss 0.754\n",
      "2022-02-02 11:05:46 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:05:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint385.pt (epoch 385 @ 16170 updates, score 0.755) (writing took 0.02619125000001077 seconds)\n",
      "2022-02-02 11:05:46 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)\n",
      "2022-02-02 11:05:46 | INFO | train | epoch 385 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 468.9 | ups 7.36 | wpb 63.7 | bsz 31.9 | num_updates 16170 | lr 3.14561e-05 | gnorm 0.611 | train_wall 2 | wall 2138\n",
      "epoch 386:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:05:46 | INFO | fairseq.trainer | begin training epoch 386\n",
      "epoch 386:  98%|▉| 41/42 [00:03<00:00, 17.10it/s, loss=0.754, nll_loss=0.377, ac2022-02-02 11:05:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 386 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 386 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:05:52 | INFO | valid | epoch 386 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1156.3 | wpb 16 | bsz 8 | num_updates 16212 | best_loss 0.754\n",
      "2022-02-02 11:05:52 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:05:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint386.pt (epoch 386 @ 16212 updates, score 0.754) (writing took 0.023639826999897195 seconds)\n",
      "2022-02-02 11:05:52 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)\n",
      "2022-02-02 11:05:52 | INFO | train | epoch 386 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 466.1 | ups 7.32 | wpb 63.7 | bsz 31.9 | num_updates 16212 | lr 3.14153e-05 | gnorm 0.744 | train_wall 2 | wall 2144\n",
      "epoch 387:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:05:52 | INFO | fairseq.trainer | begin training epoch 387\n",
      "epoch 387:  95%|██████████████████████████████▍ | 40/42 [00:04<00:00, 19.13it/s]2022-02-02 11:05:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 387 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 387 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:24,  1.76s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:05:58 | INFO | valid | epoch 387 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1185.8 | wpb 16 | bsz 8 | num_updates 16254 | best_loss 0.754\n",
      "2022-02-02 11:05:58 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:05:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint387.pt (epoch 387 @ 16254 updates, score 0.754) (writing took 0.031143577999955596 seconds)\n",
      "2022-02-02 11:05:58 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)\n",
      "2022-02-02 11:05:58 | INFO | train | epoch 387 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 435.8 | ups 6.84 | wpb 63.7 | bsz 31.9 | num_updates 16254 | lr 3.13747e-05 | gnorm 0.631 | train_wall 2 | wall 2150\n",
      "epoch 388:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:05:58 | INFO | fairseq.trainer | begin training epoch 388\n",
      "epoch 388:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.16it/s]2022-02-02 11:06:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 388 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 388 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:06:04 | INFO | valid | epoch 388 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1177.7 | wpb 16 | bsz 8 | num_updates 16296 | best_loss 0.754\n",
      "2022-02-02 11:06:04 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:06:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint388.pt (epoch 388 @ 16296 updates, score 0.755) (writing took 0.02774138699987816 seconds)\n",
      "2022-02-02 11:06:04 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)\n",
      "2022-02-02 11:06:04 | INFO | train | epoch 388 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 454.9 | ups 7.14 | wpb 63.7 | bsz 31.9 | num_updates 16296 | lr 3.13343e-05 | gnorm 0.583 | train_wall 2 | wall 2156\n",
      "epoch 389:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:06:04 | INFO | fairseq.trainer | begin training epoch 389\n",
      "epoch 389:  95%|▉| 40/42 [00:03<00:00, 21.47it/s, loss=0.744, nll_loss=0.372, ac2022-02-02 11:06:08 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 389 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 389 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:06:09 | INFO | valid | epoch 389 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1211 | wpb 16 | bsz 8 | num_updates 16338 | best_loss 0.754\n",
      "2022-02-02 11:06:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:06:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint389.pt (epoch 389 @ 16338 updates, score 0.754) (writing took 0.03643606200012073 seconds)\n",
      "2022-02-02 11:06:09 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)\n",
      "2022-02-02 11:06:09 | INFO | train | epoch 389 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 489.2 | ups 7.68 | wpb 63.7 | bsz 31.9 | num_updates 16338 | lr 3.1294e-05 | gnorm 0.665 | train_wall 2 | wall 2161\n",
      "epoch 390:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:06:09 | INFO | fairseq.trainer | begin training epoch 390\n",
      "epoch 390:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.59it/s]2022-02-02 11:06:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 390 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 390 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:06:15 | INFO | valid | epoch 390 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1122.6 | wpb 16 | bsz 8 | num_updates 16380 | best_loss 0.754\n",
      "2022-02-02 11:06:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:06:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint390.pt (epoch 390 @ 16380 updates, score 0.754) (writing took 0.03594862899990403 seconds)\n",
      "2022-02-02 11:06:15 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)\n",
      "2022-02-02 11:06:15 | INFO | train | epoch 390 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 473.6 | ups 7.43 | wpb 63.7 | bsz 31.9 | num_updates 16380 | lr 3.12538e-05 | gnorm 0.595 | train_wall 2 | wall 2167\n",
      "epoch 391:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:06:15 | INFO | fairseq.trainer | begin training epoch 391\n",
      "epoch 391:  95%|▉| 40/42 [00:03<00:00, 21.33it/s, loss=0.74, nll_loss=0.37, accu2022-02-02 11:06:19 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 391 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 391 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:06:20 | INFO | valid | epoch 391 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1282.6 | wpb 16 | bsz 8 | num_updates 16422 | best_loss 0.754\n",
      "2022-02-02 11:06:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:06:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint391.pt (epoch 391 @ 16422 updates, score 0.754) (writing took 0.03454631000022346 seconds)\n",
      "2022-02-02 11:06:20 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)\n",
      "2022-02-02 11:06:20 | INFO | train | epoch 391 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 489 | ups 7.67 | wpb 63.7 | bsz 31.9 | num_updates 16422 | lr 3.12138e-05 | gnorm 0.619 | train_wall 2 | wall 2172\n",
      "epoch 392:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:06:21 | INFO | fairseq.trainer | begin training epoch 392\n",
      "epoch 392:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.58it/s]2022-02-02 11:06:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 392 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 392 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:06:26 | INFO | valid | epoch 392 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1194 | wpb 16 | bsz 8 | num_updates 16464 | best_loss 0.754\n",
      "2022-02-02 11:06:26 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:06:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint392.pt (epoch 392 @ 16464 updates, score 0.755) (writing took 0.01885911700037468 seconds)\n",
      "2022-02-02 11:06:26 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)\n",
      "2022-02-02 11:06:26 | INFO | train | epoch 392 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 484.3 | ups 7.6 | wpb 63.7 | bsz 31.9 | num_updates 16464 | lr 3.1174e-05 | gnorm 0.542 | train_wall 2 | wall 2178\n",
      "epoch 393:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:06:26 | INFO | fairseq.trainer | begin training epoch 393\n",
      "epoch 393:  95%|▉| 40/42 [00:03<00:00, 21.91it/s, loss=0.736, nll_loss=0.368, ac2022-02-02 11:06:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 393 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 393 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.71s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:06:32 | INFO | valid | epoch 393 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1187.6 | wpb 16 | bsz 8 | num_updates 16506 | best_loss 0.754\n",
      "2022-02-02 11:06:32 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:06:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint393.pt (epoch 393 @ 16506 updates, score 0.754) (writing took 0.03512912399992274 seconds)\n",
      "2022-02-02 11:06:32 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)\n",
      "2022-02-02 11:06:32 | INFO | train | epoch 393 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 478.9 | ups 7.52 | wpb 63.7 | bsz 31.9 | num_updates 16506 | lr 3.11343e-05 | gnorm 0.562 | train_wall 2 | wall 2184\n",
      "epoch 394:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:06:32 | INFO | fairseq.trainer | begin training epoch 394\n",
      "epoch 394:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.63it/s]2022-02-02 11:06:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 394 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 394 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:06:37 | INFO | valid | epoch 394 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1254 | wpb 16 | bsz 8 | num_updates 16548 | best_loss 0.754\n",
      "2022-02-02 11:06:37 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:06:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint394.pt (epoch 394 @ 16548 updates, score 0.754) (writing took 0.03806527699998696 seconds)\n",
      "2022-02-02 11:06:37 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)\n",
      "2022-02-02 11:06:37 | INFO | train | epoch 394 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 454.6 | ups 7.14 | wpb 63.7 | bsz 31.9 | num_updates 16548 | lr 3.10948e-05 | gnorm 0.584 | train_wall 2 | wall 2189\n",
      "epoch 395:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:06:38 | INFO | fairseq.trainer | begin training epoch 395\n",
      "epoch 395:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.45it/s]2022-02-02 11:06:41 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 395 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 395 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:06:43 | INFO | valid | epoch 395 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1180.6 | wpb 16 | bsz 8 | num_updates 16590 | best_loss 0.754\n",
      "2022-02-02 11:06:43 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:06:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint395.pt (epoch 395 @ 16590 updates, score 0.755) (writing took 0.027775731000019732 seconds)\n",
      "2022-02-02 11:06:43 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)\n",
      "2022-02-02 11:06:43 | INFO | train | epoch 395 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 478 | ups 7.5 | wpb 63.7 | bsz 31.9 | num_updates 16590 | lr 3.10554e-05 | gnorm 0.681 | train_wall 2 | wall 2195\n",
      "epoch 396:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:06:43 | INFO | fairseq.trainer | begin training epoch 396\n",
      "epoch 396:  93%|▉| 39/42 [00:03<00:00, 21.62it/s, loss=0.744, nll_loss=0.372, ac2022-02-02 11:06:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 396 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 396 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:06:49 | INFO | valid | epoch 396 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1223.8 | wpb 16 | bsz 8 | num_updates 16632 | best_loss 0.754\n",
      "2022-02-02 11:06:49 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:06:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint396.pt (epoch 396 @ 16632 updates, score 0.755) (writing took 0.024134842999956163 seconds)\n",
      "2022-02-02 11:06:49 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)\n",
      "2022-02-02 11:06:49 | INFO | train | epoch 396 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 491.1 | ups 7.71 | wpb 63.7 | bsz 31.9 | num_updates 16632 | lr 3.10161e-05 | gnorm 0.523 | train_wall 2 | wall 2201\n",
      "epoch 397:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:06:49 | INFO | fairseq.trainer | begin training epoch 397\n",
      "epoch 397:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.64it/s]2022-02-02 11:06:52 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 397 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 397 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:06:54 | INFO | valid | epoch 397 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1148.3 | wpb 16 | bsz 8 | num_updates 16674 | best_loss 0.754\n",
      "2022-02-02 11:06:54 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:06:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint397.pt (epoch 397 @ 16674 updates, score 0.755) (writing took 0.02264082600004258 seconds)\n",
      "2022-02-02 11:06:54 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)\n",
      "2022-02-02 11:06:54 | INFO | train | epoch 397 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 491.7 | ups 7.72 | wpb 63.7 | bsz 31.9 | num_updates 16674 | lr 3.09771e-05 | gnorm 0.656 | train_wall 2 | wall 2206\n",
      "epoch 398:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:06:54 | INFO | fairseq.trainer | begin training epoch 398\n",
      "epoch 398:  95%|▉| 40/42 [00:03<00:00, 21.60it/s, loss=0.74, nll_loss=0.37, accu2022-02-02 11:06:58 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 398 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 398 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:06:59 | INFO | valid | epoch 398 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1308.4 | wpb 16 | bsz 8 | num_updates 16716 | best_loss 0.754\n",
      "2022-02-02 11:06:59 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:07:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint398.pt (epoch 398 @ 16716 updates, score 0.755) (writing took 0.03165412999987893 seconds)\n",
      "2022-02-02 11:07:00 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)\n",
      "2022-02-02 11:07:00 | INFO | train | epoch 398 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 483.8 | ups 7.59 | wpb 63.7 | bsz 31.9 | num_updates 16716 | lr 3.09381e-05 | gnorm 0.547 | train_wall 2 | wall 2212\n",
      "epoch 399:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:07:00 | INFO | fairseq.trainer | begin training epoch 399\n",
      "epoch 399:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.32it/s]2022-02-02 11:07:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 399 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 399 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.69s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:07:05 | INFO | valid | epoch 399 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1108.5 | wpb 16 | bsz 8 | num_updates 16758 | best_loss 0.754\n",
      "2022-02-02 11:07:05 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:07:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint399.pt (epoch 399 @ 16758 updates, score 0.755) (writing took 0.03198802399992928 seconds)\n",
      "2022-02-02 11:07:05 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)\n",
      "2022-02-02 11:07:05 | INFO | train | epoch 399 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 473.8 | ups 7.44 | wpb 63.7 | bsz 31.9 | num_updates 16758 | lr 3.08993e-05 | gnorm 0.664 | train_wall 2 | wall 2217\n",
      "epoch 400:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:07:05 | INFO | fairseq.trainer | begin training epoch 400\n",
      "epoch 400:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.01it/s]2022-02-02 11:07:09 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 400 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 400 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.65s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:07:11 | INFO | valid | epoch 400 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1219.4 | wpb 16 | bsz 8 | num_updates 16800 | best_loss 0.754\n",
      "2022-02-02 11:07:11 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:07:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint400.pt (epoch 400 @ 16800 updates, score 0.755) (writing took 0.03068759300003876 seconds)\n",
      "2022-02-02 11:07:11 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)\n",
      "2022-02-02 11:07:11 | INFO | train | epoch 400 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 469.5 | ups 7.37 | wpb 63.7 | bsz 31.9 | num_updates 16800 | lr 3.08607e-05 | gnorm 0.562 | train_wall 2 | wall 2223\n",
      "epoch 401:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:07:11 | INFO | fairseq.trainer | begin training epoch 401\n",
      "epoch 401:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.68it/s]2022-02-02 11:07:15 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 401 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 401 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:27,  1.96s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:07:17 | INFO | valid | epoch 401 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 987.3 | wpb 16 | bsz 8 | num_updates 16842 | best_loss 0.754\n",
      "2022-02-02 11:07:17 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:07:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint401.pt (epoch 401 @ 16842 updates, score 0.755) (writing took 0.03116129699992598 seconds)\n",
      "2022-02-02 11:07:17 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)\n",
      "2022-02-02 11:07:17 | INFO | train | epoch 401 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 433.2 | ups 6.8 | wpb 63.7 | bsz 31.9 | num_updates 16842 | lr 3.08222e-05 | gnorm 0.597 | train_wall 2 | wall 2229\n",
      "epoch 402:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:07:17 | INFO | fairseq.trainer | begin training epoch 402\n",
      "epoch 402:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.63it/s]2022-02-02 11:07:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 402 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 402 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:07:22 | INFO | valid | epoch 402 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1179 | wpb 16 | bsz 8 | num_updates 16884 | best_loss 0.754\n",
      "2022-02-02 11:07:22 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:07:22 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint402.pt (epoch 402 @ 16884 updates, score 0.755) (writing took 0.02524948000018412 seconds)\n",
      "2022-02-02 11:07:22 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)\n",
      "2022-02-02 11:07:22 | INFO | train | epoch 402 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 493.4 | ups 7.74 | wpb 63.7 | bsz 31.9 | num_updates 16884 | lr 3.07838e-05 | gnorm 0.633 | train_wall 2 | wall 2234\n",
      "epoch 403:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:07:22 | INFO | fairseq.trainer | begin training epoch 403\n",
      "epoch 403:  95%|▉| 40/42 [00:03<00:00, 21.70it/s, loss=0.737, nll_loss=0.369, ac2022-02-02 11:07:26 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 403 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 403 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:07:28 | INFO | valid | epoch 403 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1216.8 | wpb 16 | bsz 8 | num_updates 16926 | best_loss 0.754\n",
      "2022-02-02 11:07:28 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:07:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint403.pt (epoch 403 @ 16926 updates, score 0.755) (writing took 0.02917152400004852 seconds)\n",
      "2022-02-02 11:07:28 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)\n",
      "2022-02-02 11:07:28 | INFO | train | epoch 403 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 490 | ups 7.69 | wpb 63.7 | bsz 31.9 | num_updates 16926 | lr 3.07456e-05 | gnorm 0.625 | train_wall 2 | wall 2240\n",
      "epoch 404:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:07:28 | INFO | fairseq.trainer | begin training epoch 404\n",
      "epoch 404:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.22it/s]2022-02-02 11:07:32 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 404 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 404 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:07:33 | INFO | valid | epoch 404 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1229.6 | wpb 16 | bsz 8 | num_updates 16968 | best_loss 0.754\n",
      "2022-02-02 11:07:33 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:07:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint404.pt (epoch 404 @ 16968 updates, score 0.754) (writing took 0.03728710899986254 seconds)\n",
      "2022-02-02 11:07:34 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)\n",
      "2022-02-02 11:07:34 | INFO | train | epoch 404 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 478.9 | ups 7.52 | wpb 63.7 | bsz 31.9 | num_updates 16968 | lr 3.07075e-05 | gnorm 0.573 | train_wall 2 | wall 2246\n",
      "epoch 405:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:07:34 | INFO | fairseq.trainer | begin training epoch 405\n",
      "epoch 405:  95%|▉| 40/42 [00:03<00:00, 21.51it/s, loss=0.747, nll_loss=0.374, ac2022-02-02 11:07:38 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 405 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 405 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:07:39 | INFO | valid | epoch 405 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1195.8 | wpb 16 | bsz 8 | num_updates 17010 | best_loss 0.754\n",
      "2022-02-02 11:07:39 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:07:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint405.pt (epoch 405 @ 17010 updates, score 0.754) (writing took 0.032702673000130744 seconds)\n",
      "2022-02-02 11:07:39 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)\n",
      "2022-02-02 11:07:39 | INFO | train | epoch 405 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 459.7 | ups 7.21 | wpb 63.7 | bsz 31.9 | num_updates 17010 | lr 3.06696e-05 | gnorm 0.535 | train_wall 2 | wall 2251\n",
      "epoch 406:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:07:39 | INFO | fairseq.trainer | begin training epoch 406\n",
      "epoch 406:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.58it/s]2022-02-02 11:07:43 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 406 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 406 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:07:45 | INFO | valid | epoch 406 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1195.4 | wpb 16 | bsz 8 | num_updates 17052 | best_loss 0.754\n",
      "2022-02-02 11:07:45 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:07:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint406.pt (epoch 406 @ 17052 updates, score 0.755) (writing took 0.021999735000008513 seconds)\n",
      "2022-02-02 11:07:45 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)\n",
      "2022-02-02 11:07:45 | INFO | train | epoch 406 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 489.4 | ups 7.68 | wpb 63.7 | bsz 31.9 | num_updates 17052 | lr 3.06318e-05 | gnorm 0.625 | train_wall 2 | wall 2257\n",
      "epoch 407:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:07:45 | INFO | fairseq.trainer | begin training epoch 407\n",
      "epoch 407:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.47it/s]2022-02-02 11:07:48 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 407 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 407 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:07:50 | INFO | valid | epoch 407 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1187.6 | wpb 16 | bsz 8 | num_updates 17094 | best_loss 0.754\n",
      "2022-02-02 11:07:50 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:07:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint407.pt (epoch 407 @ 17094 updates, score 0.755) (writing took 0.03142402499997843 seconds)\n",
      "2022-02-02 11:07:50 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)\n",
      "2022-02-02 11:07:50 | INFO | train | epoch 407 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 488.7 | ups 7.67 | wpb 63.7 | bsz 31.9 | num_updates 17094 | lr 3.05941e-05 | gnorm 0.636 | train_wall 2 | wall 2262\n",
      "epoch 408:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:07:50 | INFO | fairseq.trainer | begin training epoch 408\n",
      "epoch 408:  95%|▉| 40/42 [00:03<00:00, 19.30it/s, loss=0.746, nll_loss=0.373, ac2022-02-02 11:07:54 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 408 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 408 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:07:56 | INFO | valid | epoch 408 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1191 | wpb 16 | bsz 8 | num_updates 17136 | best_loss 0.754\n",
      "2022-02-02 11:07:56 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:07:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint408.pt (epoch 408 @ 17136 updates, score 0.754) (writing took 0.03955439999981536 seconds)\n",
      "2022-02-02 11:07:56 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)\n",
      "2022-02-02 11:07:56 | INFO | train | epoch 408 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 481 | ups 7.55 | wpb 63.7 | bsz 31.9 | num_updates 17136 | lr 3.05566e-05 | gnorm 0.564 | train_wall 2 | wall 2268\n",
      "epoch 409:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:07:56 | INFO | fairseq.trainer | begin training epoch 409\n",
      "epoch 409:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.62it/s]2022-02-02 11:08:00 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 409 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 409 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.65s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:08:01 | INFO | valid | epoch 409 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1165.6 | wpb 16 | bsz 8 | num_updates 17178 | best_loss 0.754\n",
      "2022-02-02 11:08:01 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:08:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint409.pt (epoch 409 @ 17178 updates, score 0.754) (writing took 0.0387482410001212 seconds)\n",
      "2022-02-02 11:08:01 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)\n",
      "2022-02-02 11:08:01 | INFO | train | epoch 409 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 480.3 | ups 7.54 | wpb 63.7 | bsz 31.9 | num_updates 17178 | lr 3.05192e-05 | gnorm 0.615 | train_wall 2 | wall 2273\n",
      "epoch 410:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:08:01 | INFO | fairseq.trainer | begin training epoch 410\n",
      "epoch 410:  95%|▉| 40/42 [00:03<00:00, 21.92it/s, loss=0.734, nll_loss=0.367, ac2022-02-02 11:08:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 410 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 410 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:08:07 | INFO | valid | epoch 410 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1331.3 | wpb 16 | bsz 8 | num_updates 17220 | best_loss 0.754\n",
      "2022-02-02 11:08:07 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:08:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint410.pt (epoch 410 @ 17220 updates, score 0.755) (writing took 0.028253579000192985 seconds)\n",
      "2022-02-02 11:08:07 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)\n",
      "2022-02-02 11:08:07 | INFO | train | epoch 410 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 492.5 | ups 7.73 | wpb 63.7 | bsz 31.9 | num_updates 17220 | lr 3.0482e-05 | gnorm 0.656 | train_wall 2 | wall 2279\n",
      "epoch 411:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:08:07 | INFO | fairseq.trainer | begin training epoch 411\n",
      "epoch 411:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.30it/s]2022-02-02 11:08:11 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 411 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 411 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:08:12 | INFO | valid | epoch 411 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1231 | wpb 16 | bsz 8 | num_updates 17262 | best_loss 0.754\n",
      "2022-02-02 11:08:12 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:08:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint411.pt (epoch 411 @ 17262 updates, score 0.755) (writing took 0.03383249099988461 seconds)\n",
      "2022-02-02 11:08:12 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)\n",
      "2022-02-02 11:08:12 | INFO | train | epoch 411 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 488.8 | ups 7.67 | wpb 63.7 | bsz 31.9 | num_updates 17262 | lr 3.04449e-05 | gnorm 0.579 | train_wall 2 | wall 2284\n",
      "epoch 412:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:08:12 | INFO | fairseq.trainer | begin training epoch 412\n",
      "epoch 412:  95%|▉| 40/42 [00:03<00:00, 21.36it/s, loss=0.746, nll_loss=0.373, ac2022-02-02 11:08:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 412 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 412 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:08:18 | INFO | valid | epoch 412 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1292.4 | wpb 16 | bsz 8 | num_updates 17304 | best_loss 0.754\n",
      "2022-02-02 11:08:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:08:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint412.pt (epoch 412 @ 17304 updates, score 0.754) (writing took 0.02760283299994626 seconds)\n",
      "2022-02-02 11:08:18 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)\n",
      "2022-02-02 11:08:18 | INFO | train | epoch 412 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 492.6 | ups 7.73 | wpb 63.7 | bsz 31.9 | num_updates 17304 | lr 3.04079e-05 | gnorm 0.693 | train_wall 2 | wall 2290\n",
      "epoch 413:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:08:18 | INFO | fairseq.trainer | begin training epoch 413\n",
      "epoch 413:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.02it/s]2022-02-02 11:08:21 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 413 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 413 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:08:23 | INFO | valid | epoch 413 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1194.8 | wpb 16 | bsz 8 | num_updates 17346 | best_loss 0.754\n",
      "2022-02-02 11:08:23 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:08:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint413.pt (epoch 413 @ 17346 updates, score 0.755) (writing took 0.021034832000168535 seconds)\n",
      "2022-02-02 11:08:23 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)\n",
      "2022-02-02 11:08:23 | INFO | train | epoch 413 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 489.1 | ups 7.68 | wpb 63.7 | bsz 31.9 | num_updates 17346 | lr 3.03711e-05 | gnorm 0.534 | train_wall 2 | wall 2295\n",
      "epoch 414:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:08:23 | INFO | fairseq.trainer | begin training epoch 414\n",
      "epoch 414:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.72it/s]2022-02-02 11:08:27 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 414 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 414 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:08:29 | INFO | valid | epoch 414 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1218.3 | wpb 16 | bsz 8 | num_updates 17388 | best_loss 0.754\n",
      "2022-02-02 11:08:29 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:08:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint414.pt (epoch 414 @ 17388 updates, score 0.754) (writing took 0.028736179000134143 seconds)\n",
      "2022-02-02 11:08:29 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)\n",
      "2022-02-02 11:08:29 | INFO | train | epoch 414 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 498.4 | ups 7.82 | wpb 63.7 | bsz 31.9 | num_updates 17388 | lr 3.03344e-05 | gnorm 0.552 | train_wall 2 | wall 2301\n",
      "epoch 415:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:08:29 | INFO | fairseq.trainer | begin training epoch 415\n",
      "epoch 415:  95%|▉| 40/42 [00:03<00:00, 21.73it/s, loss=0.744, nll_loss=0.372, ac2022-02-02 11:08:32 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 415 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 415 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:08:34 | INFO | valid | epoch 415 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1151.5 | wpb 16 | bsz 8 | num_updates 17430 | best_loss 0.754\n",
      "2022-02-02 11:08:34 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:08:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint415.pt (epoch 415 @ 17430 updates, score 0.754) (writing took 0.02184205599996858 seconds)\n",
      "2022-02-02 11:08:34 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)\n",
      "2022-02-02 11:08:34 | INFO | train | epoch 415 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 490 | ups 7.69 | wpb 63.7 | bsz 31.9 | num_updates 17430 | lr 3.02978e-05 | gnorm 0.615 | train_wall 2 | wall 2306\n",
      "epoch 416:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:08:34 | INFO | fairseq.trainer | begin training epoch 416\n",
      "epoch 416:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.39it/s]2022-02-02 11:08:38 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 416 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 416 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:08:40 | INFO | valid | epoch 416 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1190.4 | wpb 16 | bsz 8 | num_updates 17472 | best_loss 0.754\n",
      "2022-02-02 11:08:40 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:08:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint416.pt (epoch 416 @ 17472 updates, score 0.755) (writing took 0.021398136999778217 seconds)\n",
      "2022-02-02 11:08:40 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)\n",
      "2022-02-02 11:08:40 | INFO | train | epoch 416 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 489.3 | ups 7.68 | wpb 63.7 | bsz 31.9 | num_updates 17472 | lr 3.02614e-05 | gnorm 0.617 | train_wall 2 | wall 2312\n",
      "epoch 417:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:08:40 | INFO | fairseq.trainer | begin training epoch 417\n",
      "epoch 417:  95%|▉| 40/42 [00:03<00:00, 21.50it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 11:08:43 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 417 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 417 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:08:45 | INFO | valid | epoch 417 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1164.8 | wpb 16 | bsz 8 | num_updates 17514 | best_loss 0.754\n",
      "2022-02-02 11:08:45 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:08:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint417.pt (epoch 417 @ 17514 updates, score 0.755) (writing took 0.02182972199989308 seconds)\n",
      "2022-02-02 11:08:45 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)\n",
      "2022-02-02 11:08:45 | INFO | train | epoch 417 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 494.1 | ups 7.75 | wpb 63.7 | bsz 31.9 | num_updates 17514 | lr 3.02251e-05 | gnorm 0.575 | train_wall 2 | wall 2317\n",
      "epoch 418:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:08:45 | INFO | fairseq.trainer | begin training epoch 418\n",
      "epoch 418:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.06it/s]2022-02-02 11:08:49 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 418 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 418 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:08:50 | INFO | valid | epoch 418 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1189.5 | wpb 16 | bsz 8 | num_updates 17556 | best_loss 0.754\n",
      "2022-02-02 11:08:50 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:08:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint418.pt (epoch 418 @ 17556 updates, score 0.754) (writing took 0.025408346999938658 seconds)\n",
      "2022-02-02 11:08:50 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)\n",
      "2022-02-02 11:08:50 | INFO | train | epoch 418 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 489.9 | ups 7.69 | wpb 63.7 | bsz 31.9 | num_updates 17556 | lr 3.01889e-05 | gnorm 0.64 | train_wall 2 | wall 2322\n",
      "epoch 419:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:08:50 | INFO | fairseq.trainer | begin training epoch 419\n",
      "epoch 419:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.78it/s]2022-02-02 11:08:54 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 419 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 419 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:08:56 | INFO | valid | epoch 419 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1259.5 | wpb 16 | bsz 8 | num_updates 17598 | best_loss 0.754\n",
      "2022-02-02 11:08:56 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:08:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint419.pt (epoch 419 @ 17598 updates, score 0.755) (writing took 0.029280053000093176 seconds)\n",
      "2022-02-02 11:08:56 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)\n",
      "2022-02-02 11:08:56 | INFO | train | epoch 419 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 494.7 | ups 7.76 | wpb 63.7 | bsz 31.9 | num_updates 17598 | lr 3.01528e-05 | gnorm 0.585 | train_wall 2 | wall 2328\n",
      "epoch 420:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:08:56 | INFO | fairseq.trainer | begin training epoch 420\n",
      "epoch 420:  95%|▉| 40/42 [00:03<00:00, 21.43it/s, loss=0.737, nll_loss=0.369, ac2022-02-02 11:08:59 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 420 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 420 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:09:01 | INFO | valid | epoch 420 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1194.9 | wpb 16 | bsz 8 | num_updates 17640 | best_loss 0.754\n",
      "2022-02-02 11:09:01 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:09:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint420.pt (epoch 420 @ 17640 updates, score 0.755) (writing took 0.02612040700023499 seconds)\n",
      "2022-02-02 11:09:01 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)\n",
      "2022-02-02 11:09:01 | INFO | train | epoch 420 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 491.5 | ups 7.71 | wpb 63.7 | bsz 31.9 | num_updates 17640 | lr 3.01169e-05 | gnorm 0.594 | train_wall 2 | wall 2333\n",
      "epoch 421:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:09:01 | INFO | fairseq.trainer | begin training epoch 421\n",
      "epoch 421:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.33it/s]2022-02-02 11:09:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 421 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 421 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:09:07 | INFO | valid | epoch 421 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1130.8 | wpb 16 | bsz 8 | num_updates 17682 | best_loss 0.754\n",
      "2022-02-02 11:09:07 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:09:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint421.pt (epoch 421 @ 17682 updates, score 0.755) (writing took 0.0312382100000832 seconds)\n",
      "2022-02-02 11:09:07 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)\n",
      "2022-02-02 11:09:07 | INFO | train | epoch 421 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 494.3 | ups 7.76 | wpb 63.7 | bsz 31.9 | num_updates 17682 | lr 3.00811e-05 | gnorm 0.607 | train_wall 2 | wall 2339\n",
      "epoch 422:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:09:07 | INFO | fairseq.trainer | begin training epoch 422\n",
      "epoch 422:  93%|▉| 39/42 [00:03<00:00, 21.85it/s, loss=0.748, nll_loss=0.374, ac2022-02-02 11:09:11 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 422 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 422 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:09:12 | INFO | valid | epoch 422 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1197.5 | wpb 16 | bsz 8 | num_updates 17724 | best_loss 0.754\n",
      "2022-02-02 11:09:12 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:09:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint422.pt (epoch 422 @ 17724 updates, score 0.754) (writing took 0.030491505000100005 seconds)\n",
      "2022-02-02 11:09:12 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)\n",
      "2022-02-02 11:09:12 | INFO | train | epoch 422 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 466.7 | ups 7.33 | wpb 63.7 | bsz 31.9 | num_updates 17724 | lr 3.00455e-05 | gnorm 0.502 | train_wall 2 | wall 2344\n",
      "epoch 423:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:09:12 | INFO | fairseq.trainer | begin training epoch 423\n",
      "epoch 423:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.40it/s]2022-02-02 11:09:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 423 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 423 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:09:18 | INFO | valid | epoch 423 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1155.4 | wpb 16 | bsz 8 | num_updates 17766 | best_loss 0.754\n",
      "2022-02-02 11:09:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:09:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint423.pt (epoch 423 @ 17766 updates, score 0.755) (writing took 0.026367096000285528 seconds)\n",
      "2022-02-02 11:09:18 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)\n",
      "2022-02-02 11:09:18 | INFO | train | epoch 423 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 475.2 | ups 7.46 | wpb 63.7 | bsz 31.9 | num_updates 17766 | lr 3.00099e-05 | gnorm 0.562 | train_wall 2 | wall 2350\n",
      "epoch 424:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:09:18 | INFO | fairseq.trainer | begin training epoch 424\n",
      "epoch 424:  95%|▉| 40/42 [00:03<00:00, 21.52it/s, loss=0.738, nll_loss=0.369, ac2022-02-02 11:09:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 424 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 424 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:09:23 | INFO | valid | epoch 424 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1219.4 | wpb 16 | bsz 8 | num_updates 17808 | best_loss 0.754\n",
      "2022-02-02 11:09:23 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:09:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint424.pt (epoch 424 @ 17808 updates, score 0.754) (writing took 0.03452051300018866 seconds)\n",
      "2022-02-02 11:09:23 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)\n",
      "2022-02-02 11:09:23 | INFO | train | epoch 424 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 494.2 | ups 7.76 | wpb 63.7 | bsz 31.9 | num_updates 17808 | lr 2.99745e-05 | gnorm 0.665 | train_wall 2 | wall 2355\n",
      "epoch 425:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:09:23 | INFO | fairseq.trainer | begin training epoch 425\n",
      "epoch 425:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.51it/s]2022-02-02 11:09:27 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 425 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 425 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:09:29 | INFO | valid | epoch 425 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1120.2 | wpb 16 | bsz 8 | num_updates 17850 | best_loss 0.754\n",
      "2022-02-02 11:09:29 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:09:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint425.pt (epoch 425 @ 17850 updates, score 0.754) (writing took 0.03191418000005797 seconds)\n",
      "2022-02-02 11:09:29 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)\n",
      "2022-02-02 11:09:29 | INFO | train | epoch 425 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 491.9 | ups 7.72 | wpb 63.7 | bsz 31.9 | num_updates 17850 | lr 2.99392e-05 | gnorm 0.65 | train_wall 2 | wall 2361\n",
      "epoch 426:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:09:29 | INFO | fairseq.trainer | begin training epoch 426\n",
      "epoch 426:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.50it/s]2022-02-02 11:09:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 426 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 426 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:09:34 | INFO | valid | epoch 426 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1202.9 | wpb 16 | bsz 8 | num_updates 17892 | best_loss 0.754\n",
      "2022-02-02 11:09:34 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:09:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint426.pt (epoch 426 @ 17892 updates, score 0.754) (writing took 0.035709280999981274 seconds)\n",
      "2022-02-02 11:09:34 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)\n",
      "2022-02-02 11:09:34 | INFO | train | epoch 426 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 492.2 | ups 7.73 | wpb 63.7 | bsz 31.9 | num_updates 17892 | lr 2.99041e-05 | gnorm 0.627 | train_wall 2 | wall 2366\n",
      "epoch 427:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:09:34 | INFO | fairseq.trainer | begin training epoch 427\n",
      "epoch 427:  95%|▉| 40/42 [00:03<00:00, 21.81it/s, loss=0.752, nll_loss=0.376, ac2022-02-02 11:09:38 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 427 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 427 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:09:40 | INFO | valid | epoch 427 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1134.8 | wpb 16 | bsz 8 | num_updates 17934 | best_loss 0.754\n",
      "2022-02-02 11:09:40 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:09:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint427.pt (epoch 427 @ 17934 updates, score 0.755) (writing took 0.02843505800001367 seconds)\n",
      "2022-02-02 11:09:40 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)\n",
      "2022-02-02 11:09:40 | INFO | train | epoch 427 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 487.3 | ups 7.65 | wpb 63.7 | bsz 31.9 | num_updates 17934 | lr 2.9869e-05 | gnorm 0.629 | train_wall 2 | wall 2372\n",
      "epoch 428:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:09:40 | INFO | fairseq.trainer | begin training epoch 428\n",
      "epoch 428:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.59it/s]2022-02-02 11:09:43 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 428 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 428 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:09:45 | INFO | valid | epoch 428 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1214.8 | wpb 16 | bsz 8 | num_updates 17976 | best_loss 0.754\n",
      "2022-02-02 11:09:45 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:09:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint428.pt (epoch 428 @ 17976 updates, score 0.754) (writing took 0.03696029799993994 seconds)\n",
      "2022-02-02 11:09:45 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)\n",
      "2022-02-02 11:09:45 | INFO | train | epoch 428 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 493.8 | ups 7.75 | wpb 63.7 | bsz 31.9 | num_updates 17976 | lr 2.98341e-05 | gnorm 0.529 | train_wall 2 | wall 2377\n",
      "epoch 429:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:09:45 | INFO | fairseq.trainer | begin training epoch 429\n",
      "epoch 429:  95%|▉| 40/42 [00:03<00:00, 21.07it/s, loss=0.739, nll_loss=0.369, ac2022-02-02 11:09:49 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 429 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 429 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.52s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:09:51 | INFO | valid | epoch 429 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1154 | wpb 16 | bsz 8 | num_updates 18018 | best_loss 0.754\n",
      "2022-02-02 11:09:51 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:09:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint429.pt (epoch 429 @ 18018 updates, score 0.755) (writing took 0.023502517999986594 seconds)\n",
      "2022-02-02 11:09:51 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)\n",
      "2022-02-02 11:09:51 | INFO | train | epoch 429 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 493.1 | ups 7.74 | wpb 63.7 | bsz 31.9 | num_updates 18018 | lr 2.97993e-05 | gnorm 0.605 | train_wall 2 | wall 2383\n",
      "epoch 430:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:09:51 | INFO | fairseq.trainer | begin training epoch 430\n",
      "epoch 430:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.32it/s]2022-02-02 11:09:54 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 430 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 430 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:09:56 | INFO | valid | epoch 430 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1149.4 | wpb 16 | bsz 8 | num_updates 18060 | best_loss 0.754\n",
      "2022-02-02 11:09:56 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:09:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint430.pt (epoch 430 @ 18060 updates, score 0.755) (writing took 0.020102417999623867 seconds)\n",
      "2022-02-02 11:09:56 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)\n",
      "2022-02-02 11:09:56 | INFO | train | epoch 430 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 485 | ups 7.61 | wpb 63.7 | bsz 31.9 | num_updates 18060 | lr 2.97647e-05 | gnorm 0.651 | train_wall 2 | wall 2388\n",
      "epoch 431:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:09:56 | INFO | fairseq.trainer | begin training epoch 431\n",
      "epoch 431:  95%|▉| 40/42 [00:03<00:00, 21.80it/s, loss=0.736, nll_loss=0.368, ac2022-02-02 11:10:00 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 431 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 431 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:10:02 | INFO | valid | epoch 431 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1178.4 | wpb 16 | bsz 8 | num_updates 18102 | best_loss 0.754\n",
      "2022-02-02 11:10:02 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:10:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint431.pt (epoch 431 @ 18102 updates, score 0.755) (writing took 0.03084398400005739 seconds)\n",
      "2022-02-02 11:10:02 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)\n",
      "2022-02-02 11:10:02 | INFO | train | epoch 431 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 489 | ups 7.67 | wpb 63.7 | bsz 31.9 | num_updates 18102 | lr 2.97301e-05 | gnorm 0.469 | train_wall 2 | wall 2394\n",
      "epoch 432:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:10:02 | INFO | fairseq.trainer | begin training epoch 432\n",
      "epoch 432:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.63it/s]2022-02-02 11:10:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 432 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 432 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:10:07 | INFO | valid | epoch 432 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1145.6 | wpb 16 | bsz 8 | num_updates 18144 | best_loss 0.754\n",
      "2022-02-02 11:10:07 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:10:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint432.pt (epoch 432 @ 18144 updates, score 0.754) (writing took 0.034775931000240234 seconds)\n",
      "2022-02-02 11:10:07 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)\n",
      "2022-02-02 11:10:07 | INFO | train | epoch 432 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 481.3 | ups 7.55 | wpb 63.7 | bsz 31.9 | num_updates 18144 | lr 2.96957e-05 | gnorm 0.632 | train_wall 2 | wall 2399\n",
      "epoch 433:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:10:07 | INFO | fairseq.trainer | begin training epoch 433\n",
      "epoch 433:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.76it/s]2022-02-02 11:10:11 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 433 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 433 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:10:13 | INFO | valid | epoch 433 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1165.1 | wpb 16 | bsz 8 | num_updates 18186 | best_loss 0.754\n",
      "2022-02-02 11:10:13 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:10:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint433.pt (epoch 433 @ 18186 updates, score 0.755) (writing took 0.025453184000070905 seconds)\n",
      "2022-02-02 11:10:13 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)\n",
      "2022-02-02 11:10:13 | INFO | train | epoch 433 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 484.4 | ups 7.6 | wpb 63.7 | bsz 31.9 | num_updates 18186 | lr 2.96614e-05 | gnorm 0.586 | train_wall 2 | wall 2405\n",
      "epoch 434:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:10:13 | INFO | fairseq.trainer | begin training epoch 434\n",
      "epoch 434:  95%|▉| 40/42 [00:03<00:00, 21.58it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 11:10:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 434 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 434 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:10:18 | INFO | valid | epoch 434 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1189.2 | wpb 16 | bsz 8 | num_updates 18228 | best_loss 0.754\n",
      "2022-02-02 11:10:18 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:10:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint434.pt (epoch 434 @ 18228 updates, score 0.754) (writing took 0.030622960000073363 seconds)\n",
      "2022-02-02 11:10:18 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)\n",
      "2022-02-02 11:10:18 | INFO | train | epoch 434 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 493.7 | ups 7.75 | wpb 63.7 | bsz 31.9 | num_updates 18228 | lr 2.96272e-05 | gnorm 0.627 | train_wall 2 | wall 2410\n",
      "epoch 435:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:10:18 | INFO | fairseq.trainer | begin training epoch 435\n",
      "epoch 435:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.16it/s]2022-02-02 11:10:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 435 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 435 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:10:24 | INFO | valid | epoch 435 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1102.7 | wpb 16 | bsz 8 | num_updates 18270 | best_loss 0.754\n",
      "2022-02-02 11:10:24 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:10:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint435.pt (epoch 435 @ 18270 updates, score 0.754) (writing took 0.04034753499990984 seconds)\n",
      "2022-02-02 11:10:24 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)\n",
      "2022-02-02 11:10:24 | INFO | train | epoch 435 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 485.4 | ups 7.62 | wpb 63.7 | bsz 31.9 | num_updates 18270 | lr 2.95931e-05 | gnorm 0.619 | train_wall 2 | wall 2416\n",
      "epoch 436:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:10:24 | INFO | fairseq.trainer | begin training epoch 436\n",
      "epoch 436:  95%|▉| 40/42 [00:03<00:00, 20.04it/s, loss=0.739, nll_loss=0.37, acc2022-02-02 11:10:27 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 436 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 436 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.68s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:10:29 | INFO | valid | epoch 436 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1161.1 | wpb 16 | bsz 8 | num_updates 18312 | best_loss 0.754\n",
      "2022-02-02 11:10:29 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:10:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint436.pt (epoch 436 @ 18312 updates, score 0.755) (writing took 0.026887584999713 seconds)\n",
      "2022-02-02 11:10:29 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)\n",
      "2022-02-02 11:10:29 | INFO | train | epoch 436 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 468.7 | ups 7.36 | wpb 63.7 | bsz 31.9 | num_updates 18312 | lr 2.95592e-05 | gnorm 0.612 | train_wall 2 | wall 2421\n",
      "epoch 437:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:10:29 | INFO | fairseq.trainer | begin training epoch 437\n",
      "epoch 437:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.70it/s]2022-02-02 11:10:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 437 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 437 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:24,  1.77s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:10:35 | INFO | valid | epoch 437 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 883.3 | wpb 16 | bsz 8 | num_updates 18354 | best_loss 0.754\n",
      "2022-02-02 11:10:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:10:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint437.pt (epoch 437 @ 18354 updates, score 0.754) (writing took 0.054146068999671115 seconds)\n",
      "2022-02-02 11:10:35 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)\n",
      "2022-02-02 11:10:35 | INFO | train | epoch 437 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 462 | ups 7.25 | wpb 63.7 | bsz 31.9 | num_updates 18354 | lr 2.95253e-05 | gnorm 0.623 | train_wall 2 | wall 2427\n",
      "epoch 438:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:10:35 | INFO | fairseq.trainer | begin training epoch 438\n",
      "epoch 438:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.44it/s]2022-02-02 11:10:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 438 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 438 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:25,  1.86s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:10:41 | INFO | valid | epoch 438 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1263 | wpb 16 | bsz 8 | num_updates 18396 | best_loss 0.754\n",
      "2022-02-02 11:10:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:10:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint438.pt (epoch 438 @ 18396 updates, score 0.754) (writing took 0.02616041800001767 seconds)\n",
      "2022-02-02 11:10:41 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)\n",
      "2022-02-02 11:10:41 | INFO | train | epoch 438 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 442 | ups 6.94 | wpb 63.7 | bsz 31.9 | num_updates 18396 | lr 2.94916e-05 | gnorm 0.519 | train_wall 2 | wall 2433\n",
      "epoch 439:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:10:41 | INFO | fairseq.trainer | begin training epoch 439\n",
      "epoch 439:  95%|▉| 40/42 [00:03<00:00, 21.88it/s, loss=0.744, nll_loss=0.372, ac2022-02-02 11:10:45 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 439 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 439 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:10:47 | INFO | valid | epoch 439 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1158.7 | wpb 16 | bsz 8 | num_updates 18438 | best_loss 0.754\n",
      "2022-02-02 11:10:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:10:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint439.pt (epoch 439 @ 18438 updates, score 0.754) (writing took 0.027457038999727956 seconds)\n",
      "2022-02-02 11:10:47 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)\n",
      "2022-02-02 11:10:47 | INFO | train | epoch 439 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 490.2 | ups 7.69 | wpb 63.7 | bsz 31.9 | num_updates 18438 | lr 2.9458e-05 | gnorm 0.591 | train_wall 2 | wall 2439\n",
      "epoch 440:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:10:47 | INFO | fairseq.trainer | begin training epoch 440\n",
      "epoch 440:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.27it/s]2022-02-02 11:10:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 440 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 440 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:10:52 | INFO | valid | epoch 440 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1295.7 | wpb 16 | bsz 8 | num_updates 18480 | best_loss 0.754\n",
      "2022-02-02 11:10:52 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:10:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint440.pt (epoch 440 @ 18480 updates, score 0.754) (writing took 0.027136717999837856 seconds)\n",
      "2022-02-02 11:10:52 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)\n",
      "2022-02-02 11:10:52 | INFO | train | epoch 440 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 492.1 | ups 7.72 | wpb 63.7 | bsz 31.9 | num_updates 18480 | lr 2.94245e-05 | gnorm 0.655 | train_wall 2 | wall 2444\n",
      "epoch 441:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:10:52 | INFO | fairseq.trainer | begin training epoch 441\n",
      "epoch 441:  95%|▉| 40/42 [00:03<00:00, 20.99it/s, loss=0.744, nll_loss=0.372, ac2022-02-02 11:10:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 441 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 441 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:10:58 | INFO | valid | epoch 441 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1267.6 | wpb 16 | bsz 8 | num_updates 18522 | best_loss 0.754\n",
      "2022-02-02 11:10:58 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:10:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint441.pt (epoch 441 @ 18522 updates, score 0.754) (writing took 0.04189817699989362 seconds)\n",
      "2022-02-02 11:10:58 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)\n",
      "2022-02-02 11:10:58 | INFO | train | epoch 441 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 484.5 | ups 7.6 | wpb 63.7 | bsz 31.9 | num_updates 18522 | lr 2.93911e-05 | gnorm 0.599 | train_wall 2 | wall 2450\n",
      "epoch 442:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:10:58 | INFO | fairseq.trainer | begin training epoch 442\n",
      "epoch 442:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.71it/s]2022-02-02 11:11:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 442 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 442 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:11:03 | INFO | valid | epoch 442 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1170.3 | wpb 16 | bsz 8 | num_updates 18564 | best_loss 0.754\n",
      "2022-02-02 11:11:03 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:11:03 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint442.pt (epoch 442 @ 18564 updates, score 0.755) (writing took 0.028894247000152973 seconds)\n",
      "2022-02-02 11:11:03 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)\n",
      "2022-02-02 11:11:03 | INFO | train | epoch 442 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 488.3 | ups 7.66 | wpb 63.7 | bsz 31.9 | num_updates 18564 | lr 2.93578e-05 | gnorm 0.627 | train_wall 2 | wall 2455\n",
      "epoch 443:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:11:03 | INFO | fairseq.trainer | begin training epoch 443\n",
      "epoch 443:  95%|▉| 40/42 [00:03<00:00, 20.89it/s, loss=0.741, nll_loss=0.371, ac2022-02-02 11:11:07 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 443 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 443 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.66s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:11:09 | INFO | valid | epoch 443 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1195.1 | wpb 16 | bsz 8 | num_updates 18606 | best_loss 0.754\n",
      "2022-02-02 11:11:09 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:11:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint443.pt (epoch 443 @ 18606 updates, score 0.754) (writing took 0.033507493999877624 seconds)\n",
      "2022-02-02 11:11:09 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)\n",
      "2022-02-02 11:11:09 | INFO | train | epoch 443 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 478.7 | ups 7.51 | wpb 63.7 | bsz 31.9 | num_updates 18606 | lr 2.93247e-05 | gnorm 0.561 | train_wall 2 | wall 2461\n",
      "epoch 444:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:11:09 | INFO | fairseq.trainer | begin training epoch 444\n",
      "epoch 444:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.69it/s]2022-02-02 11:11:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 444 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 444 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:11:14 | INFO | valid | epoch 444 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1262.9 | wpb 16 | bsz 8 | num_updates 18648 | best_loss 0.754\n",
      "2022-02-02 11:11:14 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:11:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint444.pt (epoch 444 @ 18648 updates, score 0.754) (writing took 0.028222187000210397 seconds)\n",
      "2022-02-02 11:11:14 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)\n",
      "2022-02-02 11:11:14 | INFO | train | epoch 444 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 486.3 | ups 7.63 | wpb 63.7 | bsz 31.9 | num_updates 18648 | lr 2.92917e-05 | gnorm 0.557 | train_wall 2 | wall 2466\n",
      "epoch 445:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:11:14 | INFO | fairseq.trainer | begin training epoch 445\n",
      "epoch 445:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.61it/s]2022-02-02 11:11:18 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 445 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 445 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:11:20 | INFO | valid | epoch 445 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1212.6 | wpb 16 | bsz 8 | num_updates 18690 | best_loss 0.754\n",
      "2022-02-02 11:11:20 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:11:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint445.pt (epoch 445 @ 18690 updates, score 0.755) (writing took 0.07567487400001482 seconds)\n",
      "2022-02-02 11:11:20 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)\n",
      "2022-02-02 11:11:20 | INFO | train | epoch 445 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 485.7 | ups 7.62 | wpb 63.7 | bsz 31.9 | num_updates 18690 | lr 2.92587e-05 | gnorm 0.577 | train_wall 2 | wall 2472\n",
      "epoch 446:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:11:20 | INFO | fairseq.trainer | begin training epoch 446\n",
      "epoch 446:  95%|▉| 40/42 [00:03<00:00, 21.56it/s, loss=0.741, nll_loss=0.37, acc2022-02-02 11:11:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 446 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 446 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:11:25 | INFO | valid | epoch 446 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1319.9 | wpb 16 | bsz 8 | num_updates 18732 | best_loss 0.754\n",
      "2022-02-02 11:11:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:11:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint446.pt (epoch 446 @ 18732 updates, score 0.755) (writing took 0.02529940300019007 seconds)\n",
      "2022-02-02 11:11:25 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)\n",
      "2022-02-02 11:11:25 | INFO | train | epoch 446 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 498.3 | ups 7.82 | wpb 63.7 | bsz 31.9 | num_updates 18732 | lr 2.92259e-05 | gnorm 0.707 | train_wall 2 | wall 2477\n",
      "epoch 447:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:11:25 | INFO | fairseq.trainer | begin training epoch 447\n",
      "epoch 447:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.33it/s]2022-02-02 11:11:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 447 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 447 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:11:31 | INFO | valid | epoch 447 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1177.3 | wpb 16 | bsz 8 | num_updates 18774 | best_loss 0.754\n",
      "2022-02-02 11:11:31 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:11:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint447.pt (epoch 447 @ 18774 updates, score 0.754) (writing took 0.04383405499993387 seconds)\n",
      "2022-02-02 11:11:31 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)\n",
      "2022-02-02 11:11:31 | INFO | train | epoch 447 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 486.7 | ups 7.64 | wpb 63.7 | bsz 31.9 | num_updates 18774 | lr 2.91932e-05 | gnorm 0.595 | train_wall 2 | wall 2483\n",
      "epoch 448:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:11:31 | INFO | fairseq.trainer | begin training epoch 448\n",
      "epoch 448:  93%|▉| 39/42 [00:03<00:00, 21.42it/s, loss=0.745, nll_loss=0.372, ac2022-02-02 11:11:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 448 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 448 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:11:36 | INFO | valid | epoch 448 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1274.3 | wpb 16 | bsz 8 | num_updates 18816 | best_loss 0.754\n",
      "2022-02-02 11:11:36 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:11:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint448.pt (epoch 448 @ 18816 updates, score 0.755) (writing took 0.03345641699979751 seconds)\n",
      "2022-02-02 11:11:36 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)\n",
      "2022-02-02 11:11:36 | INFO | train | epoch 448 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 492.1 | ups 7.72 | wpb 63.7 | bsz 31.9 | num_updates 18816 | lr 2.91606e-05 | gnorm 0.699 | train_wall 2 | wall 2488\n",
      "epoch 449:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:11:36 | INFO | fairseq.trainer | begin training epoch 449\n",
      "epoch 449:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.69it/s]2022-02-02 11:11:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 449 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 449 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.66s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:11:42 | INFO | valid | epoch 449 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1186.5 | wpb 16 | bsz 8 | num_updates 18858 | best_loss 0.754\n",
      "2022-02-02 11:11:42 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:11:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint449.pt (epoch 449 @ 18858 updates, score 0.754) (writing took 0.03974052500007019 seconds)\n",
      "2022-02-02 11:11:42 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)\n",
      "2022-02-02 11:11:42 | INFO | train | epoch 449 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 480.9 | ups 7.55 | wpb 63.7 | bsz 31.9 | num_updates 18858 | lr 2.91281e-05 | gnorm 0.621 | train_wall 2 | wall 2494\n",
      "epoch 450:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:11:42 | INFO | fairseq.trainer | begin training epoch 450\n",
      "epoch 450:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.27it/s]2022-02-02 11:11:45 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 450 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 450 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.64s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:11:47 | INFO | valid | epoch 450 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1178.1 | wpb 16 | bsz 8 | num_updates 18900 | best_loss 0.754\n",
      "2022-02-02 11:11:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:11:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint450.pt (epoch 450 @ 18900 updates, score 0.755) (writing took 0.027978151999832335 seconds)\n",
      "2022-02-02 11:11:47 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)\n",
      "2022-02-02 11:11:47 | INFO | train | epoch 450 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 478.4 | ups 7.51 | wpb 63.7 | bsz 31.9 | num_updates 18900 | lr 2.90957e-05 | gnorm 0.709 | train_wall 2 | wall 2499\n",
      "epoch 451:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:11:47 | INFO | fairseq.trainer | begin training epoch 451\n",
      "epoch 451:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.44it/s]2022-02-02 11:11:51 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 451 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 451 | valid on 'valid' subset:   7%|▍      | 1/15 [00:02<00:28,  2.07s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:11:53 | INFO | valid | epoch 451 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 917.7 | wpb 16 | bsz 8 | num_updates 18942 | best_loss 0.754\n",
      "2022-02-02 11:11:53 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:11:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint451.pt (epoch 451 @ 18942 updates, score 0.754) (writing took 0.04272981899976003 seconds)\n",
      "2022-02-02 11:11:53 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)\n",
      "2022-02-02 11:11:53 | INFO | train | epoch 451 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 440.3 | ups 6.91 | wpb 63.7 | bsz 31.9 | num_updates 18942 | lr 2.90634e-05 | gnorm 0.58 | train_wall 2 | wall 2505\n",
      "epoch 452:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:11:53 | INFO | fairseq.trainer | begin training epoch 452\n",
      "epoch 452:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.90it/s]2022-02-02 11:11:57 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 452 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 452 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:11:59 | INFO | valid | epoch 452 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1307.5 | wpb 16 | bsz 8 | num_updates 18984 | best_loss 0.754\n",
      "2022-02-02 11:11:59 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:11:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint452.pt (epoch 452 @ 18984 updates, score 0.754) (writing took 0.03928053900017403 seconds)\n",
      "2022-02-02 11:11:59 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)\n",
      "2022-02-02 11:11:59 | INFO | train | epoch 452 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 478 | ups 7.5 | wpb 63.7 | bsz 31.9 | num_updates 18984 | lr 2.90313e-05 | gnorm 0.631 | train_wall 2 | wall 2511\n",
      "epoch 453:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:11:59 | INFO | fairseq.trainer | begin training epoch 453\n",
      "epoch 453:  95%|▉| 40/42 [00:03<00:00, 21.50it/s, loss=0.734, nll_loss=0.367, ac2022-02-02 11:12:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 453 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 453 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:12:04 | INFO | valid | epoch 453 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1187.5 | wpb 16 | bsz 8 | num_updates 19026 | best_loss 0.754\n",
      "2022-02-02 11:12:04 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:12:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint453.pt (epoch 453 @ 19026 updates, score 0.755) (writing took 0.02867631800017989 seconds)\n",
      "2022-02-02 11:12:04 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)\n",
      "2022-02-02 11:12:04 | INFO | train | epoch 453 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 488.2 | ups 7.66 | wpb 63.7 | bsz 31.9 | num_updates 19026 | lr 2.89992e-05 | gnorm 0.597 | train_wall 2 | wall 2516\n",
      "epoch 454:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:12:04 | INFO | fairseq.trainer | begin training epoch 454\n",
      "epoch 454:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.49it/s]2022-02-02 11:12:08 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 454 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 454 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:12:10 | INFO | valid | epoch 454 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1288.6 | wpb 16 | bsz 8 | num_updates 19068 | best_loss 0.754\n",
      "2022-02-02 11:12:10 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:12:10 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint454.pt (epoch 454 @ 19068 updates, score 0.754) (writing took 0.04514433799977269 seconds)\n",
      "2022-02-02 11:12:10 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)\n",
      "2022-02-02 11:12:10 | INFO | train | epoch 454 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 487.1 | ups 7.64 | wpb 63.7 | bsz 31.9 | num_updates 19068 | lr 2.89673e-05 | gnorm 0.562 | train_wall 2 | wall 2522\n",
      "epoch 455:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:12:10 | INFO | fairseq.trainer | begin training epoch 455\n",
      "epoch 455:  95%|▉| 40/42 [00:03<00:00, 21.03it/s, loss=0.755, nll_loss=0.377, ac2022-02-02 11:12:14 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 455 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 455 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:12:15 | INFO | valid | epoch 455 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1174.6 | wpb 16 | bsz 8 | num_updates 19110 | best_loss 0.754\n",
      "2022-02-02 11:12:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:12:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint455.pt (epoch 455 @ 19110 updates, score 0.754) (writing took 0.036458002000017586 seconds)\n",
      "2022-02-02 11:12:15 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)\n",
      "2022-02-02 11:12:15 | INFO | train | epoch 455 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 478.9 | ups 7.52 | wpb 63.7 | bsz 31.9 | num_updates 19110 | lr 2.89354e-05 | gnorm 0.617 | train_wall 2 | wall 2527\n",
      "epoch 456:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:12:15 | INFO | fairseq.trainer | begin training epoch 456\n",
      "epoch 456:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.62it/s]2022-02-02 11:12:19 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 456 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 456 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:12:21 | INFO | valid | epoch 456 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1089.1 | wpb 16 | bsz 8 | num_updates 19152 | best_loss 0.754\n",
      "2022-02-02 11:12:21 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:12:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint456.pt (epoch 456 @ 19152 updates, score 0.755) (writing took 0.02967147500021383 seconds)\n",
      "2022-02-02 11:12:21 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)\n",
      "2022-02-02 11:12:21 | INFO | train | epoch 456 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 486.3 | ups 7.63 | wpb 63.7 | bsz 31.9 | num_updates 19152 | lr 2.89037e-05 | gnorm 0.572 | train_wall 2 | wall 2533\n",
      "epoch 457:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:12:21 | INFO | fairseq.trainer | begin training epoch 457\n",
      "epoch 457:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.55it/s]2022-02-02 11:12:25 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 457 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 457 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:12:26 | INFO | valid | epoch 457 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1151.8 | wpb 16 | bsz 8 | num_updates 19194 | best_loss 0.754\n",
      "2022-02-02 11:12:26 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:12:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint457.pt (epoch 457 @ 19194 updates, score 0.755) (writing took 0.019535923000148614 seconds)\n",
      "2022-02-02 11:12:26 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)\n",
      "2022-02-02 11:12:26 | INFO | train | epoch 457 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 487.5 | ups 7.65 | wpb 63.7 | bsz 31.9 | num_updates 19194 | lr 2.8872e-05 | gnorm 0.69 | train_wall 2 | wall 2538\n",
      "epoch 458:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:12:26 | INFO | fairseq.trainer | begin training epoch 458\n",
      "epoch 458:  95%|▉| 40/42 [00:03<00:00, 20.83it/s, loss=0.739, nll_loss=0.37, acc2022-02-02 11:12:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 458 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 458 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:12:32 | INFO | valid | epoch 458 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1324.7 | wpb 16 | bsz 8 | num_updates 19236 | best_loss 0.754\n",
      "2022-02-02 11:12:32 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:12:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint458.pt (epoch 458 @ 19236 updates, score 0.754) (writing took 0.0354560170003424 seconds)\n",
      "2022-02-02 11:12:32 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)\n",
      "2022-02-02 11:12:32 | INFO | train | epoch 458 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 497.6 | ups 7.81 | wpb 63.7 | bsz 31.9 | num_updates 19236 | lr 2.88405e-05 | gnorm 0.635 | train_wall 2 | wall 2544\n",
      "epoch 459:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:12:32 | INFO | fairseq.trainer | begin training epoch 459\n",
      "epoch 459:  93%|█████████████████████████████▋  | 39/42 [00:03<00:00, 21.52it/s]2022-02-02 11:12:36 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 459 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 459 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:12:37 | INFO | valid | epoch 459 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1258.2 | wpb 16 | bsz 8 | num_updates 19278 | best_loss 0.754\n",
      "2022-02-02 11:12:37 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:12:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint459.pt (epoch 459 @ 19278 updates, score 0.755) (writing took 0.024532918000204518 seconds)\n",
      "2022-02-02 11:12:37 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)\n",
      "2022-02-02 11:12:37 | INFO | train | epoch 459 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 484.4 | ups 7.6 | wpb 63.7 | bsz 31.9 | num_updates 19278 | lr 2.88091e-05 | gnorm 0.673 | train_wall 2 | wall 2549\n",
      "epoch 460:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:12:37 | INFO | fairseq.trainer | begin training epoch 460\n",
      "epoch 460:  95%|▉| 40/42 [00:03<00:00, 21.81it/s, loss=0.737, nll_loss=0.368, ac2022-02-02 11:12:41 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 460 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 460 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:12:43 | INFO | valid | epoch 460 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1178 | wpb 16 | bsz 8 | num_updates 19320 | best_loss 0.754\n",
      "2022-02-02 11:12:43 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:12:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint460.pt (epoch 460 @ 19320 updates, score 0.755) (writing took 0.029073778000110906 seconds)\n",
      "2022-02-02 11:12:43 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)\n",
      "2022-02-02 11:12:43 | INFO | train | epoch 460 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 490 | ups 7.69 | wpb 63.7 | bsz 31.9 | num_updates 19320 | lr 2.87777e-05 | gnorm 0.604 | train_wall 2 | wall 2555\n",
      "epoch 461:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:12:43 | INFO | fairseq.trainer | begin training epoch 461\n",
      "epoch 461:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.70it/s]2022-02-02 11:12:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 461 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 461 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:12:48 | INFO | valid | epoch 461 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1327.3 | wpb 16 | bsz 8 | num_updates 19362 | best_loss 0.754\n",
      "2022-02-02 11:12:48 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:12:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint461.pt (epoch 461 @ 19362 updates, score 0.754) (writing took 0.03255863699996553 seconds)\n",
      "2022-02-02 11:12:48 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)\n",
      "2022-02-02 11:12:48 | INFO | train | epoch 461 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 483.5 | ups 7.59 | wpb 63.7 | bsz 31.9 | num_updates 19362 | lr 2.87465e-05 | gnorm 0.57 | train_wall 2 | wall 2560\n",
      "epoch 462:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:12:48 | INFO | fairseq.trainer | begin training epoch 462\n",
      "epoch 462:  95%|▉| 40/42 [00:03<00:00, 21.86it/s, loss=0.749, nll_loss=0.374, ac2022-02-02 11:12:52 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 462 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 462 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:12:54 | INFO | valid | epoch 462 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1343.8 | wpb 16 | bsz 8 | num_updates 19404 | best_loss 0.754\n",
      "2022-02-02 11:12:54 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:12:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint462.pt (epoch 462 @ 19404 updates, score 0.754) (writing took 0.031376043999898684 seconds)\n",
      "2022-02-02 11:12:54 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)\n",
      "2022-02-02 11:12:54 | INFO | train | epoch 462 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 488 | ups 7.66 | wpb 63.7 | bsz 31.9 | num_updates 19404 | lr 2.87154e-05 | gnorm 0.549 | train_wall 2 | wall 2566\n",
      "epoch 463:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:12:54 | INFO | fairseq.trainer | begin training epoch 463\n",
      "epoch 463:  95%|██████████████████████████████▍ | 40/42 [00:04<00:00, 21.35it/s]2022-02-02 11:12:58 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 463 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 463 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:13:00 | INFO | valid | epoch 463 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1311 | wpb 16 | bsz 8 | num_updates 19446 | best_loss 0.754\n",
      "2022-02-02 11:13:00 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:13:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint463.pt (epoch 463 @ 19446 updates, score 0.755) (writing took 0.02257417400005579 seconds)\n",
      "2022-02-02 11:13:00 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)\n",
      "2022-02-02 11:13:00 | INFO | train | epoch 463 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 449.2 | ups 7.05 | wpb 63.7 | bsz 31.9 | num_updates 19446 | lr 2.86843e-05 | gnorm 0.682 | train_wall 2 | wall 2572\n",
      "epoch 464:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:13:00 | INFO | fairseq.trainer | begin training epoch 464\n",
      "epoch 464:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.53it/s]2022-02-02 11:13:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 464 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 464 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:13:05 | INFO | valid | epoch 464 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1153.2 | wpb 16 | bsz 8 | num_updates 19488 | best_loss 0.754\n",
      "2022-02-02 11:13:05 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:13:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint464.pt (epoch 464 @ 19488 updates, score 0.755) (writing took 0.03178083600005266 seconds)\n",
      "2022-02-02 11:13:05 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)\n",
      "2022-02-02 11:13:05 | INFO | train | epoch 464 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 484.8 | ups 7.61 | wpb 63.7 | bsz 31.9 | num_updates 19488 | lr 2.86534e-05 | gnorm 0.657 | train_wall 2 | wall 2577\n",
      "epoch 465:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:13:05 | INFO | fairseq.trainer | begin training epoch 465\n",
      "epoch 465:  93%|▉| 39/42 [00:03<00:00, 21.81it/s, loss=0.739, nll_loss=0.37, acc2022-02-02 11:13:09 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 465 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 465 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:13:11 | INFO | valid | epoch 465 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1091.8 | wpb 16 | bsz 8 | num_updates 19530 | best_loss 0.754\n",
      "2022-02-02 11:13:11 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:13:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint465.pt (epoch 465 @ 19530 updates, score 0.755) (writing took 0.024838356000145723 seconds)\n",
      "2022-02-02 11:13:11 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)\n",
      "2022-02-02 11:13:11 | INFO | train | epoch 465 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 478.3 | ups 7.51 | wpb 63.7 | bsz 31.9 | num_updates 19530 | lr 2.86226e-05 | gnorm 0.513 | train_wall 2 | wall 2583\n",
      "epoch 466:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:13:11 | INFO | fairseq.trainer | begin training epoch 466\n",
      "epoch 466:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.77it/s]2022-02-02 11:13:15 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 466 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 466 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:24,  1.72s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:13:17 | INFO | valid | epoch 466 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1073 | wpb 16 | bsz 8 | num_updates 19572 | best_loss 0.754\n",
      "2022-02-02 11:13:17 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:13:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint466.pt (epoch 466 @ 19572 updates, score 0.754) (writing took 0.041253129999859084 seconds)\n",
      "2022-02-02 11:13:17 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)\n",
      "2022-02-02 11:13:17 | INFO | train | epoch 466 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 472.2 | ups 7.41 | wpb 63.7 | bsz 31.9 | num_updates 19572 | lr 2.85919e-05 | gnorm 0.602 | train_wall 2 | wall 2589\n",
      "epoch 467:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:13:17 | INFO | fairseq.trainer | begin training epoch 467\n",
      "epoch 467:  95%|▉| 40/42 [00:03<00:00, 20.92it/s, loss=0.745, nll_loss=0.373, ac2022-02-02 11:13:20 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 467 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 467 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:13:22 | INFO | valid | epoch 467 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1333.9 | wpb 16 | bsz 8 | num_updates 19614 | best_loss 0.754\n",
      "2022-02-02 11:13:22 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:13:22 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint467.pt (epoch 467 @ 19614 updates, score 0.754) (writing took 0.035754827999880945 seconds)\n",
      "2022-02-02 11:13:22 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)\n",
      "2022-02-02 11:13:22 | INFO | train | epoch 467 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 492.7 | ups 7.73 | wpb 63.7 | bsz 31.9 | num_updates 19614 | lr 2.85612e-05 | gnorm 0.567 | train_wall 2 | wall 2594\n",
      "epoch 468:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:13:22 | INFO | fairseq.trainer | begin training epoch 468\n",
      "epoch 468:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.48it/s]2022-02-02 11:13:26 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 468 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 468 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:13:27 | INFO | valid | epoch 468 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1241.8 | wpb 16 | bsz 8 | num_updates 19656 | best_loss 0.754\n",
      "2022-02-02 11:13:27 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:13:27 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint468.pt (epoch 468 @ 19656 updates, score 0.755) (writing took 0.03035526600024241 seconds)\n",
      "2022-02-02 11:13:27 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)\n",
      "2022-02-02 11:13:27 | INFO | train | epoch 468 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 491.3 | ups 7.71 | wpb 63.7 | bsz 31.9 | num_updates 19656 | lr 2.85307e-05 | gnorm 0.601 | train_wall 2 | wall 2599\n",
      "epoch 469:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:13:27 | INFO | fairseq.trainer | begin training epoch 469\n",
      "epoch 469:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.70it/s]2022-02-02 11:13:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 469 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 469 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:13:33 | INFO | valid | epoch 469 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1205.7 | wpb 16 | bsz 8 | num_updates 19698 | best_loss 0.754\n",
      "2022-02-02 11:13:33 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:13:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint469.pt (epoch 469 @ 19698 updates, score 0.754) (writing took 0.03444262599987269 seconds)\n",
      "2022-02-02 11:13:33 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)\n",
      "2022-02-02 11:13:33 | INFO | train | epoch 469 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 493 | ups 7.74 | wpb 63.7 | bsz 31.9 | num_updates 19698 | lr 2.85003e-05 | gnorm 0.615 | train_wall 2 | wall 2605\n",
      "epoch 470:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:13:33 | INFO | fairseq.trainer | begin training epoch 470\n",
      "epoch 470:  95%|▉| 40/42 [00:03<00:00, 21.67it/s, loss=0.738, nll_loss=0.369, ac2022-02-02 11:13:37 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 470 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 470 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:13:38 | INFO | valid | epoch 470 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1276.4 | wpb 16 | bsz 8 | num_updates 19740 | best_loss 0.754\n",
      "2022-02-02 11:13:38 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:13:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint470.pt (epoch 470 @ 19740 updates, score 0.755) (writing took 0.024441431000013836 seconds)\n",
      "2022-02-02 11:13:38 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)\n",
      "2022-02-02 11:13:38 | INFO | train | epoch 470 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 489.6 | ups 7.68 | wpb 63.7 | bsz 31.9 | num_updates 19740 | lr 2.84699e-05 | gnorm 0.52 | train_wall 2 | wall 2610\n",
      "epoch 471:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:13:38 | INFO | fairseq.trainer | begin training epoch 471\n",
      "epoch 471:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.43it/s]2022-02-02 11:13:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 471 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 471 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:13:44 | INFO | valid | epoch 471 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1167.8 | wpb 16 | bsz 8 | num_updates 19782 | best_loss 0.754\n",
      "2022-02-02 11:13:44 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:13:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint471.pt (epoch 471 @ 19782 updates, score 0.755) (writing took 0.03349309399982303 seconds)\n",
      "2022-02-02 11:13:44 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)\n",
      "2022-02-02 11:13:44 | INFO | train | epoch 471 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 496.4 | ups 7.79 | wpb 63.7 | bsz 31.9 | num_updates 19782 | lr 2.84397e-05 | gnorm 0.631 | train_wall 2 | wall 2616\n",
      "epoch 472:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:13:44 | INFO | fairseq.trainer | begin training epoch 472\n",
      "epoch 472:  95%|▉| 40/42 [00:03<00:00, 21.88it/s, loss=0.753, nll_loss=0.377, ac2022-02-02 11:13:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 472 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 472 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.53s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:13:49 | INFO | valid | epoch 472 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1210.4 | wpb 16 | bsz 8 | num_updates 19824 | best_loss 0.754\n",
      "2022-02-02 11:13:49 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:13:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint472.pt (epoch 472 @ 19824 updates, score 0.755) (writing took 0.025338320000173553 seconds)\n",
      "2022-02-02 11:13:49 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)\n",
      "2022-02-02 11:13:49 | INFO | train | epoch 472 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 497.3 | ups 7.81 | wpb 63.7 | bsz 31.9 | num_updates 19824 | lr 2.84095e-05 | gnorm 0.705 | train_wall 2 | wall 2621\n",
      "epoch 473:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:13:49 | INFO | fairseq.trainer | begin training epoch 473\n",
      "epoch 473:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.36it/s]2022-02-02 11:13:53 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 473 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 473 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:13:55 | INFO | valid | epoch 473 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1234.5 | wpb 16 | bsz 8 | num_updates 19866 | best_loss 0.754\n",
      "2022-02-02 11:13:55 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:13:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint473.pt (epoch 473 @ 19866 updates, score 0.755) (writing took 0.020445523000034882 seconds)\n",
      "2022-02-02 11:13:55 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)\n",
      "2022-02-02 11:13:55 | INFO | train | epoch 473 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 488.9 | ups 7.67 | wpb 63.7 | bsz 31.9 | num_updates 19866 | lr 2.83795e-05 | gnorm 0.663 | train_wall 2 | wall 2627\n",
      "epoch 474:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:13:55 | INFO | fairseq.trainer | begin training epoch 474\n",
      "epoch 474:  95%|▉| 40/42 [00:03<00:00, 21.67it/s, loss=0.731, nll_loss=0.366, ac2022-02-02 11:13:58 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 474 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 474 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:14:00 | INFO | valid | epoch 474 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1174.2 | wpb 16 | bsz 8 | num_updates 19908 | best_loss 0.754\n",
      "2022-02-02 11:14:00 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:14:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint474.pt (epoch 474 @ 19908 updates, score 0.755) (writing took 0.030073574999732955 seconds)\n",
      "2022-02-02 11:14:00 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)\n",
      "2022-02-02 11:14:00 | INFO | train | epoch 474 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 492.4 | ups 7.73 | wpb 63.7 | bsz 31.9 | num_updates 19908 | lr 2.83496e-05 | gnorm 0.525 | train_wall 2 | wall 2632\n",
      "epoch 475:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:14:00 | INFO | fairseq.trainer | begin training epoch 475\n",
      "epoch 475:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.80it/s]2022-02-02 11:14:04 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 475 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 475 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:14:05 | INFO | valid | epoch 475 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1267.8 | wpb 16 | bsz 8 | num_updates 19950 | best_loss 0.754\n",
      "2022-02-02 11:14:05 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:14:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint475.pt (epoch 475 @ 19950 updates, score 0.755) (writing took 0.027801722999811318 seconds)\n",
      "2022-02-02 11:14:06 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)\n",
      "2022-02-02 11:14:06 | INFO | train | epoch 475 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 489.1 | ups 7.68 | wpb 63.7 | bsz 31.9 | num_updates 19950 | lr 2.83197e-05 | gnorm 0.564 | train_wall 2 | wall 2637\n",
      "epoch 476:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:14:06 | INFO | fairseq.trainer | begin training epoch 476\n",
      "epoch 476:  98%|███████████████████████████████▏| 41/42 [00:03<00:00, 21.56it/s]2022-02-02 11:14:09 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 476 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 476 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:14:11 | INFO | valid | epoch 476 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1151.2 | wpb 16 | bsz 8 | num_updates 19992 | best_loss 0.754\n",
      "2022-02-02 11:14:11 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:14:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint476.pt (epoch 476 @ 19992 updates, score 0.755) (writing took 0.026429480999922816 seconds)\n",
      "2022-02-02 11:14:11 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)\n",
      "2022-02-02 11:14:11 | INFO | train | epoch 476 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 483.5 | ups 7.59 | wpb 63.7 | bsz 31.9 | num_updates 19992 | lr 2.82899e-05 | gnorm 0.514 | train_wall 2 | wall 2643\n",
      "epoch 477:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:14:11 | INFO | fairseq.trainer | begin training epoch 477\n",
      "epoch 477:  17%|█████▌                           | 7/42 [00:02<00:07,  4.93it/s]2022-02-02 11:14:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 477 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 477 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:26,  1.87s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:14:15 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1005 | wpb 16 | bsz 8 | num_updates 20000 | best_loss 0.754\n",
      "2022-02-02 11:14:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:14:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint_477_20000.pt (epoch 477 @ 20000 updates, score 0.755) (writing took 0.027637811999738915 seconds)\n",
      "epoch 477:  98%|▉| 41/42 [00:05<00:00, 20.43it/s, loss=0.737, nll_loss=0.368, ac2022-02-02 11:14:17 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 477 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 477 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:14:19 | INFO | valid | epoch 477 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1334.7 | wpb 16 | bsz 8 | num_updates 20034 | best_loss 0.754\n",
      "2022-02-02 11:14:19 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:14:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint477.pt (epoch 477 @ 20034 updates, score 0.754) (writing took 0.04056384999967122 seconds)\n",
      "2022-02-02 11:14:19 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)\n",
      "2022-02-02 11:14:19 | INFO | train | epoch 477 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 344.6 | ups 5.41 | wpb 63.7 | bsz 31.9 | num_updates 20034 | lr 2.82603e-05 | gnorm 0.563 | train_wall 2 | wall 2651\n",
      "epoch 478:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:14:19 | INFO | fairseq.trainer | begin training epoch 478\n",
      "epoch 478:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.60it/s]2022-02-02 11:14:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 478 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 478 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:14:24 | INFO | valid | epoch 478 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1311.5 | wpb 16 | bsz 8 | num_updates 20076 | best_loss 0.754\n",
      "2022-02-02 11:14:24 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:14:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint478.pt (epoch 478 @ 20076 updates, score 0.754) (writing took 0.026295570000002044 seconds)\n",
      "2022-02-02 11:14:24 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)\n",
      "2022-02-02 11:14:24 | INFO | train | epoch 478 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 487.2 | ups 7.65 | wpb 63.7 | bsz 31.9 | num_updates 20076 | lr 2.82307e-05 | gnorm 0.528 | train_wall 2 | wall 2656\n",
      "epoch 479:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:14:24 | INFO | fairseq.trainer | begin training epoch 479\n",
      "epoch 479:  95%|▉| 40/42 [00:03<00:00, 21.36it/s, loss=0.749, nll_loss=0.375, ac2022-02-02 11:14:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 479 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 479 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:14:30 | INFO | valid | epoch 479 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1310 | wpb 16 | bsz 8 | num_updates 20118 | best_loss 0.754\n",
      "2022-02-02 11:14:30 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:14:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint479.pt (epoch 479 @ 20118 updates, score 0.754) (writing took 0.03469762400027321 seconds)\n",
      "2022-02-02 11:14:30 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)\n",
      "2022-02-02 11:14:30 | INFO | train | epoch 479 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 493.3 | ups 7.74 | wpb 63.7 | bsz 31.9 | num_updates 20118 | lr 2.82012e-05 | gnorm 0.644 | train_wall 2 | wall 2662\n",
      "epoch 480:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:14:30 | INFO | fairseq.trainer | begin training epoch 480\n",
      "epoch 480:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.62it/s]2022-02-02 11:14:33 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 480 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 480 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.56s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:14:35 | INFO | valid | epoch 480 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1163 | wpb 16 | bsz 8 | num_updates 20160 | best_loss 0.754\n",
      "2022-02-02 11:14:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:14:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint480.pt (epoch 480 @ 20160 updates, score 0.755) (writing took 0.02672252699994715 seconds)\n",
      "2022-02-02 11:14:35 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)\n",
      "2022-02-02 11:14:35 | INFO | train | epoch 480 | loss 0.743 | nll_loss 0.372 | accuracy 79 | wps 495.8 | ups 7.78 | wpb 63.7 | bsz 31.9 | num_updates 20160 | lr 2.81718e-05 | gnorm 0.576 | train_wall 2 | wall 2667\n",
      "epoch 481:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:14:35 | INFO | fairseq.trainer | begin training epoch 481\n",
      "epoch 481:  95%|▉| 40/42 [00:03<00:00, 21.64it/s, loss=0.742, nll_loss=0.371, ac2022-02-02 11:14:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 481 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 481 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.64s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:14:41 | INFO | valid | epoch 481 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1315.4 | wpb 16 | bsz 8 | num_updates 20202 | best_loss 0.754\n",
      "2022-02-02 11:14:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:14:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint481.pt (epoch 481 @ 20202 updates, score 0.754) (writing took 0.03570721799997045 seconds)\n",
      "2022-02-02 11:14:41 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)\n",
      "2022-02-02 11:14:41 | INFO | train | epoch 481 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 486.2 | ups 7.63 | wpb 63.7 | bsz 31.9 | num_updates 20202 | lr 2.81425e-05 | gnorm 0.601 | train_wall 2 | wall 2673\n",
      "epoch 482:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:14:41 | INFO | fairseq.trainer | begin training epoch 482\n",
      "epoch 482:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.33it/s]2022-02-02 11:14:44 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 482 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 482 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.58s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:14:46 | INFO | valid | epoch 482 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1237 | wpb 16 | bsz 8 | num_updates 20244 | best_loss 0.754\n",
      "2022-02-02 11:14:46 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:14:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint482.pt (epoch 482 @ 20244 updates, score 0.754) (writing took 0.07745547300010003 seconds)\n",
      "2022-02-02 11:14:46 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)\n",
      "2022-02-02 11:14:46 | INFO | train | epoch 482 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 485.4 | ups 7.62 | wpb 63.7 | bsz 31.9 | num_updates 20244 | lr 2.81133e-05 | gnorm 0.55 | train_wall 2 | wall 2678\n",
      "epoch 483:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:14:46 | INFO | fairseq.trainer | begin training epoch 483\n",
      "epoch 483:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.70it/s]2022-02-02 11:14:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 483 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 483 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:14:52 | INFO | valid | epoch 483 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1132 | wpb 16 | bsz 8 | num_updates 20286 | best_loss 0.754\n",
      "2022-02-02 11:14:52 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:14:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint483.pt (epoch 483 @ 20286 updates, score 0.754) (writing took 0.029814118000103917 seconds)\n",
      "2022-02-02 11:14:52 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)\n",
      "2022-02-02 11:14:52 | INFO | train | epoch 483 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 487 | ups 7.64 | wpb 63.7 | bsz 31.9 | num_updates 20286 | lr 2.80842e-05 | gnorm 0.549 | train_wall 2 | wall 2684\n",
      "epoch 484:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:14:52 | INFO | fairseq.trainer | begin training epoch 484\n",
      "epoch 484:  95%|▉| 40/42 [00:03<00:00, 21.57it/s, loss=0.744, nll_loss=0.372, ac2022-02-02 11:14:55 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 484 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 484 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:14:57 | INFO | valid | epoch 484 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1163.9 | wpb 16 | bsz 8 | num_updates 20328 | best_loss 0.754\n",
      "2022-02-02 11:14:57 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:14:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint484.pt (epoch 484 @ 20328 updates, score 0.755) (writing took 0.032108775000324385 seconds)\n",
      "2022-02-02 11:14:57 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)\n",
      "2022-02-02 11:14:57 | INFO | train | epoch 484 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 491.9 | ups 7.72 | wpb 63.7 | bsz 31.9 | num_updates 20328 | lr 2.80552e-05 | gnorm 0.519 | train_wall 2 | wall 2689\n",
      "epoch 485:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:14:57 | INFO | fairseq.trainer | begin training epoch 485\n",
      "epoch 485:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.57it/s]2022-02-02 11:15:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 485 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 485 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:15:02 | INFO | valid | epoch 485 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1195.9 | wpb 16 | bsz 8 | num_updates 20370 | best_loss 0.754\n",
      "2022-02-02 11:15:02 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:15:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint485.pt (epoch 485 @ 20370 updates, score 0.754) (writing took 0.029883222000080423 seconds)\n",
      "2022-02-02 11:15:02 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)\n",
      "2022-02-02 11:15:02 | INFO | train | epoch 485 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 495 | ups 7.77 | wpb 63.7 | bsz 31.9 | num_updates 20370 | lr 2.80262e-05 | gnorm 0.619 | train_wall 2 | wall 2694\n",
      "epoch 486:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:15:02 | INFO | fairseq.trainer | begin training epoch 486\n",
      "epoch 486:  95%|▉| 40/42 [00:03<00:00, 21.88it/s, loss=0.731, nll_loss=0.366, ac2022-02-02 11:15:06 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 486 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 486 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:15:08 | INFO | valid | epoch 486 | valid on 'valid' subset | loss 0.755 | nll_loss 0.378 | accuracy 78.3 | wps 1256.5 | wpb 16 | bsz 8 | num_updates 20412 | best_loss 0.754\n",
      "2022-02-02 11:15:08 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:15:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint486.pt (epoch 486 @ 20412 updates, score 0.755) (writing took 0.02296094500024992 seconds)\n",
      "2022-02-02 11:15:08 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)\n",
      "2022-02-02 11:15:08 | INFO | train | epoch 486 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 486.7 | ups 7.64 | wpb 63.7 | bsz 31.9 | num_updates 20412 | lr 2.79974e-05 | gnorm 0.62 | train_wall 2 | wall 2700\n",
      "epoch 487:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:15:08 | INFO | fairseq.trainer | begin training epoch 487\n",
      "epoch 487:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.76it/s]2022-02-02 11:15:12 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 487 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 487 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:15:13 | INFO | valid | epoch 487 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1165.2 | wpb 16 | bsz 8 | num_updates 20454 | best_loss 0.754\n",
      "2022-02-02 11:15:13 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:15:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint487.pt (epoch 487 @ 20454 updates, score 0.755) (writing took 0.020700259000022925 seconds)\n",
      "2022-02-02 11:15:13 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)\n",
      "2022-02-02 11:15:13 | INFO | train | epoch 487 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 486.9 | ups 7.64 | wpb 63.7 | bsz 31.9 | num_updates 20454 | lr 2.79686e-05 | gnorm 0.622 | train_wall 2 | wall 2705\n",
      "epoch 488:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:15:13 | INFO | fairseq.trainer | begin training epoch 488\n",
      "epoch 488:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 18.45it/s]2022-02-02 11:15:17 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 488 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 488 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.62s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:15:19 | INFO | valid | epoch 488 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1331.2 | wpb 16 | bsz 8 | num_updates 20496 | best_loss 0.754\n",
      "2022-02-02 11:15:19 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:15:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint488.pt (epoch 488 @ 20496 updates, score 0.754) (writing took 0.0391230740001447 seconds)\n",
      "2022-02-02 11:15:19 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)\n",
      "2022-02-02 11:15:19 | INFO | train | epoch 488 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 480.6 | ups 7.54 | wpb 63.7 | bsz 31.9 | num_updates 20496 | lr 2.79399e-05 | gnorm 0.565 | train_wall 2 | wall 2711\n",
      "epoch 489:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:15:19 | INFO | fairseq.trainer | begin training epoch 489\n",
      "epoch 489:  95%|▉| 40/42 [00:03<00:00, 21.82it/s, loss=0.756, nll_loss=0.378, ac2022-02-02 11:15:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 489 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 489 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:15:25 | INFO | valid | epoch 489 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1154.4 | wpb 16 | bsz 8 | num_updates 20538 | best_loss 0.754\n",
      "2022-02-02 11:15:25 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:15:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint489.pt (epoch 489 @ 20538 updates, score 0.755) (writing took 0.027437467999789078 seconds)\n",
      "2022-02-02 11:15:25 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)\n",
      "2022-02-02 11:15:25 | INFO | train | epoch 489 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 482.6 | ups 7.57 | wpb 63.7 | bsz 31.9 | num_updates 20538 | lr 2.79114e-05 | gnorm 0.668 | train_wall 2 | wall 2717\n",
      "epoch 490:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:15:25 | INFO | fairseq.trainer | begin training epoch 490\n",
      "epoch 490:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.61it/s]2022-02-02 11:15:28 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 490 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 490 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.55s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:15:30 | INFO | valid | epoch 490 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1307.1 | wpb 16 | bsz 8 | num_updates 20580 | best_loss 0.754\n",
      "2022-02-02 11:15:30 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:15:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint490.pt (epoch 490 @ 20580 updates, score 0.755) (writing took 0.03138011200007895 seconds)\n",
      "2022-02-02 11:15:30 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)\n",
      "2022-02-02 11:15:30 | INFO | train | epoch 490 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 493.3 | ups 7.74 | wpb 63.7 | bsz 31.9 | num_updates 20580 | lr 2.78829e-05 | gnorm 0.626 | train_wall 2 | wall 2722\n",
      "epoch 491:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:15:30 | INFO | fairseq.trainer | begin training epoch 491\n",
      "epoch 491:  95%|▉| 40/42 [00:03<00:00, 20.92it/s, loss=0.735, nll_loss=0.368, ac2022-02-02 11:15:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 491 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 491 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:15:35 | INFO | valid | epoch 491 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1282.1 | wpb 16 | bsz 8 | num_updates 20622 | best_loss 0.754\n",
      "2022-02-02 11:15:35 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:15:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint491.pt (epoch 491 @ 20622 updates, score 0.754) (writing took 0.04223982499979684 seconds)\n",
      "2022-02-02 11:15:35 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)\n",
      "2022-02-02 11:15:35 | INFO | train | epoch 491 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 489.9 | ups 7.69 | wpb 63.7 | bsz 31.9 | num_updates 20622 | lr 2.78545e-05 | gnorm 0.624 | train_wall 2 | wall 2727\n",
      "epoch 492:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:15:35 | INFO | fairseq.trainer | begin training epoch 492\n",
      "epoch 492:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.66it/s]2022-02-02 11:15:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 492 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 492 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.59s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:15:41 | INFO | valid | epoch 492 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1291 | wpb 16 | bsz 8 | num_updates 20664 | best_loss 0.754\n",
      "2022-02-02 11:15:41 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:15:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint492.pt (epoch 492 @ 20664 updates, score 0.754) (writing took 0.033358607000081975 seconds)\n",
      "2022-02-02 11:15:41 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)\n",
      "2022-02-02 11:15:41 | INFO | train | epoch 492 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 482.5 | ups 7.57 | wpb 63.7 | bsz 31.9 | num_updates 20664 | lr 2.78261e-05 | gnorm 0.596 | train_wall 2 | wall 2733\n",
      "epoch 493:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:15:41 | INFO | fairseq.trainer | begin training epoch 493\n",
      "epoch 493:  95%|▉| 40/42 [00:03<00:00, 21.52it/s, loss=0.74, nll_loss=0.37, accu2022-02-02 11:15:45 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 493 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 493 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.63s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:15:47 | INFO | valid | epoch 493 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1144.2 | wpb 16 | bsz 8 | num_updates 20706 | best_loss 0.754\n",
      "2022-02-02 11:15:47 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:15:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint493.pt (epoch 493 @ 20706 updates, score 0.755) (writing took 0.03324264000002586 seconds)\n",
      "2022-02-02 11:15:47 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)\n",
      "2022-02-02 11:15:47 | INFO | train | epoch 493 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 482.2 | ups 7.57 | wpb 63.7 | bsz 31.9 | num_updates 20706 | lr 2.77979e-05 | gnorm 0.596 | train_wall 2 | wall 2739\n",
      "epoch 494:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:15:47 | INFO | fairseq.trainer | begin training epoch 494\n",
      "epoch 494:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.18it/s]2022-02-02 11:15:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 494 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 494 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:23,  1.66s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:15:52 | INFO | valid | epoch 494 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1182.1 | wpb 16 | bsz 8 | num_updates 20748 | best_loss 0.754\n",
      "2022-02-02 11:15:52 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:15:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint494.pt (epoch 494 @ 20748 updates, score 0.755) (writing took 0.03550014799975543 seconds)\n",
      "2022-02-02 11:15:52 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)\n",
      "2022-02-02 11:15:52 | INFO | train | epoch 494 | loss 0.741 | nll_loss 0.371 | accuracy 79 | wps 464.3 | ups 7.29 | wpb 63.7 | bsz 31.9 | num_updates 20748 | lr 2.77697e-05 | gnorm 0.535 | train_wall 2 | wall 2744\n",
      "epoch 495:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:15:52 | INFO | fairseq.trainer | begin training epoch 495\n",
      "epoch 495:  98%|███████████████████████████████▏| 41/42 [00:03<00:00, 21.49it/s]2022-02-02 11:15:56 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 495 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 495 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:25,  1.79s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:15:58 | INFO | valid | epoch 495 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1006.1 | wpb 16 | bsz 8 | num_updates 20790 | best_loss 0.754\n",
      "2022-02-02 11:15:58 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:15:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint495.pt (epoch 495 @ 20790 updates, score 0.754) (writing took 0.03789696100011497 seconds)\n",
      "2022-02-02 11:15:58 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)\n",
      "2022-02-02 11:15:58 | INFO | train | epoch 495 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 450.2 | ups 7.07 | wpb 63.7 | bsz 31.9 | num_updates 20790 | lr 2.77417e-05 | gnorm 0.677 | train_wall 2 | wall 2750\n",
      "epoch 496:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:15:58 | INFO | fairseq.trainer | begin training epoch 496\n",
      "epoch 496:  95%|▉| 40/42 [00:03<00:00, 21.68it/s, loss=0.748, nll_loss=0.374, ac2022-02-02 11:16:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 496 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 496 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.57s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:16:04 | INFO | valid | epoch 496 | valid on 'valid' subset | loss 0.754 | nll_loss 0.377 | accuracy 78.3 | wps 1298.9 | wpb 16 | bsz 8 | num_updates 20832 | best_loss 0.754\n",
      "2022-02-02 11:16:04 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:16:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint496.pt (epoch 496 @ 20832 updates, score 0.754) (writing took 0.03691024899990225 seconds)\n",
      "2022-02-02 11:16:04 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)\n",
      "2022-02-02 11:16:04 | INFO | train | epoch 496 | loss 0.743 | nll_loss 0.371 | accuracy 79 | wps 482.3 | ups 7.57 | wpb 63.7 | bsz 31.9 | num_updates 20832 | lr 2.77137e-05 | gnorm 0.575 | train_wall 2 | wall 2756\n",
      "epoch 497:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:16:04 | INFO | fairseq.trainer | begin training epoch 497\n",
      "epoch 497:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 20.76it/s]2022-02-02 11:16:08 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 497 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 497 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:26,  1.87s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:16:10 | INFO | valid | epoch 497 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1103 | wpb 16 | bsz 8 | num_updates 20874 | best_loss 0.754\n",
      "2022-02-02 11:16:10 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:16:10 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint497.pt (epoch 497 @ 20874 updates, score 0.755) (writing took 0.03139438800008065 seconds)\n",
      "2022-02-02 11:16:10 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)\n",
      "2022-02-02 11:16:10 | INFO | train | epoch 497 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 458.8 | ups 7.2 | wpb 63.7 | bsz 31.9 | num_updates 20874 | lr 2.76858e-05 | gnorm 0.605 | train_wall 2 | wall 2762\n",
      "epoch 498:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:16:10 | INFO | fairseq.trainer | begin training epoch 498\n",
      "epoch 498:  93%|▉| 39/42 [00:03<00:00, 21.63it/s, loss=0.743, nll_loss=0.371, ac2022-02-02 11:16:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 498 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 498 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:21,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:16:15 | INFO | valid | epoch 498 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1177.9 | wpb 16 | bsz 8 | num_updates 20916 | best_loss 0.754\n",
      "2022-02-02 11:16:15 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:16:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint498.pt (epoch 498 @ 20916 updates, score 0.755) (writing took 0.030751531000078103 seconds)\n",
      "2022-02-02 11:16:15 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)\n",
      "2022-02-02 11:16:15 | INFO | train | epoch 498 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 492.6 | ups 7.73 | wpb 63.7 | bsz 31.9 | num_updates 20916 | lr 2.7658e-05 | gnorm 0.688 | train_wall 2 | wall 2767\n",
      "epoch 499:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:16:15 | INFO | fairseq.trainer | begin training epoch 499\n",
      "epoch 499:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.73it/s]2022-02-02 11:16:19 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 499 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 499 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.61s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:16:21 | INFO | valid | epoch 499 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1151.1 | wpb 16 | bsz 8 | num_updates 20958 | best_loss 0.754\n",
      "2022-02-02 11:16:21 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:16:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint499.pt (epoch 499 @ 20958 updates, score 0.755) (writing took 0.027786957999978767 seconds)\n",
      "2022-02-02 11:16:21 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)\n",
      "2022-02-02 11:16:21 | INFO | train | epoch 499 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 484.8 | ups 7.61 | wpb 63.7 | bsz 31.9 | num_updates 20958 | lr 2.76303e-05 | gnorm 0.627 | train_wall 2 | wall 2773\n",
      "epoch 500:   0%|                                         | 0/42 [00:00<?, ?it/s]2022-02-02 11:16:21 | INFO | fairseq.trainer | begin training epoch 500\n",
      "epoch 500:  95%|██████████████████████████████▍ | 40/42 [00:03<00:00, 21.70it/s]2022-02-02 11:16:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 500 | valid on 'valid' subset:   0%|               | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 500 | valid on 'valid' subset:   7%|▍      | 1/15 [00:01<00:22,  1.60s/it]\u001b[A\n",
      "                                                                                \u001b[A2022-02-02 11:16:26 | INFO | valid | epoch 500 | valid on 'valid' subset | loss 0.755 | nll_loss 0.377 | accuracy 78.3 | wps 1343.1 | wpb 16 | bsz 8 | num_updates 21000 | best_loss 0.754\n",
      "2022-02-02 11:16:26 | INFO | fairseq_cli.train | begin save checkpoint\n",
      "2022-02-02 11:16:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ../../data/models/fairseq/checkpoint500.pt (epoch 500 @ 21000 updates, score 0.755) (writing took 0.03279161499995098 seconds)\n",
      "2022-02-02 11:16:26 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)\n",
      "2022-02-02 11:16:26 | INFO | train | epoch 500 | loss 0.742 | nll_loss 0.371 | accuracy 79 | wps 495 | ups 7.77 | wpb 63.7 | bsz 31.9 | num_updates 21000 | lr 2.76026e-05 | gnorm 0.675 | train_wall 2 | wall 2778\n",
      "2022-02-02 11:16:26 | INFO | fairseq_cli.train | done training in 2777.9 seconds\n"
     ]
    }
   ],
   "source": [
    "!fairseq-train ../../data/fairseq/heavy/ \\\n",
    "    --restore-file ../../../../BioPhi/biophi/humanization/methods/sapiens/models/v1/checkpoint_vh.pt \\\n",
    "    --reset-optimizer --reset-dataloader --reset-meters \\\n",
    "    --dataset-impl raw \\\n",
    "    --task sentence_prediction \\\n",
    "    --criterion sentence_prediction \\\n",
    "    --classification-head-name di-pred \\\n",
    "    --user-dir ../../../../BioPhi/biophi/humanization/methods/sapiens \\\n",
    "    --arch roberta_small \\\n",
    "    --max-tokens 8096 \\\n",
    "    --batch-size 8 \\\n",
    "    --update-freq 4 \\\n",
    "    --lr 1e-4 \\\n",
    "    --optimizer adam \\\n",
    "    --lr-scheduler inverse_sqrt \\\n",
    "    --warmup-updates 1600 \\\n",
    "    --max-epoch 500 \\\n",
    "    --max-positions 144 \\\n",
    "    --skip-invalid-size-inputs-valid-test \\\n",
    "    --validate-interval-updates 5000 \\\n",
    "    --save-interval-updates 5000 \\\n",
    "    --save-dir ../../data/models/fairseq \\\n",
    "    --num-classes 2 \\\n",
    "    --shorten-method truncate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1b54918-8a94-4686-88e0-bbb9e2e14dde",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: fairseq-train [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]\n",
      "                     [--log-format {json,none,simple,tqdm}]\n",
      "                     [--tensorboard-logdir TENSORBOARD_LOGDIR] [--seed SEED]\n",
      "                     [--cpu] [--tpu] [--bf16] [--memory-efficient-bf16]\n",
      "                     [--fp16] [--memory-efficient-fp16]\n",
      "                     [--fp16-no-flatten-grads]\n",
      "                     [--fp16-init-scale FP16_INIT_SCALE]\n",
      "                     [--fp16-scale-window FP16_SCALE_WINDOW]\n",
      "                     [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]\n",
      "                     [--min-loss-scale MIN_LOSS_SCALE]\n",
      "                     [--threshold-loss-scale THRESHOLD_LOSS_SCALE]\n",
      "                     [--user-dir USER_DIR]\n",
      "                     [--empty-cache-freq EMPTY_CACHE_FREQ]\n",
      "                     [--all-gather-list-size ALL_GATHER_LIST_SIZE]\n",
      "                     [--model-parallel-size MODEL_PARALLEL_SIZE]\n",
      "                     [--checkpoint-suffix CHECKPOINT_SUFFIX]\n",
      "                     [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]\n",
      "                     [--quantization-config-path QUANTIZATION_CONFIG_PATH]\n",
      "                     [--profile]\n",
      "                     [--criterion {cross_entropy,ctc,adaptive_loss,wav2vec,legacy_masked_lm_loss,nat_loss,label_smoothed_cross_entropy,composite_loss,sentence_prediction,label_smoothed_cross_entropy_with_alignment,masked_lm,sentence_ranking,vocab_parallel_cross_entropy}]\n",
      "                     [--tokenizer {nltk,space,moses}]\n",
      "                     [--bpe {sentencepiece,fastbpe,gpt2,subword_nmt,hf_byte_bpe,bert,byte_bpe,characters,bytes}]\n",
      "                     [--optimizer {nag,adafactor,sgd,adamax,adagrad,adam,lamb,adadelta}]\n",
      "                     [--lr-scheduler {fixed,reduce_lr_on_plateau,polynomial_decay,inverse_sqrt,tri_stage,cosine,triangular}]\n",
      "                     [--scoring {sacrebleu,bleu,wer,chrf}] [--task TASK]\n",
      "                     [--num-workers NUM_WORKERS]\n",
      "                     [--skip-invalid-size-inputs-valid-test]\n",
      "                     [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]\n",
      "                     [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]\n",
      "                     [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]\n",
      "                     [--dataset-impl {raw,lazy,cached,mmap,fasta}]\n",
      "                     [--data-buffer-size DATA_BUFFER_SIZE]\n",
      "                     [--train-subset TRAIN_SUBSET]\n",
      "                     [--valid-subset VALID_SUBSET]\n",
      "                     [--validate-interval VALIDATE_INTERVAL]\n",
      "                     [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]\n",
      "                     [--validate-after-updates VALIDATE_AFTER_UPDATES]\n",
      "                     [--fixed-validation-seed FIXED_VALIDATION_SEED]\n",
      "                     [--disable-validation]\n",
      "                     [--max-tokens-valid MAX_TOKENS_VALID]\n",
      "                     [--batch-size-valid BATCH_SIZE_VALID]\n",
      "                     [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]\n",
      "                     [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]\n",
      "                     [--distributed-world-size DISTRIBUTED_WORLD_SIZE]\n",
      "                     [--distributed-rank DISTRIBUTED_RANK]\n",
      "                     [--distributed-backend DISTRIBUTED_BACKEND]\n",
      "                     [--distributed-init-method DISTRIBUTED_INIT_METHOD]\n",
      "                     [--distributed-port DISTRIBUTED_PORT]\n",
      "                     [--device-id DEVICE_ID] [--distributed-no-spawn]\n",
      "                     [--ddp-backend {c10d,no_c10d}]\n",
      "                     [--bucket-cap-mb BUCKET_CAP_MB] [--fix-batches-to-gpus]\n",
      "                     [--find-unused-parameters] [--fast-stat-sync]\n",
      "                     [--broadcast-buffers]\n",
      "                     [--distributed-wrapper {DDP,SlowMo}]\n",
      "                     [--slowmo-momentum SLOWMO_MOMENTUM]\n",
      "                     [--slowmo-algorithm SLOWMO_ALGORITHM]\n",
      "                     [--localsgd-frequency LOCALSGD_FREQUENCY]\n",
      "                     [--nprocs-per-node NPROCS_PER_NODE]\n",
      "                     [--pipeline-model-parallel]\n",
      "                     [--pipeline-balance PIPELINE_BALANCE]\n",
      "                     [--pipeline-devices PIPELINE_DEVICES]\n",
      "                     [--pipeline-chunks PIPELINE_CHUNKS]\n",
      "                     [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]\n",
      "                     [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]\n",
      "                     [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]\n",
      "                     [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]\n",
      "                     [--pipeline-checkpoint {always,never,except_last}]\n",
      "                     [--zero-sharding {none,os}] [--arch ARCH]\n",
      "                     [--max-epoch MAX_EPOCH] [--max-update MAX_UPDATE]\n",
      "                     [--stop-time-hours STOP_TIME_HOURS]\n",
      "                     [--clip-norm CLIP_NORM] [--sentence-avg]\n",
      "                     [--update-freq UPDATE_FREQ] [--lr LR] [--min-lr MIN_LR]\n",
      "                     [--use-bmuf] [--save-dir SAVE_DIR]\n",
      "                     [--restore-file RESTORE_FILE]\n",
      "                     [--finetune-from-model FINETUNE_FROM_MODEL]\n",
      "                     [--reset-dataloader] [--reset-lr-scheduler]\n",
      "                     [--reset-meters] [--reset-optimizer]\n",
      "                     [--optimizer-overrides OPTIMIZER_OVERRIDES]\n",
      "                     [--save-interval SAVE_INTERVAL]\n",
      "                     [--save-interval-updates SAVE_INTERVAL_UPDATES]\n",
      "                     [--keep-interval-updates KEEP_INTERVAL_UPDATES]\n",
      "                     [--keep-last-epochs KEEP_LAST_EPOCHS]\n",
      "                     [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS]\n",
      "                     [--no-save] [--no-epoch-checkpoints]\n",
      "                     [--no-last-checkpoints] [--no-save-optimizer-state]\n",
      "                     [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]\n",
      "                     [--maximize-best-checkpoint-metric] [--patience PATIENCE]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --no-progress-bar     disable progress bar\n",
      "  --log-interval LOG_INTERVAL\n",
      "                        log progress every N batches (when progress bar is\n",
      "                        disabled)\n",
      "  --log-format {json,none,simple,tqdm}\n",
      "                        log format to use\n",
      "  --tensorboard-logdir TENSORBOARD_LOGDIR\n",
      "                        path to save logs for tensorboard, should match\n",
      "                        --logdir of running tensorboard (default: no\n",
      "                        tensorboard logging)\n",
      "  --seed SEED           pseudo random number generator seed\n",
      "  --cpu                 use CPU instead of CUDA\n",
      "  --tpu                 use TPU instead of CUDA\n",
      "  --bf16                use bfloat16; implies --tpu\n",
      "  --memory-efficient-bf16\n",
      "                        use a memory-efficient version of BF16 training;\n",
      "                        implies --bf16\n",
      "  --fp16                use FP16\n",
      "  --memory-efficient-fp16\n",
      "                        use a memory-efficient version of FP16 training;\n",
      "                        implies --fp16\n",
      "  --fp16-no-flatten-grads\n",
      "                        don't flatten FP16 grads tensor\n",
      "  --fp16-init-scale FP16_INIT_SCALE\n",
      "                        default FP16 loss scale\n",
      "  --fp16-scale-window FP16_SCALE_WINDOW\n",
      "                        number of updates before increasing loss scale\n",
      "  --fp16-scale-tolerance FP16_SCALE_TOLERANCE\n",
      "                        pct of updates that can overflow before decreasing the\n",
      "                        loss scale\n",
      "  --min-loss-scale MIN_LOSS_SCALE\n",
      "                        minimum FP16 loss scale, after which training is\n",
      "                        stopped\n",
      "  --threshold-loss-scale THRESHOLD_LOSS_SCALE\n",
      "                        threshold FP16 loss scale from below\n",
      "  --user-dir USER_DIR   path to a python module containing custom extensions\n",
      "                        (tasks and/or architectures)\n",
      "  --empty-cache-freq EMPTY_CACHE_FREQ\n",
      "                        how often to clear the PyTorch CUDA cache (0 to\n",
      "                        disable)\n",
      "  --all-gather-list-size ALL_GATHER_LIST_SIZE\n",
      "                        number of bytes reserved for gathering stats from\n",
      "                        workers\n",
      "  --model-parallel-size MODEL_PARALLEL_SIZE\n",
      "                        total number of GPUs to parallelize model over\n",
      "  --checkpoint-suffix CHECKPOINT_SUFFIX\n",
      "                        suffix to add to the checkpoint file name\n",
      "  --checkpoint-shard-count CHECKPOINT_SHARD_COUNT\n",
      "                        Number of shards containing the checkpoint - if the\n",
      "                        checkpoint is over 300GB, it is preferable to split it\n",
      "                        into shards to prevent OOM on CPU while loading the\n",
      "                        checkpoint\n",
      "  --quantization-config-path QUANTIZATION_CONFIG_PATH\n",
      "                        path to quantization config file\n",
      "  --profile             enable autograd profiler emit_nvtx\n",
      "  --criterion {cross_entropy,ctc,adaptive_loss,wav2vec,legacy_masked_lm_loss,nat_loss,label_smoothed_cross_entropy,composite_loss,sentence_prediction,label_smoothed_cross_entropy_with_alignment,masked_lm,sentence_ranking,vocab_parallel_cross_entropy}\n",
      "  --tokenizer {nltk,space,moses}\n",
      "  --bpe {sentencepiece,fastbpe,gpt2,subword_nmt,hf_byte_bpe,bert,byte_bpe,characters,bytes}\n",
      "  --optimizer {nag,adafactor,sgd,adamax,adagrad,adam,lamb,adadelta}\n",
      "  --lr-scheduler {fixed,reduce_lr_on_plateau,polynomial_decay,inverse_sqrt,tri_stage,cosine,triangular}\n",
      "  --scoring {sacrebleu,bleu,wer,chrf}\n",
      "  --task TASK           task\n",
      "\n",
      "dataset_data_loading:\n",
      "  --num-workers NUM_WORKERS\n",
      "                        how many subprocesses to use for data loading\n",
      "  --skip-invalid-size-inputs-valid-test\n",
      "                        ignore too long or too short lines in valid and test\n",
      "                        set\n",
      "  --max-tokens MAX_TOKENS\n",
      "                        maximum number of tokens in a batch\n",
      "  --batch-size BATCH_SIZE\n",
      "                        number of examples in a batch\n",
      "  --required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE\n",
      "                        batch size will be a multiplier of this value\n",
      "  --required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE\n",
      "                        maximum sequence length in batch will be a multiplier\n",
      "                        of this value\n",
      "  --dataset-impl {raw,lazy,cached,mmap,fasta}\n",
      "                        output dataset implementation\n",
      "  --data-buffer-size DATA_BUFFER_SIZE\n",
      "                        Number of batches to preload\n",
      "  --train-subset TRAIN_SUBSET\n",
      "                        data subset to use for training (e.g. train, valid,\n",
      "                        test)\n",
      "  --valid-subset VALID_SUBSET\n",
      "                        comma separated list of data subsets to use for\n",
      "                        validation (e.g. train, valid, test)\n",
      "  --validate-interval VALIDATE_INTERVAL\n",
      "                        validate every N epochs\n",
      "  --validate-interval-updates VALIDATE_INTERVAL_UPDATES\n",
      "                        validate every N updates\n",
      "  --validate-after-updates VALIDATE_AFTER_UPDATES\n",
      "                        dont validate until reaching this many updates\n",
      "  --fixed-validation-seed FIXED_VALIDATION_SEED\n",
      "                        specified random seed for validation\n",
      "  --disable-validation  disable validation\n",
      "  --max-tokens-valid MAX_TOKENS_VALID\n",
      "                        maximum number of tokens in a validation batch\n",
      "                        (defaults to --max-tokens)\n",
      "  --batch-size-valid BATCH_SIZE_VALID\n",
      "                        batch size of the validation batch (defaults to\n",
      "                        --batch-size)\n",
      "  --curriculum CURRICULUM\n",
      "                        don't shuffle batches for first N epochs\n",
      "  --gen-subset GEN_SUBSET\n",
      "                        data subset to generate (train, valid, test)\n",
      "  --num-shards NUM_SHARDS\n",
      "                        shard generation over N shards\n",
      "  --shard-id SHARD_ID   id of the shard to generate (id < num_shards)\n",
      "\n",
      "distributed_training:\n",
      "  --distributed-world-size DISTRIBUTED_WORLD_SIZE\n",
      "                        total number of GPUs across all nodes (default: all\n",
      "                        visible GPUs)\n",
      "  --distributed-rank DISTRIBUTED_RANK\n",
      "                        rank of the current worker\n",
      "  --distributed-backend DISTRIBUTED_BACKEND\n",
      "                        distributed backend\n",
      "  --distributed-init-method DISTRIBUTED_INIT_METHOD\n",
      "                        typically tcp://hostname:port that will be used to\n",
      "                        establish initial connetion\n",
      "  --distributed-port DISTRIBUTED_PORT\n",
      "                        port number (not required if using --distributed-init-\n",
      "                        method)\n",
      "  --device-id DEVICE_ID, --local_rank DEVICE_ID\n",
      "                        which GPU to use (usually configured automatically)\n",
      "  --distributed-no-spawn\n",
      "                        do not spawn multiple processes even if multiple GPUs\n",
      "                        are visible\n",
      "  --ddp-backend {c10d,no_c10d}\n",
      "                        DistributedDataParallel backend\n",
      "  --bucket-cap-mb BUCKET_CAP_MB\n",
      "                        bucket size for reduction\n",
      "  --fix-batches-to-gpus\n",
      "                        don't shuffle batches between GPUs; this reduces\n",
      "                        overall randomness and may affect precision but avoids\n",
      "                        the cost of re-reading the data\n",
      "  --find-unused-parameters\n",
      "                        disable unused parameter detection (not applicable to\n",
      "                        no_c10d ddp-backend\n",
      "  --fast-stat-sync      [deprecated] this is now defined per Criterion\n",
      "  --broadcast-buffers   Copy non-trainable parameters between GPUs, such as\n",
      "                        batchnorm population statistics\n",
      "  --distributed-wrapper {DDP,SlowMo}\n",
      "                        DistributedDataParallel backend\n",
      "  --slowmo-momentum SLOWMO_MOMENTUM\n",
      "                        SlowMo momentum term; by default use 0.0 for 16 GPUs,\n",
      "                        0.2 for 32 GPUs; 0.5 for 64 GPUs, 0.6 for > 64 GPUs\n",
      "  --slowmo-algorithm SLOWMO_ALGORITHM\n",
      "                        whether to use LocalSGD or SGP\n",
      "  --localsgd-frequency LOCALSGD_FREQUENCY\n",
      "                        Local SGD allreduce frequency\n",
      "  --nprocs-per-node NPROCS_PER_NODE\n",
      "                        number of GPUs in each node. An allreduce operation\n",
      "                        across GPUs in a node is very fast. Hence, we do\n",
      "                        allreduce across GPUs in a node, and gossip across\n",
      "                        different nodes\n",
      "  --pipeline-model-parallel\n",
      "                        if set, use pipeline model parallelism across GPUs\n",
      "  --pipeline-balance PIPELINE_BALANCE\n",
      "                        partition the model into N_K pieces, where each piece\n",
      "                        contains N_i layers. The sum(args.pipeline_balance)\n",
      "                        should equal the total number of layers in the model\n",
      "  --pipeline-devices PIPELINE_DEVICES\n",
      "                        a list of device indices indicating which device to\n",
      "                        place each of the N_K partitions. The length of this\n",
      "                        list should equal the length of the --pipeline-balance\n",
      "                        argument\n",
      "  --pipeline-chunks PIPELINE_CHUNKS\n",
      "                        microbatch count for pipeline model parallelism\n",
      "  --pipeline-encoder-balance PIPELINE_ENCODER_BALANCE\n",
      "                        partition the pipeline parallel encoder into N_K\n",
      "                        pieces, where each piece contains N_i layers. The\n",
      "                        sum(args.pipeline_encoder_balance) should equal the\n",
      "                        total number of encoder layers in the model\n",
      "  --pipeline-encoder-devices PIPELINE_ENCODER_DEVICES\n",
      "                        a list of device indices indicating which device to\n",
      "                        place each of the N_K partitions. The length of this\n",
      "                        list should equal the length of the --pipeline-\n",
      "                        encoder-balance argument\n",
      "  --pipeline-decoder-balance PIPELINE_DECODER_BALANCE\n",
      "                        partition the pipeline parallel decoder into N_K\n",
      "                        pieces, where each piece contains N_i layers. The\n",
      "                        sum(args.pipeline_decoder_balance) should equal the\n",
      "                        total number of decoder layers in the model\n",
      "  --pipeline-decoder-devices PIPELINE_DECODER_DEVICES\n",
      "                        a list of device indices indicating which device to\n",
      "                        place each of the N_K partitions. The length of this\n",
      "                        list should equal the length of the --pipeline-\n",
      "                        decoder-balance argument\n",
      "  --pipeline-checkpoint {always,never,except_last}\n",
      "                        checkpointing mode for pipeline model parallelism\n",
      "  --zero-sharding {none,os}\n",
      "                        ZeRO sharding\n",
      "\n",
      "Model configuration:\n",
      "  --arch ARCH, -a ARCH  model architecture\n",
      "\n",
      "optimization:\n",
      "  --max-epoch MAX_EPOCH\n",
      "                        force stop training at specified epoch\n",
      "  --max-update MAX_UPDATE\n",
      "                        force stop training at specified update\n",
      "  --stop-time-hours STOP_TIME_HOURS\n",
      "                        force stop training after specified cumulative time\n",
      "                        (if >0)\n",
      "  --clip-norm CLIP_NORM\n",
      "                        clip threshold of gradients\n",
      "  --sentence-avg        normalize gradients by the number of sentences in a\n",
      "                        batch (default is to normalize by number of tokens)\n",
      "  --update-freq UPDATE_FREQ\n",
      "                        update parameters every N_i batches, when in epoch i\n",
      "  --lr LR               learning rate for the first N epochs; all epochs >N\n",
      "                        using LR_N (note: this may be interpreted differently\n",
      "                        depending on --lr-scheduler)\n",
      "  --min-lr MIN_LR       stop training when the learning rate reaches this\n",
      "                        minimum\n",
      "  --use-bmuf            specify global optimizer for syncing models on\n",
      "                        different GPUs/shards\n",
      "\n",
      "checkpoint:\n",
      "  --save-dir SAVE_DIR   path to save checkpoints\n",
      "  --restore-file RESTORE_FILE\n",
      "                        filename from which to load checkpoint (default:\n",
      "                        <save-dir>/checkpoint_last.pt\n",
      "  --finetune-from-model FINETUNE_FROM_MODEL\n",
      "                        finetune from a pretrained model; note that meters and\n",
      "                        lr scheduler will be reset\n",
      "  --reset-dataloader    if set, does not reload dataloader state from the\n",
      "                        checkpoint\n",
      "  --reset-lr-scheduler  if set, does not load lr scheduler state from the\n",
      "                        checkpoint\n",
      "  --reset-meters        if set, does not load meters from the checkpoint\n",
      "  --reset-optimizer     if set, does not load optimizer state from the\n",
      "                        checkpoint\n",
      "  --optimizer-overrides OPTIMIZER_OVERRIDES\n",
      "                        a dictionary used to override optimizer args when\n",
      "                        loading a checkpoint\n",
      "  --save-interval SAVE_INTERVAL\n",
      "                        save a checkpoint every N epochs\n",
      "  --save-interval-updates SAVE_INTERVAL_UPDATES\n",
      "                        save a checkpoint (and validate) every N updates\n",
      "  --keep-interval-updates KEEP_INTERVAL_UPDATES\n",
      "                        keep the last N checkpoints saved with --save-\n",
      "                        interval-updates\n",
      "  --keep-last-epochs KEEP_LAST_EPOCHS\n",
      "                        keep last N epoch checkpoints\n",
      "  --keep-best-checkpoints KEEP_BEST_CHECKPOINTS\n",
      "                        keep best N checkpoints based on scores\n",
      "  --no-save             don't save models or checkpoints\n",
      "  --no-epoch-checkpoints\n",
      "                        only store last and best checkpoints\n",
      "  --no-last-checkpoints\n",
      "                        don't store last checkpoints\n",
      "  --no-save-optimizer-state\n",
      "                        don't save optimizer-state as part of checkpoint\n",
      "  --best-checkpoint-metric BEST_CHECKPOINT_METRIC\n",
      "                        metric to use for saving \"best\" checkpoints\n",
      "  --maximize-best-checkpoint-metric\n",
      "                        select the largest metric value for saving \"best\"\n",
      "                        checkpoints\n",
      "  --patience PATIENCE   early stop training if valid performance doesn't\n",
      "                        improve for N consecutive validation runs; note that\n",
      "                        this is influenced by --validate-interval\n"
     ]
    }
   ],
   "source": [
    "! fairseq-train --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6245e739-3106-4a9f-8994-1a7199951349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from biophi.humanization.methods.sapiens.roberta import RoBERTa, seq2tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "60cffd4d-1f54-4686-a3f0-e03438fb02a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = RoBERTa.load(\n",
    "    path.join(DATA_DIR, \"models/fairseq\"),\n",
    "    'checkpoint_best.pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e5f4ea-3dea-4950-a0a9-47fa0bd37b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = seq2tokens(\"ASDFGHKLPIYTRE\", roberta.interface.task.target_dictionary, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f47f5f9-38eb-460a-b4ad-c8c2a5f9b106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  4, 19,  6,  8,  9, 10, 12, 13, 16, 11, 23, 20, 18,  7,  2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "096ba083-6315-4190-8cb9-e3c7e6c83cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = roberta.interface.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "532e5edf-40fe-4c60-9cd2-18d12d7c0d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (di-pred): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (out_proj): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classification_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bf62772-c745-425c-bd14-7d9c6c1195aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6514, -0.7367]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta.interface.predict(\"sentence_classification_head\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8945a62d-18b9-4099-b0d4-8a14c6ee90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_fn = lambda label: roberta.interface.task.label_dictionary.string(\n",
    "    [label + roberta.interface.task.label_dictionary.nspecial]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcb41b6b-44e1-40a3-8c79-f7923f2a7785",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = label_fn(roberta.interface.predict('sentence_classification_head', tokens).argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "004ad424-2750-4000-8551-b89862c4e973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ebdded1-2185-4339-8dc1-9a74f5980648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = chen_test.iloc[0][\"heavy\"]\n",
    "chen_test.iloc[0][\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3a205b5-ac2a-4fcf-b2e6-14c28c4b8d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens1 = seq2tokens(seq, roberta.interface.task.target_dictionary, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd9fd4ee-51a9-4997-ba68-bb905ca89346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = label_fn(roberta.interface.predict('di-pred', tokens1).argmax().item())\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5af1a4c7-5e23-4126-b654-0be86850ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(seq):\n",
    "    tokens = seq2tokens(seq, roberta.interface.task.target_dictionary, True)\n",
    "    return label_fn(roberta.interface.predict('di-pred', tokens).argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1034bf98-eb81-48f8-a27a-1d62b3ecffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chen_test[\"predictions\"] = chen_test[\"heavy\"].apply(get_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e7b0d6e3-9c80-4ffb-950f-179fd772dbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>Y</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>6obd</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFPFSNYWMNWVRQAPGKGLE...</td>\n",
       "      <td>DIVMTQTPLSLSVTPGQPASISCKSSQSLLYSNGKTYLNWVLQKPG...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>1sm3</td>\n",
       "      <td>QVQLQESGGGLVQPGGSMKLSCVASGFTFSNYWMNWVRQSPEKGLE...</td>\n",
       "      <td>DIVVTQESALTTSPGETVTLTCRSSTGAVTTSNYANWVQEKPDHLF...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>5a2i</td>\n",
       "      <td>QVQLQESGGGLVQPGGSMKLSCVASGFTFSNYWMNWVRQSPEKGLE...</td>\n",
       "      <td>DIVVTQESALTTSPGETVTLTCRSSTGAVTTSNYANWVQEKPDHLF...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>4f33</td>\n",
       "      <td>EVQLQQSGPELEKPGASVKISCKASGYSFTGYTMNWVKQSHGKSLE...</td>\n",
       "      <td>DIELTQSPAIMSASPGEKVTMTCSASSSVSYMHWYQQKSGTSPKRW...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>1q1j</td>\n",
       "      <td>EVQLVESGGGLVKPGGSLRLTCVASGFTFSDVWLNWVRQAPGKGLE...</td>\n",
       "      <td>QSVLTQPPSVSAAPGQKVTISCSGSSSNIGNNYVLWYQQFPGTAPK...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Antibody_ID                                              heavy  \\\n",
       "2372        6obd  EVQLVESGGGLVQPGGSLRLSCAASGFPFSNYWMNWVRQAPGKGLE...   \n",
       "359         1sm3  QVQLQESGGGLVQPGGSMKLSCVASGFTFSNYWMNWVRQSPEKGLE...   \n",
       "1539        5a2i  QVQLQESGGGLVQPGGSMKLSCVASGFTFSNYWMNWVRQSPEKGLE...   \n",
       "1112        4f33  EVQLQQSGPELEKPGASVKISCKASGYSFTGYTMNWVKQSHGKSLE...   \n",
       "314         1q1j  EVQLVESGGGLVKPGGSLRLTCVASGFTFSDVWLNWVRQAPGKGLE...   \n",
       "\n",
       "                                                  light  Y predictions  \n",
       "2372  DIVMTQTPLSLSVTPGQPASISCKSSQSLLYSNGKTYLNWVLQKPG...  0           0  \n",
       "359   DIVVTQESALTTSPGETVTLTCRSSTGAVTTSNYANWVQEKPDHLF...  0           0  \n",
       "1539  DIVVTQESALTTSPGETVTLTCRSSTGAVTTSNYANWVQEKPDHLF...  0           0  \n",
       "1112  DIELTQSPAIMSASPGEKVTMTCSASSSVSYMHWYQQKSGTSPKRW...  1           0  \n",
       "314   QSVLTQPPSVSAAPGQKVTISCSGSSSNIGNNYVLWYQQFPGTAPK...  0           0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6bc5b245-f328-416b-a4bb-f59fee518282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    119\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chen_test[\"predictions\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ee92e-f82d-4e39-a5af-f0c9875175a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
