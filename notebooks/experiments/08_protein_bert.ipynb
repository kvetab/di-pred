{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff8a9d94-4216-4b46-92e0-67298b77bf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, \\\n",
    "finetune, evaluate_by_len\n",
    "from proteinbert.finetuning import encode_train_and_valid_sets, encode_dataset\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
    "from os import path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d2ed9b0-3023-4f0c-b93e-3330a86f35ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4798e75-9168-4aa2-b76c-bf37d692efed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33c6481c-b3ce-47c3-86c4-5258a9553fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5db7bda-d751-4876-916f-23e824fd7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_TYPE = OutputType(False, 'binary')\n",
    "UNIQUE_LABELS = [0, 1]\n",
    "OUTPUT_SPEC = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78d4d0ff-52b0-4152-9447-182709e45923",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_generator, input_encoder = load_pretrained_model(\"../../data/protein_bert/\", \"epoch_92400_sample_23500000.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59ffc4b8-405d-4244-a4bc-f0ab0190c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function = \\\n",
    "        get_model_with_hidden_layers_as_outputs, dropout_rate = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbdaf9de-0881-43dc-8d2e-317db6302948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkvetab\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/kvetab/ManualTraining1/runs/21fljj1u\" target=\"_blank\">fluent-wood-3</a></strong> to <a href=\"https://wandb.ai/kvetab/ManualTraining1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/kvetab/ManualTraining1/runs/21fljj1u?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f1d9292d390>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=f\"ManualTraining1\", entity=\"kvetab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1743c445-302b-4f4e-9325-a6ef4fb17aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antibody_ID</th>\n",
       "      <th>heavy</th>\n",
       "      <th>light</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>6aod</td>\n",
       "      <td>EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...</td>\n",
       "      <td>DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>4yny</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>5xcv</td>\n",
       "      <td>EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...</td>\n",
       "      <td>QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>6and</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2xqy</td>\n",
       "      <td>QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...</td>\n",
       "      <td>DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Antibody_ID                                              heavy  \\\n",
       "2073        6aod  EVQLVQSGAEVKKPGASVKVSCKASGYTFTGYYMHWVRQAPGQGLE...   \n",
       "1517        4yny  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2025        5xcv  EVQLVESGGGLVQPGRSLKLSCAASGFTFSNYGMAWVRQTPTKGLE...   \n",
       "2070        6and  EVQLVESGGGLVQPGGSLRLSCAASGYEFSRSWMNWVRQAPGKGLE...   \n",
       "666         2xqy  QVQLQQPGAELVKPGASVKMSCKASGYSFTSYWMNWVKQRPGRGLE...   \n",
       "\n",
       "                                                  light  Y  \n",
       "2073  DIVMTKSPSSLSASVGDRVTITCRASQGIRNDLGWYQQKPGKAPKR...  0  \n",
       "1517  EFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2025  QFVLTQPNSVSTNLGSTVKLSCKRSTGNIGSNYVNWYQQHEGRSPT...  1  \n",
       "2070  DIQMTQSPSSLSASVGDRVTITCRSSQSIVHSVGNTFLEWYQQKPG...  1  \n",
       "666   DIVLTQSPASLALSLGQRATISCRASKSVSTSGYSYMYWYQQKPGQ...  0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_train_data.csv\"), index_col=0)\n",
    "valid_data = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_valid_data.csv\"), index_col=0)\n",
    "test_data = pd.read_csv(path.join(DATA_DIR, \"chen/deduplicated/chen_test_data.csv\"), index_col=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c09b813-ffc8-48f7-99a5-586c76ac33f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"seq\"] = train_data[\"heavy\"] + train_data[\"light\"]\n",
    "valid_data[\"seq\"] = valid_data[\"heavy\"] + valid_data[\"light\"]\n",
    "test_data[\"seq\"] = test_data[\"heavy\"] + test_data[\"light\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fe63df3-96bf-40ed-9065-216a8e67b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(patience = 1, factor = 0.25, min_lr = 1e-07, verbose = 1),\n",
    "    keras.callbacks.EarlyStopping(patience = 3, restore_best_weights = True),\n",
    "    WandbCallback()\n",
    "]\n",
    "seq_len = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72bd9e53-8469-410c-9d42-6daa3811fc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022_02_02-18:01:15] Training set: Filtered out 0 of 1338 (0.0%) records of lengths exceeding 510.\n",
      "[2022_02_02-18:01:15] Validation set: Filtered out 0 of 120 (0.0%) records of lengths exceeding 510.\n"
     ]
    }
   ],
   "source": [
    "encoded_train_set, encoded_valid_set = encode_train_and_valid_sets(\n",
    "    train_data['seq'], \n",
    "    train_data['Y'], \n",
    "    valid_data['seq'], \n",
    "    valid_data['Y'], \n",
    "    input_encoder, \n",
    "    OUTPUT_SPEC, \n",
    "    seq_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f7e7d4f-4ca7-47fd-ad0f-cedd9de6c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, train_sample_weigths = encoded_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d14dac3-1751-4172-96e6-7636bb9ad8c3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-02 18:01:32.480937: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-02 18:01:33.190773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9656 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:41:00.0, compute capability: 7.5\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "model = model_generator.create_model(seq_len=512, freeze_pretrained_layers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faeffd00-5c33-40ed-ad02-1c71cb739527",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 50\n",
    "batch_size = 128\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd45319f-0dd8-489a-b105-7163d1679298",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "      \"learning_rate\": learning_rate,\n",
    "      \"epochs\": epoch_num,\n",
    "      \"batch_size\": batch_size\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c444b8d-daf7-4e24-a86c-c97f47b80d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr = learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38f4bd33-b1b1-4e42-9cb6-8f2a597ef4f6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-02 18:01:46.045244: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-02 18:01:55.040045: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 7605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 13s 311ms/step - loss: 0.7263 - val_loss: 0.5052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model, h5py returned error: Layer GlobalAttention has arguments in `__init__` and therefore must override `get_config`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.4989 - val_loss: 0.4883\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4667 - val_loss: 0.4714\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.4502 - val_loss: 0.4925\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4400 - val_loss: 0.4652\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4316 - val_loss: 0.4543\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4273 - val_loss: 0.4563\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 1s 116ms/step - loss: 0.4329 - val_loss: 0.4504\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4257 - val_loss: 0.4497\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4237 - val_loss: 0.4500\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4255 - val_loss: 0.4491\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4256 - val_loss: 0.4491\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.4241 - val_loss: 0.4490\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.4212 - val_loss: 0.4488\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4275 - val_loss: 0.4487\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.4246 - val_loss: 0.4487\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4260 - val_loss: 0.4487\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 2.441406195430318e-06.\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.4197 - val_loss: 0.4487\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.103515488575795e-07.\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.4264 - val_loss: 0.4487\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.5258788721439487e-07.\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.4225 - val_loss: 0.4487\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.4267 - val_loss: 0.4487\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4261 - val_loss: 0.4487\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.4265 - val_loss: 0.4487\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 1s 116ms/step - loss: 0.4270 - val_loss: 0.4487\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.4184 - val_loss: 0.4487\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.4232 - val_loss: 0.4487\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.4264 - val_loss: 0.4487\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4254 - val_loss: 0.4487\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4266 - val_loss: 0.4487\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4266 - val_loss: 0.4487\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.4231 - val_loss: 0.4487\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.4262 - val_loss: 0.4487\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.4223 - val_loss: 0.4487\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 1s 112ms/step - loss: 0.4221 - val_loss: 0.4487\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.4192 - val_loss: 0.4487\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4269 - val_loss: 0.4487\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.4238 - val_loss: 0.4487\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.4192 - val_loss: 0.4487\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 1s 107ms/step - loss: 0.4254 - val_loss: 0.4487\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.4215 - val_loss: 0.4487\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 1s 106ms/step - loss: 0.4227 - val_loss: 0.4487\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4214 - val_loss: 0.4487\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4191 - val_loss: 0.4487\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4189 - val_loss: 0.4487\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.4269 - val_loss: 0.4487\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.4172 - val_loss: 0.4487\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 1s 117ms/step - loss: 0.4244 - val_loss: 0.4487\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 1s 113ms/step - loss: 0.4228 - val_loss: 0.4487\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 1s 116ms/step - loss: 0.4226 - val_loss: 0.4487\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 1s 109ms/step - loss: 0.4240 - val_loss: 0.4487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1d90084890>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=train_X,\n",
    "    y=train_Y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epoch_num,\n",
    "    callbacks=training_callbacks,\n",
    "    validation_data=encoded_valid_set\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1810cba2-f7dd-45f9-8598-4504da3f87f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_generator.update_state(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "424c836b-2244-4e5b-8c13-447856c9d39c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs:\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a28a6b4-2cfe-4604-bde0-0b293d2378aa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f72b9b14-fb85-43c9-9a23-c896a5737655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_arrays(arrays, slicing):\n",
    "    if isinstance(arrays, list) or isinstance(arrays, tuple):\n",
    "        return [array[slicing] for array in arrays]\n",
    "    else:\n",
    "        return arrays[slicing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2739434b-9f6e-43aa-987a-4a2e40fa109a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022_02_02-18:58:48] Incompatible number of optimizer weights - will not initialize them.\n"
     ]
    }
   ],
   "source": [
    "model_generator.dummy_epoch = (slice_arrays(train_X, slice(0, 1)), slice_arrays(train_Y, slice(0, 1)))\n",
    "model = model_generator.create_model(seq_len=512, freeze_pretrained_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91144bea-c8f0-4998-8682-4ca360f98da2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2vywde5d) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 42797... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▅▄▄▃▂▂▁▂▃▁▂▃▁▃▂▁▂</td></tr><tr><td>lr</td><td>█████▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▅▄▅▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>19</td></tr><tr><td>best_val_loss</td><td>0.43132</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.40285</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>val_loss</td><td>0.43132</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">icy-brook-4</strong>: <a href=\"https://wandb.ai/kvetab/ManualTraining1/runs/2vywde5d\" target=\"_blank\">https://wandb.ai/kvetab/ManualTraining1/runs/2vywde5d</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220202_185614-2vywde5d/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2vywde5d). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/kvetab/ManualTraining1/runs/31nb54rj\" target=\"_blank\">smooth-water-5</a></strong> to <a href=\"https://wandb.ai/kvetab/ManualTraining1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=f\"ManualTraining1\", entity=\"kvetab\")\n",
    "epoch_num = 50\n",
    "batch_size = 128\n",
    "learning_rate = 5e-5\n",
    "wandb.config = {\n",
    "      \"learning_rate\": learning_rate,\n",
    "      \"epochs\": epoch_num,\n",
    "      \"batch_size\": batch_size\n",
    "    }\n",
    "model.optimizer.lr = learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "830bee4d-8566-4b85-bcd9-2cb7dd4d7179",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 6/11 [===============>..............] - ETA: 1s - loss: 0.4310WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1155s vs `on_train_batch_end` time: 0.1468s). Check your callbacks.\n",
      "11/11 [==============================] - 11s 441ms/step - loss: 0.4292 - val_loss: 0.4466\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.4235 - val_loss: 0.4458\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 0.4188 - val_loss: 0.4416\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.4115 - val_loss: 0.4369\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 0.4139 - val_loss: 0.4350\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.4038 - val_loss: 0.4331\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 0.3969 - val_loss: 0.4272\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.3958 - val_loss: 0.4288\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.4046 - val_loss: 0.4255\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.3912 - val_loss: 0.4243\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 0.3846 - val_loss: 0.4242\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.3943 - val_loss: 0.4234\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.3849 - val_loss: 0.4227\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.3888 - val_loss: 0.4228\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 0.3873 - val_loss: 0.4221\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.3826 - val_loss: 0.4220\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.3837 - val_loss: 0.4218\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.3816 - val_loss: 0.4217\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 0.3836 - val_loss: 0.4215\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.3858 - val_loss: 0.4213\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.3755 - val_loss: 0.4213\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.3759 - val_loss: 0.4212\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.3813 - val_loss: 0.4212\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.3827 - val_loss: 0.4212\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.3742 - val_loss: 0.4211\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.3862 - val_loss: 0.4211\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.3863 - val_loss: 0.4211\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 0.3777 - val_loss: 0.4211\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.3741 - val_loss: 0.4211\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 3s 263ms/step - loss: 0.3808 - val_loss: 0.4211\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.3760 - val_loss: 0.4211\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.3775 - val_loss: 0.4211\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.3829 - val_loss: 0.4211\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.3700 - val_loss: 0.4211\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.3742 - val_loss: 0.4211\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 3s 261ms/step - loss: 0.3823 - val_loss: 0.4211\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.3757 - val_loss: 0.4211\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 0.3821 - val_loss: 0.4211\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.3766 - val_loss: 0.4211\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.3714 - val_loss: 0.4211\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.3738 - val_loss: 0.4211\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.3759 - val_loss: 0.4211\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.3774 - val_loss: 0.4211\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 3s 261ms/step - loss: 0.3821 - val_loss: 0.4210\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.3772 - val_loss: 0.4210\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.3847 - val_loss: 0.4210\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.3775 - val_loss: 0.4210\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 0.3774 - val_loss: 0.4210\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.3780 - val_loss: 0.4210\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.3815 - val_loss: 0.4210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1a592295d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=train_X,\n",
    "    y=train_Y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epoch_num,\n",
    "    callbacks=training_callbacks,\n",
    "    validation_data=encoded_valid_set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "228cdb72-fd47-48ed-8217-b4d09372c7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-02 19:03:55.781999: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) input-seq, input-annotations with unsupported characters which will be renamed to input_seq, input_annotations in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../data/protein_bert/manual_training_2_2022_02_02.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../data/protein_bert/manual_training_2_2022_02_02.pkl/assets\n",
      "/home/brazdilv/.conda/envs/ml/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save(path.join(DATA_DIR, \"protein_bert/manual_training_2_2022_02_02.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b547d4cf-4157-41de-b418-2ec04e47b1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022_02_02-19:04:06] Test set: Filtered out 0 of 119 (0.0%) records of lengths exceeding 510.\n"
     ]
    }
   ],
   "source": [
    "encoded_test_set = encode_dataset(test_data[\"seq\"], test_data[\"Y\"], input_encoder, OUTPUT_SPEC, seq_len = seq_len, needs_filtering = True, \\\n",
    "            dataset_name = 'Test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5caf6658-3018-4dd4-812c-4772aefc15bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "test_X, test_Y, test_sample_weigths = encoded_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c75ee599-fb86-4a25-9275-aaced56d2527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5161290322580645"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_X, batch_size=32)\n",
    "y_pred_classes = (y_pred >= 0.5)\n",
    "f1_score(test_Y, y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b6d0005-1339-4b94-b59e-346aa7e28288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1\n",
       "0  96  0\n",
       "1  15  8"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(test_Y, y_pred_classes, labels=[0, 1]), index=[0, 1], columns=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fdb4ff-15e5-4820-b07c-3806e181389b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
